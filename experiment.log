2022-06-06 20:03:19,877 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 20:03:19,879 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 20:03:19,880 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 20:03:19,880 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 20:03:19,880 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 20:03:20,796 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (2.3452) | Acc: (6.25%) (4/64) | Learning rate: (0.0001)
2022-06-06 20:03:22,576 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (2.2820) | Acc: (14.06%) (99/704) | Learning rate: (0.0001)
2022-06-06 20:03:24,356 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (2.2363) | Acc: (18.30%) (246/1344) | Learning rate: (0.0001)
2022-06-06 20:03:26,141 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (2.1854) | Acc: (24.95%) (495/1984) | Learning rate: (0.0001)
2022-06-06 20:03:27,926 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (2.1289) | Acc: (30.87%) (810/2624) | Learning rate: (0.0001)
2022-06-06 20:03:29,711 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 50 |  Loss: (2.0565) | Acc: (37.47%) (1223/3264) | Learning rate: (0.0001)
2022-06-06 20:03:31,498 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 60 |  Loss: (1.9725) | Acc: (42.78%) (1670/3904) | Learning rate: (0.0001)
2022-06-06 20:03:33,286 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 70 |  Loss: (1.8795) | Acc: (47.21%) (2145/4544) | Learning rate: (0.0001)
2022-06-06 20:03:35,078 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 80 |  Loss: (1.7779) | Acc: (51.06%) (2647/5184) | Learning rate: (0.0001)
2022-06-06 20:03:36,867 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 90 |  Loss: (1.6791) | Acc: (54.19%) (3156/5824) | Learning rate: (0.0001)
2022-06-06 20:03:38,657 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 100 |  Loss: (1.5847) | Acc: (57.12%) (3692/6464) | Learning rate: (0.0001)
2022-06-06 20:03:40,450 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 110 |  Loss: (1.5003) | Acc: (59.60%) (4234/7104) | Learning rate: (0.0001)
2022-06-06 20:03:42,241 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 120 |  Loss: (1.4199) | Acc: (61.88%) (4792/7744) | Learning rate: (0.0001)
2022-06-06 20:03:44,035 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 130 |  Loss: (1.3516) | Acc: (63.66%) (5337/8384) | Learning rate: (0.0001)
2022-06-06 20:03:45,827 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 140 |  Loss: (1.2911) | Acc: (65.33%) (5895/9024) | Learning rate: (0.0001)
2022-06-06 20:03:47,620 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 150 |  Loss: (1.2393) | Acc: (66.68%) (6444/9664) | Learning rate: (0.0001)
2022-06-06 20:03:49,413 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 160 |  Loss: (1.1859) | Acc: (68.12%) (7019/10304) | Learning rate: (0.0001)
2022-06-06 20:03:51,206 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 170 |  Loss: (1.1384) | Acc: (69.29%) (7583/10944) | Learning rate: (0.0001)
2022-06-06 20:03:53,003 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 180 |  Loss: (1.0957) | Acc: (70.41%) (8156/11584) | Learning rate: (0.0001)
2022-06-06 20:03:54,797 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 190 |  Loss: (1.0561) | Acc: (71.44%) (8733/12224) | Learning rate: (0.0001)
2022-06-06 20:03:56,591 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 200 |  Loss: (1.0193) | Acc: (72.44%) (9319/12864) | Learning rate: (0.0001)
2022-06-06 20:03:58,386 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 210 |  Loss: (0.9830) | Acc: (73.39%) (9910/13504) | Learning rate: (0.0001)
2022-06-06 20:04:00,179 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 220 |  Loss: (0.9537) | Acc: (74.10%) (10481/14144) | Learning rate: (0.0001)
2022-06-06 20:04:01,977 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 230 |  Loss: (0.9267) | Acc: (74.74%) (11050/14784) | Learning rate: (0.0001)
2022-06-06 20:04:03,771 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 240 |  Loss: (0.8987) | Acc: (75.50%) (11645/15424) | Learning rate: (0.0001)
2022-06-06 20:04:05,565 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 250 |  Loss: (0.8745) | Acc: (76.15%) (12232/16064) | Learning rate: (0.0001)
2022-06-06 20:04:07,362 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 260 |  Loss: (0.8513) | Acc: (76.74%) (12819/16704) | Learning rate: (0.0001)
2022-06-06 20:04:09,158 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 270 |  Loss: (0.8293) | Acc: (77.29%) (13405/17344) | Learning rate: (0.0001)
2022-06-06 20:04:10,954 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 280 |  Loss: (0.8086) | Acc: (77.80%) (13991/17984) | Learning rate: (0.0001)
2022-06-06 20:04:12,750 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 290 |  Loss: (0.7890) | Acc: (78.31%) (14584/18624) | Learning rate: (0.0001)
2022-06-06 20:04:14,543 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 300 |  Loss: (0.7703) | Acc: (78.80%) (15180/19264) | Learning rate: (0.0001)
2022-06-06 20:04:16,340 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 310 |  Loss: (0.7539) | Acc: (79.18%) (15760/19904) | Learning rate: (0.0001)
2022-06-06 20:04:18,133 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 320 |  Loss: (0.7380) | Acc: (79.57%) (16346/20544) | Learning rate: (0.0001)
2022-06-06 20:04:19,930 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 330 |  Loss: (0.7216) | Acc: (80.02%) (16951/21184) | Learning rate: (0.0001)
2022-06-06 20:04:21,723 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 340 |  Loss: (0.7072) | Acc: (80.41%) (17548/21824) | Learning rate: (0.0001)
2022-06-06 20:04:23,517 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 350 |  Loss: (0.6922) | Acc: (80.81%) (18154/22464) | Learning rate: (0.0001)
2022-06-06 20:04:25,315 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 360 |  Loss: (0.6793) | Acc: (81.15%) (18748/23104) | Learning rate: (0.0001)
2022-06-06 20:04:27,109 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 370 |  Loss: (0.6662) | Acc: (81.53%) (19358/23744) | Learning rate: (0.0001)
2022-06-06 20:04:28,908 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 380 |  Loss: (0.6542) | Acc: (81.82%) (19952/24384) | Learning rate: (0.0001)
2022-06-06 20:04:30,703 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 390 |  Loss: (0.6426) | Acc: (82.13%) (20552/25024) | Learning rate: (0.0001)
2022-06-06 20:04:32,499 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 400 |  Loss: (0.6317) | Acc: (82.43%) (21155/25664) | Learning rate: (0.0001)
2022-06-06 20:04:34,295 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 410 |  Loss: (0.6212) | Acc: (82.70%) (21754/26304) | Learning rate: (0.0001)
2022-06-06 20:04:36,091 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 420 |  Loss: (0.6117) | Acc: (82.93%) (22344/26944) | Learning rate: (0.0001)
2022-06-06 20:04:37,890 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 430 |  Loss: (0.6039) | Acc: (83.13%) (22931/27584) | Learning rate: (0.0001)
2022-06-06 20:04:39,686 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 440 |  Loss: (0.5950) | Acc: (83.35%) (23526/28224) | Learning rate: (0.0001)
2022-06-06 20:04:41,482 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 450 |  Loss: (0.5870) | Acc: (83.56%) (24119/28864) | Learning rate: (0.0001)
2022-06-06 20:04:43,278 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 460 |  Loss: (0.5787) | Acc: (83.78%) (24719/29504) | Learning rate: (0.0001)
2022-06-06 20:04:45,073 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 470 |  Loss: (0.5713) | Acc: (83.99%) (25319/30144) | Learning rate: (0.0001)
2022-06-06 20:04:46,871 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 480 |  Loss: (0.5637) | Acc: (84.18%) (25914/30784) | Learning rate: (0.0001)
2022-06-06 20:04:48,669 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 490 |  Loss: (0.5563) | Acc: (84.36%) (26510/31424) | Learning rate: (0.0001)
2022-06-06 20:04:50,468 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 500 |  Loss: (0.5489) | Acc: (84.55%) (27110/32064) | Learning rate: (0.0001)
2022-06-06 20:04:52,267 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 510 |  Loss: (0.5418) | Acc: (84.74%) (27715/32704) | Learning rate: (0.0001)
2022-06-06 20:04:54,062 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 520 |  Loss: (0.5345) | Acc: (84.94%) (28323/33344) | Learning rate: (0.0001)
2022-06-06 20:04:55,861 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 530 |  Loss: (0.5277) | Acc: (85.11%) (28925/33984) | Learning rate: (0.0001)
2022-06-06 20:04:57,659 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 540 |  Loss: (0.5214) | Acc: (85.29%) (29530/34624) | Learning rate: (0.0001)
2022-06-06 20:05:05,094 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 20:05:05,096 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 20:05:05,097 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 20:05:05,097 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 20:05:05,097 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 20:05:06,531 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (2.2881) | Acc: (11.72%) (15/128) | Learning rate: (0.0001)
2022-06-06 20:05:10,087 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (2.2528) | Acc: (15.77%) (222/1408) | Learning rate: (0.0001)
2022-06-06 20:05:30,006 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 20:05:30,008 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 20:05:30,009 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 20:05:30,009 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 20:05:30,009 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 20:05:30,944 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (2.3335) | Acc: (14.06%) (9/64) | Learning rate: (0.0001)
2022-06-06 20:05:32,724 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (2.2694) | Acc: (15.34%) (108/704) | Learning rate: (0.0001)
2022-06-06 20:05:34,506 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (2.2227) | Acc: (22.02%) (296/1344) | Learning rate: (0.0001)
2022-06-06 20:05:36,289 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (2.1725) | Acc: (28.73%) (570/1984) | Learning rate: (0.0001)
2022-06-06 20:05:38,074 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (2.1075) | Acc: (35.14%) (922/2624) | Learning rate: (0.0001)
2022-06-06 20:05:39,860 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 50 |  Loss: (2.0344) | Acc: (40.96%) (1337/3264) | Learning rate: (0.0001)
2022-06-06 20:05:41,648 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 60 |  Loss: (1.9512) | Acc: (45.72%) (1785/3904) | Learning rate: (0.0001)
2022-06-06 20:05:43,434 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 70 |  Loss: (1.8572) | Acc: (50.13%) (2278/4544) | Learning rate: (0.0001)
2022-06-06 20:05:45,223 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 80 |  Loss: (1.7577) | Acc: (53.99%) (2799/5184) | Learning rate: (0.0001)
2022-06-06 20:05:47,012 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 90 |  Loss: (1.6613) | Acc: (56.94%) (3316/5824) | Learning rate: (0.0001)
2022-06-06 20:05:48,803 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 100 |  Loss: (1.5690) | Acc: (59.50%) (3846/6464) | Learning rate: (0.0001)
2022-06-06 20:05:50,595 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 110 |  Loss: (1.4832) | Acc: (61.77%) (4388/7104) | Learning rate: (0.0001)
2022-06-06 20:05:52,389 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 120 |  Loss: (1.4118) | Acc: (63.53%) (4920/7744) | Learning rate: (0.0001)
2022-06-06 20:05:54,181 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 130 |  Loss: (1.3426) | Acc: (65.26%) (5471/8384) | Learning rate: (0.0001)
2022-06-06 20:05:55,974 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 140 |  Loss: (1.2774) | Acc: (66.92%) (6039/9024) | Learning rate: (0.0001)
2022-06-06 20:05:57,767 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 150 |  Loss: (1.2223) | Acc: (68.31%) (6601/9664) | Learning rate: (0.0001)
2022-06-06 20:05:59,560 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 160 |  Loss: (1.1701) | Acc: (69.57%) (7169/10304) | Learning rate: (0.0001)
2022-06-06 20:06:01,353 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 170 |  Loss: (1.1269) | Acc: (70.56%) (7722/10944) | Learning rate: (0.0001)
2022-06-06 20:06:03,148 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 180 |  Loss: (1.0850) | Acc: (71.61%) (8295/11584) | Learning rate: (0.0001)
2022-06-06 20:06:04,941 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 190 |  Loss: (1.0478) | Acc: (72.49%) (8861/12224) | Learning rate: (0.0001)
2022-06-06 20:06:06,736 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 200 |  Loss: (1.0122) | Acc: (73.38%) (9440/12864) | Learning rate: (0.0001)
2022-06-06 20:06:08,531 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 210 |  Loss: (0.9808) | Acc: (74.21%) (10021/13504) | Learning rate: (0.0001)
2022-06-06 20:06:10,325 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 220 |  Loss: (0.9498) | Acc: (74.96%) (10603/14144) | Learning rate: (0.0001)
2022-06-06 20:06:12,120 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 230 |  Loss: (0.9214) | Acc: (75.68%) (11189/14784) | Learning rate: (0.0001)
2022-06-06 20:06:13,918 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 240 |  Loss: (0.8949) | Acc: (76.32%) (11772/15424) | Learning rate: (0.0001)
2022-06-06 20:06:15,713 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 250 |  Loss: (0.8707) | Acc: (76.94%) (12360/16064) | Learning rate: (0.0001)
2022-06-06 20:06:17,509 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 260 |  Loss: (0.8481) | Acc: (77.47%) (12940/16704) | Learning rate: (0.0001)
2022-06-06 20:06:19,304 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 270 |  Loss: (0.8273) | Acc: (78.00%) (13529/17344) | Learning rate: (0.0001)
2022-06-06 20:06:21,100 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 280 |  Loss: (0.8073) | Acc: (78.52%) (14121/17984) | Learning rate: (0.0001)
2022-06-06 20:06:22,897 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 290 |  Loss: (0.7888) | Acc: (79.01%) (14715/18624) | Learning rate: (0.0001)
2022-06-06 20:06:24,692 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 300 |  Loss: (0.7703) | Acc: (79.47%) (15309/19264) | Learning rate: (0.0001)
2022-06-06 20:06:26,489 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 310 |  Loss: (0.7528) | Acc: (79.90%) (15903/19904) | Learning rate: (0.0001)
2022-06-06 20:06:28,285 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 320 |  Loss: (0.7365) | Acc: (80.32%) (16501/20544) | Learning rate: (0.0001)
2022-06-06 20:06:30,081 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 330 |  Loss: (0.7200) | Acc: (80.72%) (17099/21184) | Learning rate: (0.0001)
2022-06-06 20:06:31,877 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 340 |  Loss: (0.7057) | Acc: (81.06%) (17690/21824) | Learning rate: (0.0001)
2022-06-06 20:06:33,673 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 350 |  Loss: (0.6928) | Acc: (81.40%) (18285/22464) | Learning rate: (0.0001)
2022-06-06 20:06:35,471 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 360 |  Loss: (0.6792) | Acc: (81.69%) (18874/23104) | Learning rate: (0.0001)
2022-06-06 20:06:37,269 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 370 |  Loss: (0.6678) | Acc: (82.00%) (19470/23744) | Learning rate: (0.0001)
2022-06-06 20:06:39,065 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 380 |  Loss: (0.6560) | Acc: (82.30%) (20067/24384) | Learning rate: (0.0001)
2022-06-06 20:06:40,863 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 390 |  Loss: (0.6441) | Acc: (82.61%) (20672/25024) | Learning rate: (0.0001)
2022-06-06 20:06:42,659 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 400 |  Loss: (0.6341) | Acc: (82.86%) (21264/25664) | Learning rate: (0.0001)
2022-06-06 20:06:44,457 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 410 |  Loss: (0.6234) | Acc: (83.12%) (21864/26304) | Learning rate: (0.0001)
2022-06-06 20:06:46,253 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 420 |  Loss: (0.6144) | Acc: (83.32%) (22451/26944) | Learning rate: (0.0001)
2022-06-06 20:06:48,049 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 430 |  Loss: (0.6053) | Acc: (83.56%) (23050/27584) | Learning rate: (0.0001)
2022-06-06 20:06:49,847 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 440 |  Loss: (0.5972) | Acc: (83.75%) (23637/28224) | Learning rate: (0.0001)
2022-06-06 20:06:51,645 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 450 |  Loss: (0.5891) | Acc: (83.96%) (24234/28864) | Learning rate: (0.0001)
2022-06-06 20:06:53,442 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 460 |  Loss: (0.5809) | Acc: (84.17%) (24834/29504) | Learning rate: (0.0001)
2022-06-06 20:06:55,240 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 470 |  Loss: (0.5733) | Acc: (84.34%) (25424/30144) | Learning rate: (0.0001)
2022-06-06 20:06:57,039 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 480 |  Loss: (0.5656) | Acc: (84.52%) (26019/30784) | Learning rate: (0.0001)
2022-06-06 20:06:58,836 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 490 |  Loss: (0.5578) | Acc: (84.73%) (26627/31424) | Learning rate: (0.0001)
2022-06-06 20:07:00,633 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 500 |  Loss: (0.5512) | Acc: (84.91%) (27224/32064) | Learning rate: (0.0001)
2022-06-06 20:07:02,431 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 510 |  Loss: (0.5437) | Acc: (85.08%) (27825/32704) | Learning rate: (0.0001)
2022-06-06 20:07:04,228 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 520 |  Loss: (0.5363) | Acc: (85.28%) (28435/33344) | Learning rate: (0.0001)
2022-06-06 20:07:06,025 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 530 |  Loss: (0.5299) | Acc: (85.44%) (29037/33984) | Learning rate: (0.0001)
2022-06-06 20:07:07,823 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 540 |  Loss: (0.5234) | Acc: (85.61%) (29642/34624) | Learning rate: (0.0001)
2022-06-06 20:07:09,621 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 550 |  Loss: (0.5172) | Acc: (85.77%) (30247/35264) | Learning rate: (0.0001)
2022-06-06 20:07:11,420 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 560 |  Loss: (0.5109) | Acc: (85.93%) (30851/35904) | Learning rate: (0.0001)
2022-06-06 20:07:13,218 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 570 |  Loss: (0.5050) | Acc: (86.09%) (31461/36544) | Learning rate: (0.0001)
2022-06-06 20:07:15,014 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 580 |  Loss: (0.4993) | Acc: (86.24%) (32067/37184) | Learning rate: (0.0001)
2022-06-06 20:07:16,814 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 590 |  Loss: (0.4940) | Acc: (86.39%) (32678/37824) | Learning rate: (0.0001)
2022-06-06 20:07:18,611 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 600 |  Loss: (0.4882) | Acc: (86.54%) (33288/38464) | Learning rate: (0.0001)
2022-06-06 20:07:20,408 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 610 |  Loss: (0.4830) | Acc: (86.67%) (33893/39104) | Learning rate: (0.0001)
2022-06-06 20:07:22,205 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 620 |  Loss: (0.4779) | Acc: (86.80%) (34498/39744) | Learning rate: (0.0001)
2022-06-06 20:07:24,003 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 630 |  Loss: (0.4727) | Acc: (86.95%) (35115/40384) | Learning rate: (0.0001)
2022-06-06 20:07:25,800 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 640 |  Loss: (0.4681) | Acc: (87.05%) (35711/41024) | Learning rate: (0.0001)
2022-06-06 20:07:27,597 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 650 |  Loss: (0.4636) | Acc: (87.15%) (36312/41664) | Learning rate: (0.0001)
2022-06-06 20:07:29,396 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 660 |  Loss: (0.4594) | Acc: (87.25%) (36912/42304) | Learning rate: (0.0001)
2022-06-06 20:07:31,195 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 670 |  Loss: (0.4553) | Acc: (87.35%) (37513/42944) | Learning rate: (0.0001)
2022-06-06 20:07:32,993 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 680 |  Loss: (0.4513) | Acc: (87.46%) (38117/43584) | Learning rate: (0.0001)
2022-06-06 20:07:34,791 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 690 |  Loss: (0.4480) | Acc: (87.54%) (38715/44224) | Learning rate: (0.0001)
2022-06-06 20:07:36,587 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 700 |  Loss: (0.4440) | Acc: (87.66%) (39327/44864) | Learning rate: (0.0001)
2022-06-06 20:07:38,387 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 710 |  Loss: (0.4408) | Acc: (87.74%) (39926/45504) | Learning rate: (0.0001)
2022-06-06 20:07:40,185 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 720 |  Loss: (0.4367) | Acc: (87.85%) (40539/46144) | Learning rate: (0.0001)
2022-06-06 20:07:41,984 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 730 |  Loss: (0.4336) | Acc: (87.92%) (41132/46784) | Learning rate: (0.0001)
2022-06-06 20:07:43,782 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 740 |  Loss: (0.4297) | Acc: (88.03%) (41745/47424) | Learning rate: (0.0001)
2022-06-06 20:07:45,582 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 750 |  Loss: (0.4260) | Acc: (88.12%) (42356/48064) | Learning rate: (0.0001)
2022-06-06 20:07:47,379 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 760 |  Loss: (0.4223) | Acc: (88.22%) (42966/48704) | Learning rate: (0.0001)
2022-06-06 20:07:49,169 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 770 |  Loss: (0.4188) | Acc: (88.30%) (43570/49344) | Learning rate: (0.0001)
2022-06-06 20:07:50,961 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 780 |  Loss: (0.4151) | Acc: (88.39%) (44179/49984) | Learning rate: (0.0001)
2022-06-06 20:08:00,966 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1000) | Acc: (96.79%) (9679/10000)
2022-06-06 20:08:00,967 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 20:08:01,932 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 0 |  Loss: (0.1385) | Acc: (96.88%) (62/64) | Learning rate: (0.0001)
2022-06-06 20:08:03,724 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 10 |  Loss: (0.1084) | Acc: (96.73%) (681/704) | Learning rate: (0.0001)
2022-06-06 20:08:05,517 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 20 |  Loss: (0.1069) | Acc: (96.65%) (1299/1344) | Learning rate: (0.0001)
2022-06-06 20:08:07,310 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 30 |  Loss: (0.1191) | Acc: (96.07%) (1906/1984) | Learning rate: (0.0001)
2022-06-06 20:08:09,104 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 40 |  Loss: (0.1221) | Acc: (95.92%) (2517/2624) | Learning rate: (0.0001)
2022-06-06 20:08:10,900 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 50 |  Loss: (0.1160) | Acc: (96.17%) (3139/3264) | Learning rate: (0.0001)
2022-06-06 20:08:12,697 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 60 |  Loss: (0.1160) | Acc: (96.18%) (3755/3904) | Learning rate: (0.0001)
2022-06-06 20:08:14,493 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 70 |  Loss: (0.1148) | Acc: (96.19%) (4371/4544) | Learning rate: (0.0001)
2022-06-06 20:08:16,288 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 80 |  Loss: (0.1215) | Acc: (96.05%) (4979/5184) | Learning rate: (0.0001)
2022-06-06 20:08:18,084 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 90 |  Loss: (0.1192) | Acc: (96.19%) (5602/5824) | Learning rate: (0.0001)
2022-06-06 20:08:19,879 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 100 |  Loss: (0.1216) | Acc: (96.13%) (6214/6464) | Learning rate: (0.0001)
2022-06-06 20:08:21,675 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 110 |  Loss: (0.1196) | Acc: (96.20%) (6834/7104) | Learning rate: (0.0001)
2022-06-06 20:08:23,472 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 120 |  Loss: (0.1173) | Acc: (96.24%) (7453/7744) | Learning rate: (0.0001)
2022-06-06 20:08:25,267 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 130 |  Loss: (0.1188) | Acc: (96.24%) (8069/8384) | Learning rate: (0.0001)
2022-06-06 20:08:27,062 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 140 |  Loss: (0.1203) | Acc: (96.17%) (8678/9024) | Learning rate: (0.0001)
2022-06-06 20:08:28,858 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 150 |  Loss: (0.1202) | Acc: (96.15%) (9292/9664) | Learning rate: (0.0001)
2022-06-06 20:08:30,656 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 160 |  Loss: (0.1213) | Acc: (96.12%) (9904/10304) | Learning rate: (0.0001)
2022-06-06 20:08:32,453 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 170 |  Loss: (0.1206) | Acc: (96.15%) (10523/10944) | Learning rate: (0.0001)
2022-06-06 20:08:34,251 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 180 |  Loss: (0.1211) | Acc: (96.12%) (11135/11584) | Learning rate: (0.0001)
2022-06-06 20:08:36,049 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 190 |  Loss: (0.1199) | Acc: (96.15%) (11753/12224) | Learning rate: (0.0001)
2022-06-06 20:08:37,847 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 200 |  Loss: (0.1187) | Acc: (96.21%) (12376/12864) | Learning rate: (0.0001)
2022-06-06 20:08:39,645 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 210 |  Loss: (0.1199) | Acc: (96.15%) (12984/13504) | Learning rate: (0.0001)
2022-06-06 20:08:41,442 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 220 |  Loss: (0.1201) | Acc: (96.13%) (13597/14144) | Learning rate: (0.0001)
2022-06-06 20:08:43,239 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 230 |  Loss: (0.1205) | Acc: (96.13%) (14212/14784) | Learning rate: (0.0001)
2022-06-06 20:08:45,037 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 240 |  Loss: (0.1191) | Acc: (96.16%) (14832/15424) | Learning rate: (0.0001)
2022-06-06 20:08:46,834 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 250 |  Loss: (0.1189) | Acc: (96.17%) (15448/16064) | Learning rate: (0.0001)
2022-06-06 20:08:48,631 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 260 |  Loss: (0.1173) | Acc: (96.23%) (16074/16704) | Learning rate: (0.0001)
2022-06-06 20:08:50,429 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 270 |  Loss: (0.1164) | Acc: (96.27%) (16697/17344) | Learning rate: (0.0001)
2022-06-06 20:08:52,229 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 280 |  Loss: (0.1165) | Acc: (96.27%) (17313/17984) | Learning rate: (0.0001)
2022-06-06 20:08:54,027 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 290 |  Loss: (0.1147) | Acc: (96.33%) (17940/18624) | Learning rate: (0.0001)
2022-06-06 20:08:55,826 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 300 |  Loss: (0.1142) | Acc: (96.33%) (18557/19264) | Learning rate: (0.0001)
2022-06-06 20:08:57,625 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 310 |  Loss: (0.1140) | Acc: (96.33%) (19173/19904) | Learning rate: (0.0001)
2022-06-06 20:08:59,424 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 320 |  Loss: (0.1134) | Acc: (96.34%) (19792/20544) | Learning rate: (0.0001)
2022-06-06 20:09:01,223 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 330 |  Loss: (0.1126) | Acc: (96.36%) (20413/21184) | Learning rate: (0.0001)
2022-06-06 20:09:03,022 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 340 |  Loss: (0.1119) | Acc: (96.39%) (21036/21824) | Learning rate: (0.0001)
2022-06-06 20:09:04,820 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 350 |  Loss: (0.1121) | Acc: (96.38%) (21651/22464) | Learning rate: (0.0001)
2022-06-06 20:09:06,618 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 360 |  Loss: (0.1123) | Acc: (96.38%) (22268/23104) | Learning rate: (0.0001)
2022-06-06 20:09:08,417 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 370 |  Loss: (0.1118) | Acc: (96.39%) (22886/23744) | Learning rate: (0.0001)
2022-06-06 20:09:10,215 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 380 |  Loss: (0.1118) | Acc: (96.37%) (23499/24384) | Learning rate: (0.0001)
2022-06-06 20:09:12,015 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 390 |  Loss: (0.1117) | Acc: (96.38%) (24117/25024) | Learning rate: (0.0001)
2022-06-06 20:09:13,813 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 400 |  Loss: (0.1108) | Acc: (96.38%) (24736/25664) | Learning rate: (0.0001)
2022-06-06 20:09:15,613 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 410 |  Loss: (0.1097) | Acc: (96.43%) (25365/26304) | Learning rate: (0.0001)
2022-06-06 20:09:17,412 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 420 |  Loss: (0.1100) | Acc: (96.43%) (25983/26944) | Learning rate: (0.0001)
2022-06-06 20:09:19,211 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 430 |  Loss: (0.1101) | Acc: (96.42%) (26596/27584) | Learning rate: (0.0001)
2022-06-06 20:09:21,008 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 440 |  Loss: (0.1096) | Acc: (96.43%) (27215/28224) | Learning rate: (0.0001)
2022-06-06 20:09:22,804 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 450 |  Loss: (0.1098) | Acc: (96.42%) (27831/28864) | Learning rate: (0.0001)
2022-06-06 20:09:24,604 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 460 |  Loss: (0.1092) | Acc: (96.43%) (28452/29504) | Learning rate: (0.0001)
2022-06-06 20:09:26,402 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 470 |  Loss: (0.1094) | Acc: (96.42%) (29066/30144) | Learning rate: (0.0001)
2022-06-06 20:09:28,198 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 480 |  Loss: (0.1089) | Acc: (96.44%) (29688/30784) | Learning rate: (0.0001)
2022-06-06 20:09:29,996 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 490 |  Loss: (0.1085) | Acc: (96.46%) (30311/31424) | Learning rate: (0.0001)
2022-06-06 20:09:31,792 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 500 |  Loss: (0.1080) | Acc: (96.47%) (30931/32064) | Learning rate: (0.0001)
2022-06-06 20:09:33,593 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 510 |  Loss: (0.1081) | Acc: (96.46%) (31545/32704) | Learning rate: (0.0001)
2022-06-06 20:09:35,390 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 520 |  Loss: (0.1071) | Acc: (96.49%) (32173/33344) | Learning rate: (0.0001)
2022-06-06 20:09:37,189 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 530 |  Loss: (0.1076) | Acc: (96.49%) (32792/33984) | Learning rate: (0.0001)
2022-06-06 20:09:38,987 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 540 |  Loss: (0.1071) | Acc: (96.51%) (33414/34624) | Learning rate: (0.0001)
2022-06-06 20:09:40,784 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 550 |  Loss: (0.1072) | Acc: (96.50%) (34030/35264) | Learning rate: (0.0001)
2022-06-06 20:09:42,583 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 560 |  Loss: (0.1074) | Acc: (96.49%) (34642/35904) | Learning rate: (0.0001)
2022-06-06 20:09:44,381 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 570 |  Loss: (0.1074) | Acc: (96.49%) (35261/36544) | Learning rate: (0.0001)
2022-06-06 20:09:46,178 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 580 |  Loss: (0.1073) | Acc: (96.50%) (35881/37184) | Learning rate: (0.0001)
2022-06-06 20:09:47,977 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 590 |  Loss: (0.1073) | Acc: (96.49%) (36496/37824) | Learning rate: (0.0001)
2022-06-06 20:09:49,773 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 600 |  Loss: (0.1069) | Acc: (96.49%) (37112/38464) | Learning rate: (0.0001)
2022-06-06 20:09:51,571 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 610 |  Loss: (0.1067) | Acc: (96.49%) (37732/39104) | Learning rate: (0.0001)
2022-06-06 20:09:53,368 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 620 |  Loss: (0.1065) | Acc: (96.50%) (38352/39744) | Learning rate: (0.0001)
2022-06-06 20:09:55,166 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 630 |  Loss: (0.1064) | Acc: (96.49%) (38968/40384) | Learning rate: (0.0001)
2022-06-06 20:09:56,965 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 640 |  Loss: (0.1067) | Acc: (96.49%) (39584/41024) | Learning rate: (0.0001)
2022-06-06 20:09:58,763 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 650 |  Loss: (0.1066) | Acc: (96.48%) (40197/41664) | Learning rate: (0.0001)
2022-06-06 20:10:00,560 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 660 |  Loss: (0.1064) | Acc: (96.48%) (40817/42304) | Learning rate: (0.0001)
2022-06-06 20:10:02,360 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 670 |  Loss: (0.1067) | Acc: (96.48%) (41432/42944) | Learning rate: (0.0001)
2022-06-06 20:10:04,158 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 680 |  Loss: (0.1064) | Acc: (96.49%) (42054/43584) | Learning rate: (0.0001)
2022-06-06 20:10:05,956 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 690 |  Loss: (0.1064) | Acc: (96.49%) (42672/44224) | Learning rate: (0.0001)
2022-06-06 20:10:07,755 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 700 |  Loss: (0.1063) | Acc: (96.49%) (43289/44864) | Learning rate: (0.0001)
2022-06-06 20:10:09,553 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 710 |  Loss: (0.1059) | Acc: (96.51%) (43914/45504) | Learning rate: (0.0001)
2022-06-06 20:10:11,349 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 720 |  Loss: (0.1057) | Acc: (96.51%) (44533/46144) | Learning rate: (0.0001)
2022-06-06 20:10:13,147 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 730 |  Loss: (0.1055) | Acc: (96.52%) (45157/46784) | Learning rate: (0.0001)
2022-06-06 20:10:14,948 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 740 |  Loss: (0.1058) | Acc: (96.51%) (45771/47424) | Learning rate: (0.0001)
2022-06-06 20:10:16,744 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 750 |  Loss: (0.1061) | Acc: (96.51%) (46385/48064) | Learning rate: (0.0001)
2022-06-06 20:10:18,543 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 760 |  Loss: (0.1056) | Acc: (96.52%) (47011/48704) | Learning rate: (0.0001)
2022-06-06 20:10:20,333 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 770 |  Loss: (0.1052) | Acc: (96.54%) (47635/49344) | Learning rate: (0.0001)
2022-06-06 20:10:22,123 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 780 |  Loss: (0.1054) | Acc: (96.52%) (48245/49984) | Learning rate: (0.0001)
2022-06-06 20:10:32,056 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0862) | Acc: (97.20%) (9720/10000)
2022-06-06 20:10:32,057 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 20:10:32,945 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 0 |  Loss: (0.0567) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 20:10:34,758 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 10 |  Loss: (0.0494) | Acc: (98.72%) (695/704) | Learning rate: (0.0001)
2022-06-06 20:10:36,554 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 20 |  Loss: (0.0434) | Acc: (98.96%) (1330/1344) | Learning rate: (0.0001)
2022-06-06 20:10:38,347 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 30 |  Loss: (0.0494) | Acc: (98.74%) (1959/1984) | Learning rate: (0.0001)
2022-06-06 20:10:40,144 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 40 |  Loss: (0.0484) | Acc: (98.74%) (2591/2624) | Learning rate: (0.0001)
2022-06-06 20:10:41,940 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 50 |  Loss: (0.0478) | Acc: (98.68%) (3221/3264) | Learning rate: (0.0001)
2022-06-06 20:10:43,737 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 60 |  Loss: (0.0470) | Acc: (98.77%) (3856/3904) | Learning rate: (0.0001)
2022-06-06 20:10:45,531 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 70 |  Loss: (0.0528) | Acc: (98.57%) (4479/4544) | Learning rate: (0.0001)
2022-06-06 20:10:47,328 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 80 |  Loss: (0.0544) | Acc: (98.50%) (5106/5184) | Learning rate: (0.0001)
2022-06-06 20:10:49,124 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 90 |  Loss: (0.0544) | Acc: (98.49%) (5736/5824) | Learning rate: (0.0001)
2022-06-06 20:10:50,920 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 100 |  Loss: (0.0554) | Acc: (98.44%) (6363/6464) | Learning rate: (0.0001)
2022-06-06 20:10:52,716 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 110 |  Loss: (0.0547) | Acc: (98.47%) (6995/7104) | Learning rate: (0.0001)
2022-06-06 20:10:54,512 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 120 |  Loss: (0.0538) | Acc: (98.49%) (7627/7744) | Learning rate: (0.0001)
2022-06-06 20:10:56,309 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 130 |  Loss: (0.0533) | Acc: (98.47%) (8256/8384) | Learning rate: (0.0001)
2022-06-06 20:10:58,106 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 140 |  Loss: (0.0542) | Acc: (98.44%) (8883/9024) | Learning rate: (0.0001)
2022-06-06 20:10:59,903 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 150 |  Loss: (0.0539) | Acc: (98.40%) (9509/9664) | Learning rate: (0.0001)
2022-06-06 20:11:01,702 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 160 |  Loss: (0.0533) | Acc: (98.42%) (10141/10304) | Learning rate: (0.0001)
2022-06-06 20:11:03,499 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 170 |  Loss: (0.0542) | Acc: (98.41%) (10770/10944) | Learning rate: (0.0001)
2022-06-06 20:11:05,297 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 180 |  Loss: (0.0536) | Acc: (98.44%) (11403/11584) | Learning rate: (0.0001)
2022-06-06 20:11:07,095 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 190 |  Loss: (0.0530) | Acc: (98.45%) (12035/12224) | Learning rate: (0.0001)
2022-06-06 20:11:08,893 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 200 |  Loss: (0.0534) | Acc: (98.42%) (12661/12864) | Learning rate: (0.0001)
2022-06-06 20:11:10,690 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 210 |  Loss: (0.0531) | Acc: (98.44%) (13293/13504) | Learning rate: (0.0001)
2022-06-06 20:11:12,487 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 220 |  Loss: (0.0531) | Acc: (98.43%) (13922/14144) | Learning rate: (0.0001)
2022-06-06 20:11:14,284 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 230 |  Loss: (0.0529) | Acc: (98.40%) (14548/14784) | Learning rate: (0.0001)
2022-06-06 20:11:16,082 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 240 |  Loss: (0.0535) | Acc: (98.39%) (15175/15424) | Learning rate: (0.0001)
2022-06-06 20:11:17,879 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 250 |  Loss: (0.0530) | Acc: (98.39%) (15805/16064) | Learning rate: (0.0001)
2022-06-06 20:11:19,679 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 260 |  Loss: (0.0536) | Acc: (98.38%) (16433/16704) | Learning rate: (0.0001)
2022-06-06 20:11:21,476 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 270 |  Loss: (0.0537) | Acc: (98.37%) (17061/17344) | Learning rate: (0.0001)
2022-06-06 20:11:23,275 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 280 |  Loss: (0.0540) | Acc: (98.37%) (17691/17984) | Learning rate: (0.0001)
2022-06-06 20:11:25,074 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 290 |  Loss: (0.0534) | Acc: (98.38%) (18322/18624) | Learning rate: (0.0001)
2022-06-06 20:11:26,871 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 300 |  Loss: (0.0532) | Acc: (98.38%) (18951/19264) | Learning rate: (0.0001)
2022-06-06 20:11:28,671 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 310 |  Loss: (0.0526) | Acc: (98.39%) (19584/19904) | Learning rate: (0.0001)
2022-06-06 20:11:30,470 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 320 |  Loss: (0.0526) | Acc: (98.39%) (20214/20544) | Learning rate: (0.0001)
2022-06-06 20:11:32,267 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 330 |  Loss: (0.0528) | Acc: (98.38%) (20840/21184) | Learning rate: (0.0001)
2022-06-06 20:11:34,066 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 340 |  Loss: (0.0536) | Acc: (98.32%) (21458/21824) | Learning rate: (0.0001)
2022-06-06 20:11:35,864 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 350 |  Loss: (0.0537) | Acc: (98.31%) (22084/22464) | Learning rate: (0.0001)
2022-06-06 20:11:37,663 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 360 |  Loss: (0.0541) | Acc: (98.29%) (22710/23104) | Learning rate: (0.0001)
2022-06-06 20:11:39,459 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 370 |  Loss: (0.0542) | Acc: (98.30%) (23340/23744) | Learning rate: (0.0001)
2022-06-06 20:11:41,259 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 380 |  Loss: (0.0544) | Acc: (98.29%) (23967/24384) | Learning rate: (0.0001)
2022-06-06 20:11:43,056 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 390 |  Loss: (0.0545) | Acc: (98.29%) (24597/25024) | Learning rate: (0.0001)
2022-06-06 20:11:44,854 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 400 |  Loss: (0.0545) | Acc: (98.30%) (25227/25664) | Learning rate: (0.0001)
2022-06-06 20:11:46,652 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 410 |  Loss: (0.0546) | Acc: (98.28%) (25851/26304) | Learning rate: (0.0001)
2022-06-06 20:11:48,450 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 420 |  Loss: (0.0543) | Acc: (98.29%) (26484/26944) | Learning rate: (0.0001)
2022-06-06 20:11:50,248 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 430 |  Loss: (0.0545) | Acc: (98.28%) (27110/27584) | Learning rate: (0.0001)
2022-06-06 20:11:52,047 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 440 |  Loss: (0.0541) | Acc: (98.29%) (27740/28224) | Learning rate: (0.0001)
2022-06-06 20:11:53,846 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 450 |  Loss: (0.0544) | Acc: (98.27%) (28365/28864) | Learning rate: (0.0001)
2022-06-06 20:11:55,643 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 460 |  Loss: (0.0549) | Acc: (98.25%) (28988/29504) | Learning rate: (0.0001)
2022-06-06 20:11:57,441 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 470 |  Loss: (0.0544) | Acc: (98.26%) (29620/30144) | Learning rate: (0.0001)
2022-06-06 20:11:59,239 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 480 |  Loss: (0.0548) | Acc: (98.24%) (30241/30784) | Learning rate: (0.0001)
2022-06-06 20:12:01,037 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 490 |  Loss: (0.0545) | Acc: (98.25%) (30873/31424) | Learning rate: (0.0001)
2022-06-06 20:12:02,833 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 500 |  Loss: (0.0549) | Acc: (98.23%) (31498/32064) | Learning rate: (0.0001)
2022-06-06 20:12:04,631 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 510 |  Loss: (0.0553) | Acc: (98.21%) (32118/32704) | Learning rate: (0.0001)
2022-06-06 20:12:06,429 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 520 |  Loss: (0.0552) | Acc: (98.21%) (32747/33344) | Learning rate: (0.0001)
2022-06-06 20:12:08,227 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 530 |  Loss: (0.0552) | Acc: (98.22%) (33378/33984) | Learning rate: (0.0001)
2022-06-06 20:12:10,026 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 540 |  Loss: (0.0555) | Acc: (98.21%) (34003/34624) | Learning rate: (0.0001)
2022-06-06 20:12:11,824 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 550 |  Loss: (0.0554) | Acc: (98.20%) (34629/35264) | Learning rate: (0.0001)
2022-06-06 20:12:13,622 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 560 |  Loss: (0.0556) | Acc: (98.19%) (35255/35904) | Learning rate: (0.0001)
2022-06-06 20:12:15,421 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 570 |  Loss: (0.0557) | Acc: (98.19%) (35882/36544) | Learning rate: (0.0001)
2022-06-06 20:12:17,218 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 580 |  Loss: (0.0562) | Acc: (98.18%) (36506/37184) | Learning rate: (0.0001)
2022-06-06 20:12:19,016 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 590 |  Loss: (0.0563) | Acc: (98.18%) (37137/37824) | Learning rate: (0.0001)
2022-06-06 20:12:20,813 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 600 |  Loss: (0.0567) | Acc: (98.18%) (37763/38464) | Learning rate: (0.0001)
2022-06-06 20:12:22,612 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 610 |  Loss: (0.0566) | Acc: (98.18%) (38393/39104) | Learning rate: (0.0001)
2022-06-06 20:12:24,410 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 620 |  Loss: (0.0563) | Acc: (98.19%) (39024/39744) | Learning rate: (0.0001)
2022-06-06 20:12:26,209 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 630 |  Loss: (0.0563) | Acc: (98.19%) (39654/40384) | Learning rate: (0.0001)
2022-06-06 20:12:28,007 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 640 |  Loss: (0.0566) | Acc: (98.18%) (40278/41024) | Learning rate: (0.0001)
2022-06-06 20:12:29,803 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 650 |  Loss: (0.0565) | Acc: (98.19%) (40909/41664) | Learning rate: (0.0001)
2022-06-06 20:12:31,602 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 660 |  Loss: (0.0563) | Acc: (98.20%) (41543/42304) | Learning rate: (0.0001)
2022-06-06 20:12:33,400 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 670 |  Loss: (0.0564) | Acc: (98.20%) (42173/42944) | Learning rate: (0.0001)
2022-06-06 20:12:35,198 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 680 |  Loss: (0.0563) | Acc: (98.21%) (42803/43584) | Learning rate: (0.0001)
2022-06-06 20:12:36,995 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 690 |  Loss: (0.0561) | Acc: (98.21%) (43434/44224) | Learning rate: (0.0001)
2022-06-06 20:12:38,793 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 700 |  Loss: (0.0560) | Acc: (98.22%) (44065/44864) | Learning rate: (0.0001)
2022-06-06 20:12:40,591 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 710 |  Loss: (0.0557) | Acc: (98.22%) (44694/45504) | Learning rate: (0.0001)
2022-06-06 20:12:42,388 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 720 |  Loss: (0.0561) | Acc: (98.21%) (45317/46144) | Learning rate: (0.0001)
2022-06-06 20:12:44,186 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 730 |  Loss: (0.0564) | Acc: (98.20%) (45942/46784) | Learning rate: (0.0001)
2022-06-06 20:12:45,985 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 740 |  Loss: (0.0567) | Acc: (98.19%) (46565/47424) | Learning rate: (0.0001)
2022-06-06 20:12:47,783 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 750 |  Loss: (0.0566) | Acc: (98.19%) (47193/48064) | Learning rate: (0.0001)
2022-06-06 20:12:49,582 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 760 |  Loss: (0.0566) | Acc: (98.19%) (47822/48704) | Learning rate: (0.0001)
2022-06-06 20:12:51,373 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 770 |  Loss: (0.0565) | Acc: (98.19%) (48451/49344) | Learning rate: (0.0001)
2022-06-06 20:12:53,163 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 780 |  Loss: (0.0565) | Acc: (98.19%) (49080/49984) | Learning rate: (0.0001)
2022-06-06 20:13:03,112 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0756) | Acc: (97.80%) (9780/10000)
2022-06-06 20:13:03,113 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 20:13:03,994 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 0 |  Loss: (0.0196) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:13:05,804 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 10 |  Loss: (0.0311) | Acc: (99.15%) (698/704) | Learning rate: (0.0001)
2022-06-06 20:13:07,600 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 20 |  Loss: (0.0376) | Acc: (98.81%) (1328/1344) | Learning rate: (0.0001)
2022-06-06 20:13:09,394 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 30 |  Loss: (0.0384) | Acc: (98.84%) (1961/1984) | Learning rate: (0.0001)
2022-06-06 20:13:11,192 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 40 |  Loss: (0.0366) | Acc: (98.86%) (2594/2624) | Learning rate: (0.0001)
2022-06-06 20:13:12,987 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 50 |  Loss: (0.0338) | Acc: (98.96%) (3230/3264) | Learning rate: (0.0001)
2022-06-06 20:13:14,785 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 60 |  Loss: (0.0361) | Acc: (98.90%) (3861/3904) | Learning rate: (0.0001)
2022-06-06 20:13:16,581 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 70 |  Loss: (0.0356) | Acc: (98.88%) (4493/4544) | Learning rate: (0.0001)
2022-06-06 20:13:18,379 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 80 |  Loss: (0.0364) | Acc: (98.84%) (5124/5184) | Learning rate: (0.0001)
2022-06-06 20:13:20,176 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 90 |  Loss: (0.0368) | Acc: (98.85%) (5757/5824) | Learning rate: (0.0001)
2022-06-06 20:13:21,973 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 100 |  Loss: (0.0376) | Acc: (98.78%) (6385/6464) | Learning rate: (0.0001)
2022-06-06 20:13:23,771 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 110 |  Loss: (0.0387) | Acc: (98.80%) (7019/7104) | Learning rate: (0.0001)
2022-06-06 20:13:25,569 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 120 |  Loss: (0.0389) | Acc: (98.80%) (7651/7744) | Learning rate: (0.0001)
2022-06-06 20:13:27,367 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 130 |  Loss: (0.0383) | Acc: (98.81%) (8284/8384) | Learning rate: (0.0001)
2022-06-06 20:13:29,165 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 140 |  Loss: (0.0381) | Acc: (98.80%) (8916/9024) | Learning rate: (0.0001)
2022-06-06 20:13:30,961 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 150 |  Loss: (0.0393) | Acc: (98.76%) (9544/9664) | Learning rate: (0.0001)
2022-06-06 20:13:32,758 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 160 |  Loss: (0.0397) | Acc: (98.77%) (10177/10304) | Learning rate: (0.0001)
2022-06-06 20:13:34,554 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 170 |  Loss: (0.0416) | Acc: (98.73%) (10805/10944) | Learning rate: (0.0001)
2022-06-06 20:13:36,352 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 180 |  Loss: (0.0410) | Acc: (98.75%) (11439/11584) | Learning rate: (0.0001)
2022-06-06 20:13:38,150 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 190 |  Loss: (0.0408) | Acc: (98.75%) (12071/12224) | Learning rate: (0.0001)
2022-06-06 20:13:39,946 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 200 |  Loss: (0.0402) | Acc: (98.76%) (12704/12864) | Learning rate: (0.0001)
2022-06-06 20:13:41,744 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 210 |  Loss: (0.0407) | Acc: (98.72%) (13331/13504) | Learning rate: (0.0001)
2022-06-06 20:13:43,542 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 220 |  Loss: (0.0404) | Acc: (98.74%) (13966/14144) | Learning rate: (0.0001)
2022-06-06 20:13:45,339 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 230 |  Loss: (0.0404) | Acc: (98.76%) (14600/14784) | Learning rate: (0.0001)
2022-06-06 20:13:47,135 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 240 |  Loss: (0.0410) | Acc: (98.72%) (15227/15424) | Learning rate: (0.0001)
2022-06-06 20:13:48,931 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 250 |  Loss: (0.0414) | Acc: (98.70%) (15855/16064) | Learning rate: (0.0001)
2022-06-06 20:13:50,729 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 260 |  Loss: (0.0409) | Acc: (98.71%) (16489/16704) | Learning rate: (0.0001)
2022-06-06 20:13:52,527 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 270 |  Loss: (0.0410) | Acc: (98.72%) (17122/17344) | Learning rate: (0.0001)
2022-06-06 20:13:54,324 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 280 |  Loss: (0.0406) | Acc: (98.75%) (17759/17984) | Learning rate: (0.0001)
2022-06-06 20:13:56,121 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 290 |  Loss: (0.0405) | Acc: (98.74%) (18390/18624) | Learning rate: (0.0001)
2022-06-06 20:13:57,918 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 300 |  Loss: (0.0411) | Acc: (98.74%) (19021/19264) | Learning rate: (0.0001)
2022-06-06 20:13:59,716 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 310 |  Loss: (0.0407) | Acc: (98.74%) (19654/19904) | Learning rate: (0.0001)
2022-06-06 20:14:01,513 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 320 |  Loss: (0.0401) | Acc: (98.76%) (20290/20544) | Learning rate: (0.0001)
2022-06-06 20:14:03,310 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 330 |  Loss: (0.0399) | Acc: (98.78%) (20925/21184) | Learning rate: (0.0001)
2022-06-06 20:14:05,106 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 340 |  Loss: (0.0396) | Acc: (98.78%) (21557/21824) | Learning rate: (0.0001)
2022-06-06 20:14:06,903 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 350 |  Loss: (0.0399) | Acc: (98.75%) (22184/22464) | Learning rate: (0.0001)
2022-06-06 20:14:08,703 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 360 |  Loss: (0.0398) | Acc: (98.75%) (22816/23104) | Learning rate: (0.0001)
2022-06-06 20:14:10,500 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 370 |  Loss: (0.0396) | Acc: (98.76%) (23449/23744) | Learning rate: (0.0001)
2022-06-06 20:14:12,297 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 380 |  Loss: (0.0399) | Acc: (98.74%) (24077/24384) | Learning rate: (0.0001)
2022-06-06 20:14:14,094 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 390 |  Loss: (0.0400) | Acc: (98.74%) (24709/25024) | Learning rate: (0.0001)
2022-06-06 20:14:15,891 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 400 |  Loss: (0.0398) | Acc: (98.75%) (25343/25664) | Learning rate: (0.0001)
2022-06-06 20:14:17,690 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 410 |  Loss: (0.0397) | Acc: (98.75%) (25976/26304) | Learning rate: (0.0001)
2022-06-06 20:14:19,487 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 420 |  Loss: (0.0401) | Acc: (98.73%) (26602/26944) | Learning rate: (0.0001)
2022-06-06 20:14:21,284 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 430 |  Loss: (0.0398) | Acc: (98.73%) (27235/27584) | Learning rate: (0.0001)
2022-06-06 20:14:23,082 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 440 |  Loss: (0.0396) | Acc: (98.74%) (27867/28224) | Learning rate: (0.0001)
2022-06-06 20:14:24,878 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 450 |  Loss: (0.0395) | Acc: (98.74%) (28500/28864) | Learning rate: (0.0001)
2022-06-06 20:14:26,676 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 460 |  Loss: (0.0396) | Acc: (98.73%) (29130/29504) | Learning rate: (0.0001)
2022-06-06 20:14:28,472 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 470 |  Loss: (0.0396) | Acc: (98.73%) (29761/30144) | Learning rate: (0.0001)
2022-06-06 20:14:30,271 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 480 |  Loss: (0.0407) | Acc: (98.70%) (30384/30784) | Learning rate: (0.0001)
2022-06-06 20:14:32,069 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 490 |  Loss: (0.0405) | Acc: (98.70%) (31017/31424) | Learning rate: (0.0001)
2022-06-06 20:14:33,866 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 500 |  Loss: (0.0404) | Acc: (98.71%) (31649/32064) | Learning rate: (0.0001)
2022-06-06 20:14:35,665 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 510 |  Loss: (0.0401) | Acc: (98.72%) (32285/32704) | Learning rate: (0.0001)
2022-06-06 20:14:37,462 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 520 |  Loss: (0.0399) | Acc: (98.72%) (32918/33344) | Learning rate: (0.0001)
2022-06-06 20:14:39,259 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 530 |  Loss: (0.0402) | Acc: (98.71%) (33546/33984) | Learning rate: (0.0001)
2022-06-06 20:14:41,056 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 540 |  Loss: (0.0405) | Acc: (98.70%) (34173/34624) | Learning rate: (0.0001)
2022-06-06 20:14:42,853 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 550 |  Loss: (0.0402) | Acc: (98.71%) (34808/35264) | Learning rate: (0.0001)
2022-06-06 20:14:44,652 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 560 |  Loss: (0.0405) | Acc: (98.70%) (35439/35904) | Learning rate: (0.0001)
2022-06-06 20:14:46,450 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 570 |  Loss: (0.0401) | Acc: (98.72%) (36075/36544) | Learning rate: (0.0001)
2022-06-06 20:14:48,248 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 580 |  Loss: (0.0401) | Acc: (98.71%) (36706/37184) | Learning rate: (0.0001)
2022-06-06 20:14:50,047 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 590 |  Loss: (0.0400) | Acc: (98.72%) (37338/37824) | Learning rate: (0.0001)
2022-06-06 20:14:51,845 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 600 |  Loss: (0.0401) | Acc: (98.71%) (37969/38464) | Learning rate: (0.0001)
2022-06-06 20:14:53,645 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 610 |  Loss: (0.0398) | Acc: (98.72%) (38603/39104) | Learning rate: (0.0001)
2022-06-06 20:14:55,443 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 620 |  Loss: (0.0397) | Acc: (98.73%) (39238/39744) | Learning rate: (0.0001)
2022-06-06 20:14:57,241 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 630 |  Loss: (0.0396) | Acc: (98.73%) (39873/40384) | Learning rate: (0.0001)
2022-06-06 20:14:59,039 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 640 |  Loss: (0.0395) | Acc: (98.74%) (40509/41024) | Learning rate: (0.0001)
2022-06-06 20:15:00,837 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 650 |  Loss: (0.0398) | Acc: (98.74%) (41140/41664) | Learning rate: (0.0001)
2022-06-06 20:15:02,635 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 660 |  Loss: (0.0399) | Acc: (98.74%) (41771/42304) | Learning rate: (0.0001)
2022-06-06 20:15:04,433 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 670 |  Loss: (0.0399) | Acc: (98.74%) (42405/42944) | Learning rate: (0.0001)
2022-06-06 20:15:06,229 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 680 |  Loss: (0.0401) | Acc: (98.74%) (43035/43584) | Learning rate: (0.0001)
2022-06-06 20:15:08,028 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 690 |  Loss: (0.0403) | Acc: (98.74%) (43665/44224) | Learning rate: (0.0001)
2022-06-06 20:15:09,824 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 700 |  Loss: (0.0403) | Acc: (98.73%) (44296/44864) | Learning rate: (0.0001)
2022-06-06 20:15:11,622 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 710 |  Loss: (0.0405) | Acc: (98.73%) (44924/45504) | Learning rate: (0.0001)
2022-06-06 20:15:13,420 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 720 |  Loss: (0.0407) | Acc: (98.72%) (45552/46144) | Learning rate: (0.0001)
2022-06-06 20:15:15,218 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 730 |  Loss: (0.0408) | Acc: (98.72%) (46183/46784) | Learning rate: (0.0001)
2022-06-06 20:15:17,017 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 740 |  Loss: (0.0407) | Acc: (98.72%) (46816/47424) | Learning rate: (0.0001)
2022-06-06 20:15:18,816 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 750 |  Loss: (0.0405) | Acc: (98.72%) (47450/48064) | Learning rate: (0.0001)
2022-06-06 20:15:20,615 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 760 |  Loss: (0.0402) | Acc: (98.73%) (48087/48704) | Learning rate: (0.0001)
2022-06-06 20:15:22,405 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 770 |  Loss: (0.0403) | Acc: (98.73%) (48717/49344) | Learning rate: (0.0001)
2022-06-06 20:15:24,197 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 780 |  Loss: (0.0404) | Acc: (98.73%) (49348/49984) | Learning rate: (0.0001)
2022-06-06 20:15:34,174 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0786) | Acc: (97.63%) (9763/10000)
2022-06-06 20:15:34,175 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 20:15:35,079 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 0 |  Loss: (0.0549) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 20:15:36,868 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 10 |  Loss: (0.0300) | Acc: (99.43%) (700/704) | Learning rate: (0.0001)
2022-06-06 20:15:38,660 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 20 |  Loss: (0.0308) | Acc: (99.18%) (1333/1344) | Learning rate: (0.0001)
2022-06-06 20:15:40,455 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 30 |  Loss: (0.0321) | Acc: (99.14%) (1967/1984) | Learning rate: (0.0001)
2022-06-06 20:15:42,251 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 40 |  Loss: (0.0328) | Acc: (99.12%) (2601/2624) | Learning rate: (0.0001)
2022-06-06 20:15:44,047 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 50 |  Loss: (0.0333) | Acc: (99.02%) (3232/3264) | Learning rate: (0.0001)
2022-06-06 20:15:45,844 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 60 |  Loss: (0.0335) | Acc: (98.95%) (3863/3904) | Learning rate: (0.0001)
2022-06-06 20:15:47,641 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 70 |  Loss: (0.0333) | Acc: (98.94%) (4496/4544) | Learning rate: (0.0001)
2022-06-06 20:15:49,438 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 80 |  Loss: (0.0325) | Acc: (98.98%) (5131/5184) | Learning rate: (0.0001)
2022-06-06 20:15:51,234 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 90 |  Loss: (0.0307) | Acc: (99.04%) (5768/5824) | Learning rate: (0.0001)
2022-06-06 20:15:53,030 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 100 |  Loss: (0.0305) | Acc: (99.03%) (6401/6464) | Learning rate: (0.0001)
2022-06-06 20:15:54,827 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 110 |  Loss: (0.0303) | Acc: (99.04%) (7036/7104) | Learning rate: (0.0001)
2022-06-06 20:15:56,625 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 120 |  Loss: (0.0294) | Acc: (99.07%) (7672/7744) | Learning rate: (0.0001)
2022-06-06 20:15:58,424 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 130 |  Loss: (0.0305) | Acc: (99.06%) (8305/8384) | Learning rate: (0.0001)
2022-06-06 20:16:00,223 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 140 |  Loss: (0.0303) | Acc: (99.05%) (8938/9024) | Learning rate: (0.0001)
2022-06-06 20:16:02,020 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 150 |  Loss: (0.0296) | Acc: (99.05%) (9572/9664) | Learning rate: (0.0001)
2022-06-06 20:16:03,818 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 160 |  Loss: (0.0293) | Acc: (99.07%) (10208/10304) | Learning rate: (0.0001)
2022-06-06 20:16:05,616 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 170 |  Loss: (0.0285) | Acc: (99.10%) (10846/10944) | Learning rate: (0.0001)
2022-06-06 20:16:07,414 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 180 |  Loss: (0.0283) | Acc: (99.11%) (11481/11584) | Learning rate: (0.0001)
2022-06-06 20:16:09,210 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 190 |  Loss: (0.0292) | Acc: (99.06%) (12109/12224) | Learning rate: (0.0001)
2022-06-06 20:16:11,004 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 200 |  Loss: (0.0290) | Acc: (99.04%) (12741/12864) | Learning rate: (0.0001)
2022-06-06 20:16:12,801 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 210 |  Loss: (0.0291) | Acc: (99.04%) (13374/13504) | Learning rate: (0.0001)
2022-06-06 20:16:14,598 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 220 |  Loss: (0.0300) | Acc: (98.99%) (14001/14144) | Learning rate: (0.0001)
2022-06-06 20:16:16,395 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 230 |  Loss: (0.0314) | Acc: (98.97%) (14631/14784) | Learning rate: (0.0001)
2022-06-06 20:16:18,192 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 240 |  Loss: (0.0311) | Acc: (98.98%) (15266/15424) | Learning rate: (0.0001)
2022-06-06 20:16:19,989 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 250 |  Loss: (0.0311) | Acc: (98.99%) (15901/16064) | Learning rate: (0.0001)
2022-06-06 20:16:21,786 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 260 |  Loss: (0.0313) | Acc: (98.96%) (16531/16704) | Learning rate: (0.0001)
2022-06-06 20:16:23,582 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 270 |  Loss: (0.0314) | Acc: (98.97%) (17166/17344) | Learning rate: (0.0001)
2022-06-06 20:16:25,378 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 280 |  Loss: (0.0311) | Acc: (98.98%) (17800/17984) | Learning rate: (0.0001)
2022-06-06 20:16:27,176 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 290 |  Loss: (0.0308) | Acc: (98.99%) (18436/18624) | Learning rate: (0.0001)
2022-06-06 20:16:28,973 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 300 |  Loss: (0.0307) | Acc: (99.01%) (19073/19264) | Learning rate: (0.0001)
2022-06-06 20:16:30,770 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 310 |  Loss: (0.0304) | Acc: (99.02%) (19708/19904) | Learning rate: (0.0001)
2022-06-06 20:16:32,566 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 320 |  Loss: (0.0308) | Acc: (98.99%) (20337/20544) | Learning rate: (0.0001)
2022-06-06 20:16:34,362 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 330 |  Loss: (0.0305) | Acc: (99.00%) (20973/21184) | Learning rate: (0.0001)
2022-06-06 20:16:36,161 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 340 |  Loss: (0.0306) | Acc: (98.99%) (21603/21824) | Learning rate: (0.0001)
2022-06-06 20:16:37,957 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 350 |  Loss: (0.0303) | Acc: (99.00%) (22239/22464) | Learning rate: (0.0001)
2022-06-06 20:16:39,755 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 360 |  Loss: (0.0302) | Acc: (99.00%) (22873/23104) | Learning rate: (0.0001)
2022-06-06 20:16:41,552 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 370 |  Loss: (0.0305) | Acc: (98.99%) (23504/23744) | Learning rate: (0.0001)
2022-06-06 20:16:43,350 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 380 |  Loss: (0.0308) | Acc: (98.99%) (24137/24384) | Learning rate: (0.0001)
2022-06-06 20:16:45,147 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 390 |  Loss: (0.0309) | Acc: (98.98%) (24769/25024) | Learning rate: (0.0001)
2022-06-06 20:16:46,945 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 400 |  Loss: (0.0307) | Acc: (98.99%) (25404/25664) | Learning rate: (0.0001)
2022-06-06 20:16:48,744 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 410 |  Loss: (0.0306) | Acc: (99.00%) (26042/26304) | Learning rate: (0.0001)
2022-06-06 20:16:50,544 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 420 |  Loss: (0.0305) | Acc: (99.00%) (26675/26944) | Learning rate: (0.0001)
2022-06-06 20:16:52,341 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 430 |  Loss: (0.0302) | Acc: (99.01%) (27312/27584) | Learning rate: (0.0001)
2022-06-06 20:16:54,141 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 440 |  Loss: (0.0299) | Acc: (99.03%) (27949/28224) | Learning rate: (0.0001)
2022-06-06 20:16:55,939 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 450 |  Loss: (0.0302) | Acc: (99.01%) (28577/28864) | Learning rate: (0.0001)
2022-06-06 20:16:57,738 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 460 |  Loss: (0.0303) | Acc: (99.00%) (29210/29504) | Learning rate: (0.0001)
2022-06-06 20:16:59,537 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 470 |  Loss: (0.0301) | Acc: (99.01%) (29846/30144) | Learning rate: (0.0001)
2022-06-06 20:17:01,335 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 480 |  Loss: (0.0301) | Acc: (99.01%) (30480/30784) | Learning rate: (0.0001)
2022-06-06 20:17:03,134 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 490 |  Loss: (0.0302) | Acc: (99.00%) (31110/31424) | Learning rate: (0.0001)
2022-06-06 20:17:04,931 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 500 |  Loss: (0.0304) | Acc: (99.00%) (31743/32064) | Learning rate: (0.0001)
2022-06-06 20:17:06,731 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 510 |  Loss: (0.0303) | Acc: (99.00%) (32378/32704) | Learning rate: (0.0001)
2022-06-06 20:17:08,529 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 520 |  Loss: (0.0300) | Acc: (99.01%) (33015/33344) | Learning rate: (0.0001)
2022-06-06 20:17:10,328 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 530 |  Loss: (0.0302) | Acc: (99.01%) (33648/33984) | Learning rate: (0.0001)
2022-06-06 20:17:12,127 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 540 |  Loss: (0.0300) | Acc: (99.02%) (34284/34624) | Learning rate: (0.0001)
2022-06-06 20:17:13,924 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 550 |  Loss: (0.0297) | Acc: (99.03%) (34922/35264) | Learning rate: (0.0001)
2022-06-06 20:17:15,725 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 560 |  Loss: (0.0298) | Acc: (99.02%) (35553/35904) | Learning rate: (0.0001)
2022-06-06 20:17:17,523 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 570 |  Loss: (0.0300) | Acc: (99.01%) (36183/36544) | Learning rate: (0.0001)
2022-06-06 20:17:19,321 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 580 |  Loss: (0.0301) | Acc: (99.01%) (36817/37184) | Learning rate: (0.0001)
2022-06-06 20:17:21,118 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 590 |  Loss: (0.0301) | Acc: (99.01%) (37448/37824) | Learning rate: (0.0001)
2022-06-06 20:17:22,917 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 600 |  Loss: (0.0303) | Acc: (99.00%) (38079/38464) | Learning rate: (0.0001)
2022-06-06 20:17:24,716 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 610 |  Loss: (0.0301) | Acc: (99.01%) (38717/39104) | Learning rate: (0.0001)
2022-06-06 20:17:26,515 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 620 |  Loss: (0.0305) | Acc: (98.99%) (39342/39744) | Learning rate: (0.0001)
2022-06-06 20:17:28,313 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 630 |  Loss: (0.0303) | Acc: (99.00%) (39979/40384) | Learning rate: (0.0001)
2022-06-06 20:17:30,113 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 640 |  Loss: (0.0302) | Acc: (99.00%) (40614/41024) | Learning rate: (0.0001)
2022-06-06 20:17:31,913 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 650 |  Loss: (0.0302) | Acc: (99.01%) (41251/41664) | Learning rate: (0.0001)
2022-06-06 20:17:33,711 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 660 |  Loss: (0.0302) | Acc: (99.00%) (41882/42304) | Learning rate: (0.0001)
2022-06-06 20:17:35,509 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 670 |  Loss: (0.0301) | Acc: (99.01%) (42517/42944) | Learning rate: (0.0001)
2022-06-06 20:17:37,310 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 680 |  Loss: (0.0301) | Acc: (99.00%) (43150/43584) | Learning rate: (0.0001)
2022-06-06 20:17:39,109 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 690 |  Loss: (0.0303) | Acc: (99.00%) (43783/44224) | Learning rate: (0.0001)
2022-06-06 20:17:40,908 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 700 |  Loss: (0.0304) | Acc: (99.00%) (44415/44864) | Learning rate: (0.0001)
2022-06-06 20:17:42,707 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 710 |  Loss: (0.0302) | Acc: (99.00%) (45050/45504) | Learning rate: (0.0001)
2022-06-06 20:17:44,508 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 720 |  Loss: (0.0305) | Acc: (99.00%) (45681/46144) | Learning rate: (0.0001)
2022-06-06 20:17:46,306 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 730 |  Loss: (0.0306) | Acc: (98.99%) (46313/46784) | Learning rate: (0.0001)
2022-06-06 20:17:48,107 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 740 |  Loss: (0.0307) | Acc: (99.00%) (46948/47424) | Learning rate: (0.0001)
2022-06-06 20:17:49,904 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 750 |  Loss: (0.0308) | Acc: (98.99%) (47580/48064) | Learning rate: (0.0001)
2022-06-06 20:17:51,704 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 760 |  Loss: (0.0306) | Acc: (99.00%) (48217/48704) | Learning rate: (0.0001)
2022-06-06 20:17:53,494 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 770 |  Loss: (0.0306) | Acc: (99.00%) (48850/49344) | Learning rate: (0.0001)
2022-06-06 20:17:55,283 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 780 |  Loss: (0.0305) | Acc: (99.00%) (49485/49984) | Learning rate: (0.0001)
2022-06-06 20:18:05,243 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0874) | Acc: (97.50%) (9750/10000)
2022-06-06 20:18:05,244 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:18:06,034 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 0 |  Loss: (0.0080) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:18:07,853 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 10 |  Loss: (0.0197) | Acc: (99.43%) (700/704) | Learning rate: (0.0001)
2022-06-06 20:18:09,649 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 20 |  Loss: (0.0223) | Acc: (99.33%) (1335/1344) | Learning rate: (0.0001)
2022-06-06 20:18:11,442 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 30 |  Loss: (0.0262) | Acc: (99.24%) (1969/1984) | Learning rate: (0.0001)
2022-06-06 20:18:13,239 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 40 |  Loss: (0.0254) | Acc: (99.24%) (2604/2624) | Learning rate: (0.0001)
2022-06-06 20:18:15,037 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 50 |  Loss: (0.0245) | Acc: (99.30%) (3241/3264) | Learning rate: (0.0001)
2022-06-06 20:18:16,835 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 60 |  Loss: (0.0245) | Acc: (99.23%) (3874/3904) | Learning rate: (0.0001)
2022-06-06 20:18:18,633 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 70 |  Loss: (0.0257) | Acc: (99.23%) (4509/4544) | Learning rate: (0.0001)
2022-06-06 20:18:20,429 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 80 |  Loss: (0.0248) | Acc: (99.23%) (5144/5184) | Learning rate: (0.0001)
2022-06-06 20:18:22,226 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 90 |  Loss: (0.0233) | Acc: (99.28%) (5782/5824) | Learning rate: (0.0001)
2022-06-06 20:18:24,023 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 100 |  Loss: (0.0239) | Acc: (99.29%) (6418/6464) | Learning rate: (0.0001)
2022-06-06 20:18:25,821 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 110 |  Loss: (0.0229) | Acc: (99.34%) (7057/7104) | Learning rate: (0.0001)
2022-06-06 20:18:27,618 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 120 |  Loss: (0.0260) | Acc: (99.26%) (7687/7744) | Learning rate: (0.0001)
2022-06-06 20:18:29,415 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 130 |  Loss: (0.0258) | Acc: (99.26%) (8322/8384) | Learning rate: (0.0001)
2022-06-06 20:18:31,213 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 140 |  Loss: (0.0248) | Acc: (99.29%) (8960/9024) | Learning rate: (0.0001)
2022-06-06 20:18:33,010 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 150 |  Loss: (0.0241) | Acc: (99.31%) (9597/9664) | Learning rate: (0.0001)
2022-06-06 20:18:34,809 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 160 |  Loss: (0.0240) | Acc: (99.30%) (10232/10304) | Learning rate: (0.0001)
2022-06-06 20:18:36,608 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 170 |  Loss: (0.0232) | Acc: (99.32%) (10870/10944) | Learning rate: (0.0001)
2022-06-06 20:18:38,406 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 180 |  Loss: (0.0230) | Acc: (99.30%) (11503/11584) | Learning rate: (0.0001)
2022-06-06 20:18:40,203 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 190 |  Loss: (0.0232) | Acc: (99.30%) (12138/12224) | Learning rate: (0.0001)
2022-06-06 20:18:42,001 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 200 |  Loss: (0.0231) | Acc: (99.29%) (12773/12864) | Learning rate: (0.0001)
2022-06-06 20:18:43,800 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 210 |  Loss: (0.0234) | Acc: (99.27%) (13405/13504) | Learning rate: (0.0001)
2022-06-06 20:18:45,596 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 220 |  Loss: (0.0232) | Acc: (99.26%) (14039/14144) | Learning rate: (0.0001)
2022-06-06 20:18:47,394 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 230 |  Loss: (0.0226) | Acc: (99.28%) (14677/14784) | Learning rate: (0.0001)
2022-06-06 20:18:49,191 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 240 |  Loss: (0.0224) | Acc: (99.28%) (15313/15424) | Learning rate: (0.0001)
2022-06-06 20:18:50,988 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 250 |  Loss: (0.0226) | Acc: (99.27%) (15947/16064) | Learning rate: (0.0001)
2022-06-06 20:18:52,786 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 260 |  Loss: (0.0226) | Acc: (99.26%) (16581/16704) | Learning rate: (0.0001)
2022-06-06 20:18:54,584 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 270 |  Loss: (0.0223) | Acc: (99.28%) (17219/17344) | Learning rate: (0.0001)
2022-06-06 20:18:56,382 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 280 |  Loss: (0.0221) | Acc: (99.28%) (17854/17984) | Learning rate: (0.0001)
2022-06-06 20:18:58,183 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 290 |  Loss: (0.0222) | Acc: (99.28%) (18489/18624) | Learning rate: (0.0001)
2022-06-06 20:18:59,980 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 300 |  Loss: (0.0225) | Acc: (99.26%) (19122/19264) | Learning rate: (0.0001)
2022-06-06 20:19:01,780 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 310 |  Loss: (0.0226) | Acc: (99.26%) (19756/19904) | Learning rate: (0.0001)
2022-06-06 20:19:03,579 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 320 |  Loss: (0.0226) | Acc: (99.26%) (20391/20544) | Learning rate: (0.0001)
2022-06-06 20:19:05,376 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 330 |  Loss: (0.0225) | Acc: (99.25%) (21026/21184) | Learning rate: (0.0001)
2022-06-06 20:19:07,175 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 340 |  Loss: (0.0222) | Acc: (99.26%) (21662/21824) | Learning rate: (0.0001)
2022-06-06 20:19:08,974 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 350 |  Loss: (0.0221) | Acc: (99.26%) (22298/22464) | Learning rate: (0.0001)
2022-06-06 20:19:15,914 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 20:19:15,916 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 20:19:15,916 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 20:19:15,917 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 20:19:15,917 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 20:19:16,896 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (2.3303) | Acc: (7.81%) (5/64) | Learning rate: (0.0001)
2022-06-06 20:19:18,708 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (2.2888) | Acc: (12.64%) (89/704) | Learning rate: (0.0001)
2022-06-06 20:19:20,500 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (2.2560) | Acc: (17.34%) (233/1344) | Learning rate: (0.0001)
2022-06-06 20:19:22,293 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (2.2213) | Acc: (21.57%) (428/1984) | Learning rate: (0.0001)
2022-06-06 20:19:24,087 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (2.1785) | Acc: (27.32%) (717/2624) | Learning rate: (0.0001)
2022-06-06 20:19:25,879 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 50 |  Loss: (2.1310) | Acc: (31.40%) (1025/3264) | Learning rate: (0.0001)
2022-06-06 20:19:27,674 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 60 |  Loss: (2.0716) | Acc: (36.07%) (1408/3904) | Learning rate: (0.0001)
2022-06-06 20:19:29,470 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 70 |  Loss: (1.9989) | Acc: (40.43%) (1837/4544) | Learning rate: (0.0001)
2022-06-06 20:19:31,263 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 80 |  Loss: (1.9172) | Acc: (44.52%) (2308/5184) | Learning rate: (0.0001)
2022-06-06 20:19:33,057 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 90 |  Loss: (1.8339) | Acc: (47.84%) (2786/5824) | Learning rate: (0.0001)
2022-06-06 20:19:34,850 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 100 |  Loss: (1.7492) | Acc: (50.99%) (3296/6464) | Learning rate: (0.0001)
2022-06-06 20:19:36,646 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 110 |  Loss: (1.6707) | Acc: (53.48%) (3799/7104) | Learning rate: (0.0001)
2022-06-06 20:19:38,441 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 120 |  Loss: (1.5924) | Acc: (55.80%) (4321/7744) | Learning rate: (0.0001)
2022-06-06 20:19:40,236 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 130 |  Loss: (1.5246) | Acc: (57.76%) (4843/8384) | Learning rate: (0.0001)
2022-06-06 20:19:42,031 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 140 |  Loss: (1.4611) | Acc: (59.53%) (5372/9024) | Learning rate: (0.0001)
2022-06-06 20:19:43,828 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 150 |  Loss: (1.4031) | Acc: (61.04%) (5899/9664) | Learning rate: (0.0001)
2022-06-06 20:19:45,626 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 160 |  Loss: (1.3522) | Acc: (62.43%) (6433/10304) | Learning rate: (0.0001)
2022-06-06 20:19:47,422 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 170 |  Loss: (1.3023) | Acc: (63.72%) (6973/10944) | Learning rate: (0.0001)
2022-06-06 20:19:49,221 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 180 |  Loss: (1.2564) | Acc: (64.99%) (7529/11584) | Learning rate: (0.0001)
2022-06-06 20:19:51,017 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 190 |  Loss: (1.2136) | Acc: (66.23%) (8096/12224) | Learning rate: (0.0001)
2022-06-06 20:19:52,814 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 200 |  Loss: (1.1762) | Acc: (67.25%) (8651/12864) | Learning rate: (0.0001)
2022-06-06 20:19:54,609 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 210 |  Loss: (1.1395) | Acc: (68.19%) (9209/13504) | Learning rate: (0.0001)
2022-06-06 20:19:56,405 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 220 |  Loss: (1.1064) | Acc: (69.05%) (9767/14144) | Learning rate: (0.0001)
2022-06-06 20:19:58,202 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 230 |  Loss: (1.0746) | Acc: (69.96%) (10343/14784) | Learning rate: (0.0001)
2022-06-06 20:19:59,998 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 240 |  Loss: (1.0454) | Acc: (70.78%) (10917/15424) | Learning rate: (0.0001)
2022-06-06 20:20:01,796 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 250 |  Loss: (1.0200) | Acc: (71.47%) (11481/16064) | Learning rate: (0.0001)
2022-06-06 20:20:03,594 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 260 |  Loss: (0.9952) | Acc: (72.11%) (12046/16704) | Learning rate: (0.0001)
2022-06-06 20:20:05,393 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 270 |  Loss: (0.9711) | Acc: (72.75%) (12617/17344) | Learning rate: (0.0001)
2022-06-06 20:20:07,191 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 280 |  Loss: (0.9486) | Acc: (73.34%) (13190/17984) | Learning rate: (0.0001)
2022-06-06 20:20:08,990 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 290 |  Loss: (0.9270) | Acc: (73.93%) (13769/18624) | Learning rate: (0.0001)
2022-06-06 20:20:10,788 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 300 |  Loss: (0.9067) | Acc: (74.43%) (14338/19264) | Learning rate: (0.0001)
2022-06-06 20:20:12,585 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 310 |  Loss: (0.8870) | Acc: (74.94%) (14917/19904) | Learning rate: (0.0001)
2022-06-06 20:20:14,384 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 320 |  Loss: (0.8682) | Acc: (75.47%) (15504/20544) | Learning rate: (0.0001)
2022-06-06 20:20:16,180 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 330 |  Loss: (0.8514) | Acc: (75.91%) (16081/21184) | Learning rate: (0.0001)
2022-06-06 20:20:17,978 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 340 |  Loss: (0.8351) | Acc: (76.34%) (16660/21824) | Learning rate: (0.0001)
2022-06-06 20:20:19,776 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 350 |  Loss: (0.8200) | Acc: (76.73%) (17236/22464) | Learning rate: (0.0001)
2022-06-06 20:20:21,573 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 360 |  Loss: (0.8057) | Acc: (77.09%) (17812/23104) | Learning rate: (0.0001)
2022-06-06 20:20:23,370 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 370 |  Loss: (0.7926) | Acc: (77.45%) (18390/23744) | Learning rate: (0.0001)
2022-06-06 20:20:25,167 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 380 |  Loss: (0.7794) | Acc: (77.78%) (18966/24384) | Learning rate: (0.0001)
2022-06-06 20:20:26,965 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 390 |  Loss: (0.7674) | Acc: (78.06%) (19534/25024) | Learning rate: (0.0001)
2022-06-06 20:20:28,761 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 400 |  Loss: (0.7557) | Acc: (78.36%) (20111/25664) | Learning rate: (0.0001)
2022-06-06 20:20:30,559 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 410 |  Loss: (0.7453) | Acc: (78.64%) (20686/26304) | Learning rate: (0.0001)
2022-06-06 20:20:32,355 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 420 |  Loss: (0.7340) | Acc: (78.95%) (21271/26944) | Learning rate: (0.0001)
2022-06-06 20:20:34,153 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 430 |  Loss: (0.7240) | Acc: (79.20%) (21846/27584) | Learning rate: (0.0001)
2022-06-06 20:20:35,950 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 440 |  Loss: (0.7136) | Acc: (79.48%) (22432/28224) | Learning rate: (0.0001)
2022-06-06 20:20:37,747 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 450 |  Loss: (0.7054) | Acc: (79.69%) (23003/28864) | Learning rate: (0.0001)
2022-06-06 20:20:39,546 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 460 |  Loss: (0.6962) | Acc: (79.96%) (23590/29504) | Learning rate: (0.0001)
2022-06-06 20:20:41,344 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 470 |  Loss: (0.6861) | Acc: (80.22%) (24182/30144) | Learning rate: (0.0001)
2022-06-06 20:20:43,142 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 480 |  Loss: (0.6763) | Acc: (80.47%) (24771/30784) | Learning rate: (0.0001)
2022-06-06 20:20:44,939 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 490 |  Loss: (0.6683) | Acc: (80.67%) (25349/31424) | Learning rate: (0.0001)
2022-06-06 20:20:46,738 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 500 |  Loss: (0.6599) | Acc: (80.89%) (25937/32064) | Learning rate: (0.0001)
2022-06-06 20:20:48,536 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 510 |  Loss: (0.6522) | Acc: (81.09%) (26521/32704) | Learning rate: (0.0001)
2022-06-06 20:20:50,334 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 520 |  Loss: (0.6440) | Acc: (81.32%) (27117/33344) | Learning rate: (0.0001)
2022-06-06 20:20:52,131 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 530 |  Loss: (0.6366) | Acc: (81.54%) (27711/33984) | Learning rate: (0.0001)
2022-06-06 20:20:53,930 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 540 |  Loss: (0.6303) | Acc: (81.70%) (28289/34624) | Learning rate: (0.0001)
2022-06-06 20:20:55,729 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 550 |  Loss: (0.6236) | Acc: (81.88%) (28874/35264) | Learning rate: (0.0001)
2022-06-06 20:20:57,529 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 560 |  Loss: (0.6173) | Acc: (82.02%) (29450/35904) | Learning rate: (0.0001)
2022-06-06 20:20:59,327 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 570 |  Loss: (0.6103) | Acc: (82.23%) (30050/36544) | Learning rate: (0.0001)
2022-06-06 20:21:01,123 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 580 |  Loss: (0.6035) | Acc: (82.43%) (30652/37184) | Learning rate: (0.0001)
2022-06-06 20:21:02,924 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 590 |  Loss: (0.5969) | Acc: (82.62%) (31249/37824) | Learning rate: (0.0001)
2022-06-06 20:21:04,720 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 600 |  Loss: (0.5908) | Acc: (82.78%) (31842/38464) | Learning rate: (0.0001)
2022-06-06 20:21:06,519 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 610 |  Loss: (0.5845) | Acc: (82.95%) (32437/39104) | Learning rate: (0.0001)
2022-06-06 20:21:08,319 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 620 |  Loss: (0.5788) | Acc: (83.10%) (33028/39744) | Learning rate: (0.0001)
2022-06-06 20:21:10,116 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 630 |  Loss: (0.5732) | Acc: (83.25%) (33620/40384) | Learning rate: (0.0001)
2022-06-06 20:21:11,915 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 640 |  Loss: (0.5682) | Acc: (83.39%) (34209/41024) | Learning rate: (0.0001)
2022-06-06 20:21:13,714 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 650 |  Loss: (0.5638) | Acc: (83.50%) (34790/41664) | Learning rate: (0.0001)
2022-06-06 20:21:15,512 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 660 |  Loss: (0.5584) | Acc: (83.63%) (35379/42304) | Learning rate: (0.0001)
2022-06-06 20:21:17,310 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 670 |  Loss: (0.5536) | Acc: (83.76%) (35970/42944) | Learning rate: (0.0001)
2022-06-06 20:21:19,109 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 680 |  Loss: (0.5488) | Acc: (83.90%) (36567/43584) | Learning rate: (0.0001)
2022-06-06 20:21:20,908 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 690 |  Loss: (0.5441) | Acc: (84.02%) (37158/44224) | Learning rate: (0.0001)
2022-06-06 20:21:22,706 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 700 |  Loss: (0.5391) | Acc: (84.16%) (37757/44864) | Learning rate: (0.0001)
2022-06-06 20:21:24,506 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 710 |  Loss: (0.5352) | Acc: (84.27%) (38344/45504) | Learning rate: (0.0001)
2022-06-06 20:21:26,305 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 720 |  Loss: (0.5299) | Acc: (84.41%) (38950/46144) | Learning rate: (0.0001)
2022-06-06 20:21:28,105 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 730 |  Loss: (0.5254) | Acc: (84.54%) (39551/46784) | Learning rate: (0.0001)
2022-06-06 20:21:29,903 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 740 |  Loss: (0.5217) | Acc: (84.64%) (40139/47424) | Learning rate: (0.0001)
2022-06-06 20:21:31,704 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 750 |  Loss: (0.5177) | Acc: (84.75%) (40734/48064) | Learning rate: (0.0001)
2022-06-06 20:21:33,502 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 760 |  Loss: (0.5134) | Acc: (84.87%) (41335/48704) | Learning rate: (0.0001)
2022-06-06 20:21:35,290 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 770 |  Loss: (0.5099) | Acc: (84.97%) (41927/49344) | Learning rate: (0.0001)
2022-06-06 20:21:37,080 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 780 |  Loss: (0.5063) | Acc: (85.06%) (42518/49984) | Learning rate: (0.0001)
2022-06-06 20:21:47,329 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1463) | Acc: (94.90%) (9490/10000)
2022-06-06 20:21:47,330 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:21:48,593 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 0 |  Loss: (0.0902) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:21:50,400 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 10 |  Loss: (0.1851) | Acc: (94.74%) (667/704) | Learning rate: (0.0001)
2022-06-06 20:21:52,197 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 20 |  Loss: (0.1944) | Acc: (93.60%) (1258/1344) | Learning rate: (0.0001)
2022-06-06 20:21:53,990 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 30 |  Loss: (0.1805) | Acc: (94.15%) (1868/1984) | Learning rate: (0.0001)
2022-06-06 20:21:55,790 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 40 |  Loss: (0.1802) | Acc: (94.17%) (2471/2624) | Learning rate: (0.0001)
2022-06-06 20:21:57,587 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 50 |  Loss: (0.1784) | Acc: (94.18%) (3074/3264) | Learning rate: (0.0001)
2022-06-06 20:21:59,384 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 60 |  Loss: (0.1751) | Acc: (94.42%) (3686/3904) | Learning rate: (0.0001)
2022-06-06 20:22:01,183 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 70 |  Loss: (0.1726) | Acc: (94.52%) (4295/4544) | Learning rate: (0.0001)
2022-06-06 20:22:02,980 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 80 |  Loss: (0.1711) | Acc: (94.62%) (4905/5184) | Learning rate: (0.0001)
2022-06-06 20:22:04,779 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 90 |  Loss: (0.1729) | Acc: (94.56%) (5507/5824) | Learning rate: (0.0001)
2022-06-06 20:22:06,575 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 100 |  Loss: (0.1700) | Acc: (94.65%) (6118/6464) | Learning rate: (0.0001)
2022-06-06 20:22:08,374 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 110 |  Loss: (0.1736) | Acc: (94.48%) (6712/7104) | Learning rate: (0.0001)
2022-06-06 20:22:10,172 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 120 |  Loss: (0.1749) | Acc: (94.47%) (7316/7744) | Learning rate: (0.0001)
2022-06-06 20:22:11,971 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 130 |  Loss: (0.1744) | Acc: (94.57%) (7929/8384) | Learning rate: (0.0001)
2022-06-06 20:22:13,768 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 140 |  Loss: (0.1766) | Acc: (94.49%) (8527/9024) | Learning rate: (0.0001)
2022-06-06 20:22:15,567 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 150 |  Loss: (0.1775) | Acc: (94.47%) (9130/9664) | Learning rate: (0.0001)
2022-06-06 20:22:17,363 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 160 |  Loss: (0.1786) | Acc: (94.40%) (9727/10304) | Learning rate: (0.0001)
2022-06-06 20:22:19,159 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 170 |  Loss: (0.1805) | Acc: (94.32%) (10322/10944) | Learning rate: (0.0001)
2022-06-06 20:22:20,957 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 180 |  Loss: (0.1818) | Acc: (94.27%) (10920/11584) | Learning rate: (0.0001)
2022-06-06 20:22:22,754 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 190 |  Loss: (0.1810) | Acc: (94.27%) (11523/12224) | Learning rate: (0.0001)
2022-06-06 20:22:24,552 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 200 |  Loss: (0.1820) | Acc: (94.22%) (12121/12864) | Learning rate: (0.0001)
2022-06-06 20:22:26,350 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 210 |  Loss: (0.1807) | Acc: (94.28%) (12731/13504) | Learning rate: (0.0001)
2022-06-06 20:22:28,149 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 220 |  Loss: (0.1809) | Acc: (94.30%) (13338/14144) | Learning rate: (0.0001)
2022-06-06 20:22:29,949 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 230 |  Loss: (0.1796) | Acc: (94.33%) (13946/14784) | Learning rate: (0.0001)
2022-06-06 20:22:31,748 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 240 |  Loss: (0.1804) | Acc: (94.32%) (14548/15424) | Learning rate: (0.0001)
2022-06-06 20:22:33,547 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 250 |  Loss: (0.1795) | Acc: (94.38%) (15161/16064) | Learning rate: (0.0001)
2022-06-06 20:22:35,347 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 260 |  Loss: (0.1789) | Acc: (94.40%) (15768/16704) | Learning rate: (0.0001)
2022-06-06 20:22:37,147 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 270 |  Loss: (0.1778) | Acc: (94.44%) (16379/17344) | Learning rate: (0.0001)
2022-06-06 20:22:38,946 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 280 |  Loss: (0.1772) | Acc: (94.47%) (16989/17984) | Learning rate: (0.0001)
2022-06-06 20:22:40,747 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 290 |  Loss: (0.1768) | Acc: (94.45%) (17591/18624) | Learning rate: (0.0001)
2022-06-06 20:22:42,549 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 300 |  Loss: (0.1750) | Acc: (94.51%) (18206/19264) | Learning rate: (0.0001)
2022-06-06 20:22:44,348 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 310 |  Loss: (0.1759) | Acc: (94.49%) (18808/19904) | Learning rate: (0.0001)
2022-06-06 20:22:46,148 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 320 |  Loss: (0.1743) | Acc: (94.54%) (19423/20544) | Learning rate: (0.0001)
2022-06-06 20:22:47,947 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 330 |  Loss: (0.1751) | Acc: (94.51%) (20021/21184) | Learning rate: (0.0001)
2022-06-06 20:22:49,747 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 340 |  Loss: (0.1739) | Acc: (94.54%) (20632/21824) | Learning rate: (0.0001)
2022-06-06 20:22:51,545 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 350 |  Loss: (0.1741) | Acc: (94.53%) (21236/22464) | Learning rate: (0.0001)
2022-06-06 20:22:53,345 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 360 |  Loss: (0.1743) | Acc: (94.55%) (21844/23104) | Learning rate: (0.0001)
2022-06-06 20:22:55,147 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 370 |  Loss: (0.1732) | Acc: (94.59%) (22459/23744) | Learning rate: (0.0001)
2022-06-06 20:22:56,946 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 380 |  Loss: (0.1730) | Acc: (94.57%) (23061/24384) | Learning rate: (0.0001)
2022-06-06 20:22:58,746 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 390 |  Loss: (0.1731) | Acc: (94.56%) (23663/25024) | Learning rate: (0.0001)
2022-06-06 20:23:00,545 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 400 |  Loss: (0.1729) | Acc: (94.56%) (24267/25664) | Learning rate: (0.0001)
2022-06-06 20:23:02,345 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 410 |  Loss: (0.1716) | Acc: (94.59%) (24881/26304) | Learning rate: (0.0001)
2022-06-06 20:23:04,144 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 420 |  Loss: (0.1714) | Acc: (94.59%) (25487/26944) | Learning rate: (0.0001)
2022-06-06 20:23:05,943 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 430 |  Loss: (0.1708) | Acc: (94.59%) (26092/27584) | Learning rate: (0.0001)
2022-06-06 20:23:07,743 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 440 |  Loss: (0.1701) | Acc: (94.60%) (26701/28224) | Learning rate: (0.0001)
2022-06-06 20:23:09,543 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 450 |  Loss: (0.1695) | Acc: (94.60%) (27306/28864) | Learning rate: (0.0001)
2022-06-06 20:23:11,344 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 460 |  Loss: (0.1696) | Acc: (94.61%) (27913/29504) | Learning rate: (0.0001)
2022-06-06 20:23:13,144 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 470 |  Loss: (0.1692) | Acc: (94.61%) (28519/30144) | Learning rate: (0.0001)
2022-06-06 20:23:14,943 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 480 |  Loss: (0.1688) | Acc: (94.61%) (29124/30784) | Learning rate: (0.0001)
2022-06-06 20:23:16,740 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 490 |  Loss: (0.1687) | Acc: (94.59%) (29725/31424) | Learning rate: (0.0001)
2022-06-06 20:23:18,541 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 500 |  Loss: (0.1681) | Acc: (94.64%) (30344/32064) | Learning rate: (0.0001)
2022-06-06 20:23:20,341 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 510 |  Loss: (0.1679) | Acc: (94.64%) (30950/32704) | Learning rate: (0.0001)
2022-06-06 20:23:22,140 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 520 |  Loss: (0.1672) | Acc: (94.65%) (31561/33344) | Learning rate: (0.0001)
2022-06-06 20:23:23,938 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 530 |  Loss: (0.1663) | Acc: (94.68%) (32175/33984) | Learning rate: (0.0001)
2022-06-06 20:23:25,737 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 540 |  Loss: (0.1666) | Acc: (94.65%) (32773/34624) | Learning rate: (0.0001)
2022-06-06 20:23:27,533 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 550 |  Loss: (0.1665) | Acc: (94.67%) (33386/35264) | Learning rate: (0.0001)
2022-06-06 20:23:29,332 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 560 |  Loss: (0.1662) | Acc: (94.69%) (33996/35904) | Learning rate: (0.0001)
2022-06-06 20:23:31,132 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 570 |  Loss: (0.1655) | Acc: (94.71%) (34610/36544) | Learning rate: (0.0001)
2022-06-06 20:23:32,930 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 580 |  Loss: (0.1656) | Acc: (94.70%) (35215/37184) | Learning rate: (0.0001)
2022-06-06 20:23:34,730 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 590 |  Loss: (0.1653) | Acc: (94.73%) (35830/37824) | Learning rate: (0.0001)
2022-06-06 20:23:36,529 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 600 |  Loss: (0.1648) | Acc: (94.75%) (36445/38464) | Learning rate: (0.0001)
2022-06-06 20:23:38,329 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 610 |  Loss: (0.1648) | Acc: (94.75%) (37051/39104) | Learning rate: (0.0001)
2022-06-06 20:23:40,128 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 620 |  Loss: (0.1646) | Acc: (94.75%) (37656/39744) | Learning rate: (0.0001)
2022-06-06 20:23:41,929 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 630 |  Loss: (0.1642) | Acc: (94.75%) (38264/40384) | Learning rate: (0.0001)
2022-06-06 20:23:43,728 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 640 |  Loss: (0.1634) | Acc: (94.77%) (38878/41024) | Learning rate: (0.0001)
2022-06-06 20:23:45,528 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 650 |  Loss: (0.1629) | Acc: (94.79%) (39493/41664) | Learning rate: (0.0001)
2022-06-06 20:23:47,328 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 660 |  Loss: (0.1623) | Acc: (94.81%) (40107/42304) | Learning rate: (0.0001)
2022-06-06 20:23:49,128 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 670 |  Loss: (0.1626) | Acc: (94.80%) (40709/42944) | Learning rate: (0.0001)
2022-06-06 20:23:50,926 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 680 |  Loss: (0.1626) | Acc: (94.80%) (41317/43584) | Learning rate: (0.0001)
2022-06-06 20:23:52,725 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 690 |  Loss: (0.1624) | Acc: (94.80%) (41926/44224) | Learning rate: (0.0001)
2022-06-06 20:23:54,525 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 700 |  Loss: (0.1620) | Acc: (94.81%) (42534/44864) | Learning rate: (0.0001)
2022-06-06 20:23:56,323 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 710 |  Loss: (0.1621) | Acc: (94.82%) (43145/45504) | Learning rate: (0.0001)
2022-06-06 20:23:58,123 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 720 |  Loss: (0.1618) | Acc: (94.83%) (43760/46144) | Learning rate: (0.0001)
2022-06-06 20:23:59,923 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 730 |  Loss: (0.1612) | Acc: (94.85%) (44375/46784) | Learning rate: (0.0001)
2022-06-06 20:24:01,722 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 740 |  Loss: (0.1604) | Acc: (94.88%) (44996/47424) | Learning rate: (0.0001)
2022-06-06 20:24:03,522 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 750 |  Loss: (0.1605) | Acc: (94.87%) (45597/48064) | Learning rate: (0.0001)
2022-06-06 20:24:05,320 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 760 |  Loss: (0.1606) | Acc: (94.87%) (46204/48704) | Learning rate: (0.0001)
2022-06-06 20:24:07,110 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 770 |  Loss: (0.1607) | Acc: (94.85%) (46802/49344) | Learning rate: (0.0001)
2022-06-06 20:24:08,901 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 780 |  Loss: (0.1605) | Acc: (94.86%) (47416/49984) | Learning rate: (0.0001)
2022-06-06 20:24:19,236 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1145) | Acc: (96.32%) (9632/10000)
2022-06-06 20:24:19,237 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:24:20,359 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 0 |  Loss: (0.2503) | Acc: (92.19%) (59/64) | Learning rate: (0.0001)
2022-06-06 20:24:22,168 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 10 |  Loss: (0.1143) | Acc: (96.02%) (676/704) | Learning rate: (0.0001)
2022-06-06 20:24:23,963 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 20 |  Loss: (0.1291) | Acc: (95.83%) (1288/1344) | Learning rate: (0.0001)
2022-06-06 20:24:25,758 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 30 |  Loss: (0.1366) | Acc: (95.72%) (1899/1984) | Learning rate: (0.0001)
2022-06-06 20:24:27,554 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 40 |  Loss: (0.1352) | Acc: (95.58%) (2508/2624) | Learning rate: (0.0001)
2022-06-06 20:24:29,350 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 50 |  Loss: (0.1351) | Acc: (95.59%) (3120/3264) | Learning rate: (0.0001)
2022-06-06 20:24:31,149 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 60 |  Loss: (0.1285) | Acc: (95.85%) (3742/3904) | Learning rate: (0.0001)
2022-06-06 20:24:32,945 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 70 |  Loss: (0.1252) | Acc: (95.95%) (4360/4544) | Learning rate: (0.0001)
2022-06-06 20:24:34,740 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 80 |  Loss: (0.1225) | Acc: (95.97%) (4975/5184) | Learning rate: (0.0001)
2022-06-06 20:24:36,536 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 90 |  Loss: (0.1210) | Acc: (95.98%) (5590/5824) | Learning rate: (0.0001)
2022-06-06 20:24:38,334 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 100 |  Loss: (0.1222) | Acc: (95.88%) (6198/6464) | Learning rate: (0.0001)
2022-06-06 20:24:40,129 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 110 |  Loss: (0.1223) | Acc: (95.95%) (6816/7104) | Learning rate: (0.0001)
2022-06-06 20:24:41,927 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 120 |  Loss: (0.1223) | Acc: (95.91%) (7427/7744) | Learning rate: (0.0001)
2022-06-06 20:24:43,726 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 130 |  Loss: (0.1223) | Acc: (95.93%) (8043/8384) | Learning rate: (0.0001)
2022-06-06 20:24:45,524 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 140 |  Loss: (0.1230) | Acc: (95.89%) (8653/9024) | Learning rate: (0.0001)
2022-06-06 20:24:47,322 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 150 |  Loss: (0.1206) | Acc: (95.95%) (9273/9664) | Learning rate: (0.0001)
2022-06-06 20:24:49,119 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 160 |  Loss: (0.1191) | Acc: (95.99%) (9891/10304) | Learning rate: (0.0001)
2022-06-06 20:24:50,917 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 170 |  Loss: (0.1205) | Acc: (95.93%) (10499/10944) | Learning rate: (0.0001)
2022-06-06 20:24:52,714 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 180 |  Loss: (0.1194) | Acc: (95.98%) (11118/11584) | Learning rate: (0.0001)
2022-06-06 20:24:54,511 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 190 |  Loss: (0.1191) | Acc: (96.01%) (11736/12224) | Learning rate: (0.0001)
2022-06-06 20:24:56,310 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 200 |  Loss: (0.1183) | Acc: (96.03%) (12353/12864) | Learning rate: (0.0001)
2022-06-06 20:24:58,111 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 210 |  Loss: (0.1177) | Acc: (96.06%) (12972/13504) | Learning rate: (0.0001)
2022-06-06 20:24:59,911 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 220 |  Loss: (0.1170) | Acc: (96.08%) (13590/14144) | Learning rate: (0.0001)
2022-06-06 20:25:01,710 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 230 |  Loss: (0.1167) | Acc: (96.10%) (14207/14784) | Learning rate: (0.0001)
2022-06-06 20:25:03,508 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 240 |  Loss: (0.1167) | Acc: (96.12%) (14826/15424) | Learning rate: (0.0001)
2022-06-06 20:25:05,305 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 250 |  Loss: (0.1165) | Acc: (96.12%) (15440/16064) | Learning rate: (0.0001)
2022-06-06 20:25:07,103 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 260 |  Loss: (0.1147) | Acc: (96.17%) (16065/16704) | Learning rate: (0.0001)
2022-06-06 20:25:08,900 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 270 |  Loss: (0.1149) | Acc: (96.18%) (16682/17344) | Learning rate: (0.0001)
2022-06-06 20:25:10,700 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 280 |  Loss: (0.1141) | Acc: (96.21%) (17303/17984) | Learning rate: (0.0001)
2022-06-06 20:25:12,497 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 290 |  Loss: (0.1134) | Acc: (96.24%) (17924/18624) | Learning rate: (0.0001)
2022-06-06 20:25:14,298 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 300 |  Loss: (0.1141) | Acc: (96.23%) (18538/19264) | Learning rate: (0.0001)
2022-06-06 20:25:16,096 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 310 |  Loss: (0.1136) | Acc: (96.25%) (19158/19904) | Learning rate: (0.0001)
2022-06-06 20:25:17,896 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 320 |  Loss: (0.1138) | Acc: (96.25%) (19773/20544) | Learning rate: (0.0001)
2022-06-06 20:25:19,695 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 330 |  Loss: (0.1138) | Acc: (96.26%) (20392/21184) | Learning rate: (0.0001)
2022-06-06 20:25:21,494 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 340 |  Loss: (0.1130) | Acc: (96.30%) (21017/21824) | Learning rate: (0.0001)
2022-06-06 20:25:23,293 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 350 |  Loss: (0.1133) | Acc: (96.29%) (21630/22464) | Learning rate: (0.0001)
2022-06-06 20:25:25,090 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 360 |  Loss: (0.1136) | Acc: (96.28%) (22244/23104) | Learning rate: (0.0001)
2022-06-06 20:25:26,889 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 370 |  Loss: (0.1133) | Acc: (96.30%) (22866/23744) | Learning rate: (0.0001)
2022-06-06 20:25:28,688 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 380 |  Loss: (0.1127) | Acc: (96.30%) (23483/24384) | Learning rate: (0.0001)
2022-06-06 20:25:30,485 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 390 |  Loss: (0.1122) | Acc: (96.32%) (24103/25024) | Learning rate: (0.0001)
2022-06-06 20:25:32,285 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 400 |  Loss: (0.1116) | Acc: (96.33%) (24723/25664) | Learning rate: (0.0001)
2022-06-06 20:25:34,081 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 410 |  Loss: (0.1122) | Acc: (96.30%) (25332/26304) | Learning rate: (0.0001)
2022-06-06 20:25:35,880 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 420 |  Loss: (0.1122) | Acc: (96.31%) (25949/26944) | Learning rate: (0.0001)
2022-06-06 20:25:37,678 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 430 |  Loss: (0.1124) | Acc: (96.29%) (26562/27584) | Learning rate: (0.0001)
2022-06-06 20:25:39,475 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 440 |  Loss: (0.1127) | Acc: (96.30%) (27180/28224) | Learning rate: (0.0001)
2022-06-06 20:25:41,272 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 450 |  Loss: (0.1128) | Acc: (96.29%) (27792/28864) | Learning rate: (0.0001)
2022-06-06 20:25:43,069 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 460 |  Loss: (0.1135) | Acc: (96.24%) (28396/29504) | Learning rate: (0.0001)
2022-06-06 20:25:44,866 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 470 |  Loss: (0.1130) | Acc: (96.25%) (29014/30144) | Learning rate: (0.0001)
2022-06-06 20:25:46,665 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 480 |  Loss: (0.1131) | Acc: (96.24%) (29626/30784) | Learning rate: (0.0001)
2022-06-06 20:25:48,465 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 490 |  Loss: (0.1129) | Acc: (96.23%) (30240/31424) | Learning rate: (0.0001)
2022-06-06 20:25:50,264 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 500 |  Loss: (0.1125) | Acc: (96.24%) (30858/32064) | Learning rate: (0.0001)
2022-06-06 20:25:52,064 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 510 |  Loss: (0.1124) | Acc: (96.25%) (31477/32704) | Learning rate: (0.0001)
2022-06-06 20:25:53,862 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 520 |  Loss: (0.1122) | Acc: (96.25%) (32095/33344) | Learning rate: (0.0001)
2022-06-06 20:25:55,660 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 530 |  Loss: (0.1119) | Acc: (96.26%) (32714/33984) | Learning rate: (0.0001)
2022-06-06 20:25:57,460 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 540 |  Loss: (0.1117) | Acc: (96.27%) (33333/34624) | Learning rate: (0.0001)
2022-06-06 20:25:59,258 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 550 |  Loss: (0.1115) | Acc: (96.28%) (33952/35264) | Learning rate: (0.0001)
2022-06-06 20:26:01,059 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 560 |  Loss: (0.1116) | Acc: (96.28%) (34567/35904) | Learning rate: (0.0001)
2022-06-06 20:26:02,858 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 570 |  Loss: (0.1109) | Acc: (96.31%) (35194/36544) | Learning rate: (0.0001)
2022-06-06 20:26:04,657 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 580 |  Loss: (0.1112) | Acc: (96.29%) (35804/37184) | Learning rate: (0.0001)
2022-06-06 20:26:06,457 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 590 |  Loss: (0.1110) | Acc: (96.29%) (36421/37824) | Learning rate: (0.0001)
2022-06-06 20:26:08,256 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 600 |  Loss: (0.1107) | Acc: (96.31%) (37043/38464) | Learning rate: (0.0001)
2022-06-06 20:26:10,055 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 610 |  Loss: (0.1112) | Acc: (96.30%) (37656/39104) | Learning rate: (0.0001)
2022-06-06 20:26:11,855 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 620 |  Loss: (0.1109) | Acc: (96.30%) (38273/39744) | Learning rate: (0.0001)
2022-06-06 20:26:13,652 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 630 |  Loss: (0.1106) | Acc: (96.31%) (38895/40384) | Learning rate: (0.0001)
2022-06-06 20:26:15,450 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 640 |  Loss: (0.1106) | Acc: (96.31%) (39511/41024) | Learning rate: (0.0001)
2022-06-06 20:26:17,249 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 650 |  Loss: (0.1103) | Acc: (96.32%) (40129/41664) | Learning rate: (0.0001)
2022-06-06 20:26:19,048 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 660 |  Loss: (0.1101) | Acc: (96.34%) (40754/42304) | Learning rate: (0.0001)
2022-06-06 20:26:20,849 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 670 |  Loss: (0.1098) | Acc: (96.34%) (41374/42944) | Learning rate: (0.0001)
2022-06-06 20:26:22,647 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 680 |  Loss: (0.1093) | Acc: (96.36%) (41997/43584) | Learning rate: (0.0001)
2022-06-06 20:26:24,446 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 690 |  Loss: (0.1093) | Acc: (96.36%) (42615/44224) | Learning rate: (0.0001)
2022-06-06 20:26:26,245 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 700 |  Loss: (0.1090) | Acc: (96.37%) (43234/44864) | Learning rate: (0.0001)
2022-06-06 20:26:28,042 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 710 |  Loss: (0.1089) | Acc: (96.37%) (43854/45504) | Learning rate: (0.0001)
2022-06-06 20:26:29,843 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 720 |  Loss: (0.1088) | Acc: (96.38%) (44472/46144) | Learning rate: (0.0001)
2022-06-06 20:26:31,642 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 730 |  Loss: (0.1090) | Acc: (96.38%) (45091/46784) | Learning rate: (0.0001)
2022-06-06 20:26:33,442 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 740 |  Loss: (0.1092) | Acc: (96.37%) (45701/47424) | Learning rate: (0.0001)
2022-06-06 20:26:35,240 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 750 |  Loss: (0.1094) | Acc: (96.36%) (46315/48064) | Learning rate: (0.0001)
2022-06-06 20:26:37,041 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 760 |  Loss: (0.1094) | Acc: (96.36%) (46931/48704) | Learning rate: (0.0001)
2022-06-06 20:26:38,830 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 770 |  Loss: (0.1095) | Acc: (96.35%) (47541/49344) | Learning rate: (0.0001)
2022-06-06 20:26:40,622 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 780 |  Loss: (0.1094) | Acc: (96.35%) (48159/49984) | Learning rate: (0.0001)
2022-06-06 20:26:50,874 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1081) | Acc: (96.44%) (9644/10000)
2022-06-06 20:26:50,875 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:26:51,975 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 0 |  Loss: (0.1507) | Acc: (95.31%) (61/64) | Learning rate: (0.0001)
2022-06-06 20:26:53,798 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 10 |  Loss: (0.0801) | Acc: (97.16%) (684/704) | Learning rate: (0.0001)
2022-06-06 20:26:55,592 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 20 |  Loss: (0.0793) | Acc: (97.40%) (1309/1344) | Learning rate: (0.0001)
2022-06-06 20:26:57,386 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 30 |  Loss: (0.0821) | Acc: (97.23%) (1929/1984) | Learning rate: (0.0001)
2022-06-06 20:26:59,181 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 40 |  Loss: (0.0824) | Acc: (97.10%) (2548/2624) | Learning rate: (0.0001)
2022-06-06 20:27:00,978 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 50 |  Loss: (0.0820) | Acc: (97.03%) (3167/3264) | Learning rate: (0.0001)
2022-06-06 20:27:02,777 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 60 |  Loss: (0.0829) | Acc: (97.03%) (3788/3904) | Learning rate: (0.0001)
2022-06-06 20:27:04,576 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 70 |  Loss: (0.0848) | Acc: (96.99%) (4407/4544) | Learning rate: (0.0001)
2022-06-06 20:27:06,374 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 80 |  Loss: (0.0828) | Acc: (97.01%) (5029/5184) | Learning rate: (0.0001)
2022-06-06 20:27:08,171 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 90 |  Loss: (0.0795) | Acc: (97.17%) (5659/5824) | Learning rate: (0.0001)
2022-06-06 20:27:09,970 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 100 |  Loss: (0.0818) | Acc: (97.05%) (6273/6464) | Learning rate: (0.0001)
2022-06-06 20:27:11,771 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 110 |  Loss: (0.0818) | Acc: (97.04%) (6894/7104) | Learning rate: (0.0001)
2022-06-06 20:27:13,568 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 120 |  Loss: (0.0812) | Acc: (97.07%) (7517/7744) | Learning rate: (0.0001)
2022-06-06 20:27:15,367 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 130 |  Loss: (0.0808) | Acc: (97.10%) (8141/8384) | Learning rate: (0.0001)
2022-06-06 20:27:17,164 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 140 |  Loss: (0.0795) | Acc: (97.13%) (8765/9024) | Learning rate: (0.0001)
2022-06-06 20:27:18,961 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 150 |  Loss: (0.0808) | Acc: (97.12%) (9386/9664) | Learning rate: (0.0001)
2022-06-06 20:27:20,757 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 160 |  Loss: (0.0808) | Acc: (97.13%) (10008/10304) | Learning rate: (0.0001)
2022-06-06 20:27:22,554 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 170 |  Loss: (0.0806) | Acc: (97.14%) (10631/10944) | Learning rate: (0.0001)
2022-06-06 20:27:24,350 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 180 |  Loss: (0.0801) | Acc: (97.18%) (11257/11584) | Learning rate: (0.0001)
2022-06-06 20:27:26,147 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 190 |  Loss: (0.0805) | Acc: (97.16%) (11877/12224) | Learning rate: (0.0001)
2022-06-06 20:27:27,944 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 200 |  Loss: (0.0799) | Acc: (97.19%) (12502/12864) | Learning rate: (0.0001)
2022-06-06 20:27:29,740 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 210 |  Loss: (0.0800) | Acc: (97.19%) (13124/13504) | Learning rate: (0.0001)
2022-06-06 20:27:31,536 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 220 |  Loss: (0.0792) | Acc: (97.23%) (13752/14144) | Learning rate: (0.0001)
2022-06-06 20:27:33,335 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 230 |  Loss: (0.0788) | Acc: (97.25%) (14378/14784) | Learning rate: (0.0001)
2022-06-06 20:27:35,133 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 240 |  Loss: (0.0781) | Acc: (97.28%) (15005/15424) | Learning rate: (0.0001)
2022-06-06 20:27:36,930 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 250 |  Loss: (0.0786) | Acc: (97.27%) (15626/16064) | Learning rate: (0.0001)
2022-06-06 20:27:38,728 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 260 |  Loss: (0.0785) | Acc: (97.26%) (16247/16704) | Learning rate: (0.0001)
2022-06-06 20:27:40,525 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 270 |  Loss: (0.0779) | Acc: (97.28%) (16873/17344) | Learning rate: (0.0001)
2022-06-06 20:27:42,323 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 280 |  Loss: (0.0767) | Acc: (97.33%) (17504/17984) | Learning rate: (0.0001)
2022-06-06 20:27:44,121 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 290 |  Loss: (0.0773) | Acc: (97.33%) (18127/18624) | Learning rate: (0.0001)
2022-06-06 20:27:45,920 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 300 |  Loss: (0.0778) | Acc: (97.30%) (18744/19264) | Learning rate: (0.0001)
2022-06-06 20:27:47,718 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 310 |  Loss: (0.0775) | Acc: (97.32%) (19370/19904) | Learning rate: (0.0001)
2022-06-06 20:27:49,517 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 320 |  Loss: (0.0769) | Acc: (97.34%) (19998/20544) | Learning rate: (0.0001)
2022-06-06 20:27:51,314 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 330 |  Loss: (0.0773) | Acc: (97.34%) (20620/21184) | Learning rate: (0.0001)
2022-06-06 20:27:53,112 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 340 |  Loss: (0.0768) | Acc: (97.36%) (21247/21824) | Learning rate: (0.0001)
2022-06-06 20:27:54,908 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 350 |  Loss: (0.0766) | Acc: (97.36%) (21871/22464) | Learning rate: (0.0001)
2022-06-06 20:27:56,707 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 360 |  Loss: (0.0773) | Acc: (97.35%) (22491/23104) | Learning rate: (0.0001)
2022-06-06 20:27:58,504 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 370 |  Loss: (0.0774) | Acc: (97.34%) (23112/23744) | Learning rate: (0.0001)
2022-06-06 20:28:00,302 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 380 |  Loss: (0.0773) | Acc: (97.34%) (23735/24384) | Learning rate: (0.0001)
2022-06-06 20:28:02,100 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 390 |  Loss: (0.0775) | Acc: (97.35%) (24362/25024) | Learning rate: (0.0001)
2022-06-06 20:28:03,897 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 400 |  Loss: (0.0774) | Acc: (97.35%) (24985/25664) | Learning rate: (0.0001)
2022-06-06 20:28:05,694 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 410 |  Loss: (0.0770) | Acc: (97.37%) (25612/26304) | Learning rate: (0.0001)
2022-06-06 20:28:07,495 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 420 |  Loss: (0.0766) | Acc: (97.37%) (26236/26944) | Learning rate: (0.0001)
2022-06-06 20:28:09,293 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 430 |  Loss: (0.0769) | Acc: (97.38%) (26860/27584) | Learning rate: (0.0001)
2022-06-06 20:28:11,093 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 440 |  Loss: (0.0771) | Acc: (97.36%) (27480/28224) | Learning rate: (0.0001)
2022-06-06 20:28:12,894 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 450 |  Loss: (0.0777) | Acc: (97.35%) (28099/28864) | Learning rate: (0.0001)
2022-06-06 20:28:14,696 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 460 |  Loss: (0.0777) | Acc: (97.36%) (28724/29504) | Learning rate: (0.0001)
2022-06-06 20:28:16,498 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 470 |  Loss: (0.0780) | Acc: (97.35%) (29346/30144) | Learning rate: (0.0001)
2022-06-06 20:28:18,295 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 480 |  Loss: (0.0781) | Acc: (97.35%) (29968/30784) | Learning rate: (0.0001)
2022-06-06 20:28:20,096 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 490 |  Loss: (0.0783) | Acc: (97.35%) (30591/31424) | Learning rate: (0.0001)
2022-06-06 20:28:21,894 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 500 |  Loss: (0.0784) | Acc: (97.35%) (31213/32064) | Learning rate: (0.0001)
2022-06-06 20:28:23,693 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 510 |  Loss: (0.0785) | Acc: (97.35%) (31836/32704) | Learning rate: (0.0001)
2022-06-06 20:28:25,492 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 520 |  Loss: (0.0780) | Acc: (97.36%) (32464/33344) | Learning rate: (0.0001)
2022-06-06 20:28:27,290 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 530 |  Loss: (0.0783) | Acc: (97.34%) (33080/33984) | Learning rate: (0.0001)
2022-06-06 20:28:29,090 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 540 |  Loss: (0.0781) | Acc: (97.34%) (33703/34624) | Learning rate: (0.0001)
2022-06-06 20:28:30,889 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 550 |  Loss: (0.0780) | Acc: (97.35%) (34330/35264) | Learning rate: (0.0001)
2022-06-06 20:28:32,687 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 560 |  Loss: (0.0784) | Acc: (97.33%) (34946/35904) | Learning rate: (0.0001)
2022-06-06 20:28:34,487 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 570 |  Loss: (0.0787) | Acc: (97.33%) (35567/36544) | Learning rate: (0.0001)
2022-06-06 20:28:36,285 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 580 |  Loss: (0.0787) | Acc: (97.32%) (36187/37184) | Learning rate: (0.0001)
2022-06-06 20:28:38,084 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 590 |  Loss: (0.0790) | Acc: (97.31%) (36807/37824) | Learning rate: (0.0001)
2022-06-06 20:28:39,883 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 600 |  Loss: (0.0789) | Acc: (97.31%) (37429/38464) | Learning rate: (0.0001)
2022-06-06 20:28:41,682 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 610 |  Loss: (0.0791) | Acc: (97.30%) (38050/39104) | Learning rate: (0.0001)
2022-06-06 20:28:43,482 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 620 |  Loss: (0.0789) | Acc: (97.31%) (38675/39744) | Learning rate: (0.0001)
2022-06-06 20:28:45,282 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 630 |  Loss: (0.0786) | Acc: (97.33%) (39305/40384) | Learning rate: (0.0001)
2022-06-06 20:28:47,079 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 640 |  Loss: (0.0792) | Acc: (97.30%) (39916/41024) | Learning rate: (0.0001)
2022-06-06 20:28:48,877 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 650 |  Loss: (0.0791) | Acc: (97.30%) (40540/41664) | Learning rate: (0.0001)
2022-06-06 20:28:50,675 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 660 |  Loss: (0.0790) | Acc: (97.31%) (41168/42304) | Learning rate: (0.0001)
2022-06-06 20:28:52,474 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 670 |  Loss: (0.0789) | Acc: (97.32%) (41793/42944) | Learning rate: (0.0001)
2022-06-06 20:28:54,275 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 680 |  Loss: (0.0789) | Acc: (97.32%) (42418/43584) | Learning rate: (0.0001)
2022-06-06 20:28:56,074 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 690 |  Loss: (0.0785) | Acc: (97.35%) (43050/44224) | Learning rate: (0.0001)
2022-06-06 20:28:57,874 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 700 |  Loss: (0.0790) | Acc: (97.33%) (43666/44864) | Learning rate: (0.0001)
2022-06-06 20:28:59,674 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 710 |  Loss: (0.0787) | Acc: (97.33%) (44290/45504) | Learning rate: (0.0001)
2022-06-06 20:29:01,473 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 720 |  Loss: (0.0788) | Acc: (97.33%) (44913/46144) | Learning rate: (0.0001)
2022-06-06 20:29:03,274 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 730 |  Loss: (0.0789) | Acc: (97.33%) (45537/46784) | Learning rate: (0.0001)
2022-06-06 20:29:05,071 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 740 |  Loss: (0.0786) | Acc: (97.34%) (46164/47424) | Learning rate: (0.0001)
2022-06-06 20:29:06,870 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 750 |  Loss: (0.0785) | Acc: (97.35%) (46791/48064) | Learning rate: (0.0001)
2022-06-06 20:29:08,670 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 760 |  Loss: (0.0786) | Acc: (97.35%) (47415/48704) | Learning rate: (0.0001)
2022-06-06 20:29:10,460 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 770 |  Loss: (0.0786) | Acc: (97.36%) (48039/49344) | Learning rate: (0.0001)
2022-06-06 20:29:12,251 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 780 |  Loss: (0.0785) | Acc: (97.36%) (48664/49984) | Learning rate: (0.0001)
2022-06-06 20:29:22,565 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1025) | Acc: (96.62%) (9662/10000)
2022-06-06 20:29:22,566 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:29:23,678 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 0 |  Loss: (0.0788) | Acc: (96.88%) (62/64) | Learning rate: (0.0001)
2022-06-06 20:29:25,504 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 10 |  Loss: (0.0758) | Acc: (97.59%) (687/704) | Learning rate: (0.0001)
2022-06-06 20:29:27,297 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 20 |  Loss: (0.0708) | Acc: (97.92%) (1316/1344) | Learning rate: (0.0001)
2022-06-06 20:29:29,091 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 30 |  Loss: (0.0733) | Acc: (97.63%) (1937/1984) | Learning rate: (0.0001)
2022-06-06 20:29:30,889 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 40 |  Loss: (0.0737) | Acc: (97.56%) (2560/2624) | Learning rate: (0.0001)
2022-06-06 20:29:32,686 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 50 |  Loss: (0.0763) | Acc: (97.49%) (3182/3264) | Learning rate: (0.0001)
2022-06-06 20:29:34,484 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 60 |  Loss: (0.0735) | Acc: (97.59%) (3810/3904) | Learning rate: (0.0001)
2022-06-06 20:29:36,280 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 70 |  Loss: (0.0735) | Acc: (97.56%) (4433/4544) | Learning rate: (0.0001)
2022-06-06 20:29:38,077 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 80 |  Loss: (0.0736) | Acc: (97.51%) (5055/5184) | Learning rate: (0.0001)
2022-06-06 20:29:39,871 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 90 |  Loss: (0.0715) | Acc: (97.61%) (5685/5824) | Learning rate: (0.0001)
2022-06-06 20:29:41,667 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 100 |  Loss: (0.0712) | Acc: (97.66%) (6313/6464) | Learning rate: (0.0001)
2022-06-06 20:29:43,464 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 110 |  Loss: (0.0694) | Acc: (97.68%) (6939/7104) | Learning rate: (0.0001)
2022-06-06 20:29:45,261 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 120 |  Loss: (0.0697) | Acc: (97.65%) (7562/7744) | Learning rate: (0.0001)
2022-06-06 20:29:47,057 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 130 |  Loss: (0.0688) | Acc: (97.69%) (8190/8384) | Learning rate: (0.0001)
2022-06-06 20:29:48,854 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 140 |  Loss: (0.0676) | Acc: (97.74%) (8820/9024) | Learning rate: (0.0001)
2022-06-06 20:29:50,654 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 150 |  Loss: (0.0681) | Acc: (97.68%) (9440/9664) | Learning rate: (0.0001)
2022-06-06 20:29:52,451 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 160 |  Loss: (0.0668) | Acc: (97.74%) (10071/10304) | Learning rate: (0.0001)
2022-06-06 20:29:54,247 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 170 |  Loss: (0.0663) | Acc: (97.73%) (10696/10944) | Learning rate: (0.0001)
2022-06-06 20:29:56,045 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 180 |  Loss: (0.0667) | Acc: (97.74%) (11322/11584) | Learning rate: (0.0001)
2022-06-06 20:29:57,841 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 190 |  Loss: (0.0656) | Acc: (97.78%) (11953/12224) | Learning rate: (0.0001)
2022-06-06 20:29:59,639 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 200 |  Loss: (0.0647) | Acc: (97.82%) (12583/12864) | Learning rate: (0.0001)
2022-06-06 20:30:01,438 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 210 |  Loss: (0.0656) | Acc: (97.79%) (13206/13504) | Learning rate: (0.0001)
2022-06-06 20:30:03,236 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 220 |  Loss: (0.0653) | Acc: (97.81%) (13834/14144) | Learning rate: (0.0001)
2022-06-06 20:30:05,035 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 230 |  Loss: (0.0652) | Acc: (97.79%) (14457/14784) | Learning rate: (0.0001)
2022-06-06 20:30:06,834 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 240 |  Loss: (0.0656) | Acc: (97.81%) (15086/15424) | Learning rate: (0.0001)
2022-06-06 20:30:08,632 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 250 |  Loss: (0.0654) | Acc: (97.83%) (15715/16064) | Learning rate: (0.0001)
2022-06-06 20:30:10,432 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 260 |  Loss: (0.0651) | Acc: (97.84%) (16343/16704) | Learning rate: (0.0001)
2022-06-06 20:30:12,230 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 270 |  Loss: (0.0646) | Acc: (97.87%) (16974/17344) | Learning rate: (0.0001)
2022-06-06 20:30:14,031 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 280 |  Loss: (0.0638) | Acc: (97.89%) (17605/17984) | Learning rate: (0.0001)
2022-06-06 20:30:15,828 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 290 |  Loss: (0.0631) | Acc: (97.91%) (18234/18624) | Learning rate: (0.0001)
2022-06-06 20:30:17,628 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 300 |  Loss: (0.0635) | Acc: (97.88%) (18855/19264) | Learning rate: (0.0001)
2022-06-06 20:30:19,427 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 310 |  Loss: (0.0637) | Acc: (97.87%) (19480/19904) | Learning rate: (0.0001)
2022-06-06 20:30:21,226 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 320 |  Loss: (0.0639) | Acc: (97.88%) (20109/20544) | Learning rate: (0.0001)
2022-06-06 20:30:23,024 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 330 |  Loss: (0.0645) | Acc: (97.85%) (20728/21184) | Learning rate: (0.0001)
2022-06-06 20:30:24,823 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 340 |  Loss: (0.0646) | Acc: (97.85%) (21355/21824) | Learning rate: (0.0001)
2022-06-06 20:30:26,622 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 350 |  Loss: (0.0645) | Acc: (97.87%) (21985/22464) | Learning rate: (0.0001)
2022-06-06 20:30:28,420 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 360 |  Loss: (0.0646) | Acc: (97.87%) (22611/23104) | Learning rate: (0.0001)
2022-06-06 20:30:30,218 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 370 |  Loss: (0.0646) | Acc: (97.85%) (23234/23744) | Learning rate: (0.0001)
2022-06-06 20:30:32,016 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 380 |  Loss: (0.0648) | Acc: (97.85%) (23860/24384) | Learning rate: (0.0001)
2022-06-06 20:30:33,814 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 390 |  Loss: (0.0647) | Acc: (97.87%) (24490/25024) | Learning rate: (0.0001)
2022-06-06 20:30:35,612 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 400 |  Loss: (0.0648) | Acc: (97.85%) (25112/25664) | Learning rate: (0.0001)
2022-06-06 20:30:37,410 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 410 |  Loss: (0.0648) | Acc: (97.86%) (25742/26304) | Learning rate: (0.0001)
2022-06-06 20:30:39,211 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 420 |  Loss: (0.0645) | Acc: (97.88%) (26372/26944) | Learning rate: (0.0001)
2022-06-06 20:30:41,007 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 430 |  Loss: (0.0642) | Acc: (97.89%) (27002/27584) | Learning rate: (0.0001)
2022-06-06 20:30:42,805 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 440 |  Loss: (0.0637) | Acc: (97.91%) (27633/28224) | Learning rate: (0.0001)
2022-06-06 20:30:44,603 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 450 |  Loss: (0.0638) | Acc: (97.91%) (28261/28864) | Learning rate: (0.0001)
2022-06-06 20:30:46,402 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 460 |  Loss: (0.0639) | Acc: (97.91%) (28888/29504) | Learning rate: (0.0001)
2022-06-06 20:30:48,200 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 470 |  Loss: (0.0636) | Acc: (97.91%) (29515/30144) | Learning rate: (0.0001)
2022-06-06 20:30:50,000 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 480 |  Loss: (0.0636) | Acc: (97.92%) (30143/30784) | Learning rate: (0.0001)
2022-06-06 20:30:51,800 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 490 |  Loss: (0.0643) | Acc: (97.92%) (30769/31424) | Learning rate: (0.0001)
2022-06-06 20:30:53,600 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 500 |  Loss: (0.0645) | Acc: (97.90%) (31390/32064) | Learning rate: (0.0001)
2022-06-06 20:30:55,399 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 510 |  Loss: (0.0648) | Acc: (97.89%) (32014/32704) | Learning rate: (0.0001)
2022-06-06 20:30:57,199 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 520 |  Loss: (0.0650) | Acc: (97.88%) (32637/33344) | Learning rate: (0.0001)
2022-06-06 20:30:59,000 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 530 |  Loss: (0.0648) | Acc: (97.89%) (33266/33984) | Learning rate: (0.0001)
2022-06-06 20:31:00,799 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 540 |  Loss: (0.0651) | Acc: (97.87%) (33888/34624) | Learning rate: (0.0001)
2022-06-06 20:31:02,600 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 550 |  Loss: (0.0651) | Acc: (97.87%) (34514/35264) | Learning rate: (0.0001)
2022-06-06 20:31:04,399 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 560 |  Loss: (0.0653) | Acc: (97.86%) (35136/35904) | Learning rate: (0.0001)
2022-06-06 20:31:06,199 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 570 |  Loss: (0.0650) | Acc: (97.87%) (35766/36544) | Learning rate: (0.0001)
2022-06-06 20:31:07,999 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 580 |  Loss: (0.0650) | Acc: (97.86%) (36390/37184) | Learning rate: (0.0001)
2022-06-06 20:31:09,797 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 590 |  Loss: (0.0648) | Acc: (97.87%) (37019/37824) | Learning rate: (0.0001)
2022-06-06 20:31:11,595 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 600 |  Loss: (0.0646) | Acc: (97.88%) (37649/38464) | Learning rate: (0.0001)
2022-06-06 20:31:13,396 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 610 |  Loss: (0.0645) | Acc: (97.89%) (38277/39104) | Learning rate: (0.0001)
2022-06-06 20:31:15,195 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 620 |  Loss: (0.0643) | Acc: (97.89%) (38904/39744) | Learning rate: (0.0001)
2022-06-06 20:31:16,992 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 630 |  Loss: (0.0646) | Acc: (97.88%) (39526/40384) | Learning rate: (0.0001)
2022-06-06 20:31:18,792 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 640 |  Loss: (0.0644) | Acc: (97.89%) (40158/41024) | Learning rate: (0.0001)
2022-06-06 20:31:20,592 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 650 |  Loss: (0.0644) | Acc: (97.89%) (40786/41664) | Learning rate: (0.0001)
2022-06-06 20:31:22,391 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 660 |  Loss: (0.0642) | Acc: (97.90%) (41414/42304) | Learning rate: (0.0001)
2022-06-06 20:31:24,191 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 670 |  Loss: (0.0642) | Acc: (97.90%) (42042/42944) | Learning rate: (0.0001)
2022-06-06 20:31:25,991 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 680 |  Loss: (0.0639) | Acc: (97.91%) (42672/43584) | Learning rate: (0.0001)
2022-06-06 20:31:27,790 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 690 |  Loss: (0.0640) | Acc: (97.90%) (43295/44224) | Learning rate: (0.0001)
2022-06-06 20:31:29,589 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 700 |  Loss: (0.0639) | Acc: (97.90%) (43922/44864) | Learning rate: (0.0001)
2022-06-06 20:31:31,388 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 710 |  Loss: (0.0639) | Acc: (97.90%) (44547/45504) | Learning rate: (0.0001)
2022-06-06 20:31:33,187 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 720 |  Loss: (0.0640) | Acc: (97.90%) (45173/46144) | Learning rate: (0.0001)
2022-06-06 20:31:34,987 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 730 |  Loss: (0.0640) | Acc: (97.90%) (45800/46784) | Learning rate: (0.0001)
2022-06-06 20:31:36,785 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 740 |  Loss: (0.0639) | Acc: (97.89%) (46423/47424) | Learning rate: (0.0001)
2022-06-06 20:31:38,584 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 750 |  Loss: (0.0637) | Acc: (97.90%) (47056/48064) | Learning rate: (0.0001)
2022-06-06 20:31:40,383 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 760 |  Loss: (0.0639) | Acc: (97.90%) (47683/48704) | Learning rate: (0.0001)
2022-06-06 20:31:42,175 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 770 |  Loss: (0.0639) | Acc: (97.90%) (48310/49344) | Learning rate: (0.0001)
2022-06-06 20:31:43,966 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 780 |  Loss: (0.0641) | Acc: (97.91%) (48937/49984) | Learning rate: (0.0001)
2022-06-06 20:31:54,229 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0986) | Acc: (96.92%) (9692/10000)
2022-06-06 20:31:54,230 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:31:55,539 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 0 |  Loss: (0.0046) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:31:57,335 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 10 |  Loss: (0.0316) | Acc: (99.15%) (698/704) | Learning rate: (0.0001)
2022-06-06 20:31:59,130 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 20 |  Loss: (0.0440) | Acc: (98.66%) (1326/1344) | Learning rate: (0.0001)
2022-06-06 20:32:00,923 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 30 |  Loss: (0.0520) | Acc: (98.54%) (1955/1984) | Learning rate: (0.0001)
2022-06-06 20:32:02,720 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 40 |  Loss: (0.0495) | Acc: (98.55%) (2586/2624) | Learning rate: (0.0001)
2022-06-06 20:32:04,517 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 50 |  Loss: (0.0537) | Acc: (98.31%) (3209/3264) | Learning rate: (0.0001)
2022-06-06 20:32:06,317 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 60 |  Loss: (0.0505) | Acc: (98.44%) (3843/3904) | Learning rate: (0.0001)
2022-06-06 20:32:08,114 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 70 |  Loss: (0.0500) | Acc: (98.48%) (4475/4544) | Learning rate: (0.0001)
2022-06-06 20:32:09,912 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 80 |  Loss: (0.0532) | Acc: (98.40%) (5101/5184) | Learning rate: (0.0001)
2022-06-06 20:32:11,708 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 90 |  Loss: (0.0537) | Acc: (98.37%) (5729/5824) | Learning rate: (0.0001)
2022-06-06 20:32:13,505 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 100 |  Loss: (0.0528) | Acc: (98.36%) (6358/6464) | Learning rate: (0.0001)
2022-06-06 20:32:15,303 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 110 |  Loss: (0.0529) | Acc: (98.38%) (6989/7104) | Learning rate: (0.0001)
2022-06-06 20:32:17,101 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 120 |  Loss: (0.0542) | Acc: (98.32%) (7614/7744) | Learning rate: (0.0001)
2022-06-06 20:32:18,900 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 130 |  Loss: (0.0530) | Acc: (98.39%) (8249/8384) | Learning rate: (0.0001)
2022-06-06 20:32:20,697 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 140 |  Loss: (0.0527) | Acc: (98.42%) (8881/9024) | Learning rate: (0.0001)
2022-06-06 20:32:22,495 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 150 |  Loss: (0.0519) | Acc: (98.43%) (9512/9664) | Learning rate: (0.0001)
2022-06-06 20:32:24,293 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 160 |  Loss: (0.0520) | Acc: (98.40%) (10139/10304) | Learning rate: (0.0001)
2022-06-06 20:32:26,091 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 170 |  Loss: (0.0545) | Acc: (98.32%) (10760/10944) | Learning rate: (0.0001)
2022-06-06 20:32:27,893 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 180 |  Loss: (0.0553) | Acc: (98.29%) (11386/11584) | Learning rate: (0.0001)
2022-06-06 20:32:29,689 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 190 |  Loss: (0.0551) | Acc: (98.28%) (12014/12224) | Learning rate: (0.0001)
2022-06-06 20:32:31,487 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 200 |  Loss: (0.0545) | Acc: (98.30%) (12645/12864) | Learning rate: (0.0001)
2022-06-06 20:32:33,286 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 210 |  Loss: (0.0538) | Acc: (98.32%) (13277/13504) | Learning rate: (0.0001)
2022-06-06 20:32:35,081 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 220 |  Loss: (0.0527) | Acc: (98.35%) (13911/14144) | Learning rate: (0.0001)
2022-06-06 20:32:36,878 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 230 |  Loss: (0.0537) | Acc: (98.31%) (14534/14784) | Learning rate: (0.0001)
2022-06-06 20:32:38,675 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 240 |  Loss: (0.0540) | Acc: (98.28%) (15158/15424) | Learning rate: (0.0001)
2022-06-06 20:32:40,475 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 250 |  Loss: (0.0546) | Acc: (98.25%) (15783/16064) | Learning rate: (0.0001)
2022-06-06 20:32:42,274 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 260 |  Loss: (0.0556) | Acc: (98.24%) (16410/16704) | Learning rate: (0.0001)
2022-06-06 20:32:44,072 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 270 |  Loss: (0.0551) | Acc: (98.24%) (17039/17344) | Learning rate: (0.0001)
2022-06-06 20:32:45,870 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 280 |  Loss: (0.0547) | Acc: (98.25%) (17669/17984) | Learning rate: (0.0001)
2022-06-06 20:32:47,667 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 290 |  Loss: (0.0545) | Acc: (98.25%) (18299/18624) | Learning rate: (0.0001)
2022-06-06 20:32:49,465 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 300 |  Loss: (0.0541) | Acc: (98.26%) (18929/19264) | Learning rate: (0.0001)
2022-06-06 20:32:51,262 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 310 |  Loss: (0.0541) | Acc: (98.27%) (19559/19904) | Learning rate: (0.0001)
2022-06-06 20:32:53,059 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 320 |  Loss: (0.0543) | Acc: (98.26%) (20186/20544) | Learning rate: (0.0001)
2022-06-06 20:32:54,859 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 330 |  Loss: (0.0538) | Acc: (98.28%) (20820/21184) | Learning rate: (0.0001)
2022-06-06 20:32:56,656 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 340 |  Loss: (0.0543) | Acc: (98.25%) (21443/21824) | Learning rate: (0.0001)
2022-06-06 20:32:58,455 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 350 |  Loss: (0.0549) | Acc: (98.24%) (22069/22464) | Learning rate: (0.0001)
2022-06-06 20:33:00,252 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 360 |  Loss: (0.0546) | Acc: (98.24%) (22698/23104) | Learning rate: (0.0001)
2022-06-06 20:33:02,052 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 370 |  Loss: (0.0547) | Acc: (98.23%) (23323/23744) | Learning rate: (0.0001)
2022-06-06 20:33:03,850 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 380 |  Loss: (0.0546) | Acc: (98.23%) (23953/24384) | Learning rate: (0.0001)
2022-06-06 20:33:05,649 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 390 |  Loss: (0.0544) | Acc: (98.24%) (24583/25024) | Learning rate: (0.0001)
2022-06-06 20:33:07,447 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 400 |  Loss: (0.0537) | Acc: (98.27%) (25220/25664) | Learning rate: (0.0001)
2022-06-06 20:33:09,246 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 410 |  Loss: (0.0533) | Acc: (98.28%) (25852/26304) | Learning rate: (0.0001)
2022-06-06 20:33:11,047 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 420 |  Loss: (0.0531) | Acc: (98.28%) (26480/26944) | Learning rate: (0.0001)
2022-06-06 20:33:12,844 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 430 |  Loss: (0.0530) | Acc: (98.27%) (27108/27584) | Learning rate: (0.0001)
2022-06-06 20:33:14,643 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 440 |  Loss: (0.0530) | Acc: (98.27%) (27736/28224) | Learning rate: (0.0001)
2022-06-06 20:33:16,442 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 450 |  Loss: (0.0526) | Acc: (98.27%) (28366/28864) | Learning rate: (0.0001)
2022-06-06 20:33:18,239 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 460 |  Loss: (0.0526) | Acc: (98.27%) (28995/29504) | Learning rate: (0.0001)
2022-06-06 20:33:20,037 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 470 |  Loss: (0.0525) | Acc: (98.28%) (29627/30144) | Learning rate: (0.0001)
2022-06-06 20:33:21,836 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 480 |  Loss: (0.0530) | Acc: (98.27%) (30251/30784) | Learning rate: (0.0001)
2022-06-06 20:33:23,635 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 490 |  Loss: (0.0527) | Acc: (98.28%) (30883/31424) | Learning rate: (0.0001)
2022-06-06 20:33:25,434 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 500 |  Loss: (0.0525) | Acc: (98.29%) (31517/32064) | Learning rate: (0.0001)
2022-06-06 20:33:27,235 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 510 |  Loss: (0.0528) | Acc: (98.28%) (32143/32704) | Learning rate: (0.0001)
2022-06-06 20:33:29,035 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 520 |  Loss: (0.0534) | Acc: (98.27%) (32768/33344) | Learning rate: (0.0001)
2022-06-06 20:33:30,835 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 530 |  Loss: (0.0535) | Acc: (98.27%) (33395/33984) | Learning rate: (0.0001)
2022-06-06 20:33:32,634 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 540 |  Loss: (0.0537) | Acc: (98.25%) (34019/34624) | Learning rate: (0.0001)
2022-06-06 20:33:34,432 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 550 |  Loss: (0.0534) | Acc: (98.27%) (34654/35264) | Learning rate: (0.0001)
2022-06-06 20:33:36,234 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 560 |  Loss: (0.0539) | Acc: (98.26%) (35280/35904) | Learning rate: (0.0001)
2022-06-06 20:33:38,036 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 570 |  Loss: (0.0536) | Acc: (98.27%) (35910/36544) | Learning rate: (0.0001)
2022-06-06 20:33:39,837 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 580 |  Loss: (0.0538) | Acc: (98.25%) (36532/37184) | Learning rate: (0.0001)
2022-06-06 20:33:41,636 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 590 |  Loss: (0.0535) | Acc: (98.26%) (37165/37824) | Learning rate: (0.0001)
2022-06-06 20:33:43,435 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 600 |  Loss: (0.0536) | Acc: (98.25%) (37791/38464) | Learning rate: (0.0001)
2022-06-06 20:33:45,236 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 610 |  Loss: (0.0537) | Acc: (98.25%) (38418/39104) | Learning rate: (0.0001)
2022-06-06 20:33:47,036 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 620 |  Loss: (0.0540) | Acc: (98.23%) (39040/39744) | Learning rate: (0.0001)
2022-06-06 20:33:48,836 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 630 |  Loss: (0.0536) | Acc: (98.25%) (39676/40384) | Learning rate: (0.0001)
2022-06-06 20:33:50,633 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 640 |  Loss: (0.0536) | Acc: (98.25%) (40306/41024) | Learning rate: (0.0001)
2022-06-06 20:33:52,432 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 650 |  Loss: (0.0533) | Acc: (98.26%) (40940/41664) | Learning rate: (0.0001)
2022-06-06 20:33:54,230 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 660 |  Loss: (0.0534) | Acc: (98.26%) (41566/42304) | Learning rate: (0.0001)
2022-06-06 20:33:56,027 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 670 |  Loss: (0.0534) | Acc: (98.25%) (42194/42944) | Learning rate: (0.0001)
2022-06-06 20:33:57,824 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 680 |  Loss: (0.0533) | Acc: (98.26%) (42824/43584) | Learning rate: (0.0001)
2022-06-06 20:33:59,621 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 690 |  Loss: (0.0531) | Acc: (98.26%) (43453/44224) | Learning rate: (0.0001)
2022-06-06 20:34:01,415 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 700 |  Loss: (0.0532) | Acc: (98.25%) (44081/44864) | Learning rate: (0.0001)
2022-06-06 20:34:03,214 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 710 |  Loss: (0.0531) | Acc: (98.25%) (44709/45504) | Learning rate: (0.0001)
2022-06-06 20:34:05,010 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 720 |  Loss: (0.0532) | Acc: (98.25%) (45338/46144) | Learning rate: (0.0001)
2022-06-06 20:34:06,808 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 730 |  Loss: (0.0532) | Acc: (98.25%) (45967/46784) | Learning rate: (0.0001)
2022-06-06 20:34:08,602 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 740 |  Loss: (0.0535) | Acc: (98.25%) (46592/47424) | Learning rate: (0.0001)
2022-06-06 20:34:10,398 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 750 |  Loss: (0.0533) | Acc: (98.25%) (47221/48064) | Learning rate: (0.0001)
2022-06-06 20:34:12,194 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 760 |  Loss: (0.0532) | Acc: (98.25%) (47851/48704) | Learning rate: (0.0001)
2022-06-06 20:34:13,981 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 770 |  Loss: (0.0533) | Acc: (98.25%) (48481/49344) | Learning rate: (0.0001)
2022-06-06 20:34:15,769 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 780 |  Loss: (0.0532) | Acc: (98.26%) (49113/49984) | Learning rate: (0.0001)
2022-06-06 20:34:25,999 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0936) | Acc: (97.29%) (9729/10000)
2022-06-06 20:34:26,000 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:34:27,129 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 0 |  Loss: (0.0139) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:34:28,935 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 10 |  Loss: (0.0409) | Acc: (98.72%) (695/704) | Learning rate: (0.0001)
2022-06-06 20:34:30,730 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 20 |  Loss: (0.0404) | Acc: (98.51%) (1324/1344) | Learning rate: (0.0001)
2022-06-06 20:34:32,524 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 30 |  Loss: (0.0419) | Acc: (98.44%) (1953/1984) | Learning rate: (0.0001)
2022-06-06 20:34:34,323 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 40 |  Loss: (0.0402) | Acc: (98.51%) (2585/2624) | Learning rate: (0.0001)
2022-06-06 20:34:36,121 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 50 |  Loss: (0.0410) | Acc: (98.53%) (3216/3264) | Learning rate: (0.0001)
2022-06-06 20:34:37,921 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 60 |  Loss: (0.0417) | Acc: (98.57%) (3848/3904) | Learning rate: (0.0001)
2022-06-06 20:34:39,721 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 70 |  Loss: (0.0413) | Acc: (98.57%) (4479/4544) | Learning rate: (0.0001)
2022-06-06 20:34:41,519 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 80 |  Loss: (0.0418) | Acc: (98.59%) (5111/5184) | Learning rate: (0.0001)
2022-06-06 20:34:43,316 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 90 |  Loss: (0.0421) | Acc: (98.56%) (5740/5824) | Learning rate: (0.0001)
2022-06-06 20:34:45,112 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 100 |  Loss: (0.0417) | Acc: (98.59%) (6373/6464) | Learning rate: (0.0001)
2022-06-06 20:34:46,911 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 110 |  Loss: (0.0422) | Acc: (98.56%) (7002/7104) | Learning rate: (0.0001)
2022-06-06 20:34:48,706 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 120 |  Loss: (0.0420) | Acc: (98.59%) (7635/7744) | Learning rate: (0.0001)
2022-06-06 20:34:50,503 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 130 |  Loss: (0.0410) | Acc: (98.59%) (8266/8384) | Learning rate: (0.0001)
2022-06-06 20:34:52,300 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 140 |  Loss: (0.0418) | Acc: (98.54%) (8892/9024) | Learning rate: (0.0001)
2022-06-06 20:34:54,099 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 150 |  Loss: (0.0419) | Acc: (98.54%) (9523/9664) | Learning rate: (0.0001)
2022-06-06 20:34:55,896 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 160 |  Loss: (0.0424) | Acc: (98.54%) (10154/10304) | Learning rate: (0.0001)
2022-06-06 20:34:57,695 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 170 |  Loss: (0.0412) | Acc: (98.58%) (10789/10944) | Learning rate: (0.0001)
2022-06-06 20:34:59,491 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 180 |  Loss: (0.0411) | Acc: (98.59%) (11421/11584) | Learning rate: (0.0001)
2022-06-06 20:35:01,290 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 190 |  Loss: (0.0411) | Acc: (98.59%) (12052/12224) | Learning rate: (0.0001)
2022-06-06 20:35:03,088 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 200 |  Loss: (0.0416) | Acc: (98.56%) (12679/12864) | Learning rate: (0.0001)
2022-06-06 20:35:04,886 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 210 |  Loss: (0.0418) | Acc: (98.53%) (13306/13504) | Learning rate: (0.0001)
2022-06-06 20:35:06,682 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 220 |  Loss: (0.0425) | Acc: (98.52%) (13935/14144) | Learning rate: (0.0001)
2022-06-06 20:35:08,479 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 230 |  Loss: (0.0428) | Acc: (98.53%) (14567/14784) | Learning rate: (0.0001)
2022-06-06 20:35:10,275 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 240 |  Loss: (0.0432) | Acc: (98.55%) (15200/15424) | Learning rate: (0.0001)
2022-06-06 20:35:12,073 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 250 |  Loss: (0.0434) | Acc: (98.51%) (15825/16064) | Learning rate: (0.0001)
2022-06-06 20:35:13,870 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 260 |  Loss: (0.0428) | Acc: (98.52%) (16457/16704) | Learning rate: (0.0001)
2022-06-06 20:35:15,668 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 270 |  Loss: (0.0433) | Acc: (98.51%) (17085/17344) | Learning rate: (0.0001)
2022-06-06 20:35:17,465 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 280 |  Loss: (0.0441) | Acc: (98.49%) (17713/17984) | Learning rate: (0.0001)
2022-06-06 20:35:19,263 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 290 |  Loss: (0.0443) | Acc: (98.49%) (18343/18624) | Learning rate: (0.0001)
2022-06-06 20:35:21,064 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 300 |  Loss: (0.0447) | Acc: (98.47%) (18970/19264) | Learning rate: (0.0001)
2022-06-06 20:35:22,862 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 310 |  Loss: (0.0446) | Acc: (98.48%) (19601/19904) | Learning rate: (0.0001)
2022-06-06 20:35:24,661 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 320 |  Loss: (0.0440) | Acc: (98.50%) (20236/20544) | Learning rate: (0.0001)
2022-06-06 20:35:26,459 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 330 |  Loss: (0.0435) | Acc: (98.52%) (20870/21184) | Learning rate: (0.0001)
2022-06-06 20:35:28,258 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 340 |  Loss: (0.0431) | Acc: (98.53%) (21503/21824) | Learning rate: (0.0001)
2022-06-06 20:35:30,056 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 350 |  Loss: (0.0431) | Acc: (98.53%) (22133/22464) | Learning rate: (0.0001)
2022-06-06 20:35:31,854 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 360 |  Loss: (0.0435) | Acc: (98.50%) (22758/23104) | Learning rate: (0.0001)
2022-06-06 20:35:33,652 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 370 |  Loss: (0.0434) | Acc: (98.51%) (23390/23744) | Learning rate: (0.0001)
2022-06-06 20:35:35,451 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 380 |  Loss: (0.0435) | Acc: (98.50%) (24019/24384) | Learning rate: (0.0001)
2022-06-06 20:35:37,249 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 390 |  Loss: (0.0432) | Acc: (98.52%) (24653/25024) | Learning rate: (0.0001)
2022-06-06 20:35:39,046 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 400 |  Loss: (0.0436) | Acc: (98.49%) (25277/25664) | Learning rate: (0.0001)
2022-06-06 20:35:40,846 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 410 |  Loss: (0.0435) | Acc: (98.49%) (25907/26304) | Learning rate: (0.0001)
2022-06-06 20:35:42,645 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 420 |  Loss: (0.0431) | Acc: (98.50%) (26540/26944) | Learning rate: (0.0001)
2022-06-06 20:35:44,443 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 430 |  Loss: (0.0429) | Acc: (98.51%) (27173/27584) | Learning rate: (0.0001)
2022-06-06 20:35:46,242 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 440 |  Loss: (0.0428) | Acc: (98.50%) (27802/28224) | Learning rate: (0.0001)
2022-06-06 20:35:48,041 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 450 |  Loss: (0.0426) | Acc: (98.51%) (28433/28864) | Learning rate: (0.0001)
2022-06-06 20:35:49,840 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 460 |  Loss: (0.0423) | Acc: (98.52%) (29066/29504) | Learning rate: (0.0001)
2022-06-06 20:35:51,638 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 470 |  Loss: (0.0428) | Acc: (98.51%) (29696/30144) | Learning rate: (0.0001)
2022-06-06 20:35:53,437 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 480 |  Loss: (0.0429) | Acc: (98.51%) (30325/30784) | Learning rate: (0.0001)
2022-06-06 20:35:55,238 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 490 |  Loss: (0.0430) | Acc: (98.49%) (30951/31424) | Learning rate: (0.0001)
2022-06-06 20:35:57,036 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 500 |  Loss: (0.0431) | Acc: (98.49%) (31580/32064) | Learning rate: (0.0001)
2022-06-06 20:35:58,835 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 510 |  Loss: (0.0429) | Acc: (98.49%) (32211/32704) | Learning rate: (0.0001)
2022-06-06 20:36:00,634 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 520 |  Loss: (0.0429) | Acc: (98.49%) (32842/33344) | Learning rate: (0.0001)
2022-06-06 20:36:02,432 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 530 |  Loss: (0.0432) | Acc: (98.49%) (33470/33984) | Learning rate: (0.0001)
2022-06-06 20:36:04,233 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 540 |  Loss: (0.0434) | Acc: (98.47%) (34095/34624) | Learning rate: (0.0001)
2022-06-06 20:36:06,032 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 550 |  Loss: (0.0436) | Acc: (98.47%) (34723/35264) | Learning rate: (0.0001)
2022-06-06 20:36:07,831 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 560 |  Loss: (0.0435) | Acc: (98.47%) (35355/35904) | Learning rate: (0.0001)
2022-06-06 20:36:09,632 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 570 |  Loss: (0.0437) | Acc: (98.47%) (35985/36544) | Learning rate: (0.0001)
2022-06-06 20:36:11,432 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 580 |  Loss: (0.0437) | Acc: (98.47%) (36616/37184) | Learning rate: (0.0001)
2022-06-06 20:36:13,230 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 590 |  Loss: (0.0436) | Acc: (98.47%) (37245/37824) | Learning rate: (0.0001)
2022-06-06 20:36:15,031 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 600 |  Loss: (0.0439) | Acc: (98.46%) (37870/38464) | Learning rate: (0.0001)
2022-06-06 20:36:16,832 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 610 |  Loss: (0.0444) | Acc: (98.44%) (38495/39104) | Learning rate: (0.0001)
2022-06-06 20:36:18,631 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 620 |  Loss: (0.0442) | Acc: (98.45%) (39127/39744) | Learning rate: (0.0001)
2022-06-06 20:36:20,431 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 630 |  Loss: (0.0444) | Acc: (98.44%) (39756/40384) | Learning rate: (0.0001)
2022-06-06 20:36:22,232 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 640 |  Loss: (0.0446) | Acc: (98.42%) (40377/41024) | Learning rate: (0.0001)
2022-06-06 20:36:24,031 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 650 |  Loss: (0.0446) | Acc: (98.41%) (41003/41664) | Learning rate: (0.0001)
2022-06-06 20:36:25,831 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 660 |  Loss: (0.0444) | Acc: (98.42%) (41635/42304) | Learning rate: (0.0001)
2022-06-06 20:36:27,629 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 670 |  Loss: (0.0443) | Acc: (98.43%) (42271/42944) | Learning rate: (0.0001)
2022-06-06 20:36:29,427 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 680 |  Loss: (0.0439) | Acc: (98.45%) (42908/43584) | Learning rate: (0.0001)
2022-06-06 20:36:31,227 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 690 |  Loss: (0.0437) | Acc: (98.45%) (43540/44224) | Learning rate: (0.0001)
2022-06-06 20:36:33,028 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 700 |  Loss: (0.0437) | Acc: (98.46%) (44172/44864) | Learning rate: (0.0001)
2022-06-06 20:36:34,827 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 710 |  Loss: (0.0437) | Acc: (98.46%) (44802/45504) | Learning rate: (0.0001)
2022-06-06 20:36:36,626 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 720 |  Loss: (0.0436) | Acc: (98.46%) (45433/46144) | Learning rate: (0.0001)
2022-06-06 20:36:38,425 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 730 |  Loss: (0.0433) | Acc: (98.47%) (46069/46784) | Learning rate: (0.0001)
2022-06-06 20:36:40,224 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 740 |  Loss: (0.0434) | Acc: (98.47%) (46700/47424) | Learning rate: (0.0001)
2022-06-06 20:36:42,024 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 750 |  Loss: (0.0433) | Acc: (98.48%) (47332/48064) | Learning rate: (0.0001)
2022-06-06 20:36:43,824 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 760 |  Loss: (0.0434) | Acc: (98.47%) (47959/48704) | Learning rate: (0.0001)
2022-06-06 20:36:45,613 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 770 |  Loss: (0.0435) | Acc: (98.47%) (48588/49344) | Learning rate: (0.0001)
2022-06-06 20:36:47,402 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 780 |  Loss: (0.0437) | Acc: (98.47%) (49217/49984) | Learning rate: (0.0001)
2022-06-06 20:36:57,695 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0994) | Acc: (97.12%) (9712/10000)
2022-06-06 20:36:57,696 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:36:58,765 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 0 |  Loss: (0.0466) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 20:37:00,565 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 10 |  Loss: (0.0398) | Acc: (98.58%) (694/704) | Learning rate: (0.0001)
2022-06-06 20:37:02,359 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 20 |  Loss: (0.0347) | Acc: (98.74%) (1327/1344) | Learning rate: (0.0001)
2022-06-06 20:37:04,155 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 30 |  Loss: (0.0341) | Acc: (98.79%) (1960/1984) | Learning rate: (0.0001)
2022-06-06 20:37:05,952 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 40 |  Loss: (0.0312) | Acc: (98.93%) (2596/2624) | Learning rate: (0.0001)
2022-06-06 20:37:07,750 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 50 |  Loss: (0.0305) | Acc: (99.02%) (3232/3264) | Learning rate: (0.0001)
2022-06-06 20:37:09,550 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 60 |  Loss: (0.0329) | Acc: (98.92%) (3862/3904) | Learning rate: (0.0001)
2022-06-06 20:37:11,348 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 70 |  Loss: (0.0333) | Acc: (98.90%) (4494/4544) | Learning rate: (0.0001)
2022-06-06 20:37:13,147 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 80 |  Loss: (0.0332) | Acc: (98.88%) (5126/5184) | Learning rate: (0.0001)
2022-06-06 20:37:14,945 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 90 |  Loss: (0.0336) | Acc: (98.88%) (5759/5824) | Learning rate: (0.0001)
2022-06-06 20:37:16,744 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 100 |  Loss: (0.0336) | Acc: (98.87%) (6391/6464) | Learning rate: (0.0001)
2022-06-06 20:37:18,543 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 110 |  Loss: (0.0334) | Acc: (98.89%) (7025/7104) | Learning rate: (0.0001)
2022-06-06 20:37:20,340 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 120 |  Loss: (0.0334) | Acc: (98.86%) (7656/7744) | Learning rate: (0.0001)
2022-06-06 20:37:22,136 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 130 |  Loss: (0.0336) | Acc: (98.89%) (8291/8384) | Learning rate: (0.0001)
2022-06-06 20:37:23,931 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 140 |  Loss: (0.0332) | Acc: (98.90%) (8925/9024) | Learning rate: (0.0001)
2022-06-06 20:37:25,729 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 150 |  Loss: (0.0339) | Acc: (98.89%) (9557/9664) | Learning rate: (0.0001)
2022-06-06 20:37:27,526 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 160 |  Loss: (0.0343) | Acc: (98.88%) (10189/10304) | Learning rate: (0.0001)
2022-06-06 20:37:29,324 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 170 |  Loss: (0.0332) | Acc: (98.93%) (10827/10944) | Learning rate: (0.0001)
2022-06-06 20:37:31,119 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 180 |  Loss: (0.0329) | Acc: (98.94%) (11461/11584) | Learning rate: (0.0001)
2022-06-06 20:37:32,917 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 190 |  Loss: (0.0327) | Acc: (98.94%) (12095/12224) | Learning rate: (0.0001)
2022-06-06 20:37:34,713 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 200 |  Loss: (0.0328) | Acc: (98.94%) (12727/12864) | Learning rate: (0.0001)
2022-06-06 20:37:36,511 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 210 |  Loss: (0.0330) | Acc: (98.93%) (13360/13504) | Learning rate: (0.0001)
2022-06-06 20:37:38,309 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 220 |  Loss: (0.0333) | Acc: (98.92%) (13991/14144) | Learning rate: (0.0001)
2022-06-06 20:37:40,106 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 230 |  Loss: (0.0338) | Acc: (98.88%) (14618/14784) | Learning rate: (0.0001)
2022-06-06 20:37:41,903 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 240 |  Loss: (0.0335) | Acc: (98.88%) (15252/15424) | Learning rate: (0.0001)
2022-06-06 20:37:43,700 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 250 |  Loss: (0.0330) | Acc: (98.90%) (15887/16064) | Learning rate: (0.0001)
2022-06-06 20:37:45,503 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 260 |  Loss: (0.0329) | Acc: (98.90%) (16520/16704) | Learning rate: (0.0001)
2022-06-06 20:37:47,302 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 270 |  Loss: (0.0330) | Acc: (98.89%) (17152/17344) | Learning rate: (0.0001)
2022-06-06 20:37:49,101 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 280 |  Loss: (0.0329) | Acc: (98.90%) (17786/17984) | Learning rate: (0.0001)
2022-06-06 20:37:50,899 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 290 |  Loss: (0.0323) | Acc: (98.92%) (18423/18624) | Learning rate: (0.0001)
2022-06-06 20:37:52,698 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 300 |  Loss: (0.0321) | Acc: (98.93%) (19058/19264) | Learning rate: (0.0001)
2022-06-06 20:37:54,496 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 310 |  Loss: (0.0316) | Acc: (98.95%) (19695/19904) | Learning rate: (0.0001)
2022-06-06 20:37:56,294 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 320 |  Loss: (0.0322) | Acc: (98.92%) (20323/20544) | Learning rate: (0.0001)
2022-06-06 20:37:58,095 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 330 |  Loss: (0.0326) | Acc: (98.90%) (20952/21184) | Learning rate: (0.0001)
2022-06-06 20:37:59,896 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 340 |  Loss: (0.0324) | Acc: (98.90%) (21585/21824) | Learning rate: (0.0001)
2022-06-06 20:38:01,695 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 350 |  Loss: (0.0324) | Acc: (98.90%) (22216/22464) | Learning rate: (0.0001)
2022-06-06 20:38:03,493 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 360 |  Loss: (0.0323) | Acc: (98.90%) (22849/23104) | Learning rate: (0.0001)
2022-06-06 20:38:05,294 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 370 |  Loss: (0.0325) | Acc: (98.89%) (23480/23744) | Learning rate: (0.0001)
2022-06-06 20:38:07,094 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 380 |  Loss: (0.0327) | Acc: (98.88%) (24110/24384) | Learning rate: (0.0001)
2022-06-06 20:38:08,895 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 390 |  Loss: (0.0327) | Acc: (98.88%) (24744/25024) | Learning rate: (0.0001)
2022-06-06 20:38:10,693 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 400 |  Loss: (0.0334) | Acc: (98.86%) (25372/25664) | Learning rate: (0.0001)
2022-06-06 20:38:12,493 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 410 |  Loss: (0.0338) | Acc: (98.86%) (26003/26304) | Learning rate: (0.0001)
2022-06-06 20:38:14,294 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 420 |  Loss: (0.0338) | Acc: (98.85%) (26633/26944) | Learning rate: (0.0001)
2022-06-06 20:38:16,092 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 430 |  Loss: (0.0336) | Acc: (98.85%) (27267/27584) | Learning rate: (0.0001)
2022-06-06 20:38:17,891 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 440 |  Loss: (0.0341) | Acc: (98.84%) (27896/28224) | Learning rate: (0.0001)
2022-06-06 20:38:19,691 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 450 |  Loss: (0.0346) | Acc: (98.83%) (28527/28864) | Learning rate: (0.0001)
2022-06-06 20:38:21,491 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 460 |  Loss: (0.0345) | Acc: (98.83%) (29160/29504) | Learning rate: (0.0001)
2022-06-06 20:38:23,291 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 470 |  Loss: (0.0345) | Acc: (98.84%) (29793/30144) | Learning rate: (0.0001)
2022-06-06 20:38:25,088 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 480 |  Loss: (0.0345) | Acc: (98.84%) (30427/30784) | Learning rate: (0.0001)
2022-06-06 20:38:26,886 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 490 |  Loss: (0.0345) | Acc: (98.84%) (31061/31424) | Learning rate: (0.0001)
2022-06-06 20:38:28,686 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 500 |  Loss: (0.0347) | Acc: (98.84%) (31692/32064) | Learning rate: (0.0001)
2022-06-06 20:38:30,485 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 510 |  Loss: (0.0350) | Acc: (98.83%) (32322/32704) | Learning rate: (0.0001)
2022-06-06 20:38:32,284 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 520 |  Loss: (0.0350) | Acc: (98.83%) (32955/33344) | Learning rate: (0.0001)
2022-06-06 20:38:34,082 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 530 |  Loss: (0.0347) | Acc: (98.85%) (33592/33984) | Learning rate: (0.0001)
2022-06-06 20:38:35,880 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 540 |  Loss: (0.0348) | Acc: (98.84%) (34224/34624) | Learning rate: (0.0001)
2022-06-06 20:38:37,679 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 550 |  Loss: (0.0351) | Acc: (98.83%) (34853/35264) | Learning rate: (0.0001)
2022-06-06 20:38:39,478 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 560 |  Loss: (0.0353) | Acc: (98.83%) (35484/35904) | Learning rate: (0.0001)
2022-06-06 20:38:41,281 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 570 |  Loss: (0.0354) | Acc: (98.82%) (36113/36544) | Learning rate: (0.0001)
2022-06-06 20:38:43,081 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 580 |  Loss: (0.0351) | Acc: (98.84%) (36751/37184) | Learning rate: (0.0001)
2022-06-06 20:38:44,882 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 590 |  Loss: (0.0357) | Acc: (98.81%) (37375/37824) | Learning rate: (0.0001)
2022-06-06 20:38:46,680 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 600 |  Loss: (0.0360) | Acc: (98.81%) (38006/38464) | Learning rate: (0.0001)
2022-06-06 20:38:48,480 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 610 |  Loss: (0.0361) | Acc: (98.81%) (38638/39104) | Learning rate: (0.0001)
2022-06-06 20:38:50,280 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 620 |  Loss: (0.0362) | Acc: (98.81%) (39271/39744) | Learning rate: (0.0001)
2022-06-06 20:38:52,080 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 630 |  Loss: (0.0362) | Acc: (98.81%) (39903/40384) | Learning rate: (0.0001)
2022-06-06 20:38:53,882 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 640 |  Loss: (0.0362) | Acc: (98.81%) (40535/41024) | Learning rate: (0.0001)
2022-06-06 20:38:55,683 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 650 |  Loss: (0.0363) | Acc: (98.80%) (41163/41664) | Learning rate: (0.0001)
2022-06-06 20:38:57,484 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 660 |  Loss: (0.0365) | Acc: (98.79%) (41791/42304) | Learning rate: (0.0001)
2022-06-06 20:38:59,283 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 670 |  Loss: (0.0366) | Acc: (98.79%) (42424/42944) | Learning rate: (0.0001)
2022-06-06 20:39:01,084 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 680 |  Loss: (0.0366) | Acc: (98.79%) (43057/43584) | Learning rate: (0.0001)
2022-06-06 20:39:02,883 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 690 |  Loss: (0.0366) | Acc: (98.79%) (43688/44224) | Learning rate: (0.0001)
2022-06-06 20:39:04,683 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 700 |  Loss: (0.0371) | Acc: (98.78%) (44315/44864) | Learning rate: (0.0001)
2022-06-06 20:39:06,484 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 710 |  Loss: (0.0371) | Acc: (98.78%) (44947/45504) | Learning rate: (0.0001)
2022-06-06 20:39:08,285 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 720 |  Loss: (0.0370) | Acc: (98.77%) (45577/46144) | Learning rate: (0.0001)
2022-06-06 20:39:10,089 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 730 |  Loss: (0.0370) | Acc: (98.77%) (46208/46784) | Learning rate: (0.0001)
2022-06-06 20:39:11,887 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 740 |  Loss: (0.0369) | Acc: (98.77%) (46842/47424) | Learning rate: (0.0001)
2022-06-06 20:39:13,687 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 750 |  Loss: (0.0367) | Acc: (98.78%) (47476/48064) | Learning rate: (0.0001)
2022-06-06 20:39:15,485 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 760 |  Loss: (0.0368) | Acc: (98.77%) (48106/48704) | Learning rate: (0.0001)
2022-06-06 20:39:17,276 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 770 |  Loss: (0.0368) | Acc: (98.77%) (48738/49344) | Learning rate: (0.0001)
2022-06-06 20:39:19,066 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 780 |  Loss: (0.0369) | Acc: (98.77%) (49369/49984) | Learning rate: (0.0001)
2022-06-06 20:39:29,341 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1048) | Acc: (97.13%) (9713/10000)
2022-06-06 20:39:29,342 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:39:30,386 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 0 |  Loss: (0.0026) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:39:32,197 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 10 |  Loss: (0.0217) | Acc: (99.29%) (699/704) | Learning rate: (0.0001)
2022-06-06 20:39:33,992 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 20 |  Loss: (0.0277) | Acc: (99.26%) (1334/1344) | Learning rate: (0.0001)
2022-06-06 20:39:35,785 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 30 |  Loss: (0.0276) | Acc: (99.24%) (1969/1984) | Learning rate: (0.0001)
2022-06-06 20:39:37,582 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 40 |  Loss: (0.0341) | Acc: (99.12%) (2601/2624) | Learning rate: (0.0001)
2022-06-06 20:39:39,378 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 50 |  Loss: (0.0311) | Acc: (99.17%) (3237/3264) | Learning rate: (0.0001)
2022-06-06 20:39:41,175 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 60 |  Loss: (0.0293) | Acc: (99.18%) (3872/3904) | Learning rate: (0.0001)
2022-06-06 20:39:42,973 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 70 |  Loss: (0.0289) | Acc: (99.16%) (4506/4544) | Learning rate: (0.0001)
2022-06-06 20:39:44,767 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 80 |  Loss: (0.0330) | Acc: (99.02%) (5133/5184) | Learning rate: (0.0001)
2022-06-06 20:39:46,563 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 90 |  Loss: (0.0347) | Acc: (98.95%) (5763/5824) | Learning rate: (0.0001)
2022-06-06 20:39:48,359 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 100 |  Loss: (0.0337) | Acc: (98.99%) (6399/6464) | Learning rate: (0.0001)
2022-06-06 20:39:50,155 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 110 |  Loss: (0.0330) | Acc: (98.99%) (7032/7104) | Learning rate: (0.0001)
2022-06-06 20:39:51,951 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 120 |  Loss: (0.0334) | Acc: (98.99%) (7666/7744) | Learning rate: (0.0001)
2022-06-06 20:39:53,750 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 130 |  Loss: (0.0344) | Acc: (98.95%) (8296/8384) | Learning rate: (0.0001)
2022-06-06 20:39:55,550 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 140 |  Loss: (0.0357) | Acc: (98.89%) (8924/9024) | Learning rate: (0.0001)
2022-06-06 20:39:57,345 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 150 |  Loss: (0.0363) | Acc: (98.87%) (9555/9664) | Learning rate: (0.0001)
2022-06-06 20:39:59,138 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 160 |  Loss: (0.0362) | Acc: (98.87%) (10188/10304) | Learning rate: (0.0001)
2022-06-06 20:40:00,935 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 170 |  Loss: (0.0357) | Acc: (98.88%) (10821/10944) | Learning rate: (0.0001)
2022-06-06 20:40:02,731 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 180 |  Loss: (0.0353) | Acc: (98.89%) (11455/11584) | Learning rate: (0.0001)
2022-06-06 20:40:04,526 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 190 |  Loss: (0.0362) | Acc: (98.85%) (12084/12224) | Learning rate: (0.0001)
2022-06-06 20:40:06,322 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 200 |  Loss: (0.0362) | Acc: (98.83%) (12713/12864) | Learning rate: (0.0001)
2022-06-06 20:40:08,116 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 210 |  Loss: (0.0366) | Acc: (98.81%) (13343/13504) | Learning rate: (0.0001)
2022-06-06 20:40:09,914 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 220 |  Loss: (0.0377) | Acc: (98.77%) (13970/14144) | Learning rate: (0.0001)
2022-06-06 20:40:11,711 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 230 |  Loss: (0.0377) | Acc: (98.76%) (14601/14784) | Learning rate: (0.0001)
2022-06-06 20:40:13,508 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 240 |  Loss: (0.0374) | Acc: (98.78%) (15236/15424) | Learning rate: (0.0001)
2022-06-06 20:40:15,306 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 250 |  Loss: (0.0380) | Acc: (98.76%) (15865/16064) | Learning rate: (0.0001)
2022-06-06 20:40:17,104 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 260 |  Loss: (0.0383) | Acc: (98.75%) (16495/16704) | Learning rate: (0.0001)
2022-06-06 20:40:18,901 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 270 |  Loss: (0.0382) | Acc: (98.77%) (17130/17344) | Learning rate: (0.0001)
2022-06-06 20:40:20,699 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 280 |  Loss: (0.0382) | Acc: (98.77%) (17762/17984) | Learning rate: (0.0001)
2022-06-06 20:40:22,495 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 290 |  Loss: (0.0382) | Acc: (98.75%) (18391/18624) | Learning rate: (0.0001)
2022-06-06 20:40:24,292 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 300 |  Loss: (0.0381) | Acc: (98.75%) (19024/19264) | Learning rate: (0.0001)
2022-06-06 20:40:26,088 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 310 |  Loss: (0.0382) | Acc: (98.75%) (19656/19904) | Learning rate: (0.0001)
2022-06-06 20:40:27,884 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 320 |  Loss: (0.0392) | Acc: (98.73%) (20283/20544) | Learning rate: (0.0001)
2022-06-06 20:40:29,680 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 330 |  Loss: (0.0392) | Acc: (98.73%) (20915/21184) | Learning rate: (0.0001)
2022-06-06 20:40:31,476 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 340 |  Loss: (0.0389) | Acc: (98.73%) (21546/21824) | Learning rate: (0.0001)
2022-06-06 20:40:33,273 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 350 |  Loss: (0.0387) | Acc: (98.74%) (22180/22464) | Learning rate: (0.0001)
2022-06-06 20:40:35,071 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 360 |  Loss: (0.0388) | Acc: (98.74%) (22812/23104) | Learning rate: (0.0001)
2022-06-06 20:40:36,867 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 370 |  Loss: (0.0391) | Acc: (98.72%) (23440/23744) | Learning rate: (0.0001)
2022-06-06 20:40:38,664 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 380 |  Loss: (0.0393) | Acc: (98.71%) (24069/24384) | Learning rate: (0.0001)
2022-06-06 20:40:40,463 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 390 |  Loss: (0.0392) | Acc: (98.72%) (24703/25024) | Learning rate: (0.0001)
2022-06-06 20:40:42,261 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 400 |  Loss: (0.0388) | Acc: (98.73%) (25339/25664) | Learning rate: (0.0001)
2022-06-06 20:40:44,059 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 410 |  Loss: (0.0384) | Acc: (98.74%) (25973/26304) | Learning rate: (0.0001)
2022-06-06 20:40:45,856 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 420 |  Loss: (0.0384) | Acc: (98.75%) (26606/26944) | Learning rate: (0.0001)
2022-06-06 20:40:47,654 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 430 |  Loss: (0.0379) | Acc: (98.76%) (27242/27584) | Learning rate: (0.0001)
2022-06-06 20:40:49,452 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 440 |  Loss: (0.0380) | Acc: (98.77%) (27876/28224) | Learning rate: (0.0001)
2022-06-06 20:40:51,252 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 450 |  Loss: (0.0380) | Acc: (98.76%) (28507/28864) | Learning rate: (0.0001)
2022-06-06 20:40:53,047 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 460 |  Loss: (0.0375) | Acc: (98.78%) (29145/29504) | Learning rate: (0.0001)
2022-06-06 20:40:54,844 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 470 |  Loss: (0.0374) | Acc: (98.79%) (29779/30144) | Learning rate: (0.0001)
2022-06-06 20:40:56,644 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 480 |  Loss: (0.0373) | Acc: (98.79%) (30412/30784) | Learning rate: (0.0001)
2022-06-06 20:40:58,442 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 490 |  Loss: (0.0372) | Acc: (98.79%) (31044/31424) | Learning rate: (0.0001)
2022-06-06 20:41:00,241 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 500 |  Loss: (0.0369) | Acc: (98.81%) (31681/32064) | Learning rate: (0.0001)
2022-06-06 20:41:02,036 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 510 |  Loss: (0.0368) | Acc: (98.81%) (32314/32704) | Learning rate: (0.0001)
2022-06-06 20:41:03,836 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 520 |  Loss: (0.0366) | Acc: (98.82%) (32949/33344) | Learning rate: (0.0001)
2022-06-06 20:41:05,634 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 530 |  Loss: (0.0365) | Acc: (98.81%) (33580/33984) | Learning rate: (0.0001)
2022-06-06 20:41:07,434 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 540 |  Loss: (0.0367) | Acc: (98.80%) (34210/34624) | Learning rate: (0.0001)
2022-06-06 20:41:09,231 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 550 |  Loss: (0.0366) | Acc: (98.81%) (34843/35264) | Learning rate: (0.0001)
2022-06-06 20:41:11,032 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 560 |  Loss: (0.0362) | Acc: (98.82%) (35482/35904) | Learning rate: (0.0001)
2022-06-06 20:41:12,833 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 570 |  Loss: (0.0363) | Acc: (98.82%) (36112/36544) | Learning rate: (0.0001)
2022-06-06 20:41:14,633 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 580 |  Loss: (0.0362) | Acc: (98.82%) (36745/37184) | Learning rate: (0.0001)
2022-06-06 20:41:16,432 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 590 |  Loss: (0.0359) | Acc: (98.83%) (37380/37824) | Learning rate: (0.0001)
2022-06-06 20:41:18,232 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 600 |  Loss: (0.0359) | Acc: (98.83%) (38015/38464) | Learning rate: (0.0001)
2022-06-06 20:41:20,032 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 610 |  Loss: (0.0356) | Acc: (98.85%) (38653/39104) | Learning rate: (0.0001)
2022-06-06 20:41:21,831 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 620 |  Loss: (0.0356) | Acc: (98.84%) (39283/39744) | Learning rate: (0.0001)
2022-06-06 20:41:23,630 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 630 |  Loss: (0.0354) | Acc: (98.85%) (39918/40384) | Learning rate: (0.0001)
2022-06-06 20:41:25,431 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 640 |  Loss: (0.0357) | Acc: (98.84%) (40548/41024) | Learning rate: (0.0001)
2022-06-06 20:41:27,231 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 650 |  Loss: (0.0358) | Acc: (98.84%) (41179/41664) | Learning rate: (0.0001)
2022-06-06 20:41:29,030 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 660 |  Loss: (0.0359) | Acc: (98.84%) (41812/42304) | Learning rate: (0.0001)
2022-06-06 20:41:30,826 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 670 |  Loss: (0.0358) | Acc: (98.84%) (42447/42944) | Learning rate: (0.0001)
2022-06-06 20:41:32,625 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 680 |  Loss: (0.0355) | Acc: (98.85%) (43083/43584) | Learning rate: (0.0001)
2022-06-06 20:41:34,424 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 690 |  Loss: (0.0354) | Acc: (98.86%) (43719/44224) | Learning rate: (0.0001)
2022-06-06 20:41:36,224 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 700 |  Loss: (0.0354) | Acc: (98.86%) (44352/44864) | Learning rate: (0.0001)
2022-06-06 20:41:38,024 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 710 |  Loss: (0.0356) | Acc: (98.85%) (44982/45504) | Learning rate: (0.0001)
2022-06-06 20:41:39,824 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 720 |  Loss: (0.0356) | Acc: (98.86%) (45616/46144) | Learning rate: (0.0001)
2022-06-06 20:41:41,624 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 730 |  Loss: (0.0355) | Acc: (98.86%) (46250/46784) | Learning rate: (0.0001)
2022-06-06 20:41:43,422 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 740 |  Loss: (0.0355) | Acc: (98.85%) (46878/47424) | Learning rate: (0.0001)
2022-06-06 20:41:45,221 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 750 |  Loss: (0.0357) | Acc: (98.85%) (47510/48064) | Learning rate: (0.0001)
2022-06-06 20:41:47,018 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 760 |  Loss: (0.0355) | Acc: (98.85%) (48145/48704) | Learning rate: (0.0001)
2022-06-06 20:41:48,809 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 770 |  Loss: (0.0354) | Acc: (98.85%) (48778/49344) | Learning rate: (0.0001)
2022-06-06 20:41:50,598 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 780 |  Loss: (0.0353) | Acc: (98.85%) (49411/49984) | Learning rate: (0.0001)
2022-06-06 20:42:00,884 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1026) | Acc: (96.98%) (9698/10000)
2022-06-06 20:42:00,885 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:42:01,957 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 0 |  Loss: (0.0853) | Acc: (96.88%) (62/64) | Learning rate: (0.0001)
2022-06-06 20:42:03,754 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 10 |  Loss: (0.0307) | Acc: (99.01%) (697/704) | Learning rate: (0.0001)
2022-06-06 20:42:05,549 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 20 |  Loss: (0.0272) | Acc: (99.18%) (1333/1344) | Learning rate: (0.0001)
2022-06-06 20:42:07,345 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 30 |  Loss: (0.0246) | Acc: (99.24%) (1969/1984) | Learning rate: (0.0001)
2022-06-06 20:42:09,143 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 40 |  Loss: (0.0292) | Acc: (99.09%) (2600/2624) | Learning rate: (0.0001)
2022-06-06 20:42:10,939 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 50 |  Loss: (0.0284) | Acc: (99.14%) (3236/3264) | Learning rate: (0.0001)
2022-06-06 20:42:12,735 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 60 |  Loss: (0.0294) | Acc: (99.08%) (3868/3904) | Learning rate: (0.0001)
2022-06-06 20:42:14,531 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 70 |  Loss: (0.0277) | Acc: (99.14%) (4505/4544) | Learning rate: (0.0001)
2022-06-06 20:42:29,818 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0978) | Acc: (97.05%) (9705/10000)
2022-06-06 20:42:29,819 - CIFAR10 Classifier - INFO - Epoch time : 0:00:28
2022-06-06 20:42:30,848 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 0 |  Loss: (0.0613) | Acc: (98.44%) (63/64) | Learning rate: (1e-05)
2022-06-06 20:42:32,651 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 10 |  Loss: (0.0362) | Acc: (98.58%) (694/704) | Learning rate: (1e-05)
2022-06-06 20:42:34,444 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 20 |  Loss: (0.0340) | Acc: (98.66%) (1326/1344) | Learning rate: (1e-05)
2022-06-06 20:42:36,236 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 30 |  Loss: (0.0306) | Acc: (98.84%) (1961/1984) | Learning rate: (1e-05)
2022-06-06 20:42:38,032 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 40 |  Loss: (0.0309) | Acc: (98.89%) (2595/2624) | Learning rate: (1e-05)
2022-06-06 20:42:39,828 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 50 |  Loss: (0.0313) | Acc: (98.93%) (3229/3264) | Learning rate: (1e-05)
2022-06-06 20:42:41,626 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 60 |  Loss: (0.0295) | Acc: (98.98%) (3864/3904) | Learning rate: (1e-05)
2022-06-06 20:42:43,422 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 70 |  Loss: (0.0307) | Acc: (98.92%) (4495/4544) | Learning rate: (1e-05)
2022-06-06 20:42:45,215 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 80 |  Loss: (0.0290) | Acc: (99.02%) (5133/5184) | Learning rate: (1e-05)
2022-06-06 20:42:47,013 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 90 |  Loss: (0.0311) | Acc: (98.99%) (5765/5824) | Learning rate: (1e-05)
2022-06-06 20:42:48,810 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 100 |  Loss: (0.0299) | Acc: (99.03%) (6401/6464) | Learning rate: (1e-05)
2022-06-06 20:42:50,610 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 110 |  Loss: (0.0300) | Acc: (99.03%) (7035/7104) | Learning rate: (1e-05)
2022-06-06 20:42:52,407 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 120 |  Loss: (0.0320) | Acc: (98.95%) (7663/7744) | Learning rate: (1e-05)
2022-06-06 20:42:54,203 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 130 |  Loss: (0.0316) | Acc: (98.96%) (8297/8384) | Learning rate: (1e-05)
2022-06-06 20:42:55,998 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 140 |  Loss: (0.0314) | Acc: (98.97%) (8931/9024) | Learning rate: (1e-05)
2022-06-06 20:42:57,796 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 150 |  Loss: (0.0304) | Acc: (99.00%) (9567/9664) | Learning rate: (1e-05)
2022-06-06 20:42:59,594 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 160 |  Loss: (0.0304) | Acc: (99.02%) (10203/10304) | Learning rate: (1e-05)
2022-06-06 20:43:01,391 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 170 |  Loss: (0.0294) | Acc: (99.06%) (10841/10944) | Learning rate: (1e-05)
2022-06-06 20:43:03,189 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 180 |  Loss: (0.0289) | Acc: (99.08%) (11477/11584) | Learning rate: (1e-05)
2022-06-06 20:43:04,988 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 190 |  Loss: (0.0278) | Acc: (99.12%) (12116/12224) | Learning rate: (1e-05)
2022-06-06 20:43:06,786 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 200 |  Loss: (0.0272) | Acc: (99.14%) (12753/12864) | Learning rate: (1e-05)
2022-06-06 20:43:08,582 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 210 |  Loss: (0.0273) | Acc: (99.13%) (13387/13504) | Learning rate: (1e-05)
2022-06-06 20:43:10,377 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 220 |  Loss: (0.0277) | Acc: (99.12%) (14019/14144) | Learning rate: (1e-05)
2022-06-06 20:43:12,173 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 230 |  Loss: (0.0283) | Acc: (99.09%) (14649/14784) | Learning rate: (1e-05)
2022-06-06 20:43:13,974 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 240 |  Loss: (0.0283) | Acc: (99.07%) (15280/15424) | Learning rate: (1e-05)
2022-06-06 20:43:15,773 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 250 |  Loss: (0.0281) | Acc: (99.07%) (15915/16064) | Learning rate: (1e-05)
2022-06-06 20:43:17,571 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 260 |  Loss: (0.0279) | Acc: (99.07%) (16549/16704) | Learning rate: (1e-05)
2022-06-06 20:43:19,369 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 270 |  Loss: (0.0274) | Acc: (99.09%) (17186/17344) | Learning rate: (1e-05)
2022-06-06 20:43:21,168 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 280 |  Loss: (0.0274) | Acc: (99.08%) (17819/17984) | Learning rate: (1e-05)
2022-06-06 20:43:22,966 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 290 |  Loss: (0.0276) | Acc: (99.08%) (18453/18624) | Learning rate: (1e-05)
2022-06-06 20:43:24,764 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 300 |  Loss: (0.0271) | Acc: (99.10%) (19090/19264) | Learning rate: (1e-05)
2022-06-06 20:43:26,559 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 310 |  Loss: (0.0273) | Acc: (99.09%) (19723/19904) | Learning rate: (1e-05)
2022-06-06 20:43:28,355 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 320 |  Loss: (0.0270) | Acc: (99.09%) (20357/20544) | Learning rate: (1e-05)
2022-06-06 20:43:30,151 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 330 |  Loss: (0.0265) | Acc: (99.11%) (20995/21184) | Learning rate: (1e-05)
2022-06-06 20:43:31,945 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 340 |  Loss: (0.0266) | Acc: (99.11%) (21629/21824) | Learning rate: (1e-05)
2022-06-06 20:43:33,745 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 350 |  Loss: (0.0274) | Acc: (99.09%) (22260/22464) | Learning rate: (1e-05)
2022-06-06 20:43:35,542 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 360 |  Loss: (0.0274) | Acc: (99.09%) (22894/23104) | Learning rate: (1e-05)
2022-06-06 20:43:37,342 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 370 |  Loss: (0.0274) | Acc: (99.09%) (23529/23744) | Learning rate: (1e-05)
2022-06-06 20:43:39,138 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 380 |  Loss: (0.0271) | Acc: (99.11%) (24166/24384) | Learning rate: (1e-05)
2022-06-06 20:43:40,934 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 390 |  Loss: (0.0272) | Acc: (99.10%) (24799/25024) | Learning rate: (1e-05)
2022-06-06 20:43:42,731 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 400 |  Loss: (0.0269) | Acc: (99.11%) (25435/25664) | Learning rate: (1e-05)
2022-06-06 20:43:44,527 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 410 |  Loss: (0.0268) | Acc: (99.10%) (26068/26304) | Learning rate: (1e-05)
2022-06-06 20:43:46,326 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 420 |  Loss: (0.0267) | Acc: (99.10%) (26702/26944) | Learning rate: (1e-05)
2022-06-06 20:43:48,124 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 430 |  Loss: (0.0265) | Acc: (99.11%) (27339/27584) | Learning rate: (1e-05)
2022-06-06 20:43:49,922 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 440 |  Loss: (0.0267) | Acc: (99.11%) (27973/28224) | Learning rate: (1e-05)
2022-06-06 20:43:51,722 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 450 |  Loss: (0.0268) | Acc: (99.11%) (28607/28864) | Learning rate: (1e-05)
2022-06-06 20:43:53,519 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 460 |  Loss: (0.0271) | Acc: (99.09%) (29235/29504) | Learning rate: (1e-05)
2022-06-06 20:43:55,318 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 470 |  Loss: (0.0270) | Acc: (99.09%) (29870/30144) | Learning rate: (1e-05)
2022-06-06 20:43:57,116 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 480 |  Loss: (0.0270) | Acc: (99.08%) (30502/30784) | Learning rate: (1e-05)
2022-06-06 20:43:58,914 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 490 |  Loss: (0.0268) | Acc: (99.10%) (31140/31424) | Learning rate: (1e-05)
2022-06-06 20:44:00,711 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 500 |  Loss: (0.0268) | Acc: (99.09%) (31772/32064) | Learning rate: (1e-05)
2022-06-06 20:44:02,507 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 510 |  Loss: (0.0270) | Acc: (99.08%) (32404/32704) | Learning rate: (1e-05)
2022-06-06 20:44:04,304 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 520 |  Loss: (0.0272) | Acc: (99.08%) (33037/33344) | Learning rate: (1e-05)
2022-06-06 20:44:06,101 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 530 |  Loss: (0.0273) | Acc: (99.08%) (33670/33984) | Learning rate: (1e-05)
2022-06-06 20:44:07,899 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 540 |  Loss: (0.0272) | Acc: (99.08%) (34304/34624) | Learning rate: (1e-05)
2022-06-06 20:44:09,697 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 550 |  Loss: (0.0271) | Acc: (99.08%) (34940/35264) | Learning rate: (1e-05)
2022-06-06 20:44:11,494 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 560 |  Loss: (0.0272) | Acc: (99.08%) (35573/35904) | Learning rate: (1e-05)
2022-06-06 20:44:13,292 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 570 |  Loss: (0.0275) | Acc: (99.06%) (36201/36544) | Learning rate: (1e-05)
2022-06-06 20:44:15,089 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 580 |  Loss: (0.0272) | Acc: (99.07%) (36840/37184) | Learning rate: (1e-05)
2022-06-06 20:44:16,890 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 590 |  Loss: (0.0272) | Acc: (99.07%) (37474/37824) | Learning rate: (1e-05)
2022-06-06 20:44:18,688 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 600 |  Loss: (0.0271) | Acc: (99.07%) (38107/38464) | Learning rate: (1e-05)
2022-06-06 20:44:20,489 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 610 |  Loss: (0.0269) | Acc: (99.08%) (38745/39104) | Learning rate: (1e-05)
2022-06-06 20:44:22,288 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 620 |  Loss: (0.0271) | Acc: (99.08%) (39378/39744) | Learning rate: (1e-05)
2022-06-06 20:44:24,087 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 630 |  Loss: (0.0275) | Acc: (99.07%) (40009/40384) | Learning rate: (1e-05)
2022-06-06 20:44:25,887 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 640 |  Loss: (0.0272) | Acc: (99.08%) (40648/41024) | Learning rate: (1e-05)
2022-06-06 20:44:27,687 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 650 |  Loss: (0.0271) | Acc: (99.09%) (41285/41664) | Learning rate: (1e-05)
2022-06-06 20:44:29,488 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 660 |  Loss: (0.0270) | Acc: (99.09%) (41921/42304) | Learning rate: (1e-05)
2022-06-06 20:44:31,286 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 670 |  Loss: (0.0271) | Acc: (99.09%) (42554/42944) | Learning rate: (1e-05)
2022-06-06 20:44:33,084 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 680 |  Loss: (0.0272) | Acc: (99.08%) (43185/43584) | Learning rate: (1e-05)
2022-06-06 20:44:34,881 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 690 |  Loss: (0.0270) | Acc: (99.09%) (43823/44224) | Learning rate: (1e-05)
2022-06-06 20:44:36,679 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 700 |  Loss: (0.0270) | Acc: (99.10%) (44459/44864) | Learning rate: (1e-05)
2022-06-06 20:44:38,480 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 710 |  Loss: (0.0270) | Acc: (99.10%) (45094/45504) | Learning rate: (1e-05)
2022-06-06 20:44:40,277 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 720 |  Loss: (0.0269) | Acc: (99.10%) (45729/46144) | Learning rate: (1e-05)
2022-06-06 20:44:42,077 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 730 |  Loss: (0.0269) | Acc: (99.10%) (46363/46784) | Learning rate: (1e-05)
2022-06-06 20:44:43,875 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 740 |  Loss: (0.0269) | Acc: (99.10%) (46998/47424) | Learning rate: (1e-05)
2022-06-06 20:44:45,675 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 750 |  Loss: (0.0269) | Acc: (99.11%) (47635/48064) | Learning rate: (1e-05)
2022-06-06 20:44:47,474 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 760 |  Loss: (0.0268) | Acc: (99.11%) (48272/48704) | Learning rate: (1e-05)
2022-06-06 20:44:49,263 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 770 |  Loss: (0.0267) | Acc: (99.12%) (48909/49344) | Learning rate: (1e-05)
2022-06-06 20:44:51,053 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 780 |  Loss: (0.0268) | Acc: (99.11%) (49541/49984) | Learning rate: (1e-05)
2022-06-06 20:45:01,355 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0856) | Acc: (97.40%) (9740/10000)
2022-06-06 20:45:01,356 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:45:02,491 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 0 |  Loss: (0.0031) | Acc: (100.00%) (64/64) | Learning rate: (1e-05)
2022-06-06 20:45:04,296 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 10 |  Loss: (0.0191) | Acc: (99.57%) (701/704) | Learning rate: (1e-05)
2022-06-06 20:45:06,090 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 20 |  Loss: (0.0268) | Acc: (99.26%) (1334/1344) | Learning rate: (1e-05)
2022-06-06 20:45:07,885 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 30 |  Loss: (0.0251) | Acc: (99.34%) (1971/1984) | Learning rate: (1e-05)
2022-06-06 20:45:09,682 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 40 |  Loss: (0.0265) | Acc: (99.31%) (2606/2624) | Learning rate: (1e-05)
2022-06-06 20:45:11,480 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 50 |  Loss: (0.0245) | Acc: (99.36%) (3243/3264) | Learning rate: (1e-05)
2022-06-06 20:45:13,278 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 60 |  Loss: (0.0238) | Acc: (99.36%) (3879/3904) | Learning rate: (1e-05)
2022-06-06 20:45:15,074 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 70 |  Loss: (0.0228) | Acc: (99.36%) (4515/4544) | Learning rate: (1e-05)
2022-06-06 20:45:16,872 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 80 |  Loss: (0.0226) | Acc: (99.36%) (5151/5184) | Learning rate: (1e-05)
2022-06-06 20:45:18,669 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 90 |  Loss: (0.0216) | Acc: (99.38%) (5788/5824) | Learning rate: (1e-05)
2022-06-06 20:45:20,468 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 100 |  Loss: (0.0223) | Acc: (99.33%) (6421/6464) | Learning rate: (1e-05)
2022-06-06 20:45:22,267 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 110 |  Loss: (0.0227) | Acc: (99.32%) (7056/7104) | Learning rate: (1e-05)
2022-06-06 20:45:24,068 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 120 |  Loss: (0.0226) | Acc: (99.32%) (7691/7744) | Learning rate: (1e-05)
2022-06-06 20:45:25,867 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 130 |  Loss: (0.0219) | Acc: (99.34%) (8329/8384) | Learning rate: (1e-05)
2022-06-06 20:45:27,665 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 140 |  Loss: (0.0220) | Acc: (99.35%) (8965/9024) | Learning rate: (1e-05)
2022-06-06 20:45:29,465 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 150 |  Loss: (0.0217) | Acc: (99.35%) (9601/9664) | Learning rate: (1e-05)
2022-06-06 20:45:31,264 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 160 |  Loss: (0.0219) | Acc: (99.31%) (10233/10304) | Learning rate: (1e-05)
2022-06-06 20:45:33,062 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 170 |  Loss: (0.0232) | Acc: (99.29%) (10866/10944) | Learning rate: (1e-05)
2022-06-06 20:45:34,862 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 180 |  Loss: (0.0243) | Acc: (99.27%) (11500/11584) | Learning rate: (1e-05)
2022-06-06 20:45:36,660 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 190 |  Loss: (0.0245) | Acc: (99.27%) (12135/12224) | Learning rate: (1e-05)
2022-06-06 20:45:38,458 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 200 |  Loss: (0.0244) | Acc: (99.26%) (12769/12864) | Learning rate: (1e-05)
2022-06-06 20:45:40,254 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 210 |  Loss: (0.0241) | Acc: (99.26%) (13404/13504) | Learning rate: (1e-05)
2022-06-06 20:45:42,049 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 220 |  Loss: (0.0239) | Acc: (99.27%) (14041/14144) | Learning rate: (1e-05)
2022-06-06 20:45:43,846 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 230 |  Loss: (0.0236) | Acc: (99.28%) (14677/14784) | Learning rate: (1e-05)
2022-06-06 20:45:45,642 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 240 |  Loss: (0.0238) | Acc: (99.26%) (15310/15424) | Learning rate: (1e-05)
2022-06-06 20:45:47,441 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 250 |  Loss: (0.0240) | Acc: (99.24%) (15942/16064) | Learning rate: (1e-05)
2022-06-06 20:45:49,240 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 260 |  Loss: (0.0239) | Acc: (99.24%) (16577/16704) | Learning rate: (1e-05)
2022-06-06 20:45:51,038 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 270 |  Loss: (0.0237) | Acc: (99.24%) (17213/17344) | Learning rate: (1e-05)
2022-06-06 20:45:52,836 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 280 |  Loss: (0.0239) | Acc: (99.23%) (17846/17984) | Learning rate: (1e-05)
2022-06-06 20:45:54,632 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 290 |  Loss: (0.0237) | Acc: (99.23%) (18481/18624) | Learning rate: (1e-05)
2022-06-06 20:45:56,432 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 300 |  Loss: (0.0235) | Acc: (99.23%) (19116/19264) | Learning rate: (1e-05)
2022-06-06 20:45:58,228 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 310 |  Loss: (0.0234) | Acc: (99.23%) (19751/19904) | Learning rate: (1e-05)
2022-06-06 20:46:00,026 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 320 |  Loss: (0.0232) | Acc: (99.24%) (20388/20544) | Learning rate: (1e-05)
2022-06-06 20:46:01,822 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 330 |  Loss: (0.0230) | Acc: (99.24%) (21024/21184) | Learning rate: (1e-05)
2022-06-06 20:46:03,618 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 340 |  Loss: (0.0226) | Acc: (99.26%) (21663/21824) | Learning rate: (1e-05)
2022-06-06 20:46:05,415 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 350 |  Loss: (0.0223) | Acc: (99.27%) (22300/22464) | Learning rate: (1e-05)
2022-06-06 20:46:07,212 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 360 |  Loss: (0.0222) | Acc: (99.28%) (22937/23104) | Learning rate: (1e-05)
2022-06-06 20:46:09,010 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 370 |  Loss: (0.0219) | Acc: (99.28%) (23573/23744) | Learning rate: (1e-05)
2022-06-06 20:46:10,808 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 380 |  Loss: (0.0221) | Acc: (99.27%) (24207/24384) | Learning rate: (1e-05)
2022-06-06 20:46:12,605 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 390 |  Loss: (0.0219) | Acc: (99.28%) (24844/25024) | Learning rate: (1e-05)
2022-06-06 20:46:14,404 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 400 |  Loss: (0.0219) | Acc: (99.28%) (25480/25664) | Learning rate: (1e-05)
2022-06-06 20:46:16,200 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 410 |  Loss: (0.0222) | Acc: (99.28%) (26115/26304) | Learning rate: (1e-05)
2022-06-06 20:46:18,000 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 420 |  Loss: (0.0219) | Acc: (99.30%) (26755/26944) | Learning rate: (1e-05)
2022-06-06 20:46:19,797 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 430 |  Loss: (0.0220) | Acc: (99.29%) (27389/27584) | Learning rate: (1e-05)
2022-06-06 20:46:21,594 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 440 |  Loss: (0.0226) | Acc: (99.29%) (28023/28224) | Learning rate: (1e-05)
2022-06-06 20:46:23,393 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 450 |  Loss: (0.0225) | Acc: (99.29%) (28659/28864) | Learning rate: (1e-05)
2022-06-06 20:46:25,190 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 460 |  Loss: (0.0227) | Acc: (99.28%) (29293/29504) | Learning rate: (1e-05)
2022-06-06 20:46:26,989 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 470 |  Loss: (0.0229) | Acc: (99.28%) (29927/30144) | Learning rate: (1e-05)
2022-06-06 20:46:28,786 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 480 |  Loss: (0.0228) | Acc: (99.29%) (30564/30784) | Learning rate: (1e-05)
2022-06-06 20:46:30,586 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 490 |  Loss: (0.0227) | Acc: (99.28%) (31198/31424) | Learning rate: (1e-05)
2022-06-06 20:46:32,385 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 500 |  Loss: (0.0225) | Acc: (99.29%) (31835/32064) | Learning rate: (1e-05)
2022-06-06 20:46:34,184 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 510 |  Loss: (0.0224) | Acc: (99.29%) (32472/32704) | Learning rate: (1e-05)
2022-06-06 20:46:35,984 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 520 |  Loss: (0.0222) | Acc: (99.30%) (33110/33344) | Learning rate: (1e-05)
2022-06-06 20:46:37,784 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 530 |  Loss: (0.0220) | Acc: (99.30%) (33747/33984) | Learning rate: (1e-05)
2022-06-06 20:46:39,584 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 540 |  Loss: (0.0220) | Acc: (99.30%) (34382/34624) | Learning rate: (1e-05)
2022-06-06 20:46:41,382 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 550 |  Loss: (0.0218) | Acc: (99.31%) (35020/35264) | Learning rate: (1e-05)
2022-06-06 20:46:43,181 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 560 |  Loss: (0.0218) | Acc: (99.31%) (35656/35904) | Learning rate: (1e-05)
2022-06-06 20:46:44,981 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 570 |  Loss: (0.0218) | Acc: (99.31%) (36293/36544) | Learning rate: (1e-05)
2022-06-06 20:46:46,781 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 580 |  Loss: (0.0219) | Acc: (99.32%) (36930/37184) | Learning rate: (1e-05)
2022-06-06 20:46:48,579 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 590 |  Loss: (0.0221) | Acc: (99.30%) (37561/37824) | Learning rate: (1e-05)
2022-06-06 20:46:50,379 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 600 |  Loss: (0.0221) | Acc: (99.30%) (38195/38464) | Learning rate: (1e-05)
2022-06-06 20:46:52,179 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 610 |  Loss: (0.0220) | Acc: (99.30%) (38831/39104) | Learning rate: (1e-05)
2022-06-06 20:46:53,978 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 620 |  Loss: (0.0219) | Acc: (99.31%) (39469/39744) | Learning rate: (1e-05)
2022-06-06 20:46:55,778 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 630 |  Loss: (0.0218) | Acc: (99.31%) (40106/40384) | Learning rate: (1e-05)
2022-06-06 20:46:57,577 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 640 |  Loss: (0.0217) | Acc: (99.32%) (40743/41024) | Learning rate: (1e-05)
2022-06-06 20:46:59,376 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 650 |  Loss: (0.0218) | Acc: (99.32%) (41379/41664) | Learning rate: (1e-05)
2022-06-06 20:47:01,175 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 660 |  Loss: (0.0218) | Acc: (99.32%) (42015/42304) | Learning rate: (1e-05)
2022-06-06 20:47:02,977 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 670 |  Loss: (0.0219) | Acc: (99.31%) (42649/42944) | Learning rate: (1e-05)
2022-06-06 20:47:04,777 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 680 |  Loss: (0.0221) | Acc: (99.31%) (43282/43584) | Learning rate: (1e-05)
2022-06-06 20:47:06,578 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 690 |  Loss: (0.0220) | Acc: (99.31%) (43919/44224) | Learning rate: (1e-05)
2022-06-06 20:47:08,378 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 700 |  Loss: (0.0220) | Acc: (99.30%) (44551/44864) | Learning rate: (1e-05)
2022-06-06 20:47:10,181 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 710 |  Loss: (0.0220) | Acc: (99.30%) (45187/45504) | Learning rate: (1e-05)
2022-06-06 20:47:11,981 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 720 |  Loss: (0.0220) | Acc: (99.31%) (45824/46144) | Learning rate: (1e-05)
2022-06-06 20:47:13,779 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 730 |  Loss: (0.0220) | Acc: (99.30%) (46458/46784) | Learning rate: (1e-05)
2022-06-06 20:47:15,580 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 740 |  Loss: (0.0218) | Acc: (99.31%) (47096/47424) | Learning rate: (1e-05)
2022-06-06 20:47:17,379 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 750 |  Loss: (0.0219) | Acc: (99.31%) (47731/48064) | Learning rate: (1e-05)
2022-06-06 20:47:19,179 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 760 |  Loss: (0.0218) | Acc: (99.31%) (48369/48704) | Learning rate: (1e-05)
2022-06-06 20:47:20,968 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 770 |  Loss: (0.0218) | Acc: (99.31%) (49005/49344) | Learning rate: (1e-05)
2022-06-06 20:47:22,759 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 780 |  Loss: (0.0217) | Acc: (99.32%) (49643/49984) | Learning rate: (1e-05)
2022-06-06 20:47:33,045 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0908) | Acc: (97.33%) (9733/10000)
2022-06-06 20:47:33,046 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:47:34,121 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 0 |  Loss: (0.0403) | Acc: (98.44%) (63/64) | Learning rate: (1e-05)
2022-06-06 20:47:35,939 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 10 |  Loss: (0.0272) | Acc: (99.15%) (698/704) | Learning rate: (1e-05)
2022-06-06 20:47:37,734 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 20 |  Loss: (0.0275) | Acc: (99.26%) (1334/1344) | Learning rate: (1e-05)
2022-06-06 20:47:39,532 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 30 |  Loss: (0.0233) | Acc: (99.40%) (1972/1984) | Learning rate: (1e-05)
2022-06-06 20:47:41,332 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 40 |  Loss: (0.0238) | Acc: (99.39%) (2608/2624) | Learning rate: (1e-05)
2022-06-06 20:47:43,131 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 50 |  Loss: (0.0221) | Acc: (99.45%) (3246/3264) | Learning rate: (1e-05)
2022-06-06 20:47:44,929 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 60 |  Loss: (0.0210) | Acc: (99.41%) (3881/3904) | Learning rate: (1e-05)
2022-06-06 20:47:46,729 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 70 |  Loss: (0.0208) | Acc: (99.41%) (4517/4544) | Learning rate: (1e-05)
2022-06-06 20:47:48,527 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 80 |  Loss: (0.0209) | Acc: (99.38%) (5152/5184) | Learning rate: (1e-05)
2022-06-06 20:47:50,324 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 90 |  Loss: (0.0202) | Acc: (99.40%) (5789/5824) | Learning rate: (1e-05)
2022-06-06 20:47:52,122 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 100 |  Loss: (0.0200) | Acc: (99.40%) (6425/6464) | Learning rate: (1e-05)
2022-06-06 20:47:53,923 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 110 |  Loss: (0.0195) | Acc: (99.39%) (7061/7104) | Learning rate: (1e-05)
2022-06-06 20:47:55,723 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 120 |  Loss: (0.0199) | Acc: (99.38%) (7696/7744) | Learning rate: (1e-05)
2022-06-06 20:47:57,522 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 130 |  Loss: (0.0204) | Acc: (99.36%) (8330/8384) | Learning rate: (1e-05)
2022-06-06 20:47:59,320 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 140 |  Loss: (0.0204) | Acc: (99.35%) (8965/9024) | Learning rate: (1e-05)
2022-06-06 20:48:01,119 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 150 |  Loss: (0.0210) | Acc: (99.34%) (9600/9664) | Learning rate: (1e-05)
2022-06-06 20:48:02,917 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 160 |  Loss: (0.0212) | Acc: (99.30%) (10232/10304) | Learning rate: (1e-05)
2022-06-06 20:48:04,715 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 170 |  Loss: (0.0208) | Acc: (99.31%) (10868/10944) | Learning rate: (1e-05)
2022-06-06 20:48:06,515 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 180 |  Loss: (0.0205) | Acc: (99.33%) (11506/11584) | Learning rate: (1e-05)
2022-06-06 20:48:08,313 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 190 |  Loss: (0.0202) | Acc: (99.35%) (12144/12224) | Learning rate: (1e-05)
2022-06-06 20:48:10,112 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 200 |  Loss: (0.0200) | Acc: (99.35%) (12780/12864) | Learning rate: (1e-05)
2022-06-06 20:48:11,910 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 210 |  Loss: (0.0202) | Acc: (99.33%) (13414/13504) | Learning rate: (1e-05)
2022-06-06 20:48:13,711 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 220 |  Loss: (0.0201) | Acc: (99.31%) (14046/14144) | Learning rate: (1e-05)
2022-06-06 20:48:15,513 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 230 |  Loss: (0.0200) | Acc: (99.30%) (14680/14784) | Learning rate: (1e-05)
2022-06-06 20:48:17,312 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 240 |  Loss: (0.0198) | Acc: (99.31%) (15317/15424) | Learning rate: (1e-05)
2022-06-06 20:48:19,110 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 250 |  Loss: (0.0197) | Acc: (99.32%) (15954/16064) | Learning rate: (1e-05)
2022-06-06 20:48:20,909 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 260 |  Loss: (0.0195) | Acc: (99.32%) (16591/16704) | Learning rate: (1e-05)
2022-06-06 20:48:22,708 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 270 |  Loss: (0.0198) | Acc: (99.31%) (17225/17344) | Learning rate: (1e-05)
2022-06-06 20:48:24,507 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 280 |  Loss: (0.0194) | Acc: (99.33%) (17863/17984) | Learning rate: (1e-05)
2022-06-06 20:48:26,306 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 290 |  Loss: (0.0193) | Acc: (99.34%) (18501/18624) | Learning rate: (1e-05)
2022-06-06 20:48:28,107 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 300 |  Loss: (0.0193) | Acc: (99.33%) (19135/19264) | Learning rate: (1e-05)
2022-06-06 20:48:29,908 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 310 |  Loss: (0.0195) | Acc: (99.33%) (19770/19904) | Learning rate: (1e-05)
2022-06-06 20:48:31,704 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 320 |  Loss: (0.0203) | Acc: (99.31%) (20402/20544) | Learning rate: (1e-05)
2022-06-06 20:48:33,503 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 330 |  Loss: (0.0203) | Acc: (99.31%) (21037/21184) | Learning rate: (1e-05)
2022-06-06 20:48:35,301 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 340 |  Loss: (0.0201) | Acc: (99.31%) (21674/21824) | Learning rate: (1e-05)
2022-06-06 20:48:37,098 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 350 |  Loss: (0.0200) | Acc: (99.31%) (22308/22464) | Learning rate: (1e-05)
2022-06-06 20:48:38,896 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 360 |  Loss: (0.0197) | Acc: (99.31%) (22945/23104) | Learning rate: (1e-05)
2022-06-06 20:48:40,695 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 370 |  Loss: (0.0196) | Acc: (99.31%) (23581/23744) | Learning rate: (1e-05)
2022-06-06 20:48:42,495 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 380 |  Loss: (0.0194) | Acc: (99.32%) (24219/24384) | Learning rate: (1e-05)
2022-06-06 20:48:44,295 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 390 |  Loss: (0.0192) | Acc: (99.33%) (24856/25024) | Learning rate: (1e-05)
2022-06-06 20:48:46,094 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 400 |  Loss: (0.0195) | Acc: (99.33%) (25491/25664) | Learning rate: (1e-05)
2022-06-06 20:48:47,893 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 410 |  Loss: (0.0193) | Acc: (99.34%) (26130/26304) | Learning rate: (1e-05)
2022-06-06 20:48:49,692 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 420 |  Loss: (0.0195) | Acc: (99.33%) (26763/26944) | Learning rate: (1e-05)
2022-06-06 20:48:51,490 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 430 |  Loss: (0.0196) | Acc: (99.33%) (27400/27584) | Learning rate: (1e-05)
2022-06-06 20:48:53,289 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 440 |  Loss: (0.0198) | Acc: (99.33%) (28035/28224) | Learning rate: (1e-05)
2022-06-06 20:48:55,087 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 450 |  Loss: (0.0198) | Acc: (99.33%) (28671/28864) | Learning rate: (1e-05)
2022-06-06 20:48:56,884 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 460 |  Loss: (0.0197) | Acc: (99.33%) (29306/29504) | Learning rate: (1e-05)
2022-06-06 20:48:58,684 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 470 |  Loss: (0.0195) | Acc: (99.34%) (29945/30144) | Learning rate: (1e-05)
2022-06-06 20:49:00,484 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 480 |  Loss: (0.0196) | Acc: (99.34%) (30581/30784) | Learning rate: (1e-05)
2022-06-06 20:49:02,282 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 490 |  Loss: (0.0195) | Acc: (99.33%) (31215/31424) | Learning rate: (1e-05)
2022-06-06 20:49:04,079 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 500 |  Loss: (0.0198) | Acc: (99.33%) (31849/32064) | Learning rate: (1e-05)
2022-06-06 20:49:05,879 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 510 |  Loss: (0.0198) | Acc: (99.33%) (32484/32704) | Learning rate: (1e-05)
2022-06-06 20:49:07,678 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 520 |  Loss: (0.0197) | Acc: (99.33%) (33120/33344) | Learning rate: (1e-05)
2022-06-06 20:49:09,476 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 530 |  Loss: (0.0197) | Acc: (99.33%) (33757/33984) | Learning rate: (1e-05)
2022-06-06 20:49:11,276 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 540 |  Loss: (0.0195) | Acc: (99.34%) (34396/34624) | Learning rate: (1e-05)
2022-06-06 20:49:13,073 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 550 |  Loss: (0.0193) | Acc: (99.35%) (35034/35264) | Learning rate: (1e-05)
2022-06-06 20:49:14,871 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 560 |  Loss: (0.0193) | Acc: (99.35%) (35671/35904) | Learning rate: (1e-05)
2022-06-06 20:49:16,669 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 570 |  Loss: (0.0191) | Acc: (99.36%) (36311/36544) | Learning rate: (1e-05)
2022-06-06 20:49:18,469 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 580 |  Loss: (0.0191) | Acc: (99.36%) (36945/37184) | Learning rate: (1e-05)
2022-06-06 20:49:20,267 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 590 |  Loss: (0.0190) | Acc: (99.37%) (37584/37824) | Learning rate: (1e-05)
2022-06-06 20:49:22,067 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 600 |  Loss: (0.0188) | Acc: (99.37%) (38223/38464) | Learning rate: (1e-05)
2022-06-06 20:49:23,868 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 610 |  Loss: (0.0191) | Acc: (99.37%) (38857/39104) | Learning rate: (1e-05)
2022-06-06 20:49:25,667 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 620 |  Loss: (0.0190) | Acc: (99.37%) (39494/39744) | Learning rate: (1e-05)
2022-06-06 20:49:27,465 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 630 |  Loss: (0.0192) | Acc: (99.36%) (40127/40384) | Learning rate: (1e-05)
2022-06-06 20:49:29,264 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 640 |  Loss: (0.0193) | Acc: (99.36%) (40762/41024) | Learning rate: (1e-05)
2022-06-06 20:49:31,063 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 650 |  Loss: (0.0193) | Acc: (99.36%) (41398/41664) | Learning rate: (1e-05)
2022-06-06 20:49:32,861 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 660 |  Loss: (0.0192) | Acc: (99.37%) (42036/42304) | Learning rate: (1e-05)
2022-06-06 20:49:34,660 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 670 |  Loss: (0.0191) | Acc: (99.38%) (42676/42944) | Learning rate: (1e-05)
2022-06-06 20:49:36,459 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 680 |  Loss: (0.0189) | Acc: (99.38%) (43313/43584) | Learning rate: (1e-05)
2022-06-06 20:49:38,259 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 690 |  Loss: (0.0191) | Acc: (99.37%) (43946/44224) | Learning rate: (1e-05)
2022-06-06 20:49:40,059 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 700 |  Loss: (0.0192) | Acc: (99.37%) (44580/44864) | Learning rate: (1e-05)
2022-06-06 20:49:41,859 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 710 |  Loss: (0.0192) | Acc: (99.37%) (45217/45504) | Learning rate: (1e-05)
2022-06-06 20:49:43,659 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 720 |  Loss: (0.0194) | Acc: (99.37%) (45852/46144) | Learning rate: (1e-05)
2022-06-06 20:49:45,459 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 730 |  Loss: (0.0193) | Acc: (99.37%) (46489/46784) | Learning rate: (1e-05)
2022-06-06 20:49:47,258 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 740 |  Loss: (0.0193) | Acc: (99.37%) (47126/47424) | Learning rate: (1e-05)
2022-06-06 20:49:49,059 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 750 |  Loss: (0.0191) | Acc: (99.38%) (47765/48064) | Learning rate: (1e-05)
2022-06-06 20:49:50,858 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 760 |  Loss: (0.0193) | Acc: (99.38%) (48401/48704) | Learning rate: (1e-05)
2022-06-06 20:49:52,650 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 770 |  Loss: (0.0194) | Acc: (99.37%) (49035/49344) | Learning rate: (1e-05)
2022-06-06 20:49:54,440 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 780 |  Loss: (0.0194) | Acc: (99.37%) (49671/49984) | Learning rate: (1e-05)
2022-06-06 20:50:04,725 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0856) | Acc: (97.56%) (9756/10000)
2022-06-06 20:50:04,726 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:50:05,854 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 0 |  Loss: (0.0283) | Acc: (98.44%) (63/64) | Learning rate: (1e-05)
2022-06-06 20:50:07,656 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 10 |  Loss: (0.0153) | Acc: (99.29%) (699/704) | Learning rate: (1e-05)
2022-06-06 20:50:09,449 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 20 |  Loss: (0.0156) | Acc: (99.40%) (1336/1344) | Learning rate: (1e-05)
2022-06-06 20:50:11,243 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 30 |  Loss: (0.0156) | Acc: (99.40%) (1972/1984) | Learning rate: (1e-05)
2022-06-06 20:50:13,040 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 40 |  Loss: (0.0153) | Acc: (99.50%) (2611/2624) | Learning rate: (1e-05)
2022-06-06 20:50:14,839 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 50 |  Loss: (0.0203) | Acc: (99.36%) (3243/3264) | Learning rate: (1e-05)
2022-06-06 20:50:16,635 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 60 |  Loss: (0.0200) | Acc: (99.41%) (3881/3904) | Learning rate: (1e-05)
2022-06-06 20:50:18,433 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 70 |  Loss: (0.0199) | Acc: (99.41%) (4517/4544) | Learning rate: (1e-05)
2022-06-06 20:50:20,232 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 80 |  Loss: (0.0201) | Acc: (99.36%) (5151/5184) | Learning rate: (1e-05)
2022-06-06 20:50:22,028 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 90 |  Loss: (0.0202) | Acc: (99.35%) (5786/5824) | Learning rate: (1e-05)
2022-06-06 20:50:23,826 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 100 |  Loss: (0.0199) | Acc: (99.35%) (6422/6464) | Learning rate: (1e-05)
2022-06-06 20:50:25,624 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 110 |  Loss: (0.0192) | Acc: (99.35%) (7058/7104) | Learning rate: (1e-05)
2022-06-06 20:50:27,420 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 120 |  Loss: (0.0192) | Acc: (99.34%) (7693/7744) | Learning rate: (1e-05)
2022-06-06 20:50:29,219 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 130 |  Loss: (0.0196) | Acc: (99.37%) (8331/8384) | Learning rate: (1e-05)
2022-06-06 20:50:31,015 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 140 |  Loss: (0.0199) | Acc: (99.36%) (8966/9024) | Learning rate: (1e-05)
2022-06-06 20:50:32,814 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 150 |  Loss: (0.0195) | Acc: (99.36%) (9602/9664) | Learning rate: (1e-05)
2022-06-06 20:50:34,612 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 160 |  Loss: (0.0201) | Acc: (99.33%) (10235/10304) | Learning rate: (1e-05)
2022-06-06 20:50:36,410 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 170 |  Loss: (0.0196) | Acc: (99.34%) (10872/10944) | Learning rate: (1e-05)
2022-06-06 20:50:38,207 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 180 |  Loss: (0.0191) | Acc: (99.36%) (11510/11584) | Learning rate: (1e-05)
2022-06-06 20:50:40,004 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 190 |  Loss: (0.0193) | Acc: (99.37%) (12147/12224) | Learning rate: (1e-05)
2022-06-06 20:50:41,802 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 200 |  Loss: (0.0193) | Acc: (99.39%) (12785/12864) | Learning rate: (1e-05)
2022-06-06 20:50:43,601 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 210 |  Loss: (0.0190) | Acc: (99.40%) (13423/13504) | Learning rate: (1e-05)
2022-06-06 20:50:45,401 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 220 |  Loss: (0.0189) | Acc: (99.41%) (14061/14144) | Learning rate: (1e-05)
2022-06-06 20:50:47,200 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 230 |  Loss: (0.0193) | Acc: (99.40%) (14695/14784) | Learning rate: (1e-05)
2022-06-06 20:50:49,000 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 240 |  Loss: (0.0194) | Acc: (99.38%) (15329/15424) | Learning rate: (1e-05)
2022-06-06 20:50:50,799 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 250 |  Loss: (0.0192) | Acc: (99.39%) (15966/16064) | Learning rate: (1e-05)
2022-06-06 20:50:52,597 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 260 |  Loss: (0.0189) | Acc: (99.41%) (16605/16704) | Learning rate: (1e-05)
2022-06-06 20:50:54,396 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 270 |  Loss: (0.0188) | Acc: (99.39%) (17239/17344) | Learning rate: (1e-05)
2022-06-06 20:50:56,195 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 280 |  Loss: (0.0186) | Acc: (99.41%) (17878/17984) | Learning rate: (1e-05)
2022-06-06 20:50:57,995 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 290 |  Loss: (0.0192) | Acc: (99.39%) (18511/18624) | Learning rate: (1e-05)
2022-06-06 20:50:59,796 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 300 |  Loss: (0.0192) | Acc: (99.39%) (19147/19264) | Learning rate: (1e-05)
2022-06-06 20:51:01,596 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 310 |  Loss: (0.0192) | Acc: (99.38%) (19781/19904) | Learning rate: (1e-05)
2022-06-06 20:51:03,396 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 320 |  Loss: (0.0193) | Acc: (99.38%) (20416/20544) | Learning rate: (1e-05)
2022-06-06 20:51:05,194 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 330 |  Loss: (0.0192) | Acc: (99.38%) (21052/21184) | Learning rate: (1e-05)
2022-06-06 20:51:06,994 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 340 |  Loss: (0.0192) | Acc: (99.38%) (21689/21824) | Learning rate: (1e-05)
2022-06-06 20:51:08,793 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 350 |  Loss: (0.0191) | Acc: (99.39%) (22327/22464) | Learning rate: (1e-05)
2022-06-06 20:51:10,593 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 360 |  Loss: (0.0192) | Acc: (99.39%) (22962/23104) | Learning rate: (1e-05)
2022-06-06 20:51:12,390 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 370 |  Loss: (0.0188) | Acc: (99.40%) (23602/23744) | Learning rate: (1e-05)
2022-06-06 20:51:25,131 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0864) | Acc: (97.43%) (9743/10000)
2022-06-06 20:51:25,132 - CIFAR10 Classifier - INFO - Epoch time : 0:01:20
2022-06-06 20:51:26,205 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 0 |  Loss: (0.0261) | Acc: (98.44%) (63/64) | Learning rate: (0.0)
2022-06-06 20:51:28,018 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 10 |  Loss: (0.0211) | Acc: (98.86%) (696/704) | Learning rate: (0.0)
2022-06-06 20:51:39,138 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 20:51:39,140 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 20:51:39,141 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 20:51:39,141 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 20:51:39,141 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 20:51:40,099 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (2.3273) | Acc: (9.38%) (6/64) | Learning rate: (0.0001)
2022-06-06 20:51:41,878 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (2.2787) | Acc: (14.20%) (100/704) | Learning rate: (0.0001)
2022-06-06 20:51:43,662 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (2.2293) | Acc: (20.98%) (282/1344) | Learning rate: (0.0001)
2022-06-06 20:51:45,449 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (2.1757) | Acc: (27.12%) (538/1984) | Learning rate: (0.0001)
2022-06-06 20:51:47,240 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (2.1139) | Acc: (33.69%) (884/2624) | Learning rate: (0.0001)
2022-06-06 20:51:49,028 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 50 |  Loss: (2.0427) | Acc: (39.28%) (1282/3264) | Learning rate: (0.0001)
2022-06-06 20:51:50,817 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 60 |  Loss: (1.9640) | Acc: (43.83%) (1711/3904) | Learning rate: (0.0001)
2022-06-06 20:51:52,609 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 70 |  Loss: (1.8728) | Acc: (48.48%) (2203/4544) | Learning rate: (0.0001)
2022-06-06 20:51:54,399 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 80 |  Loss: (1.7758) | Acc: (52.51%) (2722/5184) | Learning rate: (0.0001)
2022-06-06 20:51:56,190 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 90 |  Loss: (1.6821) | Acc: (55.49%) (3232/5824) | Learning rate: (0.0001)
2022-06-06 20:51:57,982 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 100 |  Loss: (1.5934) | Acc: (57.98%) (3748/6464) | Learning rate: (0.0001)
2022-06-06 20:51:59,772 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 110 |  Loss: (1.5122) | Acc: (60.25%) (4280/7104) | Learning rate: (0.0001)
2022-06-06 20:52:01,564 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 120 |  Loss: (1.4333) | Acc: (62.31%) (4825/7744) | Learning rate: (0.0001)
2022-06-06 20:52:03,357 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 130 |  Loss: (1.3638) | Acc: (64.16%) (5379/8384) | Learning rate: (0.0001)
2022-06-06 20:52:05,152 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 140 |  Loss: (1.3006) | Acc: (65.86%) (5943/9024) | Learning rate: (0.0001)
2022-06-06 20:52:06,945 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 150 |  Loss: (1.2405) | Acc: (67.46%) (6519/9664) | Learning rate: (0.0001)
2022-06-06 20:52:08,738 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 160 |  Loss: (1.1864) | Acc: (68.91%) (7100/10304) | Learning rate: (0.0001)
2022-06-06 20:52:10,533 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 170 |  Loss: (1.1386) | Acc: (70.15%) (7677/10944) | Learning rate: (0.0001)
2022-06-06 20:52:12,328 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 180 |  Loss: (1.0973) | Acc: (71.17%) (8244/11584) | Learning rate: (0.0001)
2022-06-06 20:52:14,123 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 190 |  Loss: (1.0589) | Acc: (72.14%) (8819/12224) | Learning rate: (0.0001)
2022-06-06 20:52:15,917 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 200 |  Loss: (1.0252) | Acc: (72.95%) (9384/12864) | Learning rate: (0.0001)
2022-06-06 20:52:17,713 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 210 |  Loss: (0.9929) | Acc: (73.72%) (9955/13504) | Learning rate: (0.0001)
2022-06-06 20:52:19,509 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 220 |  Loss: (0.9631) | Acc: (74.45%) (10530/14144) | Learning rate: (0.0001)
2022-06-06 20:52:21,305 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 230 |  Loss: (0.9342) | Acc: (75.16%) (11111/14784) | Learning rate: (0.0001)
2022-06-06 20:52:23,103 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 240 |  Loss: (0.9098) | Acc: (75.76%) (11685/15424) | Learning rate: (0.0001)
2022-06-06 20:52:24,897 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 250 |  Loss: (0.8843) | Acc: (76.41%) (12275/16064) | Learning rate: (0.0001)
2022-06-06 20:52:26,692 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 260 |  Loss: (0.8597) | Acc: (77.05%) (12870/16704) | Learning rate: (0.0001)
2022-06-06 20:52:28,488 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 270 |  Loss: (0.8393) | Acc: (77.54%) (13448/17344) | Learning rate: (0.0001)
2022-06-06 20:52:30,284 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 280 |  Loss: (0.8199) | Acc: (78.00%) (14028/17984) | Learning rate: (0.0001)
2022-06-06 20:52:32,080 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 290 |  Loss: (0.8031) | Acc: (78.38%) (14597/18624) | Learning rate: (0.0001)
2022-06-06 20:52:33,876 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 300 |  Loss: (0.7837) | Acc: (78.89%) (15198/19264) | Learning rate: (0.0001)
2022-06-06 20:52:35,670 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 310 |  Loss: (0.7667) | Acc: (79.34%) (15792/19904) | Learning rate: (0.0001)
2022-06-06 20:52:37,466 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 320 |  Loss: (0.7516) | Acc: (79.69%) (16371/20544) | Learning rate: (0.0001)
2022-06-06 20:52:39,262 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 330 |  Loss: (0.7373) | Acc: (80.04%) (16955/21184) | Learning rate: (0.0001)
2022-06-06 20:52:41,059 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 340 |  Loss: (0.7227) | Acc: (80.40%) (17547/21824) | Learning rate: (0.0001)
2022-06-06 20:52:42,857 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 350 |  Loss: (0.7081) | Acc: (80.80%) (18150/22464) | Learning rate: (0.0001)
2022-06-06 20:52:44,655 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 360 |  Loss: (0.6947) | Acc: (81.15%) (18749/23104) | Learning rate: (0.0001)
2022-06-06 20:52:46,450 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 370 |  Loss: (0.6822) | Acc: (81.46%) (19342/23744) | Learning rate: (0.0001)
2022-06-06 20:52:48,245 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 380 |  Loss: (0.6710) | Acc: (81.71%) (19925/24384) | Learning rate: (0.0001)
2022-06-06 20:52:50,043 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 390 |  Loss: (0.6595) | Acc: (82.00%) (20520/25024) | Learning rate: (0.0001)
2022-06-06 20:52:51,839 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 400 |  Loss: (0.6497) | Acc: (82.23%) (21103/25664) | Learning rate: (0.0001)
2022-06-06 20:52:53,638 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 410 |  Loss: (0.6390) | Acc: (82.48%) (21696/26304) | Learning rate: (0.0001)
2022-06-06 20:52:55,436 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 420 |  Loss: (0.6278) | Acc: (82.79%) (22308/26944) | Learning rate: (0.0001)
2022-06-06 20:52:57,233 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 430 |  Loss: (0.6182) | Acc: (83.03%) (22903/27584) | Learning rate: (0.0001)
2022-06-06 20:52:59,031 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 440 |  Loss: (0.6096) | Acc: (83.22%) (23489/28224) | Learning rate: (0.0001)
2022-06-06 20:53:00,828 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 450 |  Loss: (0.6007) | Acc: (83.45%) (24088/28864) | Learning rate: (0.0001)
2022-06-06 20:53:02,623 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 460 |  Loss: (0.5918) | Acc: (83.68%) (24689/29504) | Learning rate: (0.0001)
2022-06-06 20:53:04,420 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 470 |  Loss: (0.5843) | Acc: (83.88%) (25286/30144) | Learning rate: (0.0001)
2022-06-06 20:53:06,217 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 480 |  Loss: (0.5765) | Acc: (84.08%) (25884/30784) | Learning rate: (0.0001)
2022-06-06 20:53:08,015 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 490 |  Loss: (0.5682) | Acc: (84.29%) (26487/31424) | Learning rate: (0.0001)
2022-06-06 20:53:09,813 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 500 |  Loss: (0.5604) | Acc: (84.49%) (27090/32064) | Learning rate: (0.0001)
2022-06-06 20:53:11,611 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 510 |  Loss: (0.5540) | Acc: (84.65%) (27684/32704) | Learning rate: (0.0001)
2022-06-06 20:53:13,409 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 520 |  Loss: (0.5463) | Acc: (84.86%) (28295/33344) | Learning rate: (0.0001)
2022-06-06 20:53:15,206 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 530 |  Loss: (0.5394) | Acc: (85.04%) (28899/33984) | Learning rate: (0.0001)
2022-06-06 20:53:17,005 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 540 |  Loss: (0.5325) | Acc: (85.20%) (29500/34624) | Learning rate: (0.0001)
2022-06-06 20:53:18,803 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 550 |  Loss: (0.5268) | Acc: (85.34%) (30094/35264) | Learning rate: (0.0001)
2022-06-06 20:53:20,598 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 560 |  Loss: (0.5210) | Acc: (85.46%) (30685/35904) | Learning rate: (0.0001)
2022-06-06 20:53:22,397 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 570 |  Loss: (0.5156) | Acc: (85.62%) (31288/36544) | Learning rate: (0.0001)
2022-06-06 20:53:24,194 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 580 |  Loss: (0.5099) | Acc: (85.76%) (31889/37184) | Learning rate: (0.0001)
2022-06-06 20:53:25,992 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 590 |  Loss: (0.5046) | Acc: (85.90%) (32490/37824) | Learning rate: (0.0001)
2022-06-06 20:53:27,790 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 600 |  Loss: (0.4993) | Acc: (86.03%) (33090/38464) | Learning rate: (0.0001)
2022-06-06 20:53:29,588 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 610 |  Loss: (0.4941) | Acc: (86.17%) (33695/39104) | Learning rate: (0.0001)
2022-06-06 20:53:31,387 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 620 |  Loss: (0.4891) | Acc: (86.29%) (34296/39744) | Learning rate: (0.0001)
2022-06-06 20:53:33,184 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 630 |  Loss: (0.4840) | Acc: (86.42%) (34900/40384) | Learning rate: (0.0001)
2022-06-06 20:53:34,983 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 640 |  Loss: (0.4790) | Acc: (86.55%) (35507/41024) | Learning rate: (0.0001)
2022-06-06 20:53:36,780 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 650 |  Loss: (0.4742) | Acc: (86.68%) (36115/41664) | Learning rate: (0.0001)
2022-06-06 20:53:38,580 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 660 |  Loss: (0.4699) | Acc: (86.78%) (36713/42304) | Learning rate: (0.0001)
2022-06-06 20:53:40,376 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 670 |  Loss: (0.4656) | Acc: (86.90%) (37318/42944) | Learning rate: (0.0001)
2022-06-06 20:53:42,173 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 680 |  Loss: (0.4619) | Acc: (86.98%) (37911/43584) | Learning rate: (0.0001)
2022-06-06 20:53:43,970 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 690 |  Loss: (0.4580) | Acc: (87.07%) (38504/44224) | Learning rate: (0.0001)
2022-06-06 20:53:45,766 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 700 |  Loss: (0.4541) | Acc: (87.16%) (39103/44864) | Learning rate: (0.0001)
2022-06-06 20:53:47,563 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 710 |  Loss: (0.4498) | Acc: (87.27%) (39710/45504) | Learning rate: (0.0001)
2022-06-06 20:53:49,361 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 720 |  Loss: (0.4457) | Acc: (87.37%) (40318/46144) | Learning rate: (0.0001)
2022-06-06 20:53:51,159 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 730 |  Loss: (0.4418) | Acc: (87.48%) (40925/46784) | Learning rate: (0.0001)
2022-06-06 20:53:52,958 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 740 |  Loss: (0.4379) | Acc: (87.57%) (41527/47424) | Learning rate: (0.0001)
2022-06-06 20:53:54,755 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 750 |  Loss: (0.4337) | Acc: (87.67%) (42139/48064) | Learning rate: (0.0001)
2022-06-06 20:53:56,553 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 760 |  Loss: (0.4302) | Acc: (87.77%) (42749/48704) | Learning rate: (0.0001)
2022-06-06 20:53:58,343 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 770 |  Loss: (0.4265) | Acc: (87.86%) (43356/49344) | Learning rate: (0.0001)
2022-06-06 20:54:00,133 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 780 |  Loss: (0.4230) | Acc: (87.94%) (43958/49984) | Learning rate: (0.0001)
2022-06-06 20:54:10,137 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1098) | Acc: (96.44%) (9644/10000)
2022-06-06 20:54:10,138 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 20:54:11,332 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 0 |  Loss: (0.0312) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:54:13,125 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 10 |  Loss: (0.1487) | Acc: (96.16%) (677/704) | Learning rate: (0.0001)
2022-06-06 20:54:14,920 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 20 |  Loss: (0.1253) | Acc: (96.50%) (1297/1344) | Learning rate: (0.0001)
2022-06-06 20:54:16,714 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 30 |  Loss: (0.1263) | Acc: (96.32%) (1911/1984) | Learning rate: (0.0001)
2022-06-06 20:54:18,513 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 40 |  Loss: (0.1234) | Acc: (96.42%) (2530/2624) | Learning rate: (0.0001)
2022-06-06 20:54:20,311 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 50 |  Loss: (0.1190) | Acc: (96.48%) (3149/3264) | Learning rate: (0.0001)
2022-06-06 20:54:22,111 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 60 |  Loss: (0.1149) | Acc: (96.57%) (3770/3904) | Learning rate: (0.0001)
2022-06-06 20:54:23,910 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 70 |  Loss: (0.1132) | Acc: (96.52%) (4386/4544) | Learning rate: (0.0001)
2022-06-06 20:54:25,710 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 80 |  Loss: (0.1138) | Acc: (96.49%) (5002/5184) | Learning rate: (0.0001)
2022-06-06 20:54:27,509 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 90 |  Loss: (0.1135) | Acc: (96.53%) (5622/5824) | Learning rate: (0.0001)
2022-06-06 20:54:29,308 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 100 |  Loss: (0.1128) | Acc: (96.50%) (6238/6464) | Learning rate: (0.0001)
2022-06-06 20:54:31,108 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 110 |  Loss: (0.1156) | Acc: (96.38%) (6847/7104) | Learning rate: (0.0001)
2022-06-06 20:54:32,907 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 120 |  Loss: (0.1166) | Acc: (96.33%) (7460/7744) | Learning rate: (0.0001)
2022-06-06 20:54:34,707 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 130 |  Loss: (0.1212) | Acc: (96.16%) (8062/8384) | Learning rate: (0.0001)
2022-06-06 20:54:36,507 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 140 |  Loss: (0.1229) | Acc: (96.10%) (8672/9024) | Learning rate: (0.0001)
2022-06-06 20:54:38,305 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 150 |  Loss: (0.1222) | Acc: (96.15%) (9292/9664) | Learning rate: (0.0001)
2022-06-06 20:54:40,103 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 160 |  Loss: (0.1192) | Acc: (96.26%) (9919/10304) | Learning rate: (0.0001)
2022-06-06 20:54:41,904 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 170 |  Loss: (0.1185) | Acc: (96.28%) (10537/10944) | Learning rate: (0.0001)
2022-06-06 20:54:43,704 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 180 |  Loss: (0.1180) | Acc: (96.24%) (11149/11584) | Learning rate: (0.0001)
2022-06-06 20:54:45,504 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 190 |  Loss: (0.1182) | Acc: (96.23%) (11763/12224) | Learning rate: (0.0001)
2022-06-06 20:54:47,304 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 200 |  Loss: (0.1178) | Acc: (96.22%) (12378/12864) | Learning rate: (0.0001)
2022-06-06 20:54:49,102 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 210 |  Loss: (0.1180) | Acc: (96.23%) (12995/13504) | Learning rate: (0.0001)
2022-06-06 20:54:50,901 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 220 |  Loss: (0.1172) | Acc: (96.26%) (13615/14144) | Learning rate: (0.0001)
2022-06-06 20:54:52,701 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 230 |  Loss: (0.1163) | Acc: (96.29%) (14236/14784) | Learning rate: (0.0001)
2022-06-06 20:54:54,502 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 240 |  Loss: (0.1153) | Acc: (96.31%) (14855/15424) | Learning rate: (0.0001)
2022-06-06 20:54:56,301 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 250 |  Loss: (0.1144) | Acc: (96.31%) (15472/16064) | Learning rate: (0.0001)
2022-06-06 20:54:58,099 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 260 |  Loss: (0.1134) | Acc: (96.35%) (16094/16704) | Learning rate: (0.0001)
2022-06-06 20:54:59,897 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 270 |  Loss: (0.1134) | Acc: (96.33%) (16708/17344) | Learning rate: (0.0001)
2022-06-06 20:55:01,697 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 280 |  Loss: (0.1117) | Acc: (96.41%) (17338/17984) | Learning rate: (0.0001)
2022-06-06 20:55:03,497 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 290 |  Loss: (0.1114) | Acc: (96.40%) (17953/18624) | Learning rate: (0.0001)
2022-06-06 20:55:05,296 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 300 |  Loss: (0.1104) | Acc: (96.42%) (18574/19264) | Learning rate: (0.0001)
2022-06-06 20:55:07,097 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 310 |  Loss: (0.1094) | Acc: (96.45%) (19198/19904) | Learning rate: (0.0001)
2022-06-06 20:55:08,897 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 320 |  Loss: (0.1098) | Acc: (96.45%) (19814/20544) | Learning rate: (0.0001)
2022-06-06 20:55:10,695 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 330 |  Loss: (0.1094) | Acc: (96.45%) (20433/21184) | Learning rate: (0.0001)
2022-06-06 20:55:12,495 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 340 |  Loss: (0.1089) | Acc: (96.46%) (21051/21824) | Learning rate: (0.0001)
2022-06-06 20:55:14,294 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 350 |  Loss: (0.1093) | Acc: (96.43%) (21661/22464) | Learning rate: (0.0001)
2022-06-06 20:55:16,094 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 360 |  Loss: (0.1083) | Acc: (96.46%) (22287/23104) | Learning rate: (0.0001)
2022-06-06 20:55:17,894 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 370 |  Loss: (0.1079) | Acc: (96.47%) (22907/23744) | Learning rate: (0.0001)
2022-06-06 20:55:19,693 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 380 |  Loss: (0.1070) | Acc: (96.51%) (23534/24384) | Learning rate: (0.0001)
2022-06-06 20:55:21,491 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 390 |  Loss: (0.1077) | Acc: (96.49%) (24145/25024) | Learning rate: (0.0001)
2022-06-06 20:55:23,291 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 400 |  Loss: (0.1084) | Acc: (96.47%) (24758/25664) | Learning rate: (0.0001)
2022-06-06 20:55:25,090 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 410 |  Loss: (0.1080) | Acc: (96.49%) (25382/26304) | Learning rate: (0.0001)
2022-06-06 20:55:26,889 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 420 |  Loss: (0.1071) | Acc: (96.53%) (26009/26944) | Learning rate: (0.0001)
2022-06-06 20:55:28,687 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 430 |  Loss: (0.1065) | Acc: (96.55%) (26633/27584) | Learning rate: (0.0001)
2022-06-06 20:55:30,485 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 440 |  Loss: (0.1062) | Acc: (96.58%) (27258/28224) | Learning rate: (0.0001)
2022-06-06 20:55:32,282 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 450 |  Loss: (0.1065) | Acc: (96.57%) (27873/28864) | Learning rate: (0.0001)
2022-06-06 20:55:34,079 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 460 |  Loss: (0.1069) | Acc: (96.56%) (28490/29504) | Learning rate: (0.0001)
2022-06-06 20:55:35,876 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 470 |  Loss: (0.1070) | Acc: (96.54%) (29102/30144) | Learning rate: (0.0001)
2022-06-06 20:55:37,673 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 480 |  Loss: (0.1063) | Acc: (96.57%) (29728/30784) | Learning rate: (0.0001)
2022-06-06 20:55:39,471 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 490 |  Loss: (0.1058) | Acc: (96.59%) (30352/31424) | Learning rate: (0.0001)
2022-06-06 20:55:41,268 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 500 |  Loss: (0.1054) | Acc: (96.60%) (30975/32064) | Learning rate: (0.0001)
2022-06-06 20:55:43,066 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 510 |  Loss: (0.1055) | Acc: (96.59%) (31590/32704) | Learning rate: (0.0001)
2022-06-06 20:55:44,863 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 520 |  Loss: (0.1049) | Acc: (96.61%) (32214/33344) | Learning rate: (0.0001)
2022-06-06 20:55:46,662 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 530 |  Loss: (0.1048) | Acc: (96.60%) (32829/33984) | Learning rate: (0.0001)
2022-06-06 20:55:48,462 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 540 |  Loss: (0.1053) | Acc: (96.59%) (33444/34624) | Learning rate: (0.0001)
2022-06-06 20:55:50,260 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 550 |  Loss: (0.1050) | Acc: (96.60%) (34064/35264) | Learning rate: (0.0001)
2022-06-06 20:55:52,060 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 560 |  Loss: (0.1054) | Acc: (96.59%) (34680/35904) | Learning rate: (0.0001)
2022-06-06 20:55:53,858 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 570 |  Loss: (0.1051) | Acc: (96.61%) (35305/36544) | Learning rate: (0.0001)
2022-06-06 20:55:55,655 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 580 |  Loss: (0.1047) | Acc: (96.62%) (35929/37184) | Learning rate: (0.0001)
2022-06-06 20:55:57,454 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 590 |  Loss: (0.1046) | Acc: (96.62%) (36547/37824) | Learning rate: (0.0001)
2022-06-06 20:55:59,251 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 600 |  Loss: (0.1045) | Acc: (96.62%) (37165/38464) | Learning rate: (0.0001)
2022-06-06 20:56:01,048 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 610 |  Loss: (0.1043) | Acc: (96.64%) (37790/39104) | Learning rate: (0.0001)
2022-06-06 20:56:02,845 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 620 |  Loss: (0.1042) | Acc: (96.63%) (38405/39744) | Learning rate: (0.0001)
2022-06-06 20:56:04,642 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 630 |  Loss: (0.1046) | Acc: (96.61%) (39017/40384) | Learning rate: (0.0001)
2022-06-06 20:56:06,439 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 640 |  Loss: (0.1048) | Acc: (96.61%) (39632/41024) | Learning rate: (0.0001)
2022-06-06 20:56:08,236 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 650 |  Loss: (0.1046) | Acc: (96.62%) (40255/41664) | Learning rate: (0.0001)
2022-06-06 20:56:10,035 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 660 |  Loss: (0.1046) | Acc: (96.62%) (40874/42304) | Learning rate: (0.0001)
2022-06-06 20:56:11,835 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 670 |  Loss: (0.1046) | Acc: (96.61%) (41489/42944) | Learning rate: (0.0001)
2022-06-06 20:56:13,634 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 680 |  Loss: (0.1047) | Acc: (96.61%) (42106/43584) | Learning rate: (0.0001)
2022-06-06 20:56:15,433 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 690 |  Loss: (0.1045) | Acc: (96.62%) (42730/44224) | Learning rate: (0.0001)
2022-06-06 20:56:17,233 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 700 |  Loss: (0.1044) | Acc: (96.61%) (43345/44864) | Learning rate: (0.0001)
2022-06-06 20:56:19,032 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 710 |  Loss: (0.1041) | Acc: (96.63%) (43971/45504) | Learning rate: (0.0001)
2022-06-06 20:56:20,831 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 720 |  Loss: (0.1038) | Acc: (96.64%) (44593/46144) | Learning rate: (0.0001)
2022-06-06 20:56:22,630 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 730 |  Loss: (0.1035) | Acc: (96.65%) (45215/46784) | Learning rate: (0.0001)
2022-06-06 20:56:24,429 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 740 |  Loss: (0.1032) | Acc: (96.66%) (45838/47424) | Learning rate: (0.0001)
2022-06-06 20:56:26,229 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 750 |  Loss: (0.1029) | Acc: (96.67%) (46463/48064) | Learning rate: (0.0001)
2022-06-06 20:56:28,029 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 760 |  Loss: (0.1025) | Acc: (96.68%) (47086/48704) | Learning rate: (0.0001)
2022-06-06 20:56:29,818 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 770 |  Loss: (0.1026) | Acc: (96.68%) (47704/49344) | Learning rate: (0.0001)
2022-06-06 20:56:31,609 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 780 |  Loss: (0.1022) | Acc: (96.69%) (48332/49984) | Learning rate: (0.0001)
2022-06-06 20:56:41,569 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0909) | Acc: (96.90%) (9690/10000)
2022-06-06 20:56:41,570 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 20:56:42,561 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 0 |  Loss: (0.0845) | Acc: (96.88%) (62/64) | Learning rate: (0.0001)
2022-06-06 20:56:44,381 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 10 |  Loss: (0.0876) | Acc: (97.16%) (684/704) | Learning rate: (0.0001)
2022-06-06 20:56:46,175 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 20 |  Loss: (0.0876) | Acc: (97.32%) (1308/1344) | Learning rate: (0.0001)
2022-06-06 20:56:47,968 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 30 |  Loss: (0.0778) | Acc: (97.38%) (1932/1984) | Learning rate: (0.0001)
2022-06-06 20:56:49,763 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 40 |  Loss: (0.0709) | Acc: (97.60%) (2561/2624) | Learning rate: (0.0001)
2022-06-06 20:56:51,561 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 50 |  Loss: (0.0717) | Acc: (97.73%) (3190/3264) | Learning rate: (0.0001)
2022-06-06 20:56:53,362 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 60 |  Loss: (0.0707) | Acc: (97.80%) (3818/3904) | Learning rate: (0.0001)
2022-06-06 20:56:55,160 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 70 |  Loss: (0.0681) | Acc: (97.91%) (4449/4544) | Learning rate: (0.0001)
2022-06-06 20:56:56,956 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 80 |  Loss: (0.0655) | Acc: (98.03%) (5082/5184) | Learning rate: (0.0001)
2022-06-06 20:56:58,754 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 90 |  Loss: (0.0640) | Acc: (98.09%) (5713/5824) | Learning rate: (0.0001)
2022-06-06 20:57:00,552 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 100 |  Loss: (0.0642) | Acc: (98.02%) (6336/6464) | Learning rate: (0.0001)
2022-06-06 20:57:02,348 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 110 |  Loss: (0.0650) | Acc: (98.04%) (6965/7104) | Learning rate: (0.0001)
2022-06-06 20:57:04,143 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 120 |  Loss: (0.0650) | Acc: (98.04%) (7592/7744) | Learning rate: (0.0001)
2022-06-06 20:57:05,941 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 130 |  Loss: (0.0639) | Acc: (98.08%) (8223/8384) | Learning rate: (0.0001)
2022-06-06 20:57:07,736 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 140 |  Loss: (0.0635) | Acc: (98.07%) (8850/9024) | Learning rate: (0.0001)
2022-06-06 20:57:09,533 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 150 |  Loss: (0.0630) | Acc: (98.08%) (9478/9664) | Learning rate: (0.0001)
2022-06-06 20:57:11,331 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 160 |  Loss: (0.0627) | Acc: (98.06%) (10104/10304) | Learning rate: (0.0001)
2022-06-06 20:57:13,128 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 170 |  Loss: (0.0620) | Acc: (98.08%) (10734/10944) | Learning rate: (0.0001)
2022-06-06 20:57:14,924 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 180 |  Loss: (0.0611) | Acc: (98.11%) (11365/11584) | Learning rate: (0.0001)
2022-06-06 20:57:16,718 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 190 |  Loss: (0.0608) | Acc: (98.13%) (11995/12224) | Learning rate: (0.0001)
2022-06-06 20:57:18,515 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 200 |  Loss: (0.0602) | Acc: (98.17%) (12628/12864) | Learning rate: (0.0001)
2022-06-06 20:57:20,312 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 210 |  Loss: (0.0597) | Acc: (98.19%) (13259/13504) | Learning rate: (0.0001)
2022-06-06 20:57:22,107 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 220 |  Loss: (0.0586) | Acc: (98.24%) (13895/14144) | Learning rate: (0.0001)
2022-06-06 20:57:23,904 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 230 |  Loss: (0.0582) | Acc: (98.25%) (14526/14784) | Learning rate: (0.0001)
2022-06-06 20:57:25,702 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 240 |  Loss: (0.0579) | Acc: (98.24%) (15153/15424) | Learning rate: (0.0001)
2022-06-06 20:57:27,497 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 250 |  Loss: (0.0570) | Acc: (98.28%) (15787/16064) | Learning rate: (0.0001)
2022-06-06 20:57:29,294 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 260 |  Loss: (0.0575) | Acc: (98.25%) (16411/16704) | Learning rate: (0.0001)
2022-06-06 20:57:31,091 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 270 |  Loss: (0.0592) | Acc: (98.19%) (17030/17344) | Learning rate: (0.0001)
2022-06-06 20:57:32,888 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 280 |  Loss: (0.0587) | Acc: (98.19%) (17658/17984) | Learning rate: (0.0001)
2022-06-06 20:57:34,684 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 290 |  Loss: (0.0590) | Acc: (98.16%) (18281/18624) | Learning rate: (0.0001)
2022-06-06 20:57:36,480 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 300 |  Loss: (0.0592) | Acc: (98.16%) (18910/19264) | Learning rate: (0.0001)
2022-06-06 20:57:38,277 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 310 |  Loss: (0.0604) | Acc: (98.15%) (19535/19904) | Learning rate: (0.0001)
2022-06-06 20:57:40,070 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 320 |  Loss: (0.0602) | Acc: (98.15%) (20163/20544) | Learning rate: (0.0001)
2022-06-06 20:57:41,866 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 330 |  Loss: (0.0600) | Acc: (98.14%) (20791/21184) | Learning rate: (0.0001)
2022-06-06 20:57:43,664 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 340 |  Loss: (0.0595) | Acc: (98.16%) (21422/21824) | Learning rate: (0.0001)
2022-06-06 20:57:45,461 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 350 |  Loss: (0.0596) | Acc: (98.15%) (22048/22464) | Learning rate: (0.0001)
2022-06-06 20:57:47,257 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 360 |  Loss: (0.0593) | Acc: (98.17%) (22682/23104) | Learning rate: (0.0001)
2022-06-06 20:57:49,053 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 370 |  Loss: (0.0595) | Acc: (98.16%) (23306/23744) | Learning rate: (0.0001)
2022-06-06 20:57:50,849 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 380 |  Loss: (0.0597) | Acc: (98.15%) (23932/24384) | Learning rate: (0.0001)
2022-06-06 20:57:52,645 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 390 |  Loss: (0.0593) | Acc: (98.15%) (24560/25024) | Learning rate: (0.0001)
2022-06-06 20:57:54,442 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 400 |  Loss: (0.0592) | Acc: (98.15%) (25190/25664) | Learning rate: (0.0001)
2022-06-06 20:57:56,238 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 410 |  Loss: (0.0592) | Acc: (98.14%) (25816/26304) | Learning rate: (0.0001)
2022-06-06 20:57:58,034 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 420 |  Loss: (0.0589) | Acc: (98.16%) (26449/26944) | Learning rate: (0.0001)
2022-06-06 20:57:59,831 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 430 |  Loss: (0.0593) | Acc: (98.17%) (27078/27584) | Learning rate: (0.0001)
2022-06-06 20:58:01,627 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 440 |  Loss: (0.0587) | Acc: (98.18%) (27711/28224) | Learning rate: (0.0001)
2022-06-06 20:58:03,422 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 450 |  Loss: (0.0584) | Acc: (98.19%) (28342/28864) | Learning rate: (0.0001)
2022-06-06 20:58:05,217 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 460 |  Loss: (0.0584) | Acc: (98.19%) (28971/29504) | Learning rate: (0.0001)
2022-06-06 20:58:07,014 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 470 |  Loss: (0.0584) | Acc: (98.20%) (29601/30144) | Learning rate: (0.0001)
2022-06-06 20:58:08,811 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 480 |  Loss: (0.0583) | Acc: (98.20%) (30230/30784) | Learning rate: (0.0001)
2022-06-06 20:58:10,607 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 490 |  Loss: (0.0584) | Acc: (98.20%) (30857/31424) | Learning rate: (0.0001)
2022-06-06 20:58:12,405 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 500 |  Loss: (0.0586) | Acc: (98.18%) (31482/32064) | Learning rate: (0.0001)
2022-06-06 20:58:14,201 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 510 |  Loss: (0.0585) | Acc: (98.19%) (32111/32704) | Learning rate: (0.0001)
2022-06-06 20:58:15,997 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 520 |  Loss: (0.0582) | Acc: (98.19%) (32742/33344) | Learning rate: (0.0001)
2022-06-06 20:58:17,795 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 530 |  Loss: (0.0580) | Acc: (98.21%) (33374/33984) | Learning rate: (0.0001)
2022-06-06 20:58:19,592 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 540 |  Loss: (0.0582) | Acc: (98.19%) (33997/34624) | Learning rate: (0.0001)
2022-06-06 20:58:21,389 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 550 |  Loss: (0.0584) | Acc: (98.17%) (34620/35264) | Learning rate: (0.0001)
2022-06-06 20:58:23,186 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 560 |  Loss: (0.0585) | Acc: (98.17%) (35246/35904) | Learning rate: (0.0001)
2022-06-06 20:58:24,982 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 570 |  Loss: (0.0588) | Acc: (98.15%) (35868/36544) | Learning rate: (0.0001)
2022-06-06 20:58:26,779 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 580 |  Loss: (0.0588) | Acc: (98.14%) (36493/37184) | Learning rate: (0.0001)
2022-06-06 20:58:28,576 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 590 |  Loss: (0.0593) | Acc: (98.13%) (37116/37824) | Learning rate: (0.0001)
2022-06-06 20:58:30,371 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 600 |  Loss: (0.0590) | Acc: (98.13%) (37746/38464) | Learning rate: (0.0001)
2022-06-06 20:58:32,169 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 610 |  Loss: (0.0589) | Acc: (98.14%) (38377/39104) | Learning rate: (0.0001)
2022-06-06 20:58:33,965 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 620 |  Loss: (0.0592) | Acc: (98.13%) (39001/39744) | Learning rate: (0.0001)
2022-06-06 20:58:35,762 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 630 |  Loss: (0.0593) | Acc: (98.12%) (39624/40384) | Learning rate: (0.0001)
2022-06-06 20:58:37,559 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 640 |  Loss: (0.0591) | Acc: (98.12%) (40253/41024) | Learning rate: (0.0001)
2022-06-06 20:58:39,356 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 650 |  Loss: (0.0590) | Acc: (98.12%) (40879/41664) | Learning rate: (0.0001)
2022-06-06 20:58:41,151 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 660 |  Loss: (0.0587) | Acc: (98.13%) (41512/42304) | Learning rate: (0.0001)
2022-06-06 20:58:42,947 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 670 |  Loss: (0.0585) | Acc: (98.14%) (42144/42944) | Learning rate: (0.0001)
2022-06-06 20:58:44,744 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 680 |  Loss: (0.0586) | Acc: (98.13%) (42767/43584) | Learning rate: (0.0001)
2022-06-06 20:58:46,540 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 690 |  Loss: (0.0586) | Acc: (98.12%) (43392/44224) | Learning rate: (0.0001)
2022-06-06 20:58:48,337 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 700 |  Loss: (0.0585) | Acc: (98.12%) (44019/44864) | Learning rate: (0.0001)
2022-06-06 20:58:50,134 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 710 |  Loss: (0.0585) | Acc: (98.12%) (44648/45504) | Learning rate: (0.0001)
2022-06-06 20:58:51,930 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 720 |  Loss: (0.0584) | Acc: (98.11%) (45273/46144) | Learning rate: (0.0001)
2022-06-06 20:58:53,727 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 730 |  Loss: (0.0587) | Acc: (98.10%) (45895/46784) | Learning rate: (0.0001)
2022-06-06 20:58:55,523 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 740 |  Loss: (0.0586) | Acc: (98.10%) (46524/47424) | Learning rate: (0.0001)
2022-06-06 20:58:57,320 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 750 |  Loss: (0.0585) | Acc: (98.11%) (47154/48064) | Learning rate: (0.0001)
2022-06-06 20:58:59,118 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 760 |  Loss: (0.0585) | Acc: (98.11%) (47782/48704) | Learning rate: (0.0001)
2022-06-06 20:59:00,907 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 770 |  Loss: (0.0582) | Acc: (98.12%) (48414/49344) | Learning rate: (0.0001)
2022-06-06 20:59:02,696 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 780 |  Loss: (0.0581) | Acc: (98.12%) (49043/49984) | Learning rate: (0.0001)
2022-06-06 20:59:12,665 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0806) | Acc: (97.41%) (9741/10000)
2022-06-06 20:59:12,666 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 20:59:13,767 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 0 |  Loss: (0.0280) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 20:59:15,553 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 10 |  Loss: (0.0333) | Acc: (98.86%) (696/704) | Learning rate: (0.0001)
2022-06-06 20:59:17,345 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 20 |  Loss: (0.0353) | Acc: (98.88%) (1329/1344) | Learning rate: (0.0001)
2022-06-06 20:59:19,137 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 30 |  Loss: (0.0402) | Acc: (98.64%) (1957/1984) | Learning rate: (0.0001)
2022-06-06 20:59:20,933 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 40 |  Loss: (0.0415) | Acc: (98.55%) (2586/2624) | Learning rate: (0.0001)
2022-06-06 20:59:22,728 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 50 |  Loss: (0.0459) | Acc: (98.47%) (3214/3264) | Learning rate: (0.0001)
2022-06-06 20:59:24,522 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 60 |  Loss: (0.0492) | Acc: (98.36%) (3840/3904) | Learning rate: (0.0001)
2022-06-06 20:59:26,317 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 70 |  Loss: (0.0485) | Acc: (98.37%) (4470/4544) | Learning rate: (0.0001)
2022-06-06 20:59:28,112 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 80 |  Loss: (0.0479) | Acc: (98.40%) (5101/5184) | Learning rate: (0.0001)
2022-06-06 20:59:29,908 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 90 |  Loss: (0.0454) | Acc: (98.51%) (5737/5824) | Learning rate: (0.0001)
2022-06-06 20:59:31,702 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 100 |  Loss: (0.0442) | Acc: (98.58%) (6372/6464) | Learning rate: (0.0001)
2022-06-06 20:59:33,498 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 110 |  Loss: (0.0428) | Acc: (98.59%) (7004/7104) | Learning rate: (0.0001)
2022-06-06 20:59:35,293 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 120 |  Loss: (0.0410) | Acc: (98.67%) (7641/7744) | Learning rate: (0.0001)
2022-06-06 20:59:37,087 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 130 |  Loss: (0.0407) | Acc: (98.69%) (8274/8384) | Learning rate: (0.0001)
2022-06-06 20:59:38,885 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 140 |  Loss: (0.0392) | Acc: (98.75%) (8911/9024) | Learning rate: (0.0001)
2022-06-06 20:59:40,680 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 150 |  Loss: (0.0401) | Acc: (98.70%) (9538/9664) | Learning rate: (0.0001)
2022-06-06 20:59:42,478 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 160 |  Loss: (0.0395) | Acc: (98.72%) (10172/10304) | Learning rate: (0.0001)
2022-06-06 20:59:44,272 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 170 |  Loss: (0.0395) | Acc: (98.71%) (10803/10944) | Learning rate: (0.0001)
2022-06-06 20:59:46,067 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 180 |  Loss: (0.0390) | Acc: (98.71%) (11434/11584) | Learning rate: (0.0001)
2022-06-06 20:59:47,863 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 190 |  Loss: (0.0379) | Acc: (98.74%) (12070/12224) | Learning rate: (0.0001)
2022-06-06 20:59:49,659 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 200 |  Loss: (0.0379) | Acc: (98.73%) (12701/12864) | Learning rate: (0.0001)
2022-06-06 20:59:51,455 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 210 |  Loss: (0.0391) | Acc: (98.70%) (13329/13504) | Learning rate: (0.0001)
2022-06-06 20:59:53,250 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 220 |  Loss: (0.0390) | Acc: (98.70%) (13960/14144) | Learning rate: (0.0001)
2022-06-06 20:59:55,046 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 230 |  Loss: (0.0392) | Acc: (98.69%) (14590/14784) | Learning rate: (0.0001)
2022-06-06 20:59:56,840 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 240 |  Loss: (0.0388) | Acc: (98.70%) (15224/15424) | Learning rate: (0.0001)
2022-06-06 20:59:58,638 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 250 |  Loss: (0.0391) | Acc: (98.69%) (15854/16064) | Learning rate: (0.0001)
2022-06-06 21:00:00,434 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 260 |  Loss: (0.0393) | Acc: (98.68%) (16484/16704) | Learning rate: (0.0001)
2022-06-06 21:00:02,231 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 270 |  Loss: (0.0399) | Acc: (98.66%) (17111/17344) | Learning rate: (0.0001)
2022-06-06 21:00:04,027 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 280 |  Loss: (0.0394) | Acc: (98.67%) (17744/17984) | Learning rate: (0.0001)
2022-06-06 21:00:05,823 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 290 |  Loss: (0.0394) | Acc: (98.66%) (18375/18624) | Learning rate: (0.0001)
2022-06-06 21:00:07,619 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 300 |  Loss: (0.0390) | Acc: (98.68%) (19009/19264) | Learning rate: (0.0001)
2022-06-06 21:00:09,416 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 310 |  Loss: (0.0388) | Acc: (98.69%) (19643/19904) | Learning rate: (0.0001)
2022-06-06 21:00:11,213 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 320 |  Loss: (0.0387) | Acc: (98.69%) (20275/20544) | Learning rate: (0.0001)
2022-06-06 21:00:13,008 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 330 |  Loss: (0.0386) | Acc: (98.69%) (20906/21184) | Learning rate: (0.0001)
2022-06-06 21:00:14,805 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 340 |  Loss: (0.0395) | Acc: (98.66%) (21531/21824) | Learning rate: (0.0001)
2022-06-06 21:00:16,600 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 350 |  Loss: (0.0398) | Acc: (98.65%) (22161/22464) | Learning rate: (0.0001)
2022-06-06 21:00:18,395 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 360 |  Loss: (0.0405) | Acc: (98.64%) (22790/23104) | Learning rate: (0.0001)
2022-06-06 21:00:20,194 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 370 |  Loss: (0.0403) | Acc: (98.64%) (23422/23744) | Learning rate: (0.0001)
2022-06-06 21:00:21,990 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 380 |  Loss: (0.0401) | Acc: (98.65%) (24054/24384) | Learning rate: (0.0001)
2022-06-06 21:00:23,786 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 390 |  Loss: (0.0403) | Acc: (98.65%) (24686/25024) | Learning rate: (0.0001)
2022-06-06 21:00:25,583 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 400 |  Loss: (0.0405) | Acc: (98.63%) (25313/25664) | Learning rate: (0.0001)
2022-06-06 21:00:27,378 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 410 |  Loss: (0.0405) | Acc: (98.64%) (25945/26304) | Learning rate: (0.0001)
2022-06-06 21:00:29,174 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 420 |  Loss: (0.0405) | Acc: (98.64%) (26577/26944) | Learning rate: (0.0001)
2022-06-06 21:00:30,970 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 430 |  Loss: (0.0408) | Acc: (98.64%) (27209/27584) | Learning rate: (0.0001)
2022-06-06 21:00:32,767 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 440 |  Loss: (0.0406) | Acc: (98.65%) (27844/28224) | Learning rate: (0.0001)
2022-06-06 21:00:34,565 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 450 |  Loss: (0.0405) | Acc: (98.66%) (28476/28864) | Learning rate: (0.0001)
2022-06-06 21:00:36,360 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 460 |  Loss: (0.0404) | Acc: (98.66%) (29110/29504) | Learning rate: (0.0001)
2022-06-06 21:00:38,155 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 470 |  Loss: (0.0404) | Acc: (98.67%) (29743/30144) | Learning rate: (0.0001)
2022-06-06 21:00:39,951 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 480 |  Loss: (0.0405) | Acc: (98.66%) (30370/30784) | Learning rate: (0.0001)
2022-06-06 21:00:41,747 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 490 |  Loss: (0.0406) | Acc: (98.66%) (31002/31424) | Learning rate: (0.0001)
2022-06-06 21:00:43,544 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 500 |  Loss: (0.0407) | Acc: (98.66%) (31635/32064) | Learning rate: (0.0001)
2022-06-06 21:00:45,340 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 510 |  Loss: (0.0408) | Acc: (98.66%) (32265/32704) | Learning rate: (0.0001)
2022-06-06 21:00:47,138 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 520 |  Loss: (0.0405) | Acc: (98.67%) (32899/33344) | Learning rate: (0.0001)
2022-06-06 21:00:48,936 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 530 |  Loss: (0.0406) | Acc: (98.66%) (33528/33984) | Learning rate: (0.0001)
2022-06-06 21:00:50,732 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 540 |  Loss: (0.0405) | Acc: (98.66%) (34160/34624) | Learning rate: (0.0001)
2022-06-06 21:00:52,527 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 550 |  Loss: (0.0403) | Acc: (98.67%) (34795/35264) | Learning rate: (0.0001)
2022-06-06 21:00:54,323 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 560 |  Loss: (0.0400) | Acc: (98.68%) (35431/35904) | Learning rate: (0.0001)
2022-06-06 21:00:56,120 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 570 |  Loss: (0.0400) | Acc: (98.69%) (36065/36544) | Learning rate: (0.0001)
2022-06-06 21:00:57,916 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 580 |  Loss: (0.0401) | Acc: (98.69%) (36697/37184) | Learning rate: (0.0001)
2022-06-06 21:00:59,712 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 590 |  Loss: (0.0403) | Acc: (98.68%) (37325/37824) | Learning rate: (0.0001)
2022-06-06 21:01:01,508 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 600 |  Loss: (0.0406) | Acc: (98.68%) (37955/38464) | Learning rate: (0.0001)
2022-06-06 21:01:03,304 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 610 |  Loss: (0.0407) | Acc: (98.68%) (38586/39104) | Learning rate: (0.0001)
2022-06-06 21:01:05,100 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 620 |  Loss: (0.0407) | Acc: (98.67%) (39215/39744) | Learning rate: (0.0001)
2022-06-06 21:01:06,897 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 630 |  Loss: (0.0407) | Acc: (98.67%) (39848/40384) | Learning rate: (0.0001)
2022-06-06 21:01:08,695 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 640 |  Loss: (0.0407) | Acc: (98.68%) (40482/41024) | Learning rate: (0.0001)
2022-06-06 21:01:10,490 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 650 |  Loss: (0.0407) | Acc: (98.68%) (41114/41664) | Learning rate: (0.0001)
2022-06-06 21:01:12,288 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 660 |  Loss: (0.0408) | Acc: (98.67%) (41743/42304) | Learning rate: (0.0001)
2022-06-06 21:01:14,084 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 670 |  Loss: (0.0411) | Acc: (98.66%) (42370/42944) | Learning rate: (0.0001)
2022-06-06 21:01:15,881 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 680 |  Loss: (0.0408) | Acc: (98.67%) (43006/43584) | Learning rate: (0.0001)
2022-06-06 21:01:17,677 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 690 |  Loss: (0.0410) | Acc: (98.68%) (43639/44224) | Learning rate: (0.0001)
2022-06-06 21:01:19,474 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 700 |  Loss: (0.0411) | Acc: (98.67%) (44267/44864) | Learning rate: (0.0001)
2022-06-06 21:01:21,272 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 710 |  Loss: (0.0409) | Acc: (98.67%) (44900/45504) | Learning rate: (0.0001)
2022-06-06 21:01:23,069 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 720 |  Loss: (0.0407) | Acc: (98.68%) (45536/46144) | Learning rate: (0.0001)
2022-06-06 21:01:24,866 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 730 |  Loss: (0.0406) | Acc: (98.68%) (46167/46784) | Learning rate: (0.0001)
2022-06-06 21:01:26,663 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 740 |  Loss: (0.0405) | Acc: (98.69%) (46801/47424) | Learning rate: (0.0001)
2022-06-06 21:01:28,459 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 750 |  Loss: (0.0404) | Acc: (98.69%) (47434/48064) | Learning rate: (0.0001)
2022-06-06 21:01:30,254 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 760 |  Loss: (0.0402) | Acc: (98.70%) (48070/48704) | Learning rate: (0.0001)
2022-06-06 21:01:32,042 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 770 |  Loss: (0.0403) | Acc: (98.69%) (48699/49344) | Learning rate: (0.0001)
2022-06-06 21:01:33,833 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 780 |  Loss: (0.0404) | Acc: (98.69%) (49330/49984) | Learning rate: (0.0001)
2022-06-06 21:01:43,793 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0787) | Acc: (97.62%) (9762/10000)
2022-06-06 21:01:43,794 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:01:44,840 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 0 |  Loss: (0.0544) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 21:01:46,637 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 10 |  Loss: (0.0307) | Acc: (99.01%) (697/704) | Learning rate: (0.0001)
2022-06-06 21:01:48,433 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 20 |  Loss: (0.0356) | Acc: (98.88%) (1329/1344) | Learning rate: (0.0001)
2022-06-06 21:01:50,225 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 30 |  Loss: (0.0353) | Acc: (98.79%) (1960/1984) | Learning rate: (0.0001)
2022-06-06 21:01:52,022 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 40 |  Loss: (0.0306) | Acc: (99.01%) (2598/2624) | Learning rate: (0.0001)
2022-06-06 21:01:53,823 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 50 |  Loss: (0.0309) | Acc: (98.96%) (3230/3264) | Learning rate: (0.0001)
2022-06-06 21:01:55,622 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 60 |  Loss: (0.0294) | Acc: (99.00%) (3865/3904) | Learning rate: (0.0001)
2022-06-06 21:01:57,419 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 70 |  Loss: (0.0326) | Acc: (98.90%) (4494/4544) | Learning rate: (0.0001)
2022-06-06 21:01:59,216 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 80 |  Loss: (0.0325) | Acc: (98.94%) (5129/5184) | Learning rate: (0.0001)
2022-06-06 21:02:01,012 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 90 |  Loss: (0.0316) | Acc: (98.94%) (5762/5824) | Learning rate: (0.0001)
2022-06-06 21:02:02,808 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 100 |  Loss: (0.0318) | Acc: (98.89%) (6392/6464) | Learning rate: (0.0001)
2022-06-06 21:02:04,603 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 110 |  Loss: (0.0302) | Acc: (98.94%) (7029/7104) | Learning rate: (0.0001)
2022-06-06 21:02:06,399 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 120 |  Loss: (0.0301) | Acc: (98.93%) (7661/7744) | Learning rate: (0.0001)
2022-06-06 21:02:08,197 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 130 |  Loss: (0.0295) | Acc: (98.95%) (8296/8384) | Learning rate: (0.0001)
2022-06-06 21:02:09,994 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 140 |  Loss: (0.0304) | Acc: (98.94%) (8928/9024) | Learning rate: (0.0001)
2022-06-06 21:02:11,791 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 150 |  Loss: (0.0299) | Acc: (98.98%) (9565/9664) | Learning rate: (0.0001)
2022-06-06 21:02:13,588 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 160 |  Loss: (0.0299) | Acc: (98.95%) (10196/10304) | Learning rate: (0.0001)
2022-06-06 21:02:15,384 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 170 |  Loss: (0.0309) | Acc: (98.92%) (10826/10944) | Learning rate: (0.0001)
2022-06-06 21:02:17,179 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 180 |  Loss: (0.0308) | Acc: (98.95%) (11462/11584) | Learning rate: (0.0001)
2022-06-06 21:02:18,975 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 190 |  Loss: (0.0307) | Acc: (98.97%) (12098/12224) | Learning rate: (0.0001)
2022-06-06 21:02:20,772 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 200 |  Loss: (0.0306) | Acc: (98.98%) (12733/12864) | Learning rate: (0.0001)
2022-06-06 21:02:22,569 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 210 |  Loss: (0.0299) | Acc: (99.01%) (13370/13504) | Learning rate: (0.0001)
2022-06-06 21:02:24,365 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 220 |  Loss: (0.0303) | Acc: (99.00%) (14002/14144) | Learning rate: (0.0001)
2022-06-06 21:02:26,162 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 230 |  Loss: (0.0307) | Acc: (98.99%) (14635/14784) | Learning rate: (0.0001)
2022-06-06 21:02:27,958 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 240 |  Loss: (0.0304) | Acc: (99.00%) (15270/15424) | Learning rate: (0.0001)
2022-06-06 21:02:29,754 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 250 |  Loss: (0.0304) | Acc: (99.00%) (15904/16064) | Learning rate: (0.0001)
2022-06-06 21:02:31,551 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 260 |  Loss: (0.0300) | Acc: (99.01%) (16539/16704) | Learning rate: (0.0001)
2022-06-06 21:02:33,348 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 270 |  Loss: (0.0299) | Acc: (99.00%) (17171/17344) | Learning rate: (0.0001)
2022-06-06 21:02:35,146 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 280 |  Loss: (0.0308) | Acc: (98.98%) (17800/17984) | Learning rate: (0.0001)
2022-06-06 21:02:36,942 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 290 |  Loss: (0.0303) | Acc: (98.99%) (18436/18624) | Learning rate: (0.0001)
2022-06-06 21:02:38,739 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 300 |  Loss: (0.0305) | Acc: (98.98%) (19067/19264) | Learning rate: (0.0001)
2022-06-06 21:02:40,536 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 310 |  Loss: (0.0303) | Acc: (98.99%) (19702/19904) | Learning rate: (0.0001)
2022-06-06 21:02:42,331 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 320 |  Loss: (0.0309) | Acc: (98.96%) (20331/20544) | Learning rate: (0.0001)
2022-06-06 21:02:44,128 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 330 |  Loss: (0.0314) | Acc: (98.96%) (20963/21184) | Learning rate: (0.0001)
2022-06-06 21:02:45,924 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 340 |  Loss: (0.0313) | Acc: (98.96%) (21597/21824) | Learning rate: (0.0001)
2022-06-06 21:02:47,722 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 350 |  Loss: (0.0311) | Acc: (98.96%) (22231/22464) | Learning rate: (0.0001)
2022-06-06 21:02:49,519 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 360 |  Loss: (0.0310) | Acc: (98.97%) (22865/23104) | Learning rate: (0.0001)
2022-06-06 21:02:51,316 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 370 |  Loss: (0.0310) | Acc: (98.96%) (23497/23744) | Learning rate: (0.0001)
2022-06-06 21:02:53,112 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 380 |  Loss: (0.0308) | Acc: (98.97%) (24133/24384) | Learning rate: (0.0001)
2022-06-06 21:02:54,908 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 390 |  Loss: (0.0307) | Acc: (98.97%) (24767/25024) | Learning rate: (0.0001)
2022-06-06 21:02:56,704 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 400 |  Loss: (0.0307) | Acc: (98.96%) (25398/25664) | Learning rate: (0.0001)
2022-06-06 21:02:58,501 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 410 |  Loss: (0.0306) | Acc: (98.97%) (26032/26304) | Learning rate: (0.0001)
2022-06-06 21:03:00,298 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 420 |  Loss: (0.0305) | Acc: (98.97%) (26666/26944) | Learning rate: (0.0001)
2022-06-06 21:03:02,095 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 430 |  Loss: (0.0306) | Acc: (98.96%) (27296/27584) | Learning rate: (0.0001)
2022-06-06 21:03:03,892 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 440 |  Loss: (0.0303) | Acc: (98.96%) (27931/28224) | Learning rate: (0.0001)
2022-06-06 21:03:05,689 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 450 |  Loss: (0.0303) | Acc: (98.96%) (28564/28864) | Learning rate: (0.0001)
2022-06-06 21:03:07,484 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 460 |  Loss: (0.0302) | Acc: (98.97%) (29199/29504) | Learning rate: (0.0001)
2022-06-06 21:03:09,281 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 470 |  Loss: (0.0301) | Acc: (98.96%) (29832/30144) | Learning rate: (0.0001)
2022-06-06 21:03:11,077 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 480 |  Loss: (0.0302) | Acc: (98.96%) (30465/30784) | Learning rate: (0.0001)
2022-06-06 21:03:12,875 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 490 |  Loss: (0.0305) | Acc: (98.95%) (31095/31424) | Learning rate: (0.0001)
2022-06-06 21:03:14,673 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 500 |  Loss: (0.0303) | Acc: (98.96%) (31730/32064) | Learning rate: (0.0001)
2022-06-06 21:03:16,471 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 510 |  Loss: (0.0303) | Acc: (98.95%) (32362/32704) | Learning rate: (0.0001)
2022-06-06 21:03:18,268 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 520 |  Loss: (0.0300) | Acc: (98.97%) (33000/33344) | Learning rate: (0.0001)
2022-06-06 21:03:20,066 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 530 |  Loss: (0.0299) | Acc: (98.97%) (33634/33984) | Learning rate: (0.0001)
2022-06-06 21:03:21,862 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 540 |  Loss: (0.0300) | Acc: (98.97%) (34266/34624) | Learning rate: (0.0001)
2022-06-06 21:03:23,657 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 550 |  Loss: (0.0299) | Acc: (98.98%) (34903/35264) | Learning rate: (0.0001)
2022-06-06 21:03:25,454 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 560 |  Loss: (0.0301) | Acc: (98.97%) (35534/35904) | Learning rate: (0.0001)
2022-06-06 21:03:27,251 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 570 |  Loss: (0.0301) | Acc: (98.97%) (36168/36544) | Learning rate: (0.0001)
2022-06-06 21:03:29,049 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 580 |  Loss: (0.0300) | Acc: (98.98%) (36803/37184) | Learning rate: (0.0001)
2022-06-06 21:03:30,845 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 590 |  Loss: (0.0302) | Acc: (98.97%) (37434/37824) | Learning rate: (0.0001)
2022-06-06 21:03:32,642 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 600 |  Loss: (0.0301) | Acc: (98.98%) (38071/38464) | Learning rate: (0.0001)
2022-06-06 21:03:34,439 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 610 |  Loss: (0.0299) | Acc: (98.99%) (38708/39104) | Learning rate: (0.0001)
2022-06-06 21:03:36,234 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 620 |  Loss: (0.0300) | Acc: (98.98%) (39339/39744) | Learning rate: (0.0001)
2022-06-06 21:03:38,031 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 630 |  Loss: (0.0301) | Acc: (98.98%) (39971/40384) | Learning rate: (0.0001)
2022-06-06 21:03:39,828 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 640 |  Loss: (0.0304) | Acc: (98.97%) (40600/41024) | Learning rate: (0.0001)
2022-06-06 21:03:41,627 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 650 |  Loss: (0.0307) | Acc: (98.96%) (41232/41664) | Learning rate: (0.0001)
2022-06-06 21:03:43,424 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 660 |  Loss: (0.0307) | Acc: (98.96%) (41864/42304) | Learning rate: (0.0001)
2022-06-06 21:03:45,222 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 670 |  Loss: (0.0312) | Acc: (98.95%) (42493/42944) | Learning rate: (0.0001)
2022-06-06 21:03:47,020 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 680 |  Loss: (0.0313) | Acc: (98.95%) (43126/43584) | Learning rate: (0.0001)
2022-06-06 21:03:48,817 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 690 |  Loss: (0.0314) | Acc: (98.95%) (43761/44224) | Learning rate: (0.0001)
2022-06-06 21:03:50,615 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 700 |  Loss: (0.0313) | Acc: (98.96%) (44397/44864) | Learning rate: (0.0001)
2022-06-06 21:03:52,412 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 710 |  Loss: (0.0314) | Acc: (98.96%) (45030/45504) | Learning rate: (0.0001)
2022-06-06 21:03:54,209 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 720 |  Loss: (0.0314) | Acc: (98.96%) (45665/46144) | Learning rate: (0.0001)
2022-06-06 21:03:56,007 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 730 |  Loss: (0.0313) | Acc: (98.97%) (46300/46784) | Learning rate: (0.0001)
2022-06-06 21:03:57,803 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 740 |  Loss: (0.0313) | Acc: (98.97%) (46934/47424) | Learning rate: (0.0001)
2022-06-06 21:03:59,601 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 750 |  Loss: (0.0315) | Acc: (98.96%) (47565/48064) | Learning rate: (0.0001)
2022-06-06 21:04:01,399 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 760 |  Loss: (0.0315) | Acc: (98.96%) (48196/48704) | Learning rate: (0.0001)
2022-06-06 21:04:03,189 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 770 |  Loss: (0.0318) | Acc: (98.95%) (48825/49344) | Learning rate: (0.0001)
2022-06-06 21:04:04,980 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 780 |  Loss: (0.0317) | Acc: (98.95%) (49460/49984) | Learning rate: (0.0001)
2022-06-06 21:04:14,919 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0872) | Acc: (97.49%) (9749/10000)
2022-06-06 21:04:14,920 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:04:15,959 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 0 |  Loss: (0.0202) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 21:04:17,749 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 10 |  Loss: (0.0235) | Acc: (98.86%) (696/704) | Learning rate: (0.0001)
2022-06-06 21:04:19,540 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 20 |  Loss: (0.0246) | Acc: (99.03%) (1331/1344) | Learning rate: (0.0001)
2022-06-06 21:04:21,333 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 30 |  Loss: (0.0221) | Acc: (99.29%) (1970/1984) | Learning rate: (0.0001)
2022-06-06 21:04:23,128 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 40 |  Loss: (0.0235) | Acc: (99.28%) (2605/2624) | Learning rate: (0.0001)
2022-06-06 21:04:24,921 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 50 |  Loss: (0.0238) | Acc: (99.30%) (3241/3264) | Learning rate: (0.0001)
2022-06-06 21:04:26,714 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 60 |  Loss: (0.0237) | Acc: (99.31%) (3877/3904) | Learning rate: (0.0001)
2022-06-06 21:04:28,510 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 70 |  Loss: (0.0236) | Acc: (99.32%) (4513/4544) | Learning rate: (0.0001)
2022-06-06 21:04:30,304 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 80 |  Loss: (0.0236) | Acc: (99.32%) (5149/5184) | Learning rate: (0.0001)
2022-06-06 21:04:32,098 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 90 |  Loss: (0.0234) | Acc: (99.30%) (5783/5824) | Learning rate: (0.0001)
2022-06-06 21:04:33,893 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 100 |  Loss: (0.0237) | Acc: (99.29%) (6418/6464) | Learning rate: (0.0001)
2022-06-06 21:04:35,687 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 110 |  Loss: (0.0248) | Acc: (99.25%) (7051/7104) | Learning rate: (0.0001)
2022-06-06 21:04:37,484 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 120 |  Loss: (0.0251) | Acc: (99.23%) (7684/7744) | Learning rate: (0.0001)
2022-06-06 21:04:39,279 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 130 |  Loss: (0.0254) | Acc: (99.19%) (8316/8384) | Learning rate: (0.0001)
2022-06-06 21:04:41,074 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 140 |  Loss: (0.0252) | Acc: (99.18%) (8950/9024) | Learning rate: (0.0001)
2022-06-06 21:04:42,869 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 150 |  Loss: (0.0246) | Acc: (99.21%) (9588/9664) | Learning rate: (0.0001)
2022-06-06 21:04:44,663 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 160 |  Loss: (0.0257) | Acc: (99.18%) (10219/10304) | Learning rate: (0.0001)
2022-06-06 21:04:46,459 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 170 |  Loss: (0.0256) | Acc: (99.17%) (10853/10944) | Learning rate: (0.0001)
2022-06-06 21:04:48,254 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 180 |  Loss: (0.0266) | Acc: (99.15%) (11485/11584) | Learning rate: (0.0001)
2022-06-06 21:04:50,048 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 190 |  Loss: (0.0263) | Acc: (99.15%) (12120/12224) | Learning rate: (0.0001)
2022-06-06 21:04:51,843 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 200 |  Loss: (0.0260) | Acc: (99.14%) (12754/12864) | Learning rate: (0.0001)
2022-06-06 21:04:53,640 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 210 |  Loss: (0.0255) | Acc: (99.16%) (13391/13504) | Learning rate: (0.0001)
2022-06-06 21:04:55,434 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 220 |  Loss: (0.0250) | Acc: (99.19%) (14030/14144) | Learning rate: (0.0001)
2022-06-06 21:04:57,229 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 230 |  Loss: (0.0244) | Acc: (99.22%) (14668/14784) | Learning rate: (0.0001)
2022-06-06 21:04:59,024 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 240 |  Loss: (0.0242) | Acc: (99.23%) (15305/15424) | Learning rate: (0.0001)
2022-06-06 21:05:00,821 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 250 |  Loss: (0.0244) | Acc: (99.22%) (15939/16064) | Learning rate: (0.0001)
2022-06-06 21:05:02,617 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 260 |  Loss: (0.0241) | Acc: (99.23%) (16575/16704) | Learning rate: (0.0001)
2022-06-06 21:05:04,413 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 270 |  Loss: (0.0241) | Acc: (99.23%) (17210/17344) | Learning rate: (0.0001)
2022-06-06 21:05:06,208 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 280 |  Loss: (0.0241) | Acc: (99.21%) (17842/17984) | Learning rate: (0.0001)
2022-06-06 21:05:08,003 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 290 |  Loss: (0.0244) | Acc: (99.20%) (18475/18624) | Learning rate: (0.0001)
2022-06-06 21:05:09,798 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 300 |  Loss: (0.0244) | Acc: (99.21%) (19111/19264) | Learning rate: (0.0001)
2022-06-06 21:05:11,595 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 310 |  Loss: (0.0241) | Acc: (99.21%) (19747/19904) | Learning rate: (0.0001)
2022-06-06 21:05:13,393 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 320 |  Loss: (0.0242) | Acc: (99.21%) (20381/20544) | Learning rate: (0.0001)
2022-06-06 21:05:15,188 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 330 |  Loss: (0.0240) | Acc: (99.21%) (21017/21184) | Learning rate: (0.0001)
2022-06-06 21:05:16,984 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 340 |  Loss: (0.0235) | Acc: (99.23%) (21655/21824) | Learning rate: (0.0001)
2022-06-06 21:05:18,779 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 350 |  Loss: (0.0239) | Acc: (99.22%) (22289/22464) | Learning rate: (0.0001)
2022-06-06 21:05:20,575 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 360 |  Loss: (0.0239) | Acc: (99.21%) (22922/23104) | Learning rate: (0.0001)
2022-06-06 21:05:22,371 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 370 |  Loss: (0.0239) | Acc: (99.21%) (23557/23744) | Learning rate: (0.0001)
2022-06-06 21:05:24,167 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 380 |  Loss: (0.0236) | Acc: (99.23%) (24196/24384) | Learning rate: (0.0001)
2022-06-06 21:05:25,963 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 390 |  Loss: (0.0232) | Acc: (99.24%) (24835/25024) | Learning rate: (0.0001)
2022-06-06 21:05:27,760 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 400 |  Loss: (0.0231) | Acc: (99.25%) (25472/25664) | Learning rate: (0.0001)
2022-06-06 21:05:29,555 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 410 |  Loss: (0.0230) | Acc: (99.25%) (26106/26304) | Learning rate: (0.0001)
2022-06-06 21:05:31,351 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 420 |  Loss: (0.0231) | Acc: (99.24%) (26739/26944) | Learning rate: (0.0001)
2022-06-06 21:05:33,150 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 430 |  Loss: (0.0232) | Acc: (99.24%) (27373/27584) | Learning rate: (0.0001)
2022-06-06 21:05:34,948 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 440 |  Loss: (0.0233) | Acc: (99.23%) (28006/28224) | Learning rate: (0.0001)
2022-06-06 21:05:36,746 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 450 |  Loss: (0.0233) | Acc: (99.23%) (28641/28864) | Learning rate: (0.0001)
2022-06-06 21:05:38,542 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 460 |  Loss: (0.0233) | Acc: (99.22%) (29275/29504) | Learning rate: (0.0001)
2022-06-06 21:05:40,338 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 470 |  Loss: (0.0232) | Acc: (99.23%) (29911/30144) | Learning rate: (0.0001)
2022-06-06 21:05:42,132 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 480 |  Loss: (0.0229) | Acc: (99.24%) (30550/30784) | Learning rate: (0.0001)
2022-06-06 21:05:43,927 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 490 |  Loss: (0.0229) | Acc: (99.24%) (31186/31424) | Learning rate: (0.0001)
2022-06-06 21:05:45,724 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 500 |  Loss: (0.0228) | Acc: (99.25%) (31823/32064) | Learning rate: (0.0001)
2022-06-06 21:05:47,523 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 510 |  Loss: (0.0229) | Acc: (99.24%) (32454/32704) | Learning rate: (0.0001)
2022-06-06 21:05:49,319 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 520 |  Loss: (0.0231) | Acc: (99.23%) (33086/33344) | Learning rate: (0.0001)
2022-06-06 21:05:51,116 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 530 |  Loss: (0.0231) | Acc: (99.23%) (33721/33984) | Learning rate: (0.0001)
2022-06-06 21:05:52,913 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 540 |  Loss: (0.0230) | Acc: (99.23%) (34356/34624) | Learning rate: (0.0001)
2022-06-06 21:05:54,707 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 550 |  Loss: (0.0230) | Acc: (99.22%) (34989/35264) | Learning rate: (0.0001)
2022-06-06 21:05:56,503 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 560 |  Loss: (0.0231) | Acc: (99.22%) (35623/35904) | Learning rate: (0.0001)
2022-06-06 21:05:58,300 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 570 |  Loss: (0.0232) | Acc: (99.21%) (36257/36544) | Learning rate: (0.0001)
2022-06-06 21:06:00,096 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 580 |  Loss: (0.0231) | Acc: (99.22%) (36895/37184) | Learning rate: (0.0001)
2022-06-06 21:06:01,893 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 590 |  Loss: (0.0231) | Acc: (99.22%) (37528/37824) | Learning rate: (0.0001)
2022-06-06 21:06:03,688 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 600 |  Loss: (0.0230) | Acc: (99.22%) (38165/38464) | Learning rate: (0.0001)
2022-06-06 21:06:05,483 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 610 |  Loss: (0.0232) | Acc: (99.22%) (38799/39104) | Learning rate: (0.0001)
2022-06-06 21:06:07,279 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 620 |  Loss: (0.0231) | Acc: (99.22%) (39435/39744) | Learning rate: (0.0001)
2022-06-06 21:06:09,076 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 630 |  Loss: (0.0231) | Acc: (99.22%) (40069/40384) | Learning rate: (0.0001)
2022-06-06 21:06:10,872 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 640 |  Loss: (0.0230) | Acc: (99.23%) (40707/41024) | Learning rate: (0.0001)
2022-06-06 21:06:12,668 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 650 |  Loss: (0.0232) | Acc: (99.22%) (41341/41664) | Learning rate: (0.0001)
2022-06-06 21:06:14,470 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 660 |  Loss: (0.0232) | Acc: (99.22%) (41974/42304) | Learning rate: (0.0001)
2022-06-06 21:06:16,267 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 670 |  Loss: (0.0231) | Acc: (99.22%) (42611/42944) | Learning rate: (0.0001)
2022-06-06 21:06:18,066 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 680 |  Loss: (0.0232) | Acc: (99.22%) (43246/43584) | Learning rate: (0.0001)
2022-06-06 21:06:19,866 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 690 |  Loss: (0.0232) | Acc: (99.22%) (43879/44224) | Learning rate: (0.0001)
2022-06-06 21:06:21,665 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 700 |  Loss: (0.0233) | Acc: (99.21%) (44510/44864) | Learning rate: (0.0001)
2022-06-06 21:06:23,463 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 710 |  Loss: (0.0233) | Acc: (99.21%) (45145/45504) | Learning rate: (0.0001)
2022-06-06 21:06:25,259 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 720 |  Loss: (0.0233) | Acc: (99.21%) (45780/46144) | Learning rate: (0.0001)
2022-06-06 21:06:27,058 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 730 |  Loss: (0.0233) | Acc: (99.22%) (46417/46784) | Learning rate: (0.0001)
2022-06-06 21:06:28,855 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 740 |  Loss: (0.0236) | Acc: (99.20%) (47046/47424) | Learning rate: (0.0001)
2022-06-06 21:06:30,654 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 750 |  Loss: (0.0235) | Acc: (99.21%) (47683/48064) | Learning rate: (0.0001)
2022-06-06 21:06:32,450 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 760 |  Loss: (0.0234) | Acc: (99.21%) (48318/48704) | Learning rate: (0.0001)
2022-06-06 21:06:34,241 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 770 |  Loss: (0.0235) | Acc: (99.20%) (48951/49344) | Learning rate: (0.0001)
2022-06-06 21:06:36,030 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 780 |  Loss: (0.0235) | Acc: (99.20%) (49585/49984) | Learning rate: (0.0001)
2022-06-06 21:06:46,010 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0866) | Acc: (97.52%) (9752/10000)
2022-06-06 21:06:46,011 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:06:46,947 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 0 |  Loss: (0.0073) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 21:06:48,783 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 10 |  Loss: (0.0307) | Acc: (99.29%) (699/704) | Learning rate: (0.0001)
2022-06-06 21:06:50,576 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 20 |  Loss: (0.0235) | Acc: (99.48%) (1337/1344) | Learning rate: (0.0001)
2022-06-06 21:06:52,367 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 30 |  Loss: (0.0246) | Acc: (99.40%) (1972/1984) | Learning rate: (0.0001)
2022-06-06 21:06:54,160 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 40 |  Loss: (0.0227) | Acc: (99.43%) (2609/2624) | Learning rate: (0.0001)
2022-06-06 21:06:55,954 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 50 |  Loss: (0.0237) | Acc: (99.39%) (3244/3264) | Learning rate: (0.0001)
2022-06-06 21:06:57,747 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 60 |  Loss: (0.0232) | Acc: (99.36%) (3879/3904) | Learning rate: (0.0001)
2022-06-06 21:06:59,541 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 70 |  Loss: (0.0228) | Acc: (99.32%) (4513/4544) | Learning rate: (0.0001)
2022-06-06 21:07:01,335 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 80 |  Loss: (0.0250) | Acc: (99.23%) (5144/5184) | Learning rate: (0.0001)
2022-06-06 21:07:03,131 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 90 |  Loss: (0.0239) | Acc: (99.26%) (5781/5824) | Learning rate: (0.0001)
2022-06-06 21:07:04,925 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 100 |  Loss: (0.0230) | Acc: (99.27%) (6417/6464) | Learning rate: (0.0001)
2022-06-06 21:07:06,719 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 110 |  Loss: (0.0217) | Acc: (99.32%) (7056/7104) | Learning rate: (0.0001)
2022-06-06 21:07:08,514 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 120 |  Loss: (0.0234) | Acc: (99.28%) (7688/7744) | Learning rate: (0.0001)
2022-06-06 21:07:10,309 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 130 |  Loss: (0.0229) | Acc: (99.28%) (8324/8384) | Learning rate: (0.0001)
2022-06-06 21:07:12,103 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 140 |  Loss: (0.0232) | Acc: (99.28%) (8959/9024) | Learning rate: (0.0001)
2022-06-06 21:07:13,897 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 150 |  Loss: (0.0243) | Acc: (99.23%) (9590/9664) | Learning rate: (0.0001)
2022-06-06 21:07:15,692 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 160 |  Loss: (0.0232) | Acc: (99.27%) (10229/10304) | Learning rate: (0.0001)
2022-06-06 21:07:17,488 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 170 |  Loss: (0.0228) | Acc: (99.27%) (10864/10944) | Learning rate: (0.0001)
2022-06-06 21:07:19,285 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 180 |  Loss: (0.0235) | Acc: (99.23%) (11495/11584) | Learning rate: (0.0001)
2022-06-06 21:07:21,079 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 190 |  Loss: (0.0234) | Acc: (99.25%) (12132/12224) | Learning rate: (0.0001)
2022-06-06 21:07:22,873 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 200 |  Loss: (0.0228) | Acc: (99.26%) (12769/12864) | Learning rate: (0.0001)
2022-06-06 21:07:24,670 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 210 |  Loss: (0.0223) | Acc: (99.27%) (13406/13504) | Learning rate: (0.0001)
2022-06-06 21:07:26,465 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 220 |  Loss: (0.0231) | Acc: (99.24%) (14037/14144) | Learning rate: (0.0001)
2022-06-06 21:07:28,262 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 230 |  Loss: (0.0227) | Acc: (99.25%) (14673/14784) | Learning rate: (0.0001)
2022-06-06 21:07:30,056 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 240 |  Loss: (0.0226) | Acc: (99.24%) (15307/15424) | Learning rate: (0.0001)
2022-06-06 21:07:31,851 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 250 |  Loss: (0.0222) | Acc: (99.25%) (15944/16064) | Learning rate: (0.0001)
2022-06-06 21:07:33,647 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 260 |  Loss: (0.0220) | Acc: (99.26%) (16581/16704) | Learning rate: (0.0001)
2022-06-06 21:07:35,442 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 270 |  Loss: (0.0222) | Acc: (99.25%) (17214/17344) | Learning rate: (0.0001)
2022-06-06 21:07:37,238 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 280 |  Loss: (0.0220) | Acc: (99.26%) (17851/17984) | Learning rate: (0.0001)
2022-06-06 21:07:39,034 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 290 |  Loss: (0.0219) | Acc: (99.26%) (18486/18624) | Learning rate: (0.0001)
2022-06-06 21:07:40,829 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 300 |  Loss: (0.0218) | Acc: (99.26%) (19122/19264) | Learning rate: (0.0001)
2022-06-06 21:07:42,624 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 310 |  Loss: (0.0216) | Acc: (99.27%) (19759/19904) | Learning rate: (0.0001)
2022-06-06 21:07:44,421 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 320 |  Loss: (0.0218) | Acc: (99.26%) (20393/20544) | Learning rate: (0.0001)
2022-06-06 21:07:46,217 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 330 |  Loss: (0.0215) | Acc: (99.28%) (21032/21184) | Learning rate: (0.0001)
2022-06-06 21:07:48,011 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 340 |  Loss: (0.0215) | Acc: (99.27%) (21665/21824) | Learning rate: (0.0001)
2022-06-06 21:07:49,805 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 350 |  Loss: (0.0218) | Acc: (99.27%) (22300/22464) | Learning rate: (0.0001)
2022-06-06 21:07:51,601 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 360 |  Loss: (0.0217) | Acc: (99.27%) (22935/23104) | Learning rate: (0.0001)
2022-06-06 21:07:53,399 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 370 |  Loss: (0.0215) | Acc: (99.27%) (23571/23744) | Learning rate: (0.0001)
2022-06-06 21:07:55,195 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 380 |  Loss: (0.0211) | Acc: (99.28%) (24209/24384) | Learning rate: (0.0001)
2022-06-06 21:07:56,990 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 390 |  Loss: (0.0210) | Acc: (99.28%) (24844/25024) | Learning rate: (0.0001)
2022-06-06 21:07:58,785 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 400 |  Loss: (0.0212) | Acc: (99.28%) (25478/25664) | Learning rate: (0.0001)
2022-06-06 21:08:00,580 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 410 |  Loss: (0.0213) | Acc: (99.27%) (26113/26304) | Learning rate: (0.0001)
2022-06-06 21:08:02,377 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 420 |  Loss: (0.0213) | Acc: (99.27%) (26748/26944) | Learning rate: (0.0001)
2022-06-06 21:08:04,173 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 430 |  Loss: (0.0212) | Acc: (99.28%) (27385/27584) | Learning rate: (0.0001)
2022-06-06 21:08:05,970 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 440 |  Loss: (0.0211) | Acc: (99.28%) (28020/28224) | Learning rate: (0.0001)
2022-06-06 21:08:07,765 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 450 |  Loss: (0.0209) | Acc: (99.28%) (28657/28864) | Learning rate: (0.0001)
2022-06-06 21:08:09,561 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 460 |  Loss: (0.0206) | Acc: (99.29%) (29295/29504) | Learning rate: (0.0001)
2022-06-06 21:08:11,358 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 470 |  Loss: (0.0204) | Acc: (99.30%) (29933/30144) | Learning rate: (0.0001)
2022-06-06 21:08:13,155 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 480 |  Loss: (0.0203) | Acc: (99.30%) (30569/30784) | Learning rate: (0.0001)
2022-06-06 21:08:14,952 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 490 |  Loss: (0.0205) | Acc: (99.30%) (31203/31424) | Learning rate: (0.0001)
2022-06-06 21:08:16,747 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 500 |  Loss: (0.0205) | Acc: (99.30%) (31838/32064) | Learning rate: (0.0001)
2022-06-06 21:08:18,543 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 510 |  Loss: (0.0208) | Acc: (99.28%) (32469/32704) | Learning rate: (0.0001)
2022-06-06 21:08:20,337 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 520 |  Loss: (0.0209) | Acc: (99.27%) (33100/33344) | Learning rate: (0.0001)
2022-06-06 21:08:22,133 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 530 |  Loss: (0.0210) | Acc: (99.27%) (33735/33984) | Learning rate: (0.0001)
2022-06-06 21:08:23,930 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 540 |  Loss: (0.0217) | Acc: (99.25%) (34365/34624) | Learning rate: (0.0001)
2022-06-06 21:08:25,727 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 550 |  Loss: (0.0216) | Acc: (99.25%) (35000/35264) | Learning rate: (0.0001)
2022-06-06 21:08:27,523 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 560 |  Loss: (0.0214) | Acc: (99.26%) (35638/35904) | Learning rate: (0.0001)
2022-06-06 21:08:29,317 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 570 |  Loss: (0.0217) | Acc: (99.26%) (36272/36544) | Learning rate: (0.0001)
2022-06-06 21:08:31,113 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 580 |  Loss: (0.0216) | Acc: (99.26%) (36910/37184) | Learning rate: (0.0001)
2022-06-06 21:08:32,909 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 590 |  Loss: (0.0216) | Acc: (99.27%) (37546/37824) | Learning rate: (0.0001)
2022-06-06 21:08:34,704 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 600 |  Loss: (0.0215) | Acc: (99.27%) (38182/38464) | Learning rate: (0.0001)
2022-06-06 21:08:36,501 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 610 |  Loss: (0.0216) | Acc: (99.26%) (38816/39104) | Learning rate: (0.0001)
2022-06-06 21:08:38,298 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 620 |  Loss: (0.0216) | Acc: (99.26%) (39449/39744) | Learning rate: (0.0001)
2022-06-06 21:08:40,092 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 630 |  Loss: (0.0216) | Acc: (99.26%) (40086/40384) | Learning rate: (0.0001)
2022-06-06 21:08:41,887 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 640 |  Loss: (0.0215) | Acc: (99.27%) (40723/41024) | Learning rate: (0.0001)
2022-06-06 21:08:43,685 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 650 |  Loss: (0.0215) | Acc: (99.27%) (41359/41664) | Learning rate: (0.0001)
2022-06-06 21:08:45,482 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 660 |  Loss: (0.0214) | Acc: (99.27%) (41995/42304) | Learning rate: (0.0001)
2022-06-06 21:08:47,279 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 670 |  Loss: (0.0214) | Acc: (99.27%) (42631/42944) | Learning rate: (0.0001)
2022-06-06 21:08:49,074 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 680 |  Loss: (0.0214) | Acc: (99.27%) (43266/43584) | Learning rate: (0.0001)
2022-06-06 21:08:50,869 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 690 |  Loss: (0.0215) | Acc: (99.27%) (43900/44224) | Learning rate: (0.0001)
2022-06-06 21:08:52,666 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 700 |  Loss: (0.0213) | Acc: (99.27%) (44537/44864) | Learning rate: (0.0001)
2022-06-06 21:08:54,462 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 710 |  Loss: (0.0212) | Acc: (99.28%) (45176/45504) | Learning rate: (0.0001)
2022-06-06 21:08:56,259 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 720 |  Loss: (0.0212) | Acc: (99.27%) (45809/46144) | Learning rate: (0.0001)
2022-06-06 21:08:58,056 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 730 |  Loss: (0.0211) | Acc: (99.28%) (46445/46784) | Learning rate: (0.0001)
2022-06-06 21:08:59,852 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 740 |  Loss: (0.0211) | Acc: (99.28%) (47081/47424) | Learning rate: (0.0001)
2022-06-06 21:09:01,647 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 750 |  Loss: (0.0214) | Acc: (99.27%) (47712/48064) | Learning rate: (0.0001)
2022-06-06 21:09:03,444 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 760 |  Loss: (0.0214) | Acc: (99.26%) (48346/48704) | Learning rate: (0.0001)
2022-06-06 21:09:05,232 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 770 |  Loss: (0.0215) | Acc: (99.27%) (48983/49344) | Learning rate: (0.0001)
2022-06-06 21:09:07,020 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 780 |  Loss: (0.0216) | Acc: (99.27%) (49620/49984) | Learning rate: (0.0001)
2022-06-06 21:09:17,009 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0998) | Acc: (97.25%) (9725/10000)
2022-06-06 21:09:17,010 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:09:18,031 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 0 |  Loss: (0.0024) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 21:09:19,821 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 10 |  Loss: (0.0138) | Acc: (99.43%) (700/704) | Learning rate: (0.0001)
2022-06-06 21:09:21,611 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 20 |  Loss: (0.0114) | Acc: (99.55%) (1338/1344) | Learning rate: (0.0001)
2022-06-06 21:09:23,404 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 30 |  Loss: (0.0182) | Acc: (99.29%) (1970/1984) | Learning rate: (0.0001)
2022-06-06 21:09:25,201 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 40 |  Loss: (0.0182) | Acc: (99.31%) (2606/2624) | Learning rate: (0.0001)
2022-06-06 21:09:26,995 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 50 |  Loss: (0.0169) | Acc: (99.36%) (3243/3264) | Learning rate: (0.0001)
2022-06-06 21:09:28,791 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 60 |  Loss: (0.0174) | Acc: (99.33%) (3878/3904) | Learning rate: (0.0001)
2022-06-06 21:09:30,587 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 70 |  Loss: (0.0166) | Acc: (99.38%) (4516/4544) | Learning rate: (0.0001)
2022-06-06 21:09:32,382 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 80 |  Loss: (0.0157) | Acc: (99.44%) (5155/5184) | Learning rate: (0.0001)
2022-06-06 21:09:34,176 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 90 |  Loss: (0.0155) | Acc: (99.45%) (5792/5824) | Learning rate: (0.0001)
2022-06-06 21:09:35,971 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 100 |  Loss: (0.0155) | Acc: (99.47%) (6430/6464) | Learning rate: (0.0001)
2022-06-06 21:09:37,767 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 110 |  Loss: (0.0150) | Acc: (99.48%) (7067/7104) | Learning rate: (0.0001)
2022-06-06 21:09:39,563 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 120 |  Loss: (0.0156) | Acc: (99.44%) (7701/7744) | Learning rate: (0.0001)
2022-06-06 21:09:41,359 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 130 |  Loss: (0.0159) | Acc: (99.44%) (8337/8384) | Learning rate: (0.0001)
2022-06-06 21:09:43,152 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 140 |  Loss: (0.0157) | Acc: (99.45%) (8974/9024) | Learning rate: (0.0001)
2022-06-06 21:09:44,945 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 150 |  Loss: (0.0163) | Acc: (99.45%) (9611/9664) | Learning rate: (0.0001)
2022-06-06 21:09:46,738 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 160 |  Loss: (0.0164) | Acc: (99.46%) (10248/10304) | Learning rate: (0.0001)
2022-06-06 21:09:48,531 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 170 |  Loss: (0.0164) | Acc: (99.46%) (10885/10944) | Learning rate: (0.0001)
2022-06-06 21:09:50,325 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 180 |  Loss: (0.0163) | Acc: (99.47%) (11523/11584) | Learning rate: (0.0001)
2022-06-06 21:09:52,120 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 190 |  Loss: (0.0167) | Acc: (99.45%) (12157/12224) | Learning rate: (0.0001)
2022-06-06 21:09:53,917 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 200 |  Loss: (0.0166) | Acc: (99.43%) (12791/12864) | Learning rate: (0.0001)
2022-06-06 21:09:55,711 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 210 |  Loss: (0.0172) | Acc: (99.41%) (13425/13504) | Learning rate: (0.0001)
2022-06-06 21:09:57,503 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 220 |  Loss: (0.0171) | Acc: (99.40%) (14059/14144) | Learning rate: (0.0001)
2022-06-06 21:09:59,299 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 230 |  Loss: (0.0167) | Acc: (99.41%) (14697/14784) | Learning rate: (0.0001)
2022-06-06 21:10:01,094 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 240 |  Loss: (0.0168) | Acc: (99.40%) (15332/15424) | Learning rate: (0.0001)
2022-06-06 21:10:02,890 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 250 |  Loss: (0.0167) | Acc: (99.40%) (15968/16064) | Learning rate: (0.0001)
2022-06-06 21:10:04,685 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 260 |  Loss: (0.0166) | Acc: (99.40%) (16604/16704) | Learning rate: (0.0001)
2022-06-06 21:10:06,480 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 270 |  Loss: (0.0166) | Acc: (99.40%) (17240/17344) | Learning rate: (0.0001)
2022-06-06 21:10:08,277 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 280 |  Loss: (0.0170) | Acc: (99.38%) (17873/17984) | Learning rate: (0.0001)
2022-06-06 21:10:10,074 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 290 |  Loss: (0.0172) | Acc: (99.38%) (18508/18624) | Learning rate: (0.0001)
2022-06-06 21:10:11,869 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 300 |  Loss: (0.0169) | Acc: (99.39%) (19146/19264) | Learning rate: (0.0001)
2022-06-06 21:10:13,665 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 310 |  Loss: (0.0170) | Acc: (99.39%) (19782/19904) | Learning rate: (0.0001)
2022-06-06 21:10:15,459 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 320 |  Loss: (0.0167) | Acc: (99.40%) (20420/20544) | Learning rate: (0.0001)
2022-06-06 21:10:17,256 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 330 |  Loss: (0.0166) | Acc: (99.41%) (21058/21184) | Learning rate: (0.0001)
2022-06-06 21:10:19,053 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 340 |  Loss: (0.0164) | Acc: (99.41%) (21696/21824) | Learning rate: (0.0001)
2022-06-06 21:10:20,850 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.40%) (22330/22464) | Learning rate: (0.0001)
2022-06-06 21:10:22,647 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 360 |  Loss: (0.0165) | Acc: (99.41%) (22968/23104) | Learning rate: (0.0001)
2022-06-06 21:10:24,441 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 370 |  Loss: (0.0162) | Acc: (99.42%) (23606/23744) | Learning rate: (0.0001)
2022-06-06 21:10:26,236 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 380 |  Loss: (0.0162) | Acc: (99.42%) (24243/24384) | Learning rate: (0.0001)
2022-06-06 21:10:28,031 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 390 |  Loss: (0.0160) | Acc: (99.43%) (24881/25024) | Learning rate: (0.0001)
2022-06-06 21:10:29,828 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 400 |  Loss: (0.0161) | Acc: (99.43%) (25517/25664) | Learning rate: (0.0001)
2022-06-06 21:10:31,625 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 410 |  Loss: (0.0160) | Acc: (99.43%) (26154/26304) | Learning rate: (0.0001)
2022-06-06 21:10:33,421 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 420 |  Loss: (0.0159) | Acc: (99.44%) (26792/26944) | Learning rate: (0.0001)
2022-06-06 21:10:35,217 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 430 |  Loss: (0.0158) | Acc: (99.43%) (27428/27584) | Learning rate: (0.0001)
2022-06-06 21:10:37,011 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 440 |  Loss: (0.0156) | Acc: (99.44%) (28067/28224) | Learning rate: (0.0001)
2022-06-06 21:10:38,808 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 450 |  Loss: (0.0157) | Acc: (99.44%) (28703/28864) | Learning rate: (0.0001)
2022-06-06 21:10:40,604 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 460 |  Loss: (0.0156) | Acc: (99.44%) (29340/29504) | Learning rate: (0.0001)
2022-06-06 21:10:42,401 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 470 |  Loss: (0.0160) | Acc: (99.44%) (29974/30144) | Learning rate: (0.0001)
2022-06-06 21:10:44,197 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 480 |  Loss: (0.0163) | Acc: (99.43%) (30608/30784) | Learning rate: (0.0001)
2022-06-06 21:10:45,991 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 490 |  Loss: (0.0167) | Acc: (99.42%) (31241/31424) | Learning rate: (0.0001)
2022-06-06 21:10:47,788 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 500 |  Loss: (0.0165) | Acc: (99.43%) (31880/32064) | Learning rate: (0.0001)
2022-06-06 21:10:49,584 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 510 |  Loss: (0.0166) | Acc: (99.42%) (32514/32704) | Learning rate: (0.0001)
2022-06-06 21:10:51,381 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 520 |  Loss: (0.0166) | Acc: (99.42%) (33149/33344) | Learning rate: (0.0001)
2022-06-06 21:10:53,178 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 530 |  Loss: (0.0165) | Acc: (99.42%) (33786/33984) | Learning rate: (0.0001)
2022-06-06 21:10:54,975 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 540 |  Loss: (0.0167) | Acc: (99.41%) (34421/34624) | Learning rate: (0.0001)
2022-06-06 21:10:56,770 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 550 |  Loss: (0.0169) | Acc: (99.41%) (35056/35264) | Learning rate: (0.0001)
2022-06-06 21:10:58,567 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 560 |  Loss: (0.0169) | Acc: (99.41%) (35692/35904) | Learning rate: (0.0001)
2022-06-06 21:11:00,363 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 570 |  Loss: (0.0169) | Acc: (99.41%) (36328/36544) | Learning rate: (0.0001)
2022-06-06 21:11:02,160 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 580 |  Loss: (0.0170) | Acc: (99.41%) (36965/37184) | Learning rate: (0.0001)
2022-06-06 21:11:03,956 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 590 |  Loss: (0.0169) | Acc: (99.41%) (37602/37824) | Learning rate: (0.0001)
2022-06-06 21:11:05,752 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 600 |  Loss: (0.0168) | Acc: (99.42%) (38239/38464) | Learning rate: (0.0001)
2022-06-06 21:11:07,548 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 610 |  Loss: (0.0169) | Acc: (99.41%) (38873/39104) | Learning rate: (0.0001)
2022-06-06 21:11:09,342 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 620 |  Loss: (0.0170) | Acc: (99.41%) (39508/39744) | Learning rate: (0.0001)
2022-06-06 21:11:11,138 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 630 |  Loss: (0.0169) | Acc: (99.41%) (40147/40384) | Learning rate: (0.0001)
2022-06-06 21:11:12,934 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 640 |  Loss: (0.0167) | Acc: (99.42%) (40786/41024) | Learning rate: (0.0001)
2022-06-06 21:11:14,730 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 650 |  Loss: (0.0166) | Acc: (99.43%) (41425/41664) | Learning rate: (0.0001)
2022-06-06 21:11:16,527 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 660 |  Loss: (0.0166) | Acc: (99.43%) (42062/42304) | Learning rate: (0.0001)
2022-06-06 21:11:18,323 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 670 |  Loss: (0.0167) | Acc: (99.42%) (42696/42944) | Learning rate: (0.0001)
2022-06-06 21:11:20,118 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 680 |  Loss: (0.0168) | Acc: (99.42%) (43331/43584) | Learning rate: (0.0001)
2022-06-06 21:11:21,914 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 690 |  Loss: (0.0170) | Acc: (99.42%) (43968/44224) | Learning rate: (0.0001)
2022-06-06 21:11:23,712 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 700 |  Loss: (0.0170) | Acc: (99.42%) (44605/44864) | Learning rate: (0.0001)
2022-06-06 21:11:25,508 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 710 |  Loss: (0.0172) | Acc: (99.42%) (45238/45504) | Learning rate: (0.0001)
2022-06-06 21:11:27,304 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 720 |  Loss: (0.0172) | Acc: (99.41%) (45874/46144) | Learning rate: (0.0001)
2022-06-06 21:11:29,102 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 730 |  Loss: (0.0172) | Acc: (99.41%) (46510/46784) | Learning rate: (0.0001)
2022-06-06 21:11:30,897 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 740 |  Loss: (0.0173) | Acc: (99.42%) (47147/47424) | Learning rate: (0.0001)
2022-06-06 21:11:32,693 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 750 |  Loss: (0.0172) | Acc: (99.42%) (47786/48064) | Learning rate: (0.0001)
2022-06-06 21:11:34,489 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 760 |  Loss: (0.0173) | Acc: (99.42%) (48422/48704) | Learning rate: (0.0001)
2022-06-06 21:11:36,278 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 770 |  Loss: (0.0173) | Acc: (99.42%) (49059/49344) | Learning rate: (0.0001)
2022-06-06 21:11:38,067 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 780 |  Loss: (0.0173) | Acc: (99.43%) (49698/49984) | Learning rate: (0.0001)
2022-06-06 21:11:48,002 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0868) | Acc: (97.56%) (9756/10000)
2022-06-06 21:11:48,003 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:11:48,962 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 0 |  Loss: (0.0141) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 21:11:50,775 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 10 |  Loss: (0.0113) | Acc: (99.43%) (700/704) | Learning rate: (0.0001)
2022-06-06 21:11:52,569 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 20 |  Loss: (0.0196) | Acc: (99.26%) (1334/1344) | Learning rate: (0.0001)
2022-06-06 21:11:54,364 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 30 |  Loss: (0.0301) | Acc: (98.89%) (1962/1984) | Learning rate: (0.0001)
2022-06-06 21:11:56,160 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 40 |  Loss: (0.0263) | Acc: (99.09%) (2600/2624) | Learning rate: (0.0001)
2022-06-06 21:11:57,955 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 50 |  Loss: (0.0235) | Acc: (99.20%) (3238/3264) | Learning rate: (0.0001)
2022-06-06 21:11:59,750 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 60 |  Loss: (0.0231) | Acc: (99.26%) (3875/3904) | Learning rate: (0.0001)
2022-06-06 21:12:17,440 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0833) | Acc: (97.77%) (9777/10000)
2022-06-06 21:12:17,441 - CIFAR10 Classifier - INFO - Epoch time : 0:00:29
2022-06-06 21:12:18,445 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 0 |  Loss: (0.0573) | Acc: (98.44%) (63/64) | Learning rate: (1e-05)
2022-06-06 21:12:20,232 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 10 |  Loss: (0.0165) | Acc: (99.72%) (702/704) | Learning rate: (1e-05)
2022-06-06 21:12:22,020 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.55%) (1338/1344) | Learning rate: (1e-05)
2022-06-06 21:12:23,808 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 30 |  Loss: (0.0150) | Acc: (99.55%) (1975/1984) | Learning rate: (1e-05)
2022-06-06 21:12:25,599 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 40 |  Loss: (0.0147) | Acc: (99.50%) (2611/2624) | Learning rate: (1e-05)
2022-06-06 21:12:27,390 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.48%) (3247/3264) | Learning rate: (1e-05)
2022-06-06 21:12:29,181 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 60 |  Loss: (0.0130) | Acc: (99.54%) (3886/3904) | Learning rate: (1e-05)
2022-06-06 21:12:30,972 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 70 |  Loss: (0.0128) | Acc: (99.54%) (4523/4544) | Learning rate: (1e-05)
2022-06-06 21:12:32,764 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 80 |  Loss: (0.0124) | Acc: (99.58%) (5162/5184) | Learning rate: (1e-05)
2022-06-06 21:12:34,555 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 90 |  Loss: (0.0134) | Acc: (99.55%) (5798/5824) | Learning rate: (1e-05)
2022-06-06 21:12:36,346 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 100 |  Loss: (0.0133) | Acc: (99.55%) (6435/6464) | Learning rate: (1e-05)
2022-06-06 21:12:38,142 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 110 |  Loss: (0.0127) | Acc: (99.58%) (7074/7104) | Learning rate: (1e-05)
2022-06-06 21:12:39,938 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 120 |  Loss: (0.0125) | Acc: (99.57%) (7711/7744) | Learning rate: (1e-05)
2022-06-06 21:12:41,731 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 130 |  Loss: (0.0129) | Acc: (99.57%) (8348/8384) | Learning rate: (1e-05)
2022-06-06 21:12:43,527 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 140 |  Loss: (0.0129) | Acc: (99.58%) (8986/9024) | Learning rate: (1e-05)
2022-06-06 21:12:45,322 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 150 |  Loss: (0.0126) | Acc: (99.60%) (9625/9664) | Learning rate: (1e-05)
2022-06-06 21:12:47,119 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 160 |  Loss: (0.0130) | Acc: (99.59%) (10262/10304) | Learning rate: (1e-05)
2022-06-06 21:12:48,914 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.59%) (10899/10944) | Learning rate: (1e-05)
2022-06-06 21:12:50,708 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 180 |  Loss: (0.0130) | Acc: (99.59%) (11537/11584) | Learning rate: (1e-05)
2022-06-06 21:12:52,504 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 190 |  Loss: (0.0129) | Acc: (99.61%) (12176/12224) | Learning rate: (1e-05)
2022-06-06 21:12:54,302 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 200 |  Loss: (0.0127) | Acc: (99.61%) (12814/12864) | Learning rate: (1e-05)
2022-06-06 21:12:56,099 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 210 |  Loss: (0.0124) | Acc: (99.62%) (13453/13504) | Learning rate: (1e-05)
2022-06-06 21:12:57,896 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 220 |  Loss: (0.0121) | Acc: (99.63%) (14092/14144) | Learning rate: (1e-05)
2022-06-06 21:12:59,694 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 230 |  Loss: (0.0126) | Acc: (99.60%) (14725/14784) | Learning rate: (1e-05)
2022-06-06 21:13:01,490 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 240 |  Loss: (0.0128) | Acc: (99.60%) (15362/15424) | Learning rate: (1e-05)
2022-06-06 21:13:03,286 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 250 |  Loss: (0.0130) | Acc: (99.60%) (15999/16064) | Learning rate: (1e-05)
2022-06-06 21:13:05,081 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 260 |  Loss: (0.0129) | Acc: (99.60%) (16638/16704) | Learning rate: (1e-05)
2022-06-06 21:13:06,878 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 270 |  Loss: (0.0127) | Acc: (99.61%) (17277/17344) | Learning rate: (1e-05)
2022-06-06 21:13:08,675 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 280 |  Loss: (0.0128) | Acc: (99.62%) (17915/17984) | Learning rate: (1e-05)
2022-06-06 21:13:10,471 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 290 |  Loss: (0.0128) | Acc: (99.62%) (18553/18624) | Learning rate: (1e-05)
2022-06-06 21:13:12,267 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 300 |  Loss: (0.0127) | Acc: (99.62%) (19191/19264) | Learning rate: (1e-05)
2022-06-06 21:13:14,064 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 310 |  Loss: (0.0125) | Acc: (99.62%) (19829/19904) | Learning rate: (1e-05)
2022-06-06 21:13:15,861 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 320 |  Loss: (0.0125) | Acc: (99.62%) (20466/20544) | Learning rate: (1e-05)
2022-06-06 21:13:17,656 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 330 |  Loss: (0.0123) | Acc: (99.63%) (21106/21184) | Learning rate: (1e-05)
2022-06-06 21:13:19,455 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 340 |  Loss: (0.0122) | Acc: (99.63%) (21744/21824) | Learning rate: (1e-05)
2022-06-06 21:13:21,251 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 350 |  Loss: (0.0121) | Acc: (99.63%) (22380/22464) | Learning rate: (1e-05)
2022-06-06 21:13:23,047 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 360 |  Loss: (0.0121) | Acc: (99.63%) (23018/23104) | Learning rate: (1e-05)
2022-06-06 21:13:24,843 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 370 |  Loss: (0.0122) | Acc: (99.63%) (23656/23744) | Learning rate: (1e-05)
2022-06-06 21:13:26,638 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 380 |  Loss: (0.0122) | Acc: (99.62%) (24292/24384) | Learning rate: (1e-05)
2022-06-06 21:13:28,434 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 390 |  Loss: (0.0124) | Acc: (99.62%) (24930/25024) | Learning rate: (1e-05)
2022-06-06 21:13:30,230 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 400 |  Loss: (0.0126) | Acc: (99.61%) (25565/25664) | Learning rate: (1e-05)
2022-06-06 21:13:32,026 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 410 |  Loss: (0.0123) | Acc: (99.62%) (26205/26304) | Learning rate: (1e-05)
2022-06-06 21:13:33,823 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 420 |  Loss: (0.0125) | Acc: (99.61%) (26839/26944) | Learning rate: (1e-05)
2022-06-06 21:13:35,619 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 430 |  Loss: (0.0127) | Acc: (99.60%) (27475/27584) | Learning rate: (1e-05)
2022-06-06 21:13:37,415 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 440 |  Loss: (0.0129) | Acc: (99.61%) (28113/28224) | Learning rate: (1e-05)
2022-06-06 21:13:39,212 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 450 |  Loss: (0.0130) | Acc: (99.61%) (28751/28864) | Learning rate: (1e-05)
2022-06-06 21:13:41,010 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 460 |  Loss: (0.0129) | Acc: (99.60%) (29387/29504) | Learning rate: (1e-05)
2022-06-06 21:13:42,807 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 470 |  Loss: (0.0129) | Acc: (99.61%) (30025/30144) | Learning rate: (1e-05)
2022-06-06 21:13:44,606 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 480 |  Loss: (0.0127) | Acc: (99.61%) (30664/30784) | Learning rate: (1e-05)
2022-06-06 21:13:46,405 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 490 |  Loss: (0.0127) | Acc: (99.61%) (31301/31424) | Learning rate: (1e-05)
2022-06-06 21:13:48,204 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 500 |  Loss: (0.0126) | Acc: (99.61%) (31939/32064) | Learning rate: (1e-05)
2022-06-06 21:13:50,005 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 510 |  Loss: (0.0128) | Acc: (99.60%) (32573/32704) | Learning rate: (1e-05)
2022-06-06 21:13:51,804 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 520 |  Loss: (0.0128) | Acc: (99.60%) (33209/33344) | Learning rate: (1e-05)
2022-06-06 21:13:53,603 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 530 |  Loss: (0.0130) | Acc: (99.60%) (33847/33984) | Learning rate: (1e-05)
2022-06-06 21:13:55,403 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 540 |  Loss: (0.0129) | Acc: (99.60%) (34486/34624) | Learning rate: (1e-05)
2022-06-06 21:13:57,202 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 550 |  Loss: (0.0130) | Acc: (99.59%) (35121/35264) | Learning rate: (1e-05)
2022-06-06 21:13:59,001 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 560 |  Loss: (0.0129) | Acc: (99.60%) (35760/35904) | Learning rate: (1e-05)
2022-06-06 21:14:00,801 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 570 |  Loss: (0.0129) | Acc: (99.60%) (36398/36544) | Learning rate: (1e-05)
2022-06-06 21:14:02,600 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 580 |  Loss: (0.0131) | Acc: (99.60%) (37035/37184) | Learning rate: (1e-05)
2022-06-06 21:14:04,399 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 590 |  Loss: (0.0132) | Acc: (99.59%) (37670/37824) | Learning rate: (1e-05)
2022-06-06 21:14:06,198 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 600 |  Loss: (0.0132) | Acc: (99.59%) (38308/38464) | Learning rate: (1e-05)
2022-06-06 21:14:07,997 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 610 |  Loss: (0.0132) | Acc: (99.60%) (38946/39104) | Learning rate: (1e-05)
2022-06-06 21:14:09,797 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 620 |  Loss: (0.0131) | Acc: (99.60%) (39586/39744) | Learning rate: (1e-05)
2022-06-06 21:14:11,596 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 630 |  Loss: (0.0131) | Acc: (99.60%) (40222/40384) | Learning rate: (1e-05)
2022-06-06 21:14:13,395 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 640 |  Loss: (0.0130) | Acc: (99.61%) (40862/41024) | Learning rate: (1e-05)
2022-06-06 21:14:15,195 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 650 |  Loss: (0.0130) | Acc: (99.61%) (41500/41664) | Learning rate: (1e-05)
2022-06-06 21:14:16,994 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 660 |  Loss: (0.0131) | Acc: (99.60%) (42135/42304) | Learning rate: (1e-05)
2022-06-06 21:14:18,793 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 670 |  Loss: (0.0130) | Acc: (99.60%) (42774/42944) | Learning rate: (1e-05)
2022-06-06 21:14:20,592 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 680 |  Loss: (0.0129) | Acc: (99.61%) (43413/43584) | Learning rate: (1e-05)
2022-06-06 21:14:22,392 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 690 |  Loss: (0.0131) | Acc: (99.60%) (44049/44224) | Learning rate: (1e-05)
2022-06-06 21:14:24,191 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 700 |  Loss: (0.0130) | Acc: (99.61%) (44689/44864) | Learning rate: (1e-05)
2022-06-06 21:14:25,991 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 710 |  Loss: (0.0129) | Acc: (99.61%) (45327/45504) | Learning rate: (1e-05)
2022-06-06 21:14:27,791 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 720 |  Loss: (0.0129) | Acc: (99.61%) (45964/46144) | Learning rate: (1e-05)
2022-06-06 21:14:29,592 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 730 |  Loss: (0.0128) | Acc: (99.61%) (46602/46784) | Learning rate: (1e-05)
2022-06-06 21:14:31,390 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 740 |  Loss: (0.0128) | Acc: (99.61%) (47240/47424) | Learning rate: (1e-05)
2022-06-06 21:14:33,189 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 750 |  Loss: (0.0128) | Acc: (99.61%) (47878/48064) | Learning rate: (1e-05)
2022-06-06 21:14:34,987 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 760 |  Loss: (0.0127) | Acc: (99.61%) (48516/48704) | Learning rate: (1e-05)
2022-06-06 21:14:36,777 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 770 |  Loss: (0.0127) | Acc: (99.61%) (49153/49344) | Learning rate: (1e-05)
2022-06-06 21:14:38,567 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 780 |  Loss: (0.0126) | Acc: (99.61%) (49791/49984) | Learning rate: (1e-05)
2022-06-06 21:14:48,555 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0793) | Acc: (97.87%) (9787/10000)
2022-06-06 21:14:48,556 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:14:49,587 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 0 |  Loss: (0.0118) | Acc: (100.00%) (64/64) | Learning rate: (1e-05)
2022-06-06 21:14:51,379 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 10 |  Loss: (0.0128) | Acc: (99.72%) (702/704) | Learning rate: (1e-05)
2022-06-06 21:14:53,174 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 20 |  Loss: (0.0085) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-05)
2022-06-06 21:14:54,968 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 30 |  Loss: (0.0082) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-05)
2022-06-06 21:14:56,763 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 40 |  Loss: (0.0077) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-05)
2022-06-06 21:14:58,561 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 50 |  Loss: (0.0088) | Acc: (99.79%) (3257/3264) | Learning rate: (1e-05)
2022-06-06 21:15:00,359 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 60 |  Loss: (0.0084) | Acc: (99.80%) (3896/3904) | Learning rate: (1e-05)
2022-06-06 21:15:02,158 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 70 |  Loss: (0.0080) | Acc: (99.80%) (4535/4544) | Learning rate: (1e-05)
2022-06-06 21:15:03,954 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 80 |  Loss: (0.0087) | Acc: (99.79%) (5173/5184) | Learning rate: (1e-05)
2022-06-06 21:15:05,754 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 90 |  Loss: (0.0086) | Acc: (99.78%) (5811/5824) | Learning rate: (1e-05)
2022-06-06 21:15:07,551 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 100 |  Loss: (0.0089) | Acc: (99.75%) (6448/6464) | Learning rate: (1e-05)
2022-06-06 21:15:09,347 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 110 |  Loss: (0.0087) | Acc: (99.76%) (7087/7104) | Learning rate: (1e-05)
2022-06-06 21:15:11,145 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 120 |  Loss: (0.0097) | Acc: (99.72%) (7722/7744) | Learning rate: (1e-05)
2022-06-06 21:15:12,940 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 130 |  Loss: (0.0094) | Acc: (99.73%) (8361/8384) | Learning rate: (1e-05)
2022-06-06 21:15:14,737 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 140 |  Loss: (0.0097) | Acc: (99.71%) (8998/9024) | Learning rate: (1e-05)
2022-06-06 21:15:16,535 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 150 |  Loss: (0.0095) | Acc: (99.72%) (9637/9664) | Learning rate: (1e-05)
2022-06-06 21:15:18,335 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 160 |  Loss: (0.0101) | Acc: (99.70%) (10273/10304) | Learning rate: (1e-05)
2022-06-06 21:15:20,132 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 170 |  Loss: (0.0099) | Acc: (99.71%) (10912/10944) | Learning rate: (1e-05)
2022-06-06 21:15:21,929 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 180 |  Loss: (0.0097) | Acc: (99.72%) (11551/11584) | Learning rate: (1e-05)
2022-06-06 21:15:23,726 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 190 |  Loss: (0.0098) | Acc: (99.71%) (12188/12224) | Learning rate: (1e-05)
2022-06-06 21:15:25,524 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 200 |  Loss: (0.0099) | Acc: (99.70%) (12825/12864) | Learning rate: (1e-05)
2022-06-06 21:15:27,321 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 210 |  Loss: (0.0100) | Acc: (99.69%) (13462/13504) | Learning rate: (1e-05)
2022-06-06 21:15:29,116 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 220 |  Loss: (0.0098) | Acc: (99.70%) (14102/14144) | Learning rate: (1e-05)
2022-06-06 21:15:30,913 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 230 |  Loss: (0.0097) | Acc: (99.71%) (14741/14784) | Learning rate: (1e-05)
2022-06-06 21:15:32,711 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 240 |  Loss: (0.0100) | Acc: (99.70%) (15377/15424) | Learning rate: (1e-05)
2022-06-06 21:15:34,509 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 250 |  Loss: (0.0098) | Acc: (99.71%) (16017/16064) | Learning rate: (1e-05)
2022-06-06 21:15:36,309 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 260 |  Loss: (0.0097) | Acc: (99.71%) (16656/16704) | Learning rate: (1e-05)
2022-06-06 21:15:38,107 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 270 |  Loss: (0.0102) | Acc: (99.70%) (17292/17344) | Learning rate: (1e-05)
2022-06-06 21:15:39,906 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 280 |  Loss: (0.0106) | Acc: (99.68%) (17927/17984) | Learning rate: (1e-05)
2022-06-06 21:15:41,702 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 290 |  Loss: (0.0105) | Acc: (99.68%) (18564/18624) | Learning rate: (1e-05)
2022-06-06 21:15:43,499 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 300 |  Loss: (0.0107) | Acc: (99.67%) (19200/19264) | Learning rate: (1e-05)
2022-06-06 21:15:45,297 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 310 |  Loss: (0.0107) | Acc: (99.67%) (19838/19904) | Learning rate: (1e-05)
2022-06-06 21:15:47,096 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 320 |  Loss: (0.0105) | Acc: (99.68%) (20478/20544) | Learning rate: (1e-05)
2022-06-06 21:15:48,892 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 330 |  Loss: (0.0105) | Acc: (99.68%) (21116/21184) | Learning rate: (1e-05)
2022-06-06 21:15:50,688 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 340 |  Loss: (0.0103) | Acc: (99.68%) (21755/21824) | Learning rate: (1e-05)
2022-06-06 21:15:52,485 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 350 |  Loss: (0.0105) | Acc: (99.68%) (22392/22464) | Learning rate: (1e-05)
2022-06-06 21:15:54,283 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 360 |  Loss: (0.0105) | Acc: (99.68%) (23030/23104) | Learning rate: (1e-05)
2022-06-06 21:15:56,082 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 370 |  Loss: (0.0105) | Acc: (99.68%) (23669/23744) | Learning rate: (1e-05)
2022-06-06 21:15:57,882 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 380 |  Loss: (0.0104) | Acc: (99.69%) (24309/24384) | Learning rate: (1e-05)
2022-06-06 21:15:59,680 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 390 |  Loss: (0.0106) | Acc: (99.68%) (24945/25024) | Learning rate: (1e-05)
2022-06-06 21:16:01,481 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 400 |  Loss: (0.0107) | Acc: (99.68%) (25582/25664) | Learning rate: (1e-05)
2022-06-06 21:16:03,279 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 410 |  Loss: (0.0105) | Acc: (99.69%) (26222/26304) | Learning rate: (1e-05)
2022-06-06 21:16:05,078 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 420 |  Loss: (0.0103) | Acc: (99.69%) (26861/26944) | Learning rate: (1e-05)
2022-06-06 21:16:06,878 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 430 |  Loss: (0.0103) | Acc: (99.70%) (27500/27584) | Learning rate: (1e-05)
2022-06-06 21:16:08,677 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 440 |  Loss: (0.0105) | Acc: (99.69%) (28136/28224) | Learning rate: (1e-05)
2022-06-06 21:16:10,476 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 450 |  Loss: (0.0104) | Acc: (99.69%) (28775/28864) | Learning rate: (1e-05)
2022-06-06 21:16:12,276 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 460 |  Loss: (0.0103) | Acc: (99.69%) (29413/29504) | Learning rate: (1e-05)
2022-06-06 21:16:14,074 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 470 |  Loss: (0.0102) | Acc: (99.69%) (30052/30144) | Learning rate: (1e-05)
2022-06-06 21:16:15,872 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 480 |  Loss: (0.0100) | Acc: (99.70%) (30692/30784) | Learning rate: (1e-05)
2022-06-06 21:16:17,669 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 490 |  Loss: (0.0100) | Acc: (99.70%) (31331/31424) | Learning rate: (1e-05)
2022-06-06 21:16:19,467 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 500 |  Loss: (0.0099) | Acc: (99.71%) (31970/32064) | Learning rate: (1e-05)
2022-06-06 21:16:21,267 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 510 |  Loss: (0.0098) | Acc: (99.71%) (32610/32704) | Learning rate: (1e-05)
2022-06-06 21:16:23,065 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 520 |  Loss: (0.0098) | Acc: (99.71%) (33246/33344) | Learning rate: (1e-05)
2022-06-06 21:16:24,862 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 530 |  Loss: (0.0098) | Acc: (99.70%) (33882/33984) | Learning rate: (1e-05)
2022-06-06 21:16:26,661 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 540 |  Loss: (0.0097) | Acc: (99.70%) (34521/34624) | Learning rate: (1e-05)
2022-06-06 21:16:28,458 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 550 |  Loss: (0.0096) | Acc: (99.71%) (35161/35264) | Learning rate: (1e-05)
2022-06-06 21:16:30,256 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 560 |  Loss: (0.0097) | Acc: (99.70%) (35798/35904) | Learning rate: (1e-05)
2022-06-06 21:16:32,052 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 570 |  Loss: (0.0098) | Acc: (99.70%) (36436/36544) | Learning rate: (1e-05)
2022-06-06 21:16:33,850 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 580 |  Loss: (0.0097) | Acc: (99.71%) (37075/37184) | Learning rate: (1e-05)
2022-06-06 21:16:35,650 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 590 |  Loss: (0.0098) | Acc: (99.71%) (37713/37824) | Learning rate: (1e-05)
2022-06-06 21:16:37,448 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 600 |  Loss: (0.0097) | Acc: (99.71%) (38351/38464) | Learning rate: (1e-05)
2022-06-06 21:16:39,247 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 610 |  Loss: (0.0097) | Acc: (99.70%) (38988/39104) | Learning rate: (1e-05)
2022-06-06 21:16:41,046 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 620 |  Loss: (0.0097) | Acc: (99.71%) (39627/39744) | Learning rate: (1e-05)
2022-06-06 21:16:42,845 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 630 |  Loss: (0.0097) | Acc: (99.71%) (40266/40384) | Learning rate: (1e-05)
2022-06-06 21:16:44,644 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 640 |  Loss: (0.0097) | Acc: (99.71%) (40905/41024) | Learning rate: (1e-05)
2022-06-06 21:16:46,442 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 650 |  Loss: (0.0096) | Acc: (99.71%) (41544/41664) | Learning rate: (1e-05)
2022-06-06 21:16:48,239 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 660 |  Loss: (0.0096) | Acc: (99.71%) (42183/42304) | Learning rate: (1e-05)
2022-06-06 21:16:50,038 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 670 |  Loss: (0.0098) | Acc: (99.71%) (42820/42944) | Learning rate: (1e-05)
2022-06-06 21:16:51,836 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 680 |  Loss: (0.0098) | Acc: (99.71%) (43458/43584) | Learning rate: (1e-05)
2022-06-06 21:16:53,633 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 690 |  Loss: (0.0098) | Acc: (99.71%) (44097/44224) | Learning rate: (1e-05)
2022-06-06 21:16:55,431 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 700 |  Loss: (0.0100) | Acc: (99.71%) (44732/44864) | Learning rate: (1e-05)
2022-06-06 21:16:57,228 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 710 |  Loss: (0.0099) | Acc: (99.71%) (45370/45504) | Learning rate: (1e-05)
2022-06-06 21:16:59,025 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 720 |  Loss: (0.0099) | Acc: (99.71%) (46010/46144) | Learning rate: (1e-05)
2022-06-06 21:17:00,823 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 730 |  Loss: (0.0099) | Acc: (99.71%) (46646/46784) | Learning rate: (1e-05)
2022-06-06 21:17:02,620 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 740 |  Loss: (0.0099) | Acc: (99.70%) (47284/47424) | Learning rate: (1e-05)
2022-06-06 21:17:04,419 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 750 |  Loss: (0.0099) | Acc: (99.71%) (47923/48064) | Learning rate: (1e-05)
2022-06-06 21:17:06,218 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 760 |  Loss: (0.0098) | Acc: (99.71%) (48562/48704) | Learning rate: (1e-05)
2022-06-06 21:17:08,009 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 770 |  Loss: (0.0098) | Acc: (99.71%) (49200/49344) | Learning rate: (1e-05)
2022-06-06 21:17:09,798 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 780 |  Loss: (0.0098) | Acc: (99.71%) (49838/49984) | Learning rate: (1e-05)
2022-06-06 21:17:19,730 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0756) | Acc: (97.90%) (9790/10000)
2022-06-06 21:17:19,730 - CIFAR10 Classifier - INFO - Epoch time : 0:02:31
2022-06-06 21:17:20,762 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 0 |  Loss: (0.0015) | Acc: (100.00%) (64/64) | Learning rate: (1e-05)
2022-06-06 21:17:22,555 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 10 |  Loss: (0.0138) | Acc: (99.57%) (701/704) | Learning rate: (1e-05)
2022-06-06 21:17:24,347 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 20 |  Loss: (0.0086) | Acc: (99.78%) (1341/1344) | Learning rate: (1e-05)
2022-06-06 21:17:26,142 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 30 |  Loss: (0.0134) | Acc: (99.65%) (1977/1984) | Learning rate: (1e-05)
2022-06-06 21:17:27,939 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 40 |  Loss: (0.0112) | Acc: (99.70%) (2616/2624) | Learning rate: (1e-05)
2022-06-06 21:17:29,734 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 50 |  Loss: (0.0118) | Acc: (99.69%) (3254/3264) | Learning rate: (1e-05)
2022-06-06 21:17:31,531 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 60 |  Loss: (0.0122) | Acc: (99.72%) (3893/3904) | Learning rate: (1e-05)
2022-06-06 21:17:33,331 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 70 |  Loss: (0.0115) | Acc: (99.74%) (4532/4544) | Learning rate: (1e-05)
2022-06-06 21:17:35,129 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 80 |  Loss: (0.0108) | Acc: (99.75%) (5171/5184) | Learning rate: (1e-05)
2022-06-06 21:17:36,927 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 90 |  Loss: (0.0099) | Acc: (99.78%) (5811/5824) | Learning rate: (1e-05)
2022-06-06 21:17:38,722 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 100 |  Loss: (0.0094) | Acc: (99.78%) (6450/6464) | Learning rate: (1e-05)
2022-06-06 21:17:40,518 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 110 |  Loss: (0.0108) | Acc: (99.76%) (7087/7104) | Learning rate: (1e-05)
2022-06-06 21:17:42,313 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 120 |  Loss: (0.0103) | Acc: (99.78%) (7727/7744) | Learning rate: (1e-05)
2022-06-06 21:17:44,109 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 130 |  Loss: (0.0102) | Acc: (99.77%) (8365/8384) | Learning rate: (1e-05)
2022-06-06 21:17:45,906 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 140 |  Loss: (0.0099) | Acc: (99.78%) (9004/9024) | Learning rate: (1e-05)
2022-06-06 21:17:47,704 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 150 |  Loss: (0.0096) | Acc: (99.78%) (9643/9664) | Learning rate: (1e-05)
2022-06-06 21:17:49,501 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 160 |  Loss: (0.0098) | Acc: (99.78%) (10281/10304) | Learning rate: (1e-05)
2022-06-06 21:17:51,297 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 170 |  Loss: (0.0096) | Acc: (99.77%) (10919/10944) | Learning rate: (1e-05)
2022-06-06 21:17:53,095 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 180 |  Loss: (0.0093) | Acc: (99.78%) (11559/11584) | Learning rate: (1e-05)
2022-06-06 21:17:54,892 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 190 |  Loss: (0.0091) | Acc: (99.78%) (12197/12224) | Learning rate: (1e-05)
2022-06-06 21:17:56,687 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 200 |  Loss: (0.0088) | Acc: (99.79%) (12837/12864) | Learning rate: (1e-05)
2022-06-06 21:17:58,482 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 210 |  Loss: (0.0086) | Acc: (99.79%) (13476/13504) | Learning rate: (1e-05)
2022-06-06 21:18:00,280 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 220 |  Loss: (0.0084) | Acc: (99.80%) (14116/14144) | Learning rate: (1e-05)
2022-06-06 21:18:02,077 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 230 |  Loss: (0.0085) | Acc: (99.80%) (14754/14784) | Learning rate: (1e-05)
2022-06-06 21:18:03,875 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 240 |  Loss: (0.0086) | Acc: (99.79%) (15392/15424) | Learning rate: (1e-05)
2022-06-06 21:18:05,671 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 250 |  Loss: (0.0086) | Acc: (99.78%) (16029/16064) | Learning rate: (1e-05)
2022-06-06 21:18:07,470 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 260 |  Loss: (0.0086) | Acc: (99.78%) (16667/16704) | Learning rate: (1e-05)
2022-06-06 21:18:09,266 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 270 |  Loss: (0.0086) | Acc: (99.78%) (17305/17344) | Learning rate: (1e-05)
2022-06-06 21:18:11,061 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 280 |  Loss: (0.0084) | Acc: (99.78%) (17944/17984) | Learning rate: (1e-05)
2022-06-06 21:18:12,857 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 290 |  Loss: (0.0084) | Acc: (99.77%) (18582/18624) | Learning rate: (1e-05)
2022-06-06 21:18:14,656 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 300 |  Loss: (0.0081) | Acc: (99.78%) (19222/19264) | Learning rate: (1e-05)
2022-06-06 21:18:16,455 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 310 |  Loss: (0.0080) | Acc: (99.79%) (19862/19904) | Learning rate: (1e-05)
2022-06-06 21:18:18,253 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 320 |  Loss: (0.0083) | Acc: (99.77%) (20497/20544) | Learning rate: (1e-05)
2022-06-06 21:18:20,051 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 330 |  Loss: (0.0081) | Acc: (99.78%) (21137/21184) | Learning rate: (1e-05)
2022-06-06 21:18:21,848 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 340 |  Loss: (0.0082) | Acc: (99.77%) (21774/21824) | Learning rate: (1e-05)
2022-06-06 21:18:23,645 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 350 |  Loss: (0.0082) | Acc: (99.78%) (22414/22464) | Learning rate: (1e-05)
2022-06-06 21:18:25,442 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 360 |  Loss: (0.0081) | Acc: (99.78%) (23053/23104) | Learning rate: (1e-05)
2022-06-06 21:18:27,238 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 370 |  Loss: (0.0079) | Acc: (99.79%) (23693/23744) | Learning rate: (1e-05)
2022-06-06 21:18:29,036 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 380 |  Loss: (0.0079) | Acc: (99.79%) (24333/24384) | Learning rate: (1e-05)
2022-06-06 21:18:30,832 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 390 |  Loss: (0.0079) | Acc: (99.78%) (24970/25024) | Learning rate: (1e-05)
2022-06-06 21:18:32,631 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 400 |  Loss: (0.0078) | Acc: (99.79%) (25610/25664) | Learning rate: (1e-05)
2022-06-06 21:18:34,430 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 410 |  Loss: (0.0079) | Acc: (99.78%) (26247/26304) | Learning rate: (1e-05)
2022-06-06 21:18:36,228 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 420 |  Loss: (0.0078) | Acc: (99.78%) (26886/26944) | Learning rate: (1e-05)
2022-06-06 21:18:38,027 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 430 |  Loss: (0.0078) | Acc: (99.78%) (27524/27584) | Learning rate: (1e-05)
2022-06-06 21:18:39,824 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 440 |  Loss: (0.0078) | Acc: (99.78%) (28162/28224) | Learning rate: (1e-05)
2022-06-06 21:18:41,621 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 450 |  Loss: (0.0077) | Acc: (99.78%) (28801/28864) | Learning rate: (1e-05)
2022-06-06 21:18:43,420 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 460 |  Loss: (0.0077) | Acc: (99.78%) (29439/29504) | Learning rate: (1e-05)
2022-06-06 21:18:45,216 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 470 |  Loss: (0.0078) | Acc: (99.78%) (30078/30144) | Learning rate: (1e-05)
2022-06-06 21:18:47,013 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 480 |  Loss: (0.0078) | Acc: (99.78%) (30716/30784) | Learning rate: (1e-05)
2022-06-06 21:18:48,811 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 490 |  Loss: (0.0078) | Acc: (99.77%) (31353/31424) | Learning rate: (1e-05)
2022-06-06 21:18:50,607 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 500 |  Loss: (0.0078) | Acc: (99.78%) (31993/32064) | Learning rate: (1e-05)
2022-06-06 21:18:52,404 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 510 |  Loss: (0.0077) | Acc: (99.78%) (32633/32704) | Learning rate: (1e-05)
2022-06-06 21:18:54,202 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 520 |  Loss: (0.0076) | Acc: (99.79%) (33273/33344) | Learning rate: (1e-05)
2022-06-06 21:18:56,000 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 530 |  Loss: (0.0075) | Acc: (99.79%) (33913/33984) | Learning rate: (1e-05)
2022-06-06 21:18:57,797 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 540 |  Loss: (0.0077) | Acc: (99.79%) (34550/34624) | Learning rate: (1e-05)
2022-06-06 21:18:59,594 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 550 |  Loss: (0.0078) | Acc: (99.78%) (35188/35264) | Learning rate: (1e-05)
2022-06-06 21:19:01,392 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 560 |  Loss: (0.0078) | Acc: (99.78%) (35826/35904) | Learning rate: (1e-05)
2022-06-06 21:19:03,191 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 570 |  Loss: (0.0078) | Acc: (99.78%) (36464/36544) | Learning rate: (1e-05)
2022-06-06 21:19:04,989 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 580 |  Loss: (0.0078) | Acc: (99.78%) (37103/37184) | Learning rate: (1e-05)
2022-06-06 21:19:06,785 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 590 |  Loss: (0.0077) | Acc: (99.78%) (37742/37824) | Learning rate: (1e-05)
2022-06-06 21:19:08,581 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 600 |  Loss: (0.0077) | Acc: (99.78%) (38380/38464) | Learning rate: (1e-05)
2022-06-06 21:19:10,378 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 610 |  Loss: (0.0077) | Acc: (99.78%) (39018/39104) | Learning rate: (1e-05)
2022-06-06 21:19:12,177 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 620 |  Loss: (0.0077) | Acc: (99.78%) (39656/39744) | Learning rate: (1e-05)
2022-06-06 21:19:13,977 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 630 |  Loss: (0.0078) | Acc: (99.78%) (40295/40384) | Learning rate: (1e-05)
2022-06-06 21:19:15,775 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 640 |  Loss: (0.0079) | Acc: (99.78%) (40933/41024) | Learning rate: (1e-05)
2022-06-06 21:19:17,573 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 650 |  Loss: (0.0079) | Acc: (99.78%) (41572/41664) | Learning rate: (1e-05)
2022-06-06 21:19:19,372 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 660 |  Loss: (0.0078) | Acc: (99.78%) (42211/42304) | Learning rate: (1e-05)
2022-06-06 21:19:21,169 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 670 |  Loss: (0.0079) | Acc: (99.78%) (42849/42944) | Learning rate: (1e-05)
2022-06-06 21:19:22,967 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 680 |  Loss: (0.0078) | Acc: (99.78%) (43489/43584) | Learning rate: (1e-05)
2022-06-06 21:19:24,765 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 690 |  Loss: (0.0078) | Acc: (99.78%) (44128/44224) | Learning rate: (1e-05)
2022-06-06 21:19:26,563 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 700 |  Loss: (0.0078) | Acc: (99.78%) (44766/44864) | Learning rate: (1e-05)
2022-06-06 21:19:28,360 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 710 |  Loss: (0.0079) | Acc: (99.78%) (45402/45504) | Learning rate: (1e-05)
2022-06-06 21:19:30,158 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 720 |  Loss: (0.0079) | Acc: (99.78%) (46041/46144) | Learning rate: (1e-05)
2022-06-06 21:19:31,955 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 730 |  Loss: (0.0080) | Acc: (99.77%) (46678/46784) | Learning rate: (1e-05)
2022-06-06 21:19:33,751 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 740 |  Loss: (0.0080) | Acc: (99.77%) (47317/47424) | Learning rate: (1e-05)
2022-06-06 21:19:35,549 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 750 |  Loss: (0.0079) | Acc: (99.78%) (47957/48064) | Learning rate: (1e-05)
2022-06-06 21:19:37,348 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 760 |  Loss: (0.0079) | Acc: (99.78%) (48596/48704) | Learning rate: (1e-05)
2022-06-06 21:19:39,139 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 770 |  Loss: (0.0079) | Acc: (99.78%) (49233/49344) | Learning rate: (1e-05)
2022-06-06 21:19:40,929 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 780 |  Loss: (0.0079) | Acc: (99.77%) (49871/49984) | Learning rate: (1e-05)
2022-06-06 21:19:50,898 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0798) | Acc: (97.94%) (9794/10000)
2022-06-06 21:19:50,899 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:19:51,895 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (64/64) | Learning rate: (1e-05)
2022-06-06 21:19:53,687 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 10 |  Loss: (0.0072) | Acc: (99.72%) (702/704) | Learning rate: (1e-05)
2022-06-06 21:19:55,480 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 20 |  Loss: (0.0074) | Acc: (99.70%) (1340/1344) | Learning rate: (1e-05)
2022-06-06 21:19:57,271 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 30 |  Loss: (0.0060) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-05)
2022-06-06 21:19:59,063 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 40 |  Loss: (0.0053) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-05)
2022-06-06 21:20:00,856 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 50 |  Loss: (0.0064) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-05)
2022-06-06 21:20:02,652 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 60 |  Loss: (0.0060) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-05)
2022-06-06 21:20:04,444 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 70 |  Loss: (0.0055) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-05)
2022-06-06 21:20:06,237 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 80 |  Loss: (0.0061) | Acc: (99.85%) (5176/5184) | Learning rate: (1e-05)
2022-06-06 21:20:08,033 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 90 |  Loss: (0.0061) | Acc: (99.83%) (5814/5824) | Learning rate: (1e-05)
2022-06-06 21:20:09,825 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.81%) (6452/6464) | Learning rate: (1e-05)
2022-06-06 21:20:11,618 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.83%) (7092/7104) | Learning rate: (1e-05)
2022-06-06 21:20:13,411 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 120 |  Loss: (0.0060) | Acc: (99.82%) (7730/7744) | Learning rate: (1e-05)
2022-06-06 21:20:15,205 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.82%) (8369/8384) | Learning rate: (1e-05)
2022-06-06 21:20:16,998 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 140 |  Loss: (0.0060) | Acc: (99.82%) (9008/9024) | Learning rate: (1e-05)
2022-06-06 21:20:18,792 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 150 |  Loss: (0.0063) | Acc: (99.80%) (9645/9664) | Learning rate: (1e-05)
2022-06-06 21:20:20,586 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 160 |  Loss: (0.0063) | Acc: (99.81%) (10284/10304) | Learning rate: (1e-05)
2022-06-06 21:20:22,378 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 170 |  Loss: (0.0064) | Acc: (99.80%) (10922/10944) | Learning rate: (1e-05)
2022-06-06 21:20:24,173 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 180 |  Loss: (0.0065) | Acc: (99.79%) (11560/11584) | Learning rate: (1e-05)
2022-06-06 21:20:25,967 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 190 |  Loss: (0.0066) | Acc: (99.80%) (12199/12224) | Learning rate: (1e-05)
2022-06-06 21:20:27,760 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 200 |  Loss: (0.0064) | Acc: (99.80%) (12838/12864) | Learning rate: (1e-05)
2022-06-06 21:20:29,554 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 210 |  Loss: (0.0066) | Acc: (99.79%) (13475/13504) | Learning rate: (1e-05)
2022-06-06 21:20:31,348 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 220 |  Loss: (0.0067) | Acc: (99.78%) (14113/14144) | Learning rate: (1e-05)
2022-06-06 21:20:33,143 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 230 |  Loss: (0.0066) | Acc: (99.78%) (14752/14784) | Learning rate: (1e-05)
2022-06-06 21:20:34,937 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 240 |  Loss: (0.0066) | Acc: (99.78%) (15390/15424) | Learning rate: (1e-05)
2022-06-06 21:20:36,729 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 250 |  Loss: (0.0067) | Acc: (99.78%) (16029/16064) | Learning rate: (1e-05)
2022-06-06 21:20:38,525 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 260 |  Loss: (0.0066) | Acc: (99.79%) (16669/16704) | Learning rate: (1e-05)
2022-06-06 21:20:40,320 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 270 |  Loss: (0.0065) | Acc: (99.79%) (17308/17344) | Learning rate: (1e-05)
2022-06-06 21:20:42,114 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 280 |  Loss: (0.0064) | Acc: (99.79%) (17946/17984) | Learning rate: (1e-05)
2022-06-06 21:20:43,907 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.79%) (18585/18624) | Learning rate: (1e-05)
2022-06-06 21:20:45,702 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 300 |  Loss: (0.0064) | Acc: (99.79%) (19224/19264) | Learning rate: (1e-05)
2022-06-06 21:20:47,497 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 310 |  Loss: (0.0070) | Acc: (99.77%) (19859/19904) | Learning rate: (1e-05)
2022-06-06 21:20:49,294 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 320 |  Loss: (0.0071) | Acc: (99.77%) (20497/20544) | Learning rate: (1e-05)
2022-06-06 21:20:51,088 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 330 |  Loss: (0.0070) | Acc: (99.77%) (21136/21184) | Learning rate: (1e-05)
2022-06-06 21:20:52,884 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 340 |  Loss: (0.0069) | Acc: (99.78%) (21775/21824) | Learning rate: (1e-05)
2022-06-06 21:20:54,681 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 350 |  Loss: (0.0069) | Acc: (99.78%) (22414/22464) | Learning rate: (1e-05)
2022-06-06 21:20:56,477 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 360 |  Loss: (0.0069) | Acc: (99.77%) (23052/23104) | Learning rate: (1e-05)
2022-06-06 21:20:58,273 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 370 |  Loss: (0.0073) | Acc: (99.76%) (23686/23744) | Learning rate: (1e-05)
2022-06-06 21:21:00,069 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 380 |  Loss: (0.0076) | Acc: (99.75%) (24322/24384) | Learning rate: (1e-05)
2022-06-06 21:21:01,865 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 390 |  Loss: (0.0076) | Acc: (99.74%) (24960/25024) | Learning rate: (1e-05)
2022-06-06 21:21:03,661 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 400 |  Loss: (0.0076) | Acc: (99.74%) (25597/25664) | Learning rate: (1e-05)
2022-06-06 21:21:05,458 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 410 |  Loss: (0.0075) | Acc: (99.74%) (26235/26304) | Learning rate: (1e-05)
2022-06-06 21:21:07,256 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 420 |  Loss: (0.0075) | Acc: (99.74%) (26874/26944) | Learning rate: (1e-05)
2022-06-06 21:21:09,052 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 430 |  Loss: (0.0077) | Acc: (99.74%) (27512/27584) | Learning rate: (1e-05)
2022-06-06 21:21:10,849 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 440 |  Loss: (0.0076) | Acc: (99.74%) (28150/28224) | Learning rate: (1e-05)
2022-06-06 21:21:12,644 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 450 |  Loss: (0.0075) | Acc: (99.74%) (28789/28864) | Learning rate: (1e-05)
2022-06-06 21:21:14,441 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 460 |  Loss: (0.0075) | Acc: (99.74%) (29427/29504) | Learning rate: (1e-05)
2022-06-06 21:21:16,236 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 470 |  Loss: (0.0075) | Acc: (99.74%) (30066/30144) | Learning rate: (1e-05)
2022-06-06 21:21:18,034 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 480 |  Loss: (0.0075) | Acc: (99.74%) (30704/30784) | Learning rate: (1e-05)
2022-06-06 21:21:19,831 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 490 |  Loss: (0.0074) | Acc: (99.75%) (31344/31424) | Learning rate: (1e-05)
2022-06-06 21:21:21,628 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 500 |  Loss: (0.0074) | Acc: (99.74%) (31982/32064) | Learning rate: (1e-05)
2022-06-06 21:21:23,425 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 510 |  Loss: (0.0074) | Acc: (99.75%) (32621/32704) | Learning rate: (1e-05)
2022-06-06 21:21:25,221 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 520 |  Loss: (0.0076) | Acc: (99.74%) (33258/33344) | Learning rate: (1e-05)
2022-06-06 21:21:27,016 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 530 |  Loss: (0.0075) | Acc: (99.75%) (33898/33984) | Learning rate: (1e-05)
2022-06-06 21:21:28,812 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 540 |  Loss: (0.0074) | Acc: (99.75%) (34537/34624) | Learning rate: (1e-05)
2022-06-06 21:21:30,608 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 550 |  Loss: (0.0073) | Acc: (99.75%) (35176/35264) | Learning rate: (1e-05)
2022-06-06 21:21:32,404 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 560 |  Loss: (0.0073) | Acc: (99.75%) (35814/35904) | Learning rate: (1e-05)
2022-06-06 21:21:34,200 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 570 |  Loss: (0.0073) | Acc: (99.75%) (36453/36544) | Learning rate: (1e-05)
2022-06-06 21:21:35,995 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 580 |  Loss: (0.0072) | Acc: (99.75%) (37092/37184) | Learning rate: (1e-05)
2022-06-06 21:21:37,790 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 590 |  Loss: (0.0072) | Acc: (99.75%) (37731/37824) | Learning rate: (1e-05)
2022-06-06 21:21:39,588 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 600 |  Loss: (0.0071) | Acc: (99.76%) (38370/38464) | Learning rate: (1e-05)
2022-06-06 21:21:41,384 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 610 |  Loss: (0.0070) | Acc: (99.76%) (39010/39104) | Learning rate: (1e-05)
2022-06-06 21:21:43,181 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 620 |  Loss: (0.0070) | Acc: (99.76%) (39649/39744) | Learning rate: (1e-05)
2022-06-06 21:21:44,976 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 630 |  Loss: (0.0070) | Acc: (99.76%) (40289/40384) | Learning rate: (1e-05)
2022-06-06 21:21:46,772 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 640 |  Loss: (0.0069) | Acc: (99.77%) (40929/41024) | Learning rate: (1e-05)
2022-06-06 21:21:48,567 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 650 |  Loss: (0.0068) | Acc: (99.77%) (41569/41664) | Learning rate: (1e-05)
2022-06-06 21:21:50,363 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 660 |  Loss: (0.0068) | Acc: (99.77%) (42208/42304) | Learning rate: (1e-05)
2022-06-06 21:21:52,160 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 670 |  Loss: (0.0067) | Acc: (99.78%) (42848/42944) | Learning rate: (1e-05)
2022-06-06 21:21:53,957 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 680 |  Loss: (0.0067) | Acc: (99.78%) (43488/43584) | Learning rate: (1e-05)
2022-06-06 21:21:55,754 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 690 |  Loss: (0.0066) | Acc: (99.78%) (44128/44224) | Learning rate: (1e-05)
2022-06-06 21:21:57,550 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 700 |  Loss: (0.0067) | Acc: (99.78%) (44766/44864) | Learning rate: (1e-05)
2022-06-06 21:21:59,345 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 710 |  Loss: (0.0066) | Acc: (99.78%) (45405/45504) | Learning rate: (1e-05)
2022-06-06 21:22:01,141 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 720 |  Loss: (0.0066) | Acc: (99.78%) (46044/46144) | Learning rate: (1e-05)
2022-06-06 21:22:02,937 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 730 |  Loss: (0.0066) | Acc: (99.78%) (46683/46784) | Learning rate: (1e-05)
2022-06-06 21:22:04,732 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 740 |  Loss: (0.0066) | Acc: (99.79%) (47323/47424) | Learning rate: (1e-05)
2022-06-06 21:22:06,529 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 750 |  Loss: (0.0066) | Acc: (99.79%) (47961/48064) | Learning rate: (1e-05)
2022-06-06 21:22:08,325 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 760 |  Loss: (0.0066) | Acc: (99.79%) (48600/48704) | Learning rate: (1e-05)
2022-06-06 21:22:10,113 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 770 |  Loss: (0.0067) | Acc: (99.79%) (49238/49344) | Learning rate: (1e-05)
2022-06-06 21:22:11,902 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 780 |  Loss: (0.0066) | Acc: (99.79%) (49877/49984) | Learning rate: (1e-05)
2022-06-06 21:22:21,844 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0788) | Acc: (97.99%) (9799/10000)
2022-06-06 21:22:21,845 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:22:22,766 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 0 |  Loss: (0.0013) | Acc: (100.00%) (64/64) | Learning rate: (1e-05)
2022-06-06 21:22:24,575 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (99.72%) (702/704) | Learning rate: (1e-05)
2022-06-06 21:22:26,368 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 20 |  Loss: (0.0037) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-05)
2022-06-06 21:22:28,161 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-05)
2022-06-06 21:22:29,954 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 40 |  Loss: (0.0049) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-05)
2022-06-06 21:22:31,748 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 50 |  Loss: (0.0050) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-05)
2022-06-06 21:22:33,542 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 60 |  Loss: (0.0055) | Acc: (99.82%) (3897/3904) | Learning rate: (1e-05)
2022-06-06 21:22:35,337 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 70 |  Loss: (0.0056) | Acc: (99.80%) (4535/4544) | Learning rate: (1e-05)
2022-06-06 21:22:37,131 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 80 |  Loss: (0.0055) | Acc: (99.79%) (5173/5184) | Learning rate: (1e-05)
2022-06-06 21:22:38,926 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 90 |  Loss: (0.0052) | Acc: (99.81%) (5813/5824) | Learning rate: (1e-05)
2022-06-06 21:22:40,721 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 100 |  Loss: (0.0053) | Acc: (99.81%) (6452/6464) | Learning rate: (1e-05)
2022-06-06 21:22:42,516 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 110 |  Loss: (0.0052) | Acc: (99.82%) (7091/7104) | Learning rate: (1e-05)
2022-06-06 21:22:44,309 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.83%) (7731/7744) | Learning rate: (1e-05)
2022-06-06 21:22:46,104 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.83%) (8370/8384) | Learning rate: (1e-05)
2022-06-06 21:22:47,899 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 140 |  Loss: (0.0050) | Acc: (99.83%) (9009/9024) | Learning rate: (1e-05)
2022-06-06 21:22:49,694 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 150 |  Loss: (0.0048) | Acc: (99.84%) (9649/9664) | Learning rate: (1e-05)
2022-06-06 21:22:51,487 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 160 |  Loss: (0.0047) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-05)
2022-06-06 21:22:53,283 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 170 |  Loss: (0.0048) | Acc: (99.84%) (10927/10944) | Learning rate: (1e-05)
2022-06-06 21:22:55,078 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 180 |  Loss: (0.0049) | Acc: (99.84%) (11566/11584) | Learning rate: (1e-05)
2022-06-06 21:22:56,873 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 190 |  Loss: (0.0048) | Acc: (99.85%) (12206/12224) | Learning rate: (1e-05)
2022-06-06 21:22:58,666 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 200 |  Loss: (0.0052) | Acc: (99.82%) (12841/12864) | Learning rate: (1e-05)
2022-06-06 21:23:00,461 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 210 |  Loss: (0.0050) | Acc: (99.83%) (13481/13504) | Learning rate: (1e-05)
2022-06-06 21:23:02,257 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.83%) (14120/14144) | Learning rate: (1e-05)
2022-06-06 21:23:04,053 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.84%) (14760/14784) | Learning rate: (1e-05)
2022-06-06 21:23:05,848 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.84%) (15399/15424) | Learning rate: (1e-05)
2022-06-06 21:23:07,643 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 250 |  Loss: (0.0053) | Acc: (99.83%) (16036/16064) | Learning rate: (1e-05)
2022-06-06 21:23:09,441 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.83%) (16675/16704) | Learning rate: (1e-05)
2022-06-06 21:23:11,237 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.83%) (17314/17344) | Learning rate: (1e-05)
2022-06-06 21:23:13,034 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 280 |  Loss: (0.0052) | Acc: (99.83%) (17954/17984) | Learning rate: (1e-05)
2022-06-06 21:23:14,830 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 290 |  Loss: (0.0052) | Acc: (99.83%) (18593/18624) | Learning rate: (1e-05)
2022-06-06 21:23:16,625 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 300 |  Loss: (0.0054) | Acc: (99.82%) (19230/19264) | Learning rate: (1e-05)
2022-06-06 21:23:18,420 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.83%) (19870/19904) | Learning rate: (1e-05)
2022-06-06 21:23:20,214 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 320 |  Loss: (0.0054) | Acc: (99.82%) (20507/20544) | Learning rate: (1e-05)
2022-06-06 21:23:22,010 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 330 |  Loss: (0.0054) | Acc: (99.82%) (21146/21184) | Learning rate: (1e-05)
2022-06-06 21:23:23,806 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 340 |  Loss: (0.0054) | Acc: (99.82%) (21785/21824) | Learning rate: (1e-05)
2022-06-06 21:23:25,602 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 350 |  Loss: (0.0054) | Acc: (99.82%) (22424/22464) | Learning rate: (1e-05)
2022-06-06 21:23:27,397 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.82%) (23062/23104) | Learning rate: (1e-05)
2022-06-06 21:23:29,192 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.81%) (23700/23744) | Learning rate: (1e-05)
2022-06-06 21:23:30,989 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.82%) (24339/24384) | Learning rate: (1e-05)
2022-06-06 21:23:32,787 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 390 |  Loss: (0.0054) | Acc: (99.82%) (24979/25024) | Learning rate: (1e-05)
2022-06-06 21:23:34,584 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 400 |  Loss: (0.0054) | Acc: (99.82%) (25619/25664) | Learning rate: (1e-05)
2022-06-06 21:23:36,380 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 410 |  Loss: (0.0053) | Acc: (99.83%) (26259/26304) | Learning rate: (1e-05)
2022-06-06 21:23:38,173 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 420 |  Loss: (0.0055) | Acc: (99.82%) (26896/26944) | Learning rate: (1e-05)
2022-06-06 21:23:39,967 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 430 |  Loss: (0.0054) | Acc: (99.83%) (27536/27584) | Learning rate: (1e-05)
2022-06-06 21:23:41,762 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 440 |  Loss: (0.0054) | Acc: (99.83%) (28175/28224) | Learning rate: (1e-05)
2022-06-06 21:23:43,559 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 450 |  Loss: (0.0055) | Acc: (99.82%) (28812/28864) | Learning rate: (1e-05)
2022-06-06 21:23:45,355 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 460 |  Loss: (0.0054) | Acc: (99.82%) (29452/29504) | Learning rate: (1e-05)
2022-06-06 21:23:47,150 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 470 |  Loss: (0.0054) | Acc: (99.82%) (30090/30144) | Learning rate: (1e-05)
2022-06-06 21:23:48,945 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 480 |  Loss: (0.0055) | Acc: (99.82%) (30728/30784) | Learning rate: (1e-05)
2022-06-06 21:23:50,742 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 490 |  Loss: (0.0055) | Acc: (99.82%) (31367/31424) | Learning rate: (1e-05)
2022-06-06 21:23:52,537 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 500 |  Loss: (0.0055) | Acc: (99.82%) (32006/32064) | Learning rate: (1e-05)
2022-06-06 21:23:54,335 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 510 |  Loss: (0.0054) | Acc: (99.82%) (32646/32704) | Learning rate: (1e-05)
2022-06-06 21:23:56,128 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 520 |  Loss: (0.0054) | Acc: (99.83%) (33286/33344) | Learning rate: (1e-05)
2022-06-06 21:23:57,924 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 530 |  Loss: (0.0054) | Acc: (99.83%) (33925/33984) | Learning rate: (1e-05)
2022-06-06 21:23:59,722 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 540 |  Loss: (0.0054) | Acc: (99.82%) (34563/34624) | Learning rate: (1e-05)
2022-06-06 21:24:01,518 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 550 |  Loss: (0.0054) | Acc: (99.82%) (35202/35264) | Learning rate: (1e-05)
2022-06-06 21:24:03,315 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 560 |  Loss: (0.0053) | Acc: (99.82%) (35841/35904) | Learning rate: (1e-05)
2022-06-06 21:24:05,111 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 570 |  Loss: (0.0055) | Acc: (99.82%) (36478/36544) | Learning rate: (1e-05)
2022-06-06 21:24:06,908 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 580 |  Loss: (0.0054) | Acc: (99.82%) (37118/37184) | Learning rate: (1e-05)
2022-06-06 21:24:08,705 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 590 |  Loss: (0.0054) | Acc: (99.82%) (37757/37824) | Learning rate: (1e-05)
2022-06-06 21:24:10,501 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 600 |  Loss: (0.0054) | Acc: (99.82%) (38396/38464) | Learning rate: (1e-05)
2022-06-06 21:24:12,297 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 610 |  Loss: (0.0055) | Acc: (99.82%) (39034/39104) | Learning rate: (1e-05)
2022-06-06 21:24:14,094 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 620 |  Loss: (0.0055) | Acc: (99.82%) (39673/39744) | Learning rate: (1e-05)
2022-06-06 21:24:15,892 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 630 |  Loss: (0.0055) | Acc: (99.82%) (40311/40384) | Learning rate: (1e-05)
2022-06-06 21:24:17,689 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 640 |  Loss: (0.0055) | Acc: (99.82%) (40950/41024) | Learning rate: (1e-05)
2022-06-06 21:24:19,487 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 650 |  Loss: (0.0056) | Acc: (99.82%) (41589/41664) | Learning rate: (1e-05)
2022-06-06 21:24:21,283 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 660 |  Loss: (0.0055) | Acc: (99.82%) (42229/42304) | Learning rate: (1e-05)
2022-06-06 21:24:23,078 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 670 |  Loss: (0.0056) | Acc: (99.82%) (42866/42944) | Learning rate: (1e-05)
2022-06-06 21:24:24,874 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 680 |  Loss: (0.0057) | Acc: (99.82%) (43504/43584) | Learning rate: (1e-05)
2022-06-06 21:24:26,672 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 690 |  Loss: (0.0057) | Acc: (99.81%) (44141/44224) | Learning rate: (1e-05)
2022-06-06 21:24:28,470 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 700 |  Loss: (0.0057) | Acc: (99.81%) (44780/44864) | Learning rate: (1e-05)
2022-06-06 21:24:30,266 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 710 |  Loss: (0.0057) | Acc: (99.82%) (45420/45504) | Learning rate: (1e-05)
2022-06-06 21:24:32,063 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 720 |  Loss: (0.0056) | Acc: (99.82%) (46060/46144) | Learning rate: (1e-05)
2022-06-06 21:24:33,860 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 730 |  Loss: (0.0056) | Acc: (99.82%) (46699/46784) | Learning rate: (1e-05)
2022-06-06 21:24:35,656 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 740 |  Loss: (0.0056) | Acc: (99.82%) (47339/47424) | Learning rate: (1e-05)
2022-06-06 21:24:37,451 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 750 |  Loss: (0.0056) | Acc: (99.82%) (47978/48064) | Learning rate: (1e-05)
2022-06-06 21:24:39,248 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 760 |  Loss: (0.0057) | Acc: (99.81%) (48613/48704) | Learning rate: (1e-05)
2022-06-06 21:24:41,039 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 770 |  Loss: (0.0057) | Acc: (99.81%) (49252/49344) | Learning rate: (1e-05)
2022-06-06 21:24:42,828 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 780 |  Loss: (0.0056) | Acc: (99.82%) (49892/49984) | Learning rate: (1e-05)
2022-06-06 21:24:52,777 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0776) | Acc: (97.94%) (9794/10000)
2022-06-06 21:24:52,778 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:24:53,761 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 0 |  Loss: (0.0109) | Acc: (100.00%) (64/64) | Learning rate: (1e-05)
2022-06-06 21:24:55,559 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 10 |  Loss: (0.0029) | Acc: (100.00%) (704/704) | Learning rate: (1e-05)
2022-06-06 21:24:57,351 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 20 |  Loss: (0.0034) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-05)
2022-06-06 21:24:59,145 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 30 |  Loss: (0.0037) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-05)
2022-06-06 21:25:00,940 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 40 |  Loss: (0.0060) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-05)
2022-06-06 21:25:02,736 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 50 |  Loss: (0.0071) | Acc: (99.79%) (3257/3264) | Learning rate: (1e-05)
2022-06-06 21:25:04,532 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.82%) (3897/3904) | Learning rate: (1e-05)
2022-06-06 21:25:06,325 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 70 |  Loss: (0.0064) | Acc: (99.80%) (4535/4544) | Learning rate: (1e-05)
2022-06-06 21:25:08,119 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 80 |  Loss: (0.0063) | Acc: (99.81%) (5174/5184) | Learning rate: (1e-05)
2022-06-06 21:25:09,916 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 90 |  Loss: (0.0064) | Acc: (99.81%) (5813/5824) | Learning rate: (1e-05)
2022-06-06 21:25:11,710 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 100 |  Loss: (0.0064) | Acc: (99.81%) (6452/6464) | Learning rate: (1e-05)
2022-06-06 21:25:13,506 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 110 |  Loss: (0.0072) | Acc: (99.79%) (7089/7104) | Learning rate: (1e-05)
2022-06-06 21:25:15,299 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 120 |  Loss: (0.0072) | Acc: (99.78%) (7727/7744) | Learning rate: (1e-05)
2022-06-06 21:25:17,095 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 130 |  Loss: (0.0073) | Acc: (99.79%) (8366/8384) | Learning rate: (1e-05)
2022-06-06 21:25:18,892 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 140 |  Loss: (0.0069) | Acc: (99.80%) (9006/9024) | Learning rate: (1e-05)
2022-06-06 21:25:20,688 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 150 |  Loss: (0.0066) | Acc: (99.80%) (9645/9664) | Learning rate: (1e-05)
2022-06-06 21:25:22,485 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 160 |  Loss: (0.0065) | Acc: (99.81%) (10284/10304) | Learning rate: (1e-05)
2022-06-06 21:25:24,278 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 170 |  Loss: (0.0063) | Acc: (99.82%) (10924/10944) | Learning rate: (1e-05)
2022-06-06 21:25:26,072 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 180 |  Loss: (0.0067) | Acc: (99.79%) (11560/11584) | Learning rate: (1e-05)
2022-06-06 21:25:27,869 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 190 |  Loss: (0.0067) | Acc: (99.80%) (12199/12224) | Learning rate: (1e-05)
2022-06-06 21:25:29,665 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 200 |  Loss: (0.0066) | Acc: (99.80%) (12838/12864) | Learning rate: (1e-05)
2022-06-06 21:25:31,460 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 210 |  Loss: (0.0067) | Acc: (99.79%) (13475/13504) | Learning rate: (1e-05)
2022-06-06 21:25:33,255 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 220 |  Loss: (0.0066) | Acc: (99.78%) (14113/14144) | Learning rate: (1e-05)
2022-06-06 21:25:35,051 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 230 |  Loss: (0.0064) | Acc: (99.79%) (14753/14784) | Learning rate: (1e-05)
2022-06-06 21:25:36,847 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 240 |  Loss: (0.0063) | Acc: (99.79%) (15392/15424) | Learning rate: (1e-05)
2022-06-06 21:25:38,642 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 250 |  Loss: (0.0061) | Acc: (99.80%) (16032/16064) | Learning rate: (1e-05)
2022-06-06 21:25:40,438 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 260 |  Loss: (0.0060) | Acc: (99.81%) (16672/16704) | Learning rate: (1e-05)
2022-06-06 21:25:42,232 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.81%) (17311/17344) | Learning rate: (1e-05)
2022-06-06 21:25:44,026 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.81%) (17950/17984) | Learning rate: (1e-05)
2022-06-06 21:25:45,824 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 290 |  Loss: (0.0059) | Acc: (99.81%) (18589/18624) | Learning rate: (1e-05)
2022-06-06 21:25:47,619 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 300 |  Loss: (0.0058) | Acc: (99.82%) (19229/19264) | Learning rate: (1e-05)
2022-06-06 21:26:06,297 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0811) | Acc: (97.98%) (9798/10000)
2022-06-06 21:26:06,298 - CIFAR10 Classifier - INFO - Epoch time : 0:01:13
2022-06-06 21:26:07,121 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 0 |  Loss: (0.0003) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 21:26:08,925 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 10 |  Loss: (0.0017) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 21:26:10,715 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 20 |  Loss: (0.0040) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 21:26:12,500 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 30 |  Loss: (0.0041) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 21:26:14,291 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 40 |  Loss: (0.0041) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 21:26:16,079 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 50 |  Loss: (0.0039) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 21:26:17,870 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 60 |  Loss: (0.0042) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 21:26:19,660 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 70 |  Loss: (0.0051) | Acc: (99.82%) (4536/4544) | Learning rate: (1e-06)
2022-06-06 21:26:21,450 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 80 |  Loss: (0.0056) | Acc: (99.81%) (5174/5184) | Learning rate: (1e-06)
2022-06-06 21:26:23,240 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 90 |  Loss: (0.0061) | Acc: (99.81%) (5813/5824) | Learning rate: (1e-06)
2022-06-06 21:26:25,030 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 100 |  Loss: (0.0061) | Acc: (99.81%) (6452/6464) | Learning rate: (1e-06)
2022-06-06 21:26:26,825 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.83%) (7092/7104) | Learning rate: (1e-06)
2022-06-06 21:26:28,621 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.83%) (7731/7744) | Learning rate: (1e-06)
2022-06-06 21:26:30,417 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 130 |  Loss: (0.0053) | Acc: (99.84%) (8371/8384) | Learning rate: (1e-06)
2022-06-06 21:26:32,211 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.83%) (9009/9024) | Learning rate: (1e-06)
2022-06-06 21:26:34,008 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.83%) (9648/9664) | Learning rate: (1e-06)
2022-06-06 21:26:35,807 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 21:26:37,606 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.85%) (10928/10944) | Learning rate: (1e-06)
2022-06-06 21:26:39,407 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.85%) (11567/11584) | Learning rate: (1e-06)
2022-06-06 21:26:41,206 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.86%) (12207/12224) | Learning rate: (1e-06)
2022-06-06 21:26:43,002 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 200 |  Loss: (0.0052) | Acc: (99.86%) (12846/12864) | Learning rate: (1e-06)
2022-06-06 21:26:44,801 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 210 |  Loss: (0.0052) | Acc: (99.86%) (13485/13504) | Learning rate: (1e-06)
2022-06-06 21:26:46,598 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 220 |  Loss: (0.0058) | Acc: (99.84%) (14121/14144) | Learning rate: (1e-06)
2022-06-06 21:26:48,395 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.84%) (14760/14784) | Learning rate: (1e-06)
2022-06-06 21:26:50,191 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 240 |  Loss: (0.0057) | Acc: (99.84%) (15399/15424) | Learning rate: (1e-06)
2022-06-06 21:26:51,986 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 250 |  Loss: (0.0060) | Acc: (99.83%) (16037/16064) | Learning rate: (1e-06)
2022-06-06 21:26:53,782 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.84%) (16677/16704) | Learning rate: (1e-06)
2022-06-06 21:26:55,580 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 270 |  Loss: (0.0058) | Acc: (99.84%) (17316/17344) | Learning rate: (1e-06)
2022-06-06 21:26:57,377 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 280 |  Loss: (0.0058) | Acc: (99.84%) (17955/17984) | Learning rate: (1e-06)
2022-06-06 21:26:59,174 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 290 |  Loss: (0.0058) | Acc: (99.84%) (18594/18624) | Learning rate: (1e-06)
2022-06-06 21:27:00,972 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 300 |  Loss: (0.0059) | Acc: (99.83%) (19232/19264) | Learning rate: (1e-06)
2022-06-06 21:27:02,771 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 310 |  Loss: (0.0060) | Acc: (99.83%) (19871/19904) | Learning rate: (1e-06)
2022-06-06 21:27:04,567 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 320 |  Loss: (0.0063) | Acc: (99.83%) (20509/20544) | Learning rate: (1e-06)
2022-06-06 21:27:06,362 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 330 |  Loss: (0.0062) | Acc: (99.83%) (21148/21184) | Learning rate: (1e-06)
2022-06-06 21:27:08,159 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 340 |  Loss: (0.0061) | Acc: (99.84%) (21788/21824) | Learning rate: (1e-06)
2022-06-06 21:27:09,957 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 350 |  Loss: (0.0061) | Acc: (99.84%) (22428/22464) | Learning rate: (1e-06)
2022-06-06 21:27:11,756 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 360 |  Loss: (0.0061) | Acc: (99.84%) (23067/23104) | Learning rate: (1e-06)
2022-06-06 21:27:13,556 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 370 |  Loss: (0.0061) | Acc: (99.84%) (23706/23744) | Learning rate: (1e-06)
2022-06-06 21:27:15,355 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 380 |  Loss: (0.0060) | Acc: (99.84%) (24346/24384) | Learning rate: (1e-06)
2022-06-06 21:27:17,154 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 390 |  Loss: (0.0060) | Acc: (99.84%) (24984/25024) | Learning rate: (1e-06)
2022-06-06 21:27:18,954 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 400 |  Loss: (0.0061) | Acc: (99.84%) (25622/25664) | Learning rate: (1e-06)
2022-06-06 21:27:20,754 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 410 |  Loss: (0.0060) | Acc: (99.84%) (26261/26304) | Learning rate: (1e-06)
2022-06-06 21:27:22,553 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 420 |  Loss: (0.0061) | Acc: (99.84%) (26900/26944) | Learning rate: (1e-06)
2022-06-06 21:27:24,352 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 430 |  Loss: (0.0060) | Acc: (99.84%) (27539/27584) | Learning rate: (1e-06)
2022-06-06 21:27:26,151 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 440 |  Loss: (0.0061) | Acc: (99.83%) (28177/28224) | Learning rate: (1e-06)
2022-06-06 21:27:27,950 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 450 |  Loss: (0.0062) | Acc: (99.83%) (28816/28864) | Learning rate: (1e-06)
2022-06-06 21:27:29,751 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 460 |  Loss: (0.0062) | Acc: (99.84%) (29456/29504) | Learning rate: (1e-06)
2022-06-06 21:27:31,550 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 470 |  Loss: (0.0061) | Acc: (99.84%) (30095/30144) | Learning rate: (1e-06)
2022-06-06 21:27:33,350 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 480 |  Loss: (0.0061) | Acc: (99.84%) (30734/30784) | Learning rate: (1e-06)
2022-06-06 21:27:35,149 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 490 |  Loss: (0.0061) | Acc: (99.84%) (31373/31424) | Learning rate: (1e-06)
2022-06-06 21:27:36,948 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 500 |  Loss: (0.0060) | Acc: (99.84%) (32013/32064) | Learning rate: (1e-06)
2022-06-06 21:27:38,748 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 510 |  Loss: (0.0059) | Acc: (99.84%) (32653/32704) | Learning rate: (1e-06)
2022-06-06 21:27:40,546 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 520 |  Loss: (0.0058) | Acc: (99.85%) (33293/33344) | Learning rate: (1e-06)
2022-06-06 21:27:42,347 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 530 |  Loss: (0.0058) | Acc: (99.85%) (33932/33984) | Learning rate: (1e-06)
2022-06-06 21:27:44,146 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 540 |  Loss: (0.0058) | Acc: (99.85%) (34571/34624) | Learning rate: (1e-06)
2022-06-06 21:27:45,945 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 550 |  Loss: (0.0059) | Acc: (99.84%) (35209/35264) | Learning rate: (1e-06)
2022-06-06 21:27:47,744 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 560 |  Loss: (0.0058) | Acc: (99.85%) (35849/35904) | Learning rate: (1e-06)
2022-06-06 21:27:49,544 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 570 |  Loss: (0.0057) | Acc: (99.85%) (36489/36544) | Learning rate: (1e-06)
2022-06-06 21:27:51,343 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 580 |  Loss: (0.0057) | Acc: (99.85%) (37128/37184) | Learning rate: (1e-06)
2022-06-06 21:27:53,142 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 590 |  Loss: (0.0057) | Acc: (99.85%) (37766/37824) | Learning rate: (1e-06)
2022-06-06 21:27:54,942 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 600 |  Loss: (0.0057) | Acc: (99.84%) (38404/38464) | Learning rate: (1e-06)
2022-06-06 21:27:56,742 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 610 |  Loss: (0.0057) | Acc: (99.84%) (39043/39104) | Learning rate: (1e-06)
2022-06-06 21:27:58,541 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 620 |  Loss: (0.0058) | Acc: (99.84%) (39682/39744) | Learning rate: (1e-06)
2022-06-06 21:28:00,340 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 630 |  Loss: (0.0058) | Acc: (99.85%) (40322/40384) | Learning rate: (1e-06)
2022-06-06 21:28:02,140 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 640 |  Loss: (0.0057) | Acc: (99.85%) (40962/41024) | Learning rate: (1e-06)
2022-06-06 21:28:03,939 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 650 |  Loss: (0.0057) | Acc: (99.85%) (41602/41664) | Learning rate: (1e-06)
2022-06-06 21:28:05,738 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 660 |  Loss: (0.0057) | Acc: (99.85%) (42240/42304) | Learning rate: (1e-06)
2022-06-06 21:28:07,538 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 670 |  Loss: (0.0056) | Acc: (99.85%) (42879/42944) | Learning rate: (1e-06)
2022-06-06 21:28:09,337 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 680 |  Loss: (0.0057) | Acc: (99.85%) (43518/43584) | Learning rate: (1e-06)
2022-06-06 21:28:11,137 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 690 |  Loss: (0.0057) | Acc: (99.85%) (44156/44224) | Learning rate: (1e-06)
2022-06-06 21:28:12,936 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 700 |  Loss: (0.0058) | Acc: (99.84%) (44793/44864) | Learning rate: (1e-06)
2022-06-06 21:28:14,736 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 710 |  Loss: (0.0059) | Acc: (99.84%) (45431/45504) | Learning rate: (1e-06)
2022-06-06 21:28:16,535 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 720 |  Loss: (0.0059) | Acc: (99.84%) (46068/46144) | Learning rate: (1e-06)
2022-06-06 21:28:18,335 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 730 |  Loss: (0.0059) | Acc: (99.84%) (46708/46784) | Learning rate: (1e-06)
2022-06-06 21:28:20,134 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 740 |  Loss: (0.0058) | Acc: (99.84%) (47347/47424) | Learning rate: (1e-06)
2022-06-06 21:28:21,932 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 750 |  Loss: (0.0059) | Acc: (99.84%) (47985/48064) | Learning rate: (1e-06)
2022-06-06 21:28:23,732 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 760 |  Loss: (0.0059) | Acc: (99.83%) (48623/48704) | Learning rate: (1e-06)
2022-06-06 21:28:25,524 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 770 |  Loss: (0.0061) | Acc: (99.82%) (49257/49344) | Learning rate: (1e-06)
2022-06-06 21:28:27,314 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 780 |  Loss: (0.0061) | Acc: (99.82%) (49896/49984) | Learning rate: (1e-06)
2022-06-06 21:28:37,278 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0812) | Acc: (97.86%) (9786/10000)
2022-06-06 21:28:37,279 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:28:38,121 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 0 |  Loss: (0.0034) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 21:28:39,916 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 10 |  Loss: (0.0095) | Acc: (99.43%) (700/704) | Learning rate: (1e-06)
2022-06-06 21:28:41,708 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 20 |  Loss: (0.0073) | Acc: (99.63%) (1339/1344) | Learning rate: (1e-06)
2022-06-06 21:28:43,499 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 30 |  Loss: (0.0059) | Acc: (99.75%) (1979/1984) | Learning rate: (1e-06)
2022-06-06 21:28:45,294 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-06)
2022-06-06 21:28:47,087 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 50 |  Loss: (0.0049) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-06)
2022-06-06 21:28:48,882 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 60 |  Loss: (0.0044) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-06)
2022-06-06 21:28:50,677 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 70 |  Loss: (0.0046) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-06)
2022-06-06 21:28:52,472 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 80 |  Loss: (0.0048) | Acc: (99.85%) (5176/5184) | Learning rate: (1e-06)
2022-06-06 21:28:54,265 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 90 |  Loss: (0.0046) | Acc: (99.86%) (5816/5824) | Learning rate: (1e-06)
2022-06-06 21:28:56,061 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 100 |  Loss: (0.0052) | Acc: (99.85%) (6454/6464) | Learning rate: (1e-06)
2022-06-06 21:28:57,857 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 110 |  Loss: (0.0053) | Acc: (99.85%) (7093/7104) | Learning rate: (1e-06)
2022-06-06 21:28:59,652 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 120 |  Loss: (0.0053) | Acc: (99.85%) (7732/7744) | Learning rate: (1e-06)
2022-06-06 21:29:01,446 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.86%) (8372/8384) | Learning rate: (1e-06)
2022-06-06 21:29:03,240 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 140 |  Loss: (0.0051) | Acc: (99.86%) (9011/9024) | Learning rate: (1e-06)
2022-06-06 21:29:05,036 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.84%) (9649/9664) | Learning rate: (1e-06)
2022-06-06 21:29:06,831 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 160 |  Loss: (0.0055) | Acc: (99.83%) (10286/10304) | Learning rate: (1e-06)
2022-06-06 21:29:08,627 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.83%) (10925/10944) | Learning rate: (1e-06)
2022-06-06 21:29:10,421 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 180 |  Loss: (0.0056) | Acc: (99.83%) (11564/11584) | Learning rate: (1e-06)
2022-06-06 21:29:12,216 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 190 |  Loss: (0.0054) | Acc: (99.84%) (12204/12224) | Learning rate: (1e-06)
2022-06-06 21:29:14,013 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 200 |  Loss: (0.0054) | Acc: (99.84%) (12843/12864) | Learning rate: (1e-06)
2022-06-06 21:29:15,808 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 210 |  Loss: (0.0052) | Acc: (99.84%) (13483/13504) | Learning rate: (1e-06)
2022-06-06 21:29:17,603 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 220 |  Loss: (0.0050) | Acc: (99.85%) (14123/14144) | Learning rate: (1e-06)
2022-06-06 21:29:19,398 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.85%) (14762/14784) | Learning rate: (1e-06)
2022-06-06 21:29:21,192 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 240 |  Loss: (0.0053) | Acc: (99.84%) (15400/15424) | Learning rate: (1e-06)
2022-06-06 21:29:22,989 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 250 |  Loss: (0.0052) | Acc: (99.85%) (16040/16064) | Learning rate: (1e-06)
2022-06-06 21:29:24,786 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.84%) (16678/16704) | Learning rate: (1e-06)
2022-06-06 21:29:26,581 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 270 |  Loss: (0.0054) | Acc: (99.84%) (17317/17344) | Learning rate: (1e-06)
2022-06-06 21:29:28,375 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.84%) (17955/17984) | Learning rate: (1e-06)
2022-06-06 21:29:30,170 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.84%) (18595/18624) | Learning rate: (1e-06)
2022-06-06 21:29:31,966 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 300 |  Loss: (0.0053) | Acc: (99.84%) (19234/19264) | Learning rate: (1e-06)
2022-06-06 21:29:33,762 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 310 |  Loss: (0.0054) | Acc: (99.83%) (19871/19904) | Learning rate: (1e-06)
2022-06-06 21:29:35,558 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 320 |  Loss: (0.0054) | Acc: (99.83%) (20509/20544) | Learning rate: (1e-06)
2022-06-06 21:29:37,352 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 330 |  Loss: (0.0053) | Acc: (99.83%) (21149/21184) | Learning rate: (1e-06)
2022-06-06 21:29:39,147 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 340 |  Loss: (0.0055) | Acc: (99.84%) (21788/21824) | Learning rate: (1e-06)
2022-06-06 21:29:40,944 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 350 |  Loss: (0.0054) | Acc: (99.84%) (22427/22464) | Learning rate: (1e-06)
2022-06-06 21:29:42,739 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.83%) (23065/23104) | Learning rate: (1e-06)
2022-06-06 21:29:44,536 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.83%) (23704/23744) | Learning rate: (1e-06)
2022-06-06 21:29:46,330 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.83%) (24342/24384) | Learning rate: (1e-06)
2022-06-06 21:29:48,124 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.83%) (24981/25024) | Learning rate: (1e-06)
2022-06-06 21:29:49,921 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 400 |  Loss: (0.0054) | Acc: (99.82%) (25619/25664) | Learning rate: (1e-06)
2022-06-06 21:29:51,717 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 410 |  Loss: (0.0055) | Acc: (99.83%) (26258/26304) | Learning rate: (1e-06)
2022-06-06 21:29:53,514 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 420 |  Loss: (0.0055) | Acc: (99.83%) (26898/26944) | Learning rate: (1e-06)
2022-06-06 21:29:55,309 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 430 |  Loss: (0.0054) | Acc: (99.83%) (27536/27584) | Learning rate: (1e-06)
2022-06-06 21:29:57,105 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 440 |  Loss: (0.0055) | Acc: (99.83%) (28175/28224) | Learning rate: (1e-06)
2022-06-06 21:29:58,902 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 450 |  Loss: (0.0056) | Acc: (99.82%) (28813/28864) | Learning rate: (1e-06)
2022-06-06 21:30:00,699 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 460 |  Loss: (0.0055) | Acc: (99.82%) (29452/29504) | Learning rate: (1e-06)
2022-06-06 21:30:02,496 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 470 |  Loss: (0.0055) | Acc: (99.82%) (30091/30144) | Learning rate: (1e-06)
2022-06-06 21:30:04,293 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 480 |  Loss: (0.0055) | Acc: (99.82%) (30730/30784) | Learning rate: (1e-06)
2022-06-06 21:30:06,089 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 490 |  Loss: (0.0055) | Acc: (99.82%) (31368/31424) | Learning rate: (1e-06)
2022-06-06 21:30:07,883 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 500 |  Loss: (0.0056) | Acc: (99.82%) (32007/32064) | Learning rate: (1e-06)
2022-06-06 21:30:09,679 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 510 |  Loss: (0.0056) | Acc: (99.82%) (32646/32704) | Learning rate: (1e-06)
2022-06-06 21:30:11,476 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 520 |  Loss: (0.0055) | Acc: (99.83%) (33286/33344) | Learning rate: (1e-06)
2022-06-06 21:30:13,274 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 530 |  Loss: (0.0054) | Acc: (99.83%) (33926/33984) | Learning rate: (1e-06)
2022-06-06 21:30:15,072 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 540 |  Loss: (0.0054) | Acc: (99.83%) (34566/34624) | Learning rate: (1e-06)
2022-06-06 21:30:16,868 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 550 |  Loss: (0.0053) | Acc: (99.84%) (35206/35264) | Learning rate: (1e-06)
2022-06-06 21:30:18,664 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 560 |  Loss: (0.0053) | Acc: (99.84%) (35845/35904) | Learning rate: (1e-06)
2022-06-06 21:30:20,459 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 570 |  Loss: (0.0053) | Acc: (99.84%) (36485/36544) | Learning rate: (1e-06)
2022-06-06 21:30:22,255 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 580 |  Loss: (0.0052) | Acc: (99.84%) (37125/37184) | Learning rate: (1e-06)
2022-06-06 21:30:24,053 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 590 |  Loss: (0.0051) | Acc: (99.84%) (37765/37824) | Learning rate: (1e-06)
2022-06-06 21:30:25,851 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 600 |  Loss: (0.0051) | Acc: (99.85%) (38405/38464) | Learning rate: (1e-06)
2022-06-06 21:30:27,651 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 610 |  Loss: (0.0051) | Acc: (99.85%) (39044/39104) | Learning rate: (1e-06)
2022-06-06 21:30:29,450 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 620 |  Loss: (0.0051) | Acc: (99.85%) (39683/39744) | Learning rate: (1e-06)
2022-06-06 21:30:31,249 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 630 |  Loss: (0.0050) | Acc: (99.85%) (40323/40384) | Learning rate: (1e-06)
2022-06-06 21:30:33,047 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 640 |  Loss: (0.0050) | Acc: (99.85%) (40963/41024) | Learning rate: (1e-06)
2022-06-06 21:30:34,848 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 650 |  Loss: (0.0051) | Acc: (99.85%) (41600/41664) | Learning rate: (1e-06)
2022-06-06 21:30:36,647 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 660 |  Loss: (0.0050) | Acc: (99.85%) (42240/42304) | Learning rate: (1e-06)
2022-06-06 21:30:38,447 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 670 |  Loss: (0.0051) | Acc: (99.85%) (42879/42944) | Learning rate: (1e-06)
2022-06-06 21:30:40,245 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 680 |  Loss: (0.0051) | Acc: (99.85%) (43518/43584) | Learning rate: (1e-06)
2022-06-06 21:30:42,043 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 690 |  Loss: (0.0052) | Acc: (99.85%) (44156/44224) | Learning rate: (1e-06)
2022-06-06 21:30:43,843 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 700 |  Loss: (0.0051) | Acc: (99.85%) (44796/44864) | Learning rate: (1e-06)
2022-06-06 21:30:45,641 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 710 |  Loss: (0.0051) | Acc: (99.85%) (45434/45504) | Learning rate: (1e-06)
2022-06-06 21:30:47,438 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 720 |  Loss: (0.0052) | Acc: (99.84%) (46072/46144) | Learning rate: (1e-06)
2022-06-06 21:30:49,236 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 730 |  Loss: (0.0052) | Acc: (99.84%) (46711/46784) | Learning rate: (1e-06)
2022-06-06 21:30:51,035 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 740 |  Loss: (0.0052) | Acc: (99.85%) (47351/47424) | Learning rate: (1e-06)
2022-06-06 21:30:52,834 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 750 |  Loss: (0.0052) | Acc: (99.85%) (47990/48064) | Learning rate: (1e-06)
2022-06-06 21:30:54,631 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 760 |  Loss: (0.0051) | Acc: (99.85%) (48630/48704) | Learning rate: (1e-06)
2022-06-06 21:30:56,421 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 770 |  Loss: (0.0052) | Acc: (99.84%) (49267/49344) | Learning rate: (1e-06)
2022-06-06 21:30:58,211 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 780 |  Loss: (0.0051) | Acc: (99.85%) (49907/49984) | Learning rate: (1e-06)
2022-06-06 21:31:08,211 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0804) | Acc: (98.06%) (9806/10000)
2022-06-06 21:31:08,212 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:31:09,010 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 0 |  Loss: (0.0014) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 21:31:10,836 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 10 |  Loss: (0.0041) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 21:31:12,631 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 20 |  Loss: (0.0026) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 21:31:14,423 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 30 |  Loss: (0.0022) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 21:31:16,217 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 40 |  Loss: (0.0023) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 21:31:18,012 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 50 |  Loss: (0.0023) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-06)
2022-06-06 21:31:19,808 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 60 |  Loss: (0.0036) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 21:31:21,603 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 70 |  Loss: (0.0036) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 21:31:23,398 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 80 |  Loss: (0.0041) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 21:31:25,193 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 90 |  Loss: (0.0046) | Acc: (99.88%) (5817/5824) | Learning rate: (1e-06)
2022-06-06 21:31:26,991 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.88%) (6456/6464) | Learning rate: (1e-06)
2022-06-06 21:31:28,788 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 110 |  Loss: (0.0049) | Acc: (99.86%) (7094/7104) | Learning rate: (1e-06)
2022-06-06 21:31:30,584 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 120 |  Loss: (0.0053) | Acc: (99.83%) (7731/7744) | Learning rate: (1e-06)
2022-06-06 21:31:32,381 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 130 |  Loss: (0.0057) | Acc: (99.82%) (8369/8384) | Learning rate: (1e-06)
2022-06-06 21:31:34,176 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.83%) (9009/9024) | Learning rate: (1e-06)
2022-06-06 21:31:35,971 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 150 |  Loss: (0.0056) | Acc: (99.82%) (9647/9664) | Learning rate: (1e-06)
2022-06-06 21:31:37,767 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.84%) (10287/10304) | Learning rate: (1e-06)
2022-06-06 21:31:39,563 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.84%) (10926/10944) | Learning rate: (1e-06)
2022-06-06 21:31:41,361 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.84%) (11566/11584) | Learning rate: (1e-06)
2022-06-06 21:31:43,157 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.85%) (12206/12224) | Learning rate: (1e-06)
2022-06-06 21:31:44,954 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 200 |  Loss: (0.0050) | Acc: (99.86%) (12846/12864) | Learning rate: (1e-06)
2022-06-06 21:31:46,751 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.85%) (13484/13504) | Learning rate: (1e-06)
2022-06-06 21:31:48,547 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 220 |  Loss: (0.0050) | Acc: (99.86%) (14124/14144) | Learning rate: (1e-06)
2022-06-06 21:31:50,343 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 230 |  Loss: (0.0050) | Acc: (99.86%) (14763/14784) | Learning rate: (1e-06)
2022-06-06 21:31:52,139 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.86%) (15402/15424) | Learning rate: (1e-06)
2022-06-06 21:31:53,936 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 250 |  Loss: (0.0051) | Acc: (99.86%) (16042/16064) | Learning rate: (1e-06)
2022-06-06 21:31:55,733 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 260 |  Loss: (0.0050) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-06)
2022-06-06 21:31:57,528 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 270 |  Loss: (0.0049) | Acc: (99.86%) (17320/17344) | Learning rate: (1e-06)
2022-06-06 21:31:59,323 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.86%) (17959/17984) | Learning rate: (1e-06)
2022-06-06 21:32:01,119 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 290 |  Loss: (0.0050) | Acc: (99.86%) (18598/18624) | Learning rate: (1e-06)
2022-06-06 21:32:02,915 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 300 |  Loss: (0.0052) | Acc: (99.86%) (19237/19264) | Learning rate: (1e-06)
2022-06-06 21:32:04,711 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.86%) (19876/19904) | Learning rate: (1e-06)
2022-06-06 21:32:06,509 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.85%) (20514/20544) | Learning rate: (1e-06)
2022-06-06 21:32:08,305 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 330 |  Loss: (0.0056) | Acc: (99.84%) (21150/21184) | Learning rate: (1e-06)
2022-06-06 21:32:10,101 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 340 |  Loss: (0.0058) | Acc: (99.84%) (21789/21824) | Learning rate: (1e-06)
2022-06-06 21:32:11,897 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 350 |  Loss: (0.0058) | Acc: (99.84%) (22428/22464) | Learning rate: (1e-06)
2022-06-06 21:32:13,696 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 360 |  Loss: (0.0058) | Acc: (99.84%) (23066/23104) | Learning rate: (1e-06)
2022-06-06 21:32:15,493 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 370 |  Loss: (0.0058) | Acc: (99.83%) (23704/23744) | Learning rate: (1e-06)
2022-06-06 21:32:17,289 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 380 |  Loss: (0.0059) | Acc: (99.83%) (24342/24384) | Learning rate: (1e-06)
2022-06-06 21:32:19,088 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 390 |  Loss: (0.0058) | Acc: (99.83%) (24981/25024) | Learning rate: (1e-06)
2022-06-06 21:32:20,884 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 400 |  Loss: (0.0058) | Acc: (99.83%) (25620/25664) | Learning rate: (1e-06)
2022-06-06 21:32:22,679 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 410 |  Loss: (0.0058) | Acc: (99.83%) (26260/26304) | Learning rate: (1e-06)
2022-06-06 21:32:24,475 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 420 |  Loss: (0.0057) | Acc: (99.83%) (26899/26944) | Learning rate: (1e-06)
2022-06-06 21:32:26,272 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 430 |  Loss: (0.0058) | Acc: (99.83%) (27537/27584) | Learning rate: (1e-06)
2022-06-06 21:32:28,069 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 440 |  Loss: (0.0057) | Acc: (99.83%) (28177/28224) | Learning rate: (1e-06)
2022-06-06 21:32:29,867 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 450 |  Loss: (0.0057) | Acc: (99.83%) (28815/28864) | Learning rate: (1e-06)
2022-06-06 21:32:31,665 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 460 |  Loss: (0.0056) | Acc: (99.83%) (29454/29504) | Learning rate: (1e-06)
2022-06-06 21:32:33,462 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 470 |  Loss: (0.0056) | Acc: (99.83%) (30093/30144) | Learning rate: (1e-06)
2022-06-06 21:32:35,259 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 480 |  Loss: (0.0056) | Acc: (99.83%) (30733/30784) | Learning rate: (1e-06)
2022-06-06 21:32:37,054 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 490 |  Loss: (0.0055) | Acc: (99.84%) (31373/31424) | Learning rate: (1e-06)
2022-06-06 21:32:57,780 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0800) | Acc: (98.03%) (9803/10000)
2022-06-06 21:32:57,781 - CIFAR10 Classifier - INFO - Epoch time : 0:01:49
2022-06-06 21:32:58,624 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 0 |  Loss: (0.0019) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-06 21:33:00,427 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 10 |  Loss: (0.0017) | Acc: (100.00%) (704/704) | Learning rate: (1e-07)
2022-06-06 21:33:02,214 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-07)
2022-06-06 21:33:04,000 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 30 |  Loss: (0.0066) | Acc: (99.75%) (1979/1984) | Learning rate: (1e-07)
2022-06-06 21:33:05,788 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 40 |  Loss: (0.0051) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-07)

2022-06-06 21:36:02,866 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 21:36:02,868 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 21:36:02,869 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 21:36:02,869 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 21:36:02,869 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 21:36:04,137 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (128/128) | Learning rate: (1e-06)
2022-06-06 21:36:06,271 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (0.0026) | Acc: (99.93%) (1407/1408) | Learning rate: (1e-06)
2022-06-06 21:36:08,400 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (0.0021) | Acc: (99.96%) (2687/2688) | Learning rate: (1e-06)
2022-06-06 21:36:10,525 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (0.0027) | Acc: (99.92%) (3965/3968) | Learning rate: (1e-06)
2022-06-06 21:36:12,656 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (0.0026) | Acc: (99.92%) (5244/5248) | Learning rate: (1e-06)
2022-06-06 21:36:14,788 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 50 |  Loss: (0.0025) | Acc: (99.94%) (6524/6528) | Learning rate: (1e-06)
2022-06-06 21:36:16,921 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 60 |  Loss: (0.0025) | Acc: (99.94%) (7803/7808) | Learning rate: (1e-06)
2022-06-06 21:36:19,056 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 70 |  Loss: (0.0026) | Acc: (99.92%) (9081/9088) | Learning rate: (1e-06)
2022-06-06 21:36:21,192 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 80 |  Loss: (0.0025) | Acc: (99.93%) (10361/10368) | Learning rate: (1e-06)
2022-06-06 21:36:23,331 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 90 |  Loss: (0.0034) | Acc: (99.91%) (11637/11648) | Learning rate: (1e-06)
2022-06-06 21:36:25,471 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 100 |  Loss: (0.0033) | Acc: (99.91%) (12916/12928) | Learning rate: (1e-06)
2022-06-06 21:36:27,610 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 110 |  Loss: (0.0032) | Acc: (99.91%) (14195/14208) | Learning rate: (1e-06)
2022-06-06 21:36:29,751 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 120 |  Loss: (0.0032) | Acc: (99.91%) (15474/15488) | Learning rate: (1e-06)
2022-06-06 21:36:31,891 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 130 |  Loss: (0.0034) | Acc: (99.91%) (16753/16768) | Learning rate: (1e-06)
2022-06-06 21:36:34,033 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 140 |  Loss: (0.0034) | Acc: (99.91%) (18032/18048) | Learning rate: (1e-06)
2022-06-06 21:36:36,175 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 150 |  Loss: (0.0033) | Acc: (99.92%) (19312/19328) | Learning rate: (1e-06)
2022-06-06 21:36:38,319 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 160 |  Loss: (0.0033) | Acc: (99.90%) (20588/20608) | Learning rate: (1e-06)
2022-06-06 21:36:40,463 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 170 |  Loss: (0.0032) | Acc: (99.91%) (21868/21888) | Learning rate: (1e-06)
2022-06-06 21:36:42,607 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 180 |  Loss: (0.0032) | Acc: (99.91%) (23147/23168) | Learning rate: (1e-06)
2022-06-06 21:36:44,751 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 190 |  Loss: (0.0030) | Acc: (99.91%) (24427/24448) | Learning rate: (1e-06)
2022-06-06 21:36:46,899 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 200 |  Loss: (0.0030) | Acc: (99.91%) (25706/25728) | Learning rate: (1e-06)
2022-06-06 21:36:49,045 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 210 |  Loss: (0.0029) | Acc: (99.92%) (26986/27008) | Learning rate: (1e-06)
2022-06-06 21:36:51,192 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 220 |  Loss: (0.0028) | Acc: (99.92%) (28266/28288) | Learning rate: (1e-06)
2022-06-06 21:36:53,342 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 230 |  Loss: (0.0028) | Acc: (99.93%) (29546/29568) | Learning rate: (1e-06)
2022-06-06 21:36:55,490 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 240 |  Loss: (0.0028) | Acc: (99.93%) (30825/30848) | Learning rate: (1e-06)
2022-06-06 21:36:57,641 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 250 |  Loss: (0.0028) | Acc: (99.92%) (32103/32128) | Learning rate: (1e-06)
2022-06-06 21:36:59,790 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 260 |  Loss: (0.0028) | Acc: (99.92%) (33381/33408) | Learning rate: (1e-06)
2022-06-06 21:37:01,943 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 270 |  Loss: (0.0028) | Acc: (99.92%) (34660/34688) | Learning rate: (1e-06)
2022-06-06 21:37:04,096 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 280 |  Loss: (0.0029) | Acc: (99.92%) (35938/35968) | Learning rate: (1e-06)
2022-06-06 21:37:06,251 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 290 |  Loss: (0.0029) | Acc: (99.92%) (37217/37248) | Learning rate: (1e-06)
2022-06-06 21:37:08,407 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 300 |  Loss: (0.0030) | Acc: (99.91%) (38495/38528) | Learning rate: (1e-06)
2022-06-06 21:37:10,563 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 310 |  Loss: (0.0031) | Acc: (99.92%) (39775/39808) | Learning rate: (1e-06)
2022-06-06 21:37:12,720 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 320 |  Loss: (0.0032) | Acc: (99.91%) (41053/41088) | Learning rate: (1e-06)
2022-06-06 21:37:14,876 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 330 |  Loss: (0.0032) | Acc: (99.92%) (42332/42368) | Learning rate: (1e-06)
2022-06-06 21:37:17,032 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 340 |  Loss: (0.0032) | Acc: (99.92%) (43611/43648) | Learning rate: (1e-06)
2022-06-06 21:37:19,191 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 350 |  Loss: (0.0031) | Acc: (99.92%) (44890/44928) | Learning rate: (1e-06)
2022-06-06 21:37:21,349 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 360 |  Loss: (0.0031) | Acc: (99.92%) (46169/46208) | Learning rate: (1e-06)
2022-06-06 21:37:23,503 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 370 |  Loss: (0.0031) | Acc: (99.92%) (47449/47488) | Learning rate: (1e-06)
2022-06-06 21:37:25,649 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 380 |  Loss: (0.0031) | Acc: (99.92%) (48729/48768) | Learning rate: (1e-06)
2022-06-06 21:37:27,716 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 390 |  Loss: (0.0031) | Acc: (99.92%) (49960/50000) | Learning rate: (1e-06)
2022-06-06 21:37:36,839 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0758) | Acc: (98.01%) (9801/10000)
2022-06-06 21:37:36,839 - CIFAR10 Classifier - INFO - Epoch time : 0:01:33
2022-06-06 21:37:38,061 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 0 |  Loss: (0.0003) | Acc: (100.00%) (128/128) | Learning rate: (1e-06)
2022-06-06 21:37:40,261 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 10 |  Loss: (0.0019) | Acc: (99.93%) (1407/1408) | Learning rate: (1e-06)
2022-06-06 21:37:42,418 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 20 |  Loss: (0.0016) | Acc: (99.96%) (2687/2688) | Learning rate: (1e-06)
2022-06-06 21:37:44,574 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 30 |  Loss: (0.0025) | Acc: (99.92%) (3965/3968) | Learning rate: (1e-06)
2022-06-06 21:37:46,733 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 40 |  Loss: (0.0021) | Acc: (99.94%) (5245/5248) | Learning rate: (1e-06)
2022-06-06 21:37:48,891 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 50 |  Loss: (0.0020) | Acc: (99.95%) (6525/6528) | Learning rate: (1e-06)
2022-06-06 21:37:51,052 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 60 |  Loss: (0.0023) | Acc: (99.95%) (7804/7808) | Learning rate: (1e-06)
2022-06-06 21:37:53,211 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 70 |  Loss: (0.0028) | Acc: (99.94%) (9083/9088) | Learning rate: (1e-06)
2022-06-06 21:37:55,372 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 80 |  Loss: (0.0029) | Acc: (99.94%) (10362/10368) | Learning rate: (1e-06)
2022-06-06 21:37:57,533 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 90 |  Loss: (0.0029) | Acc: (99.94%) (11641/11648) | Learning rate: (1e-06)
2022-06-06 21:37:59,693 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 100 |  Loss: (0.0028) | Acc: (99.94%) (12920/12928) | Learning rate: (1e-06)
2022-06-06 21:38:01,853 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 110 |  Loss: (0.0030) | Acc: (99.94%) (14199/14208) | Learning rate: (1e-06)
2022-06-06 21:38:04,016 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 120 |  Loss: (0.0030) | Acc: (99.94%) (15478/15488) | Learning rate: (1e-06)
2022-06-06 21:38:06,177 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 130 |  Loss: (0.0030) | Acc: (99.93%) (16757/16768) | Learning rate: (1e-06)
2022-06-06 21:38:08,343 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 140 |  Loss: (0.0031) | Acc: (99.93%) (18035/18048) | Learning rate: (1e-06)
2022-06-06 21:38:10,503 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 150 |  Loss: (0.0034) | Acc: (99.92%) (19313/19328) | Learning rate: (1e-06)
2022-06-06 21:38:12,665 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 160 |  Loss: (0.0033) | Acc: (99.92%) (20592/20608) | Learning rate: (1e-06)
2022-06-06 21:38:14,826 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 170 |  Loss: (0.0032) | Acc: (99.93%) (21872/21888) | Learning rate: (1e-06)
2022-06-06 21:38:16,989 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 180 |  Loss: (0.0034) | Acc: (99.92%) (23150/23168) | Learning rate: (1e-06)
2022-06-06 21:38:19,152 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 190 |  Loss: (0.0034) | Acc: (99.92%) (24428/24448) | Learning rate: (1e-06)
2022-06-06 21:38:21,313 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 200 |  Loss: (0.0033) | Acc: (99.92%) (25708/25728) | Learning rate: (1e-06)
2022-06-06 21:38:23,475 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 210 |  Loss: (0.0033) | Acc: (99.92%) (26986/27008) | Learning rate: (1e-06)
2022-06-06 21:38:25,637 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 220 |  Loss: (0.0033) | Acc: (99.92%) (28265/28288) | Learning rate: (1e-06)
2022-06-06 21:38:27,801 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 230 |  Loss: (0.0033) | Acc: (99.92%) (29545/29568) | Learning rate: (1e-06)
2022-06-06 21:38:29,964 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 240 |  Loss: (0.0032) | Acc: (99.93%) (30825/30848) | Learning rate: (1e-06)
2022-06-06 21:38:32,126 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 250 |  Loss: (0.0031) | Acc: (99.93%) (32104/32128) | Learning rate: (1e-06)
2022-06-06 21:38:34,287 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 260 |  Loss: (0.0031) | Acc: (99.92%) (33382/33408) | Learning rate: (1e-06)
2022-06-06 21:38:36,450 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 270 |  Loss: (0.0033) | Acc: (99.92%) (34661/34688) | Learning rate: (1e-06)
2022-06-06 21:38:38,614 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 280 |  Loss: (0.0032) | Acc: (99.92%) (35940/35968) | Learning rate: (1e-06)
2022-06-06 21:38:40,776 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 290 |  Loss: (0.0033) | Acc: (99.92%) (37218/37248) | Learning rate: (1e-06)
2022-06-06 21:38:42,940 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 300 |  Loss: (0.0032) | Acc: (99.92%) (38497/38528) | Learning rate: (1e-06)
2022-06-06 21:38:45,103 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 310 |  Loss: (0.0032) | Acc: (99.92%) (39777/39808) | Learning rate: (1e-06)
2022-06-06 21:38:47,266 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 320 |  Loss: (0.0031) | Acc: (99.92%) (41057/41088) | Learning rate: (1e-06)
2022-06-06 21:38:49,432 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 330 |  Loss: (0.0031) | Acc: (99.92%) (42335/42368) | Learning rate: (1e-06)
2022-06-06 21:38:51,595 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 340 |  Loss: (0.0031) | Acc: (99.92%) (43614/43648) | Learning rate: (1e-06)
2022-06-06 21:38:53,758 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 350 |  Loss: (0.0032) | Acc: (99.92%) (44892/44928) | Learning rate: (1e-06)
2022-06-06 21:38:55,920 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 360 |  Loss: (0.0031) | Acc: (99.92%) (46172/46208) | Learning rate: (1e-06)
2022-06-06 21:38:58,081 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 370 |  Loss: (0.0033) | Acc: (99.92%) (47449/47488) | Learning rate: (1e-06)
2022-06-06 21:39:00,229 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 380 |  Loss: (0.0034) | Acc: (99.92%) (48727/48768) | Learning rate: (1e-06)
2022-06-06 21:39:02,302 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 390 |  Loss: (0.0034) | Acc: (99.92%) (49958/50000) | Learning rate: (1e-06)
2022-06-06 21:39:11,328 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0763) | Acc: (97.99%) (9799/10000)
2022-06-06 21:39:11,328 - CIFAR10 Classifier - INFO - Epoch time : 0:01:34
2022-06-06 21:39:12,452 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 0 |  Loss: (0.0010) | Acc: (100.00%) (128/128) | Learning rate: (1e-06)
2022-06-06 21:39:14,658 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 10 |  Loss: (0.0025) | Acc: (99.93%) (1407/1408) | Learning rate: (1e-06)
2022-06-06 21:39:16,817 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 20 |  Loss: (0.0026) | Acc: (99.93%) (2686/2688) | Learning rate: (1e-06)
2022-06-06 21:39:18,981 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 30 |  Loss: (0.0024) | Acc: (99.92%) (3965/3968) | Learning rate: (1e-06)
2022-06-06 21:39:21,143 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 40 |  Loss: (0.0032) | Acc: (99.92%) (5244/5248) | Learning rate: (1e-06)
2022-06-06 21:39:23,303 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 50 |  Loss: (0.0029) | Acc: (99.94%) (6524/6528) | Learning rate: (1e-06)
2022-06-06 21:39:25,465 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 60 |  Loss: (0.0031) | Acc: (99.92%) (7802/7808) | Learning rate: (1e-06)
2022-06-06 21:39:27,624 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 70 |  Loss: (0.0030) | Acc: (99.93%) (9082/9088) | Learning rate: (1e-06)
2022-06-06 21:39:29,788 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 80 |  Loss: (0.0033) | Acc: (99.91%) (10359/10368) | Learning rate: (1e-06)
2022-06-06 21:39:31,949 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 90 |  Loss: (0.0033) | Acc: (99.91%) (11638/11648) | Learning rate: (1e-06)
2022-06-06 21:39:34,109 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 100 |  Loss: (0.0031) | Acc: (99.92%) (12918/12928) | Learning rate: (1e-06)
2022-06-06 21:39:36,269 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 110 |  Loss: (0.0030) | Acc: (99.92%) (14197/14208) | Learning rate: (1e-06)
2022-06-06 21:39:38,432 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 120 |  Loss: (0.0029) | Acc: (99.93%) (15477/15488) | Learning rate: (1e-06)
2022-06-06 21:39:40,594 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 130 |  Loss: (0.0029) | Acc: (99.93%) (16756/16768) | Learning rate: (1e-06)
2022-06-06 21:39:42,763 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 140 |  Loss: (0.0030) | Acc: (99.93%) (18035/18048) | Learning rate: (1e-06)
2022-06-06 21:39:44,925 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 150 |  Loss: (0.0031) | Acc: (99.92%) (19313/19328) | Learning rate: (1e-06)
2022-06-06 21:39:47,091 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 160 |  Loss: (0.0031) | Acc: (99.92%) (20592/20608) | Learning rate: (1e-06)
2022-06-06 21:39:49,258 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 170 |  Loss: (0.0030) | Acc: (99.93%) (21872/21888) | Learning rate: (1e-06)
2022-06-06 21:39:51,424 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 180 |  Loss: (0.0031) | Acc: (99.92%) (23150/23168) | Learning rate: (1e-06)
2022-06-06 21:39:53,592 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 190 |  Loss: (0.0031) | Acc: (99.92%) (24429/24448) | Learning rate: (1e-06)
2022-06-06 21:39:55,757 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 200 |  Loss: (0.0031) | Acc: (99.92%) (25708/25728) | Learning rate: (1e-06)
2022-06-06 21:39:57,924 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 210 |  Loss: (0.0030) | Acc: (99.92%) (26987/27008) | Learning rate: (1e-06)
2022-06-06 21:40:00,092 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 220 |  Loss: (0.0031) | Acc: (99.92%) (28265/28288) | Learning rate: (1e-06)
2022-06-06 21:40:02,262 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 230 |  Loss: (0.0031) | Acc: (99.92%) (29543/29568) | Learning rate: (1e-06)
2022-06-06 21:40:04,430 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 240 |  Loss: (0.0030) | Acc: (99.92%) (30823/30848) | Learning rate: (1e-06)
2022-06-06 21:40:06,594 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 250 |  Loss: (0.0030) | Acc: (99.92%) (32102/32128) | Learning rate: (1e-06)
2022-06-06 21:40:08,763 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 260 |  Loss: (0.0032) | Acc: (99.91%) (33378/33408) | Learning rate: (1e-06)
2022-06-06 21:40:10,938 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 270 |  Loss: (0.0032) | Acc: (99.91%) (34658/34688) | Learning rate: (1e-06)
2022-06-06 21:40:13,110 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 280 |  Loss: (0.0031) | Acc: (99.91%) (35937/35968) | Learning rate: (1e-06)
2022-06-06 21:40:15,280 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 290 |  Loss: (0.0031) | Acc: (99.91%) (37215/37248) | Learning rate: (1e-06)
2022-06-06 21:40:17,448 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 300 |  Loss: (0.0032) | Acc: (99.91%) (38493/38528) | Learning rate: (1e-06)
2022-06-06 21:40:35,344 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 21:40:35,346 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 21:40:35,347 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 21:40:35,347 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 21:40:35,347 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 21:40:36,996 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (1.1758) | Acc: (78.91%) (101/128) | Learning rate: (1e-05)
2022-06-06 21:40:40,531 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (0.8981) | Acc: (80.40%) (1132/1408) | Learning rate: (1e-05)
2022-06-06 21:40:44,074 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (0.8687) | Acc: (80.62%) (2167/2688) | Learning rate: (1e-05)
2022-06-06 21:40:47,619 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (0.8935) | Acc: (80.12%) (3179/3968) | Learning rate: (1e-05)
2022-06-06 21:40:51,172 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (0.8682) | Acc: (80.43%) (4221/5248) | Learning rate: (1e-05)
2022-06-06 21:40:54,726 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 50 |  Loss: (0.8419) | Acc: (80.81%) (5275/6528) | Learning rate: (1e-05)
2022-06-06 21:40:58,281 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 60 |  Loss: (0.8237) | Acc: (80.78%) (6307/7808) | Learning rate: (1e-05)
2022-06-06 21:41:01,835 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 70 |  Loss: (0.7923) | Acc: (81.33%) (7391/9088) | Learning rate: (1e-05)
2022-06-06 21:41:05,392 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 80 |  Loss: (0.7732) | Acc: (81.63%) (8463/10368) | Learning rate: (1e-05)
2022-06-06 21:41:08,950 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 90 |  Loss: (0.7609) | Acc: (81.80%) (9528/11648) | Learning rate: (1e-05)
2022-06-06 21:41:12,505 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 100 |  Loss: (0.7462) | Acc: (82.03%) (10605/12928) | Learning rate: (1e-05)
2022-06-06 21:41:16,065 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 110 |  Loss: (0.7306) | Acc: (82.29%) (11692/14208) | Learning rate: (1e-05)
2022-06-06 21:41:19,632 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 120 |  Loss: (0.7199) | Acc: (82.42%) (12765/15488) | Learning rate: (1e-05)
2022-06-06 21:41:23,197 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 130 |  Loss: (0.7071) | Acc: (82.62%) (13853/16768) | Learning rate: (1e-05)
2022-06-06 21:41:26,762 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 140 |  Loss: (0.6969) | Acc: (82.74%) (14933/18048) | Learning rate: (1e-05)
2022-06-06 21:41:30,328 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 150 |  Loss: (0.6859) | Acc: (82.92%) (16026/19328) | Learning rate: (1e-05)
2022-06-06 21:41:33,892 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 160 |  Loss: (0.6758) | Acc: (83.06%) (17118/20608) | Learning rate: (1e-05)
2022-06-06 21:41:43,424 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 21:41:43,426 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 21:41:43,426 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 21:41:43,426 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 21:41:43,426 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 21:41:44,458 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (1.0007) | Acc: (78.12%) (50/64) | Learning rate: (1e-05)
2022-06-06 21:41:46,240 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (0.9257) | Acc: (79.69%) (561/704) | Learning rate: (1e-05)
2022-06-06 21:41:48,026 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (0.9285) | Acc: (79.76%) (1072/1344) | Learning rate: (1e-05)
2022-06-06 21:41:49,811 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (0.9326) | Acc: (78.83%) (1564/1984) | Learning rate: (1e-05)
2022-06-06 21:41:51,599 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (0.8856) | Acc: (79.88%) (2096/2624) | Learning rate: (1e-05)
2022-06-06 21:41:53,386 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 50 |  Loss: (0.8591) | Acc: (80.21%) (2618/3264) | Learning rate: (1e-05)
2022-06-06 21:41:55,176 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 60 |  Loss: (0.8271) | Acc: (80.79%) (3154/3904) | Learning rate: (1e-05)
2022-06-06 21:41:56,963 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 70 |  Loss: (0.8157) | Acc: (80.88%) (3675/4544) | Learning rate: (1e-05)
2022-06-06 21:41:58,753 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 80 |  Loss: (0.8110) | Acc: (80.83%) (4190/5184) | Learning rate: (1e-05)
2022-06-06 21:42:00,541 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 90 |  Loss: (0.7979) | Acc: (81.04%) (4720/5824) | Learning rate: (1e-05)
2022-06-06 21:42:02,330 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 100 |  Loss: (0.7808) | Acc: (81.33%) (5257/6464) | Learning rate: (1e-05)
2022-06-06 21:42:04,122 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 110 |  Loss: (0.7601) | Acc: (81.63%) (5799/7104) | Learning rate: (1e-05)
2022-06-06 21:42:05,914 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 120 |  Loss: (0.7532) | Acc: (81.73%) (6329/7744) | Learning rate: (1e-05)
2022-06-06 21:42:07,704 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 130 |  Loss: (0.7431) | Acc: (81.89%) (6866/8384) | Learning rate: (1e-05)
2022-06-06 21:42:09,496 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 140 |  Loss: (0.7333) | Acc: (81.88%) (7389/9024) | Learning rate: (1e-05)
2022-06-06 21:42:11,288 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 150 |  Loss: (0.7318) | Acc: (81.87%) (7912/9664) | Learning rate: (1e-05)
2022-06-06 21:42:13,079 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 160 |  Loss: (0.7133) | Acc: (82.14%) (8464/10304) | Learning rate: (1e-05)
2022-06-06 21:42:14,870 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 170 |  Loss: (0.7075) | Acc: (82.27%) (9004/10944) | Learning rate: (1e-05)
2022-06-06 21:42:16,661 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 180 |  Loss: (0.6959) | Acc: (82.42%) (9547/11584) | Learning rate: (1e-05)
2022-06-06 21:42:18,454 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 190 |  Loss: (0.6892) | Acc: (82.58%) (10095/12224) | Learning rate: (1e-05)
2022-06-06 21:42:20,246 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 200 |  Loss: (0.6815) | Acc: (82.80%) (10652/12864) | Learning rate: (1e-05)
2022-06-06 21:42:22,038 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 210 |  Loss: (0.6777) | Acc: (82.90%) (11195/13504) | Learning rate: (1e-05)
2022-06-06 21:42:23,832 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 220 |  Loss: (0.6645) | Acc: (83.09%) (11752/14144) | Learning rate: (1e-05)
2022-06-06 21:42:25,628 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 230 |  Loss: (0.6571) | Acc: (83.16%) (12295/14784) | Learning rate: (1e-05)
2022-06-06 21:42:27,424 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 240 |  Loss: (0.6473) | Acc: (83.38%) (12860/15424) | Learning rate: (1e-05)
2022-06-06 21:42:29,218 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 250 |  Loss: (0.6420) | Acc: (83.40%) (13397/16064) | Learning rate: (1e-05)
2022-06-06 21:42:31,014 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 260 |  Loss: (0.6336) | Acc: (83.53%) (13953/16704) | Learning rate: (1e-05)
2022-06-06 21:42:32,810 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 270 |  Loss: (0.6270) | Acc: (83.65%) (14509/17344) | Learning rate: (1e-05)
2022-06-06 21:42:34,606 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 280 |  Loss: (0.6262) | Acc: (83.69%) (15051/17984) | Learning rate: (1e-05)
2022-06-06 21:42:36,403 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 290 |  Loss: (0.6185) | Acc: (83.84%) (15615/18624) | Learning rate: (1e-05)
2022-06-06 21:42:38,201 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 300 |  Loss: (0.6150) | Acc: (83.89%) (16160/19264) | Learning rate: (1e-05)
2022-06-06 21:42:39,999 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 310 |  Loss: (0.6080) | Acc: (84.01%) (16722/19904) | Learning rate: (1e-05)
2022-06-06 21:42:41,793 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 320 |  Loss: (0.6026) | Acc: (84.12%) (17281/20544) | Learning rate: (1e-05)
2022-06-06 21:42:43,589 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 330 |  Loss: (0.5968) | Acc: (84.21%) (17840/21184) | Learning rate: (1e-05)
2022-06-06 21:42:45,385 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 340 |  Loss: (0.5895) | Acc: (84.33%) (18405/21824) | Learning rate: (1e-05)
2022-06-06 21:42:47,181 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 350 |  Loss: (0.5863) | Acc: (84.40%) (18960/22464) | Learning rate: (1e-05)
2022-06-06 21:42:48,979 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 360 |  Loss: (0.5791) | Acc: (84.57%) (19538/23104) | Learning rate: (1e-05)
2022-06-06 21:42:50,775 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 370 |  Loss: (0.5751) | Acc: (84.66%) (20102/23744) | Learning rate: (1e-05)
2022-06-06 21:42:52,570 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 380 |  Loss: (0.5732) | Acc: (84.66%) (20644/24384) | Learning rate: (1e-05)
2022-06-06 21:42:54,368 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 390 |  Loss: (0.5686) | Acc: (84.74%) (21205/25024) | Learning rate: (1e-05)
2022-06-06 21:42:56,162 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 400 |  Loss: (0.5653) | Acc: (84.81%) (21766/25664) | Learning rate: (1e-05)
2022-06-06 21:42:57,958 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 410 |  Loss: (0.5598) | Acc: (84.95%) (22346/26304) | Learning rate: (1e-05)
2022-06-06 21:42:59,753 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 420 |  Loss: (0.5557) | Acc: (85.01%) (22905/26944) | Learning rate: (1e-05)
2022-06-06 21:43:01,548 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 430 |  Loss: (0.5511) | Acc: (85.09%) (23470/27584) | Learning rate: (1e-05)
2022-06-06 21:43:03,343 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 440 |  Loss: (0.5462) | Acc: (85.18%) (24041/28224) | Learning rate: (1e-05)
2022-06-06 21:43:05,139 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 450 |  Loss: (0.5426) | Acc: (85.24%) (24605/28864) | Learning rate: (1e-05)
2022-06-06 21:43:06,938 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 460 |  Loss: (0.5398) | Acc: (85.28%) (25161/29504) | Learning rate: (1e-05)
2022-06-06 21:43:08,737 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 470 |  Loss: (0.5349) | Acc: (85.40%) (25744/30144) | Learning rate: (1e-05)
2022-06-06 21:43:10,536 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 480 |  Loss: (0.5331) | Acc: (85.42%) (26295/30784) | Learning rate: (1e-05)
2022-06-06 21:43:12,333 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 490 |  Loss: (0.5310) | Acc: (85.43%) (26847/31424) | Learning rate: (1e-05)
2022-06-06 21:43:14,130 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 500 |  Loss: (0.5276) | Acc: (85.49%) (27410/32064) | Learning rate: (1e-05)
2022-06-06 21:43:15,929 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 510 |  Loss: (0.5245) | Acc: (85.52%) (27970/32704) | Learning rate: (1e-05)
2022-06-06 21:43:17,727 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 520 |  Loss: (0.5221) | Acc: (85.57%) (28532/33344) | Learning rate: (1e-05)
2022-06-06 21:43:19,523 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 530 |  Loss: (0.5186) | Acc: (85.65%) (29106/33984) | Learning rate: (1e-05)
2022-06-06 21:43:21,318 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 540 |  Loss: (0.5152) | Acc: (85.71%) (29675/34624) | Learning rate: (1e-05)
2022-06-06 21:43:23,114 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 550 |  Loss: (0.5119) | Acc: (85.75%) (30240/35264) | Learning rate: (1e-05)
2022-06-06 21:43:24,913 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 560 |  Loss: (0.5097) | Acc: (85.80%) (30805/35904) | Learning rate: (1e-05)
2022-06-06 21:43:26,711 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 570 |  Loss: (0.5072) | Acc: (85.84%) (31370/36544) | Learning rate: (1e-05)
2022-06-06 21:43:28,510 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 580 |  Loss: (0.5054) | Acc: (85.86%) (31926/37184) | Learning rate: (1e-05)
2022-06-06 21:43:30,308 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 590 |  Loss: (0.5028) | Acc: (85.92%) (32498/37824) | Learning rate: (1e-05)
2022-06-06 21:43:32,105 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 600 |  Loss: (0.4991) | Acc: (86.01%) (33081/38464) | Learning rate: (1e-05)
2022-06-06 21:43:33,903 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 610 |  Loss: (0.4970) | Acc: (86.04%) (33644/39104) | Learning rate: (1e-05)
2022-06-06 21:43:35,701 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 620 |  Loss: (0.4941) | Acc: (86.09%) (34216/39744) | Learning rate: (1e-05)
2022-06-06 21:43:37,499 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 630 |  Loss: (0.4923) | Acc: (86.13%) (34783/40384) | Learning rate: (1e-05)
2022-06-06 21:43:39,296 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 640 |  Loss: (0.4887) | Acc: (86.22%) (35371/41024) | Learning rate: (1e-05)
2022-06-06 21:43:41,090 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 650 |  Loss: (0.4849) | Acc: (86.30%) (35956/41664) | Learning rate: (1e-05)
2022-06-06 21:43:42,887 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 660 |  Loss: (0.4826) | Acc: (86.35%) (36530/42304) | Learning rate: (1e-05)
2022-06-06 21:43:44,685 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 670 |  Loss: (0.4808) | Acc: (86.40%) (37103/42944) | Learning rate: (1e-05)
2022-06-06 21:43:46,484 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 680 |  Loss: (0.4776) | Acc: (86.47%) (37689/43584) | Learning rate: (1e-05)
2022-06-06 21:43:48,283 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 690 |  Loss: (0.4763) | Acc: (86.52%) (38264/44224) | Learning rate: (1e-05)
2022-06-06 21:43:50,080 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 700 |  Loss: (0.4748) | Acc: (86.55%) (38832/44864) | Learning rate: (1e-05)
2022-06-06 21:43:51,878 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 710 |  Loss: (0.4732) | Acc: (86.58%) (39398/45504) | Learning rate: (1e-05)
2022-06-06 21:43:53,676 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 720 |  Loss: (0.4705) | Acc: (86.64%) (39981/46144) | Learning rate: (1e-05)
2022-06-06 21:43:55,473 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 730 |  Loss: (0.4687) | Acc: (86.67%) (40550/46784) | Learning rate: (1e-05)
2022-06-06 21:43:57,270 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 740 |  Loss: (0.4657) | Acc: (86.74%) (41137/47424) | Learning rate: (1e-05)
2022-06-06 21:43:59,065 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 750 |  Loss: (0.4639) | Acc: (86.79%) (41713/48064) | Learning rate: (1e-05)
2022-06-06 21:44:00,862 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 760 |  Loss: (0.4616) | Acc: (86.83%) (42288/48704) | Learning rate: (1e-05)
2022-06-06 21:44:02,652 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 770 |  Loss: (0.4591) | Acc: (86.88%) (42870/49344) | Learning rate: (1e-05)
2022-06-06 21:44:04,441 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 780 |  Loss: (0.4577) | Acc: (86.90%) (43437/49984) | Learning rate: (1e-05)
2022-06-06 21:44:14,459 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.3166) | Acc: (89.81%) (8981/10000)
2022-06-06 21:44:14,460 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:44:15,556 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 0 |  Loss: (0.2561) | Acc: (89.06%) (57/64) | Learning rate: (1e-05)
2022-06-06 21:44:17,350 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 10 |  Loss: (0.2444) | Acc: (92.05%) (648/704) | Learning rate: (1e-05)
2022-06-06 21:44:19,141 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 20 |  Loss: (0.2792) | Acc: (91.07%) (1224/1344) | Learning rate: (1e-05)
2022-06-06 21:44:20,934 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 30 |  Loss: (0.2757) | Acc: (90.98%) (1805/1984) | Learning rate: (1e-05)
2022-06-06 21:44:22,729 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 40 |  Loss: (0.2638) | Acc: (91.58%) (2403/2624) | Learning rate: (1e-05)
2022-06-06 21:44:24,523 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 50 |  Loss: (0.2699) | Acc: (91.18%) (2976/3264) | Learning rate: (1e-05)
2022-06-06 21:44:26,316 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 60 |  Loss: (0.2742) | Acc: (90.98%) (3552/3904) | Learning rate: (1e-05)
2022-06-06 21:44:28,110 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 70 |  Loss: (0.2657) | Acc: (91.33%) (4150/4544) | Learning rate: (1e-05)
2022-06-06 21:44:29,905 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 80 |  Loss: (0.2698) | Acc: (91.09%) (4722/5184) | Learning rate: (1e-05)
2022-06-06 21:44:31,700 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 90 |  Loss: (0.2706) | Acc: (90.95%) (5297/5824) | Learning rate: (1e-05)
2022-06-06 21:44:33,494 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 100 |  Loss: (0.2695) | Acc: (91.01%) (5883/6464) | Learning rate: (1e-05)
2022-06-06 21:44:35,290 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 110 |  Loss: (0.2712) | Acc: (90.96%) (6462/7104) | Learning rate: (1e-05)
2022-06-06 21:44:37,085 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 120 |  Loss: (0.2749) | Acc: (90.87%) (7037/7744) | Learning rate: (1e-05)
2022-06-06 21:44:38,879 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 130 |  Loss: (0.2728) | Acc: (90.91%) (7622/8384) | Learning rate: (1e-05)
2022-06-06 21:44:40,674 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 140 |  Loss: (0.2718) | Acc: (90.95%) (8207/9024) | Learning rate: (1e-05)
2022-06-06 21:44:42,467 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 150 |  Loss: (0.2687) | Acc: (91.08%) (8802/9664) | Learning rate: (1e-05)
2022-06-06 21:44:44,264 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 160 |  Loss: (0.2679) | Acc: (91.12%) (9389/10304) | Learning rate: (1e-05)
2022-06-06 21:44:46,060 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 170 |  Loss: (0.2691) | Acc: (91.05%) (9965/10944) | Learning rate: (1e-05)
2022-06-06 21:44:47,855 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 180 |  Loss: (0.2707) | Acc: (90.94%) (10535/11584) | Learning rate: (1e-05)
2022-06-06 21:44:49,651 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 190 |  Loss: (0.2681) | Acc: (91.01%) (11125/12224) | Learning rate: (1e-05)
2022-06-06 21:44:51,445 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 200 |  Loss: (0.2686) | Acc: (91.04%) (11711/12864) | Learning rate: (1e-05)
2022-06-06 21:44:53,242 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 210 |  Loss: (0.2679) | Acc: (91.07%) (12298/13504) | Learning rate: (1e-05)
2022-06-06 21:44:55,037 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 220 |  Loss: (0.2662) | Acc: (91.08%) (12883/14144) | Learning rate: (1e-05)
2022-06-06 21:44:56,831 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 230 |  Loss: (0.2677) | Acc: (91.04%) (13460/14784) | Learning rate: (1e-05)
2022-06-06 21:44:58,625 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 240 |  Loss: (0.2695) | Acc: (90.97%) (14031/15424) | Learning rate: (1e-05)
2022-06-06 21:45:00,419 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 250 |  Loss: (0.2706) | Acc: (90.96%) (14612/16064) | Learning rate: (1e-05)
2022-06-06 21:45:02,215 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 260 |  Loss: (0.2700) | Acc: (90.98%) (15197/16704) | Learning rate: (1e-05)
2022-06-06 21:45:04,010 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 270 |  Loss: (0.2681) | Acc: (91.06%) (15793/17344) | Learning rate: (1e-05)
2022-06-06 21:45:05,805 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 280 |  Loss: (0.2682) | Acc: (91.06%) (16376/17984) | Learning rate: (1e-05)
2022-06-06 21:45:07,599 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 290 |  Loss: (0.2675) | Acc: (91.12%) (16970/18624) | Learning rate: (1e-05)
2022-06-06 21:45:09,396 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 300 |  Loss: (0.2690) | Acc: (91.07%) (17544/19264) | Learning rate: (1e-05)
2022-06-06 21:45:11,192 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 310 |  Loss: (0.2683) | Acc: (91.11%) (18134/19904) | Learning rate: (1e-05)
2022-06-06 21:45:25,638 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.2813) | Acc: (90.88%) (9088/10000)
2022-06-06 21:45:25,639 - CIFAR10 Classifier - INFO - Epoch time : 0:01:10
2022-06-06 21:45:26,609 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 0 |  Loss: (0.2787) | Acc: (93.75%) (60/64) | Learning rate: (0.0001)
2022-06-06 21:45:28,432 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 10 |  Loss: (0.2652) | Acc: (91.05%) (641/704) | Learning rate: (0.0001)
2022-06-06 21:45:30,221 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 20 |  Loss: (0.2558) | Acc: (91.74%) (1233/1344) | Learning rate: (0.0001)
2022-06-06 21:45:32,010 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 30 |  Loss: (0.2553) | Acc: (91.68%) (1819/1984) | Learning rate: (0.0001)
2022-06-06 21:45:33,805 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 40 |  Loss: (0.2500) | Acc: (91.81%) (2409/2624) | Learning rate: (0.0001)
2022-06-06 21:45:35,598 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 50 |  Loss: (0.2466) | Acc: (91.91%) (3000/3264) | Learning rate: (0.0001)
2022-06-06 21:45:37,392 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 60 |  Loss: (0.2379) | Acc: (92.21%) (3600/3904) | Learning rate: (0.0001)
2022-06-06 21:45:39,185 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 70 |  Loss: (0.2324) | Acc: (92.39%) (4198/4544) | Learning rate: (0.0001)
2022-06-06 21:45:40,980 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 80 |  Loss: (0.2353) | Acc: (92.26%) (4783/5184) | Learning rate: (0.0001)
2022-06-06 21:45:42,775 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 90 |  Loss: (0.2306) | Acc: (92.38%) (5380/5824) | Learning rate: (0.0001)
2022-06-06 21:45:44,567 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 100 |  Loss: (0.2321) | Acc: (92.42%) (5974/6464) | Learning rate: (0.0001)
2022-06-06 21:45:46,363 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 110 |  Loss: (0.2278) | Acc: (92.47%) (6569/7104) | Learning rate: (0.0001)
2022-06-06 21:45:48,158 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 120 |  Loss: (0.2286) | Acc: (92.42%) (7157/7744) | Learning rate: (0.0001)
2022-06-06 21:45:49,951 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 130 |  Loss: (0.2236) | Acc: (92.59%) (7763/8384) | Learning rate: (0.0001)
2022-06-06 21:45:51,745 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 140 |  Loss: (0.2229) | Acc: (92.61%) (8357/9024) | Learning rate: (0.0001)
2022-06-06 21:45:53,538 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 150 |  Loss: (0.2203) | Acc: (92.68%) (8957/9664) | Learning rate: (0.0001)
2022-06-06 21:45:55,333 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 160 |  Loss: (0.2192) | Acc: (92.73%) (9555/10304) | Learning rate: (0.0001)
2022-06-06 21:45:57,126 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 170 |  Loss: (0.2143) | Acc: (92.89%) (10166/10944) | Learning rate: (0.0001)
2022-06-06 21:45:58,922 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 180 |  Loss: (0.2129) | Acc: (92.93%) (10765/11584) | Learning rate: (0.0001)
2022-06-06 21:46:00,716 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 190 |  Loss: (0.2123) | Acc: (92.96%) (11364/12224) | Learning rate: (0.0001)
2022-06-06 21:46:02,511 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 200 |  Loss: (0.2103) | Acc: (93.00%) (11964/12864) | Learning rate: (0.0001)
2022-06-06 21:46:04,306 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 210 |  Loss: (0.2084) | Acc: (93.05%) (12565/13504) | Learning rate: (0.0001)
2022-06-06 21:46:06,099 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 220 |  Loss: (0.2068) | Acc: (93.07%) (13164/14144) | Learning rate: (0.0001)
2022-06-06 21:46:07,896 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 230 |  Loss: (0.2047) | Acc: (93.15%) (13771/14784) | Learning rate: (0.0001)
2022-06-06 21:46:09,691 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 240 |  Loss: (0.2024) | Acc: (93.18%) (14372/15424) | Learning rate: (0.0001)
2022-06-06 21:46:11,485 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 250 |  Loss: (0.2012) | Acc: (93.23%) (14977/16064) | Learning rate: (0.0001)
2022-06-06 21:46:13,279 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 260 |  Loss: (0.1991) | Acc: (93.34%) (15591/16704) | Learning rate: (0.0001)
2022-06-06 21:46:15,074 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 270 |  Loss: (0.1967) | Acc: (93.41%) (16201/17344) | Learning rate: (0.0001)
2022-06-06 21:46:16,870 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 280 |  Loss: (0.1951) | Acc: (93.46%) (16808/17984) | Learning rate: (0.0001)
2022-06-06 21:46:18,666 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 290 |  Loss: (0.1943) | Acc: (93.50%) (17413/18624) | Learning rate: (0.0001)
2022-06-06 21:46:20,459 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 300 |  Loss: (0.1939) | Acc: (93.51%) (18014/19264) | Learning rate: (0.0001)
2022-06-06 21:46:22,254 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 310 |  Loss: (0.1922) | Acc: (93.55%) (18621/19904) | Learning rate: (0.0001)
2022-06-06 21:46:24,050 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 320 |  Loss: (0.1912) | Acc: (93.58%) (19226/20544) | Learning rate: (0.0001)
2022-06-06 21:46:25,845 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 330 |  Loss: (0.1907) | Acc: (93.58%) (19825/21184) | Learning rate: (0.0001)
2022-06-06 21:46:27,639 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 340 |  Loss: (0.1910) | Acc: (93.56%) (20419/21824) | Learning rate: (0.0001)
2022-06-06 21:46:29,432 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 350 |  Loss: (0.1891) | Acc: (93.62%) (21030/22464) | Learning rate: (0.0001)
2022-06-06 21:46:31,230 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 360 |  Loss: (0.1871) | Acc: (93.69%) (21645/23104) | Learning rate: (0.0001)
2022-06-06 21:46:33,027 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 370 |  Loss: (0.1863) | Acc: (93.72%) (22252/23744) | Learning rate: (0.0001)
2022-06-06 21:46:34,822 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 380 |  Loss: (0.1858) | Acc: (93.74%) (22858/24384) | Learning rate: (0.0001)
2022-06-06 21:46:36,618 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 390 |  Loss: (0.1840) | Acc: (93.82%) (23478/25024) | Learning rate: (0.0001)
2022-06-06 21:46:38,411 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 400 |  Loss: (0.1820) | Acc: (93.89%) (24097/25664) | Learning rate: (0.0001)
2022-06-06 21:46:40,208 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 410 |  Loss: (0.1805) | Acc: (93.93%) (24708/26304) | Learning rate: (0.0001)
2022-06-06 21:46:42,004 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 420 |  Loss: (0.1800) | Acc: (93.95%) (25315/26944) | Learning rate: (0.0001)
2022-06-06 21:46:43,799 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 430 |  Loss: (0.1790) | Acc: (93.97%) (25921/27584) | Learning rate: (0.0001)
2022-06-06 21:46:45,597 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 440 |  Loss: (0.1777) | Acc: (94.02%) (26536/28224) | Learning rate: (0.0001)
2022-06-06 21:46:47,391 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 450 |  Loss: (0.1767) | Acc: (94.05%) (27148/28864) | Learning rate: (0.0001)
2022-06-06 21:46:49,187 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 460 |  Loss: (0.1751) | Acc: (94.12%) (27768/29504) | Learning rate: (0.0001)
2022-06-06 21:46:50,982 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 470 |  Loss: (0.1758) | Acc: (94.10%) (28365/30144) | Learning rate: (0.0001)
2022-06-06 21:46:52,779 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 480 |  Loss: (0.1748) | Acc: (94.13%) (28976/30784) | Learning rate: (0.0001)
2022-06-06 21:46:54,575 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 490 |  Loss: (0.1750) | Acc: (94.13%) (29579/31424) | Learning rate: (0.0001)
2022-06-06 21:46:56,370 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 500 |  Loss: (0.1749) | Acc: (94.13%) (30182/32064) | Learning rate: (0.0001)
2022-06-06 21:46:58,165 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 510 |  Loss: (0.1744) | Acc: (94.14%) (30786/32704) | Learning rate: (0.0001)
2022-06-06 21:46:59,961 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 520 |  Loss: (0.1741) | Acc: (94.16%) (31397/33344) | Learning rate: (0.0001)
2022-06-06 21:47:01,757 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 530 |  Loss: (0.1739) | Acc: (94.17%) (32003/33984) | Learning rate: (0.0001)
2022-06-06 21:47:03,553 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 540 |  Loss: (0.1732) | Acc: (94.19%) (32611/34624) | Learning rate: (0.0001)
2022-06-06 21:47:05,348 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 550 |  Loss: (0.1721) | Acc: (94.21%) (33222/35264) | Learning rate: (0.0001)
2022-06-06 21:47:07,142 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 560 |  Loss: (0.1717) | Acc: (94.23%) (33832/35904) | Learning rate: (0.0001)
2022-06-06 21:47:08,938 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 570 |  Loss: (0.1709) | Acc: (94.27%) (34451/36544) | Learning rate: (0.0001)
2022-06-06 21:47:10,735 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 580 |  Loss: (0.1700) | Acc: (94.29%) (35062/37184) | Learning rate: (0.0001)
2022-06-06 21:47:12,532 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 590 |  Loss: (0.1687) | Acc: (94.34%) (35683/37824) | Learning rate: (0.0001)
2022-06-06 21:47:14,329 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 600 |  Loss: (0.1679) | Acc: (94.38%) (36301/38464) | Learning rate: (0.0001)
2022-06-06 21:47:16,125 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 610 |  Loss: (0.1666) | Acc: (94.43%) (36925/39104) | Learning rate: (0.0001)
2022-06-06 21:47:17,921 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 620 |  Loss: (0.1660) | Acc: (94.44%) (37536/39744) | Learning rate: (0.0001)
2022-06-06 21:47:19,716 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 630 |  Loss: (0.1653) | Acc: (94.47%) (38151/40384) | Learning rate: (0.0001)
2022-06-06 21:47:21,513 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 640 |  Loss: (0.1641) | Acc: (94.50%) (38766/41024) | Learning rate: (0.0001)
2022-06-06 21:47:23,311 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 650 |  Loss: (0.1633) | Acc: (94.51%) (39378/41664) | Learning rate: (0.0001)
2022-06-06 21:47:25,108 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 660 |  Loss: (0.1625) | Acc: (94.54%) (39994/42304) | Learning rate: (0.0001)
2022-06-06 21:47:26,904 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 670 |  Loss: (0.1619) | Acc: (94.57%) (40611/42944) | Learning rate: (0.0001)
2022-06-06 21:47:28,699 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 680 |  Loss: (0.1613) | Acc: (94.58%) (41222/43584) | Learning rate: (0.0001)
2022-06-06 21:47:30,494 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 690 |  Loss: (0.1605) | Acc: (94.60%) (41837/44224) | Learning rate: (0.0001)
2022-06-06 21:47:32,289 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 700 |  Loss: (0.1598) | Acc: (94.63%) (42455/44864) | Learning rate: (0.0001)
2022-06-06 21:47:34,087 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 710 |  Loss: (0.1592) | Acc: (94.65%) (43070/45504) | Learning rate: (0.0001)
2022-06-06 21:47:35,883 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 720 |  Loss: (0.1586) | Acc: (94.68%) (43687/46144) | Learning rate: (0.0001)
2022-06-06 21:47:37,680 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 730 |  Loss: (0.1580) | Acc: (94.70%) (44303/46784) | Learning rate: (0.0001)
2022-06-06 21:47:39,476 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 740 |  Loss: (0.1573) | Acc: (94.72%) (44919/47424) | Learning rate: (0.0001)
2022-06-06 21:47:41,271 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 750 |  Loss: (0.1569) | Acc: (94.73%) (45533/48064) | Learning rate: (0.0001)
2022-06-06 21:47:43,067 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 760 |  Loss: (0.1562) | Acc: (94.75%) (46146/48704) | Learning rate: (0.0001)
2022-06-06 21:47:44,855 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 770 |  Loss: (0.1558) | Acc: (94.76%) (46757/49344) | Learning rate: (0.0001)
2022-06-06 21:47:46,643 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 780 |  Loss: (0.1551) | Acc: (94.78%) (47375/49984) | Learning rate: (0.0001)
2022-06-06 21:47:56,617 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1415) | Acc: (95.44%) (9544/10000)
2022-06-06 21:47:56,618 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:47:57,596 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 0 |  Loss: (0.0369) | Acc: (100.00%) (64/64) | Learning rate: (0.0001)
2022-06-06 21:47:59,384 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 10 |  Loss: (0.1060) | Acc: (96.73%) (681/704) | Learning rate: (0.0001)
2022-06-06 21:48:01,173 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 20 |  Loss: (0.0864) | Acc: (97.47%) (1310/1344) | Learning rate: (0.0001)
2022-06-06 21:48:02,964 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 30 |  Loss: (0.0810) | Acc: (97.48%) (1934/1984) | Learning rate: (0.0001)
2022-06-06 21:48:04,758 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 40 |  Loss: (0.0881) | Acc: (97.37%) (2555/2624) | Learning rate: (0.0001)
2022-06-06 21:48:06,552 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 50 |  Loss: (0.0873) | Acc: (97.37%) (3178/3264) | Learning rate: (0.0001)
2022-06-06 21:48:08,349 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 60 |  Loss: (0.0883) | Acc: (97.31%) (3799/3904) | Learning rate: (0.0001)
2022-06-06 21:48:10,141 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 70 |  Loss: (0.0855) | Acc: (97.40%) (4426/4544) | Learning rate: (0.0001)
2022-06-06 21:48:11,936 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 80 |  Loss: (0.0857) | Acc: (97.34%) (5046/5184) | Learning rate: (0.0001)
2022-06-06 21:48:13,733 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 90 |  Loss: (0.0839) | Acc: (97.34%) (5669/5824) | Learning rate: (0.0001)
2022-06-06 21:48:15,527 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 100 |  Loss: (0.0867) | Acc: (97.20%) (6283/6464) | Learning rate: (0.0001)
2022-06-06 21:48:17,320 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 110 |  Loss: (0.0877) | Acc: (97.20%) (6905/7104) | Learning rate: (0.0001)
2022-06-06 21:48:19,114 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 120 |  Loss: (0.0882) | Acc: (97.17%) (7525/7744) | Learning rate: (0.0001)
2022-06-06 21:48:20,910 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 130 |  Loss: (0.0906) | Acc: (97.08%) (8139/8384) | Learning rate: (0.0001)
2022-06-06 21:48:22,705 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 140 |  Loss: (0.0910) | Acc: (97.06%) (8759/9024) | Learning rate: (0.0001)
2022-06-06 21:48:24,501 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 150 |  Loss: (0.0906) | Acc: (97.04%) (9378/9664) | Learning rate: (0.0001)
2022-06-06 21:48:26,295 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 160 |  Loss: (0.0893) | Acc: (97.07%) (10002/10304) | Learning rate: (0.0001)
2022-06-06 21:48:28,091 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 170 |  Loss: (0.0895) | Acc: (97.05%) (10621/10944) | Learning rate: (0.0001)
2022-06-06 21:48:29,886 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 180 |  Loss: (0.0895) | Acc: (97.02%) (11239/11584) | Learning rate: (0.0001)
2022-06-06 21:48:31,682 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 190 |  Loss: (0.0894) | Acc: (97.03%) (11861/12224) | Learning rate: (0.0001)
2022-06-06 21:48:33,476 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 200 |  Loss: (0.0877) | Acc: (97.08%) (12488/12864) | Learning rate: (0.0001)
2022-06-06 21:48:35,270 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 210 |  Loss: (0.0878) | Acc: (97.07%) (13109/13504) | Learning rate: (0.0001)
2022-06-06 21:48:37,066 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 220 |  Loss: (0.0858) | Acc: (97.14%) (13740/14144) | Learning rate: (0.0001)
2022-06-06 21:48:38,862 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 230 |  Loss: (0.0860) | Acc: (97.14%) (14361/14784) | Learning rate: (0.0001)
2022-06-06 21:48:40,657 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 240 |  Loss: (0.0860) | Acc: (97.13%) (14981/15424) | Learning rate: (0.0001)
2022-06-06 21:48:42,452 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 250 |  Loss: (0.0860) | Acc: (97.14%) (15604/16064) | Learning rate: (0.0001)
2022-06-06 21:48:44,248 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 260 |  Loss: (0.0863) | Acc: (97.14%) (16227/16704) | Learning rate: (0.0001)
2022-06-06 21:48:46,043 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 270 |  Loss: (0.0869) | Acc: (97.13%) (16846/17344) | Learning rate: (0.0001)
2022-06-06 21:48:47,839 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 280 |  Loss: (0.0870) | Acc: (97.15%) (17471/17984) | Learning rate: (0.0001)
2022-06-06 21:48:49,635 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 290 |  Loss: (0.0873) | Acc: (97.12%) (18087/18624) | Learning rate: (0.0001)
2022-06-06 21:48:51,428 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 300 |  Loss: (0.0868) | Acc: (97.14%) (18713/19264) | Learning rate: (0.0001)
2022-06-06 21:48:53,223 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 310 |  Loss: (0.0867) | Acc: (97.15%) (19336/19904) | Learning rate: (0.0001)
2022-06-06 21:48:55,018 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 320 |  Loss: (0.0863) | Acc: (97.15%) (19959/20544) | Learning rate: (0.0001)
2022-06-06 21:48:56,816 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 330 |  Loss: (0.0866) | Acc: (97.15%) (20580/21184) | Learning rate: (0.0001)
2022-06-06 21:48:58,612 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 340 |  Loss: (0.0860) | Acc: (97.16%) (21205/21824) | Learning rate: (0.0001)
2022-06-06 21:49:00,405 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 350 |  Loss: (0.0863) | Acc: (97.16%) (21825/22464) | Learning rate: (0.0001)
2022-06-06 21:49:02,201 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 360 |  Loss: (0.0863) | Acc: (97.15%) (22446/23104) | Learning rate: (0.0001)
2022-06-06 21:49:03,999 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 370 |  Loss: (0.0864) | Acc: (97.16%) (23070/23744) | Learning rate: (0.0001)
2022-06-06 21:49:05,796 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 380 |  Loss: (0.0865) | Acc: (97.16%) (23692/24384) | Learning rate: (0.0001)
2022-06-06 21:49:07,592 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 390 |  Loss: (0.0867) | Acc: (97.12%) (24304/25024) | Learning rate: (0.0001)
2022-06-06 21:49:09,387 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 400 |  Loss: (0.0865) | Acc: (97.13%) (24927/25664) | Learning rate: (0.0001)
2022-06-06 21:49:11,182 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 410 |  Loss: (0.0861) | Acc: (97.15%) (25555/26304) | Learning rate: (0.0001)
2022-06-06 21:49:12,977 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 420 |  Loss: (0.0860) | Acc: (97.16%) (26179/26944) | Learning rate: (0.0001)
2022-06-06 21:49:14,772 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 430 |  Loss: (0.0853) | Acc: (97.18%) (26806/27584) | Learning rate: (0.0001)
2022-06-06 21:49:16,568 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 440 |  Loss: (0.0853) | Acc: (97.17%) (27424/28224) | Learning rate: (0.0001)
2022-06-06 21:49:18,363 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 450 |  Loss: (0.0852) | Acc: (97.16%) (28043/28864) | Learning rate: (0.0001)
2022-06-06 21:49:20,157 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 460 |  Loss: (0.0849) | Acc: (97.15%) (28663/29504) | Learning rate: (0.0001)
2022-06-06 21:49:21,953 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 470 |  Loss: (0.0842) | Acc: (97.16%) (29287/30144) | Learning rate: (0.0001)
2022-06-06 21:49:23,751 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 480 |  Loss: (0.0844) | Acc: (97.16%) (29909/30784) | Learning rate: (0.0001)
2022-06-06 21:49:25,549 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 490 |  Loss: (0.0842) | Acc: (97.16%) (30533/31424) | Learning rate: (0.0001)
2022-06-06 21:49:27,345 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 500 |  Loss: (0.0840) | Acc: (97.17%) (31158/32064) | Learning rate: (0.0001)
2022-06-06 21:49:29,142 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 510 |  Loss: (0.0840) | Acc: (97.17%) (31779/32704) | Learning rate: (0.0001)
2022-06-06 21:49:30,937 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 520 |  Loss: (0.0838) | Acc: (97.19%) (32406/33344) | Learning rate: (0.0001)
2022-06-06 21:49:32,733 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 530 |  Loss: (0.0835) | Acc: (97.19%) (33030/33984) | Learning rate: (0.0001)
2022-06-06 21:49:34,529 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 540 |  Loss: (0.0832) | Acc: (97.20%) (33653/34624) | Learning rate: (0.0001)
2022-06-06 21:49:36,324 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 550 |  Loss: (0.0835) | Acc: (97.19%) (34272/35264) | Learning rate: (0.0001)
2022-06-06 21:49:38,121 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 560 |  Loss: (0.0835) | Acc: (97.20%) (34898/35904) | Learning rate: (0.0001)
2022-06-06 21:49:39,918 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 570 |  Loss: (0.0833) | Acc: (97.20%) (35521/36544) | Learning rate: (0.0001)
2022-06-06 21:49:41,713 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 580 |  Loss: (0.0833) | Acc: (97.20%) (36142/37184) | Learning rate: (0.0001)
2022-06-06 21:49:43,509 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 590 |  Loss: (0.0829) | Acc: (97.22%) (36772/37824) | Learning rate: (0.0001)
2022-06-06 21:49:45,305 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 600 |  Loss: (0.0829) | Acc: (97.21%) (37390/38464) | Learning rate: (0.0001)
2022-06-06 21:49:47,104 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 610 |  Loss: (0.0826) | Acc: (97.22%) (38017/39104) | Learning rate: (0.0001)
2022-06-06 21:49:48,899 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 620 |  Loss: (0.0824) | Acc: (97.22%) (38641/39744) | Learning rate: (0.0001)
2022-06-06 21:49:50,696 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 630 |  Loss: (0.0824) | Acc: (97.23%) (39264/40384) | Learning rate: (0.0001)
2022-06-06 21:49:52,492 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 640 |  Loss: (0.0821) | Acc: (97.23%) (39888/41024) | Learning rate: (0.0001)
2022-06-06 21:49:54,288 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 650 |  Loss: (0.0815) | Acc: (97.25%) (40520/41664) | Learning rate: (0.0001)
2022-06-06 21:49:56,083 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 660 |  Loss: (0.0813) | Acc: (97.27%) (41149/42304) | Learning rate: (0.0001)
2022-06-06 21:49:57,880 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 670 |  Loss: (0.0813) | Acc: (97.26%) (41769/42944) | Learning rate: (0.0001)
2022-06-06 21:49:59,677 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 680 |  Loss: (0.0811) | Acc: (97.28%) (42397/43584) | Learning rate: (0.0001)
2022-06-06 21:50:01,475 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 690 |  Loss: (0.0808) | Acc: (97.29%) (43025/44224) | Learning rate: (0.0001)
2022-06-06 21:50:03,272 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 700 |  Loss: (0.0810) | Acc: (97.28%) (43644/44864) | Learning rate: (0.0001)
2022-06-06 21:50:05,068 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 710 |  Loss: (0.0809) | Acc: (97.27%) (44264/45504) | Learning rate: (0.0001)
2022-06-06 21:50:06,863 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 720 |  Loss: (0.0814) | Acc: (97.27%) (44882/46144) | Learning rate: (0.0001)
2022-06-06 21:50:08,658 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 730 |  Loss: (0.0814) | Acc: (97.26%) (45504/46784) | Learning rate: (0.0001)
2022-06-06 21:50:10,456 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 740 |  Loss: (0.0816) | Acc: (97.27%) (46127/47424) | Learning rate: (0.0001)
2022-06-06 21:50:12,251 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 750 |  Loss: (0.0818) | Acc: (97.26%) (46746/48064) | Learning rate: (0.0001)
2022-06-06 21:50:14,049 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 760 |  Loss: (0.0815) | Acc: (97.25%) (47367/48704) | Learning rate: (0.0001)
2022-06-06 21:50:15,838 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 770 |  Loss: (0.0817) | Acc: (97.25%) (47988/49344) | Learning rate: (0.0001)
2022-06-06 21:50:17,627 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 780 |  Loss: (0.0819) | Acc: (97.25%) (48610/49984) | Learning rate: (0.0001)
2022-06-06 21:50:27,641 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1219) | Acc: (96.24%) (9624/10000)
2022-06-06 21:50:27,642 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:50:28,557 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 0 |  Loss: (0.0387) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 21:50:30,368 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 10 |  Loss: (0.0482) | Acc: (98.58%) (694/704) | Learning rate: (0.0001)
2022-06-06 21:50:32,160 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 20 |  Loss: (0.0597) | Acc: (98.36%) (1322/1344) | Learning rate: (0.0001)
2022-06-06 21:50:33,951 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 30 |  Loss: (0.0677) | Acc: (97.98%) (1944/1984) | Learning rate: (0.0001)
2022-06-06 21:50:35,749 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 40 |  Loss: (0.0745) | Acc: (97.68%) (2563/2624) | Learning rate: (0.0001)
2022-06-06 21:50:37,543 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 50 |  Loss: (0.0719) | Acc: (97.79%) (3192/3264) | Learning rate: (0.0001)
2022-06-06 21:50:39,339 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 60 |  Loss: (0.0722) | Acc: (97.77%) (3817/3904) | Learning rate: (0.0001)
2022-06-06 21:50:41,134 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 70 |  Loss: (0.0701) | Acc: (97.84%) (4446/4544) | Learning rate: (0.0001)
2022-06-06 21:50:42,928 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 80 |  Loss: (0.0693) | Acc: (97.90%) (5075/5184) | Learning rate: (0.0001)
2022-06-06 21:50:44,722 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 90 |  Loss: (0.0686) | Acc: (97.92%) (5703/5824) | Learning rate: (0.0001)
2022-06-06 21:50:46,517 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 100 |  Loss: (0.0667) | Acc: (97.97%) (6333/6464) | Learning rate: (0.0001)
2022-06-06 21:50:48,313 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 110 |  Loss: (0.0645) | Acc: (98.00%) (6962/7104) | Learning rate: (0.0001)
2022-06-06 21:50:50,108 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 120 |  Loss: (0.0636) | Acc: (98.02%) (7591/7744) | Learning rate: (0.0001)
2022-06-06 21:50:51,903 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 130 |  Loss: (0.0633) | Acc: (97.98%) (8215/8384) | Learning rate: (0.0001)
2022-06-06 21:50:53,698 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 140 |  Loss: (0.0636) | Acc: (97.96%) (8840/9024) | Learning rate: (0.0001)
2022-06-06 21:50:55,492 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 150 |  Loss: (0.0622) | Acc: (98.00%) (9471/9664) | Learning rate: (0.0001)
2022-06-06 21:50:57,287 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 160 |  Loss: (0.0618) | Acc: (98.01%) (10099/10304) | Learning rate: (0.0001)
2022-06-06 21:50:59,081 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 170 |  Loss: (0.0605) | Acc: (98.02%) (10727/10944) | Learning rate: (0.0001)
2022-06-06 21:51:00,878 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 180 |  Loss: (0.0597) | Acc: (98.05%) (11358/11584) | Learning rate: (0.0001)
2022-06-06 21:51:02,675 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 190 |  Loss: (0.0598) | Acc: (98.03%) (11983/12224) | Learning rate: (0.0001)
2022-06-06 21:51:04,471 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 200 |  Loss: (0.0608) | Acc: (98.02%) (12609/12864) | Learning rate: (0.0001)
2022-06-06 21:51:06,266 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 210 |  Loss: (0.0608) | Acc: (98.00%) (13234/13504) | Learning rate: (0.0001)
2022-06-06 21:51:08,060 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 220 |  Loss: (0.0600) | Acc: (98.03%) (13865/14144) | Learning rate: (0.0001)
2022-06-06 21:51:09,856 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 230 |  Loss: (0.0598) | Acc: (98.03%) (14493/14784) | Learning rate: (0.0001)
2022-06-06 21:51:11,652 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 240 |  Loss: (0.0596) | Acc: (98.03%) (15120/15424) | Learning rate: (0.0001)
2022-06-06 21:51:13,447 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 250 |  Loss: (0.0591) | Acc: (98.05%) (15751/16064) | Learning rate: (0.0001)
2022-06-06 21:51:15,242 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 260 |  Loss: (0.0590) | Acc: (98.04%) (16377/16704) | Learning rate: (0.0001)
2022-06-06 21:51:17,035 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 270 |  Loss: (0.0594) | Acc: (98.03%) (17002/17344) | Learning rate: (0.0001)
2022-06-06 21:51:18,836 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 280 |  Loss: (0.0596) | Acc: (98.03%) (17629/17984) | Learning rate: (0.0001)
2022-06-06 21:51:20,631 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 290 |  Loss: (0.0598) | Acc: (98.03%) (18257/18624) | Learning rate: (0.0001)
2022-06-06 21:51:22,426 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 300 |  Loss: (0.0593) | Acc: (98.05%) (18888/19264) | Learning rate: (0.0001)
2022-06-06 21:51:24,224 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 310 |  Loss: (0.0601) | Acc: (98.03%) (19511/19904) | Learning rate: (0.0001)
2022-06-06 21:51:26,018 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 320 |  Loss: (0.0594) | Acc: (98.06%) (20145/20544) | Learning rate: (0.0001)
2022-06-06 21:51:27,813 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 330 |  Loss: (0.0590) | Acc: (98.07%) (20776/21184) | Learning rate: (0.0001)
2022-06-06 21:51:29,609 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 340 |  Loss: (0.0588) | Acc: (98.08%) (21406/21824) | Learning rate: (0.0001)
2022-06-06 21:51:31,403 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 350 |  Loss: (0.0584) | Acc: (98.10%) (22038/22464) | Learning rate: (0.0001)
2022-06-06 21:51:33,202 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 360 |  Loss: (0.0581) | Acc: (98.10%) (22666/23104) | Learning rate: (0.0001)
2022-06-06 21:51:34,997 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 370 |  Loss: (0.0576) | Acc: (98.12%) (23298/23744) | Learning rate: (0.0001)
2022-06-06 21:51:36,790 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 380 |  Loss: (0.0574) | Acc: (98.12%) (23926/24384) | Learning rate: (0.0001)
2022-06-06 21:51:38,586 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 390 |  Loss: (0.0582) | Acc: (98.09%) (24547/25024) | Learning rate: (0.0001)
2022-06-06 21:51:40,381 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 400 |  Loss: (0.0582) | Acc: (98.09%) (25173/25664) | Learning rate: (0.0001)
2022-06-06 21:51:42,176 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 410 |  Loss: (0.0580) | Acc: (98.09%) (25802/26304) | Learning rate: (0.0001)
2022-06-06 21:51:43,970 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 420 |  Loss: (0.0587) | Acc: (98.08%) (26427/26944) | Learning rate: (0.0001)
2022-06-06 21:51:45,765 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 430 |  Loss: (0.0592) | Acc: (98.06%) (27050/27584) | Learning rate: (0.0001)
2022-06-06 21:51:47,562 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 440 |  Loss: (0.0593) | Acc: (98.07%) (27679/28224) | Learning rate: (0.0001)
2022-06-06 21:51:49,357 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 450 |  Loss: (0.0594) | Acc: (98.07%) (28306/28864) | Learning rate: (0.0001)
2022-06-06 21:51:51,154 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 460 |  Loss: (0.0596) | Acc: (98.06%) (28932/29504) | Learning rate: (0.0001)
2022-06-06 21:51:52,947 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 470 |  Loss: (0.0600) | Acc: (98.05%) (29556/30144) | Learning rate: (0.0001)
2022-06-06 21:51:54,743 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 480 |  Loss: (0.0602) | Acc: (98.05%) (30183/30784) | Learning rate: (0.0001)
2022-06-06 21:51:56,539 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 490 |  Loss: (0.0606) | Acc: (98.04%) (30808/31424) | Learning rate: (0.0001)
2022-06-06 21:51:58,334 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 500 |  Loss: (0.0605) | Acc: (98.04%) (31436/32064) | Learning rate: (0.0001)
2022-06-06 21:52:00,131 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 510 |  Loss: (0.0603) | Acc: (98.04%) (32064/32704) | Learning rate: (0.0001)
2022-06-06 21:52:01,928 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 520 |  Loss: (0.0602) | Acc: (98.04%) (32692/33344) | Learning rate: (0.0001)
2022-06-06 21:52:03,722 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 530 |  Loss: (0.0605) | Acc: (98.02%) (33312/33984) | Learning rate: (0.0001)
2022-06-06 21:52:05,518 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 540 |  Loss: (0.0603) | Acc: (98.03%) (33941/34624) | Learning rate: (0.0001)
2022-06-06 21:52:07,313 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 550 |  Loss: (0.0600) | Acc: (98.03%) (34571/35264) | Learning rate: (0.0001)
2022-06-06 21:52:09,109 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 560 |  Loss: (0.0602) | Acc: (98.02%) (35193/35904) | Learning rate: (0.0001)
2022-06-06 21:52:10,903 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 570 |  Loss: (0.0600) | Acc: (98.01%) (35818/36544) | Learning rate: (0.0001)
2022-06-06 21:52:12,697 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 580 |  Loss: (0.0600) | Acc: (98.02%) (36449/37184) | Learning rate: (0.0001)
2022-06-06 21:52:14,494 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 590 |  Loss: (0.0601) | Acc: (98.03%) (37077/37824) | Learning rate: (0.0001)
2022-06-06 21:52:16,291 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 600 |  Loss: (0.0600) | Acc: (98.02%) (37703/38464) | Learning rate: (0.0001)
2022-06-06 21:52:18,086 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 610 |  Loss: (0.0599) | Acc: (98.02%) (38330/39104) | Learning rate: (0.0001)
2022-06-06 21:52:19,880 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 620 |  Loss: (0.0598) | Acc: (98.02%) (38957/39744) | Learning rate: (0.0001)
2022-06-06 21:52:21,674 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 630 |  Loss: (0.0598) | Acc: (98.01%) (39581/40384) | Learning rate: (0.0001)
2022-06-06 21:52:23,470 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 640 |  Loss: (0.0601) | Acc: (98.00%) (40205/41024) | Learning rate: (0.0001)
2022-06-06 21:52:25,266 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 650 |  Loss: (0.0601) | Acc: (98.01%) (40835/41664) | Learning rate: (0.0001)
2022-06-06 21:52:27,063 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 660 |  Loss: (0.0599) | Acc: (98.02%) (41467/42304) | Learning rate: (0.0001)
2022-06-06 21:52:28,858 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 670 |  Loss: (0.0599) | Acc: (98.03%) (42096/42944) | Learning rate: (0.0001)
2022-06-06 21:52:30,654 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 680 |  Loss: (0.0596) | Acc: (98.03%) (42726/43584) | Learning rate: (0.0001)
2022-06-06 21:52:32,449 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 690 |  Loss: (0.0597) | Acc: (98.02%) (43350/44224) | Learning rate: (0.0001)
2022-06-06 21:52:34,244 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 700 |  Loss: (0.0596) | Acc: (98.02%) (43977/44864) | Learning rate: (0.0001)
2022-06-06 21:52:36,041 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 710 |  Loss: (0.0600) | Acc: (98.01%) (44597/45504) | Learning rate: (0.0001)
2022-06-06 21:52:37,837 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 720 |  Loss: (0.0599) | Acc: (98.00%) (45223/46144) | Learning rate: (0.0001)
2022-06-06 21:52:39,631 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 730 |  Loss: (0.0600) | Acc: (98.00%) (45849/46784) | Learning rate: (0.0001)
2022-06-06 21:52:41,426 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 740 |  Loss: (0.0602) | Acc: (97.99%) (46472/47424) | Learning rate: (0.0001)
2022-06-06 21:52:43,225 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 750 |  Loss: (0.0605) | Acc: (97.98%) (47091/48064) | Learning rate: (0.0001)
2022-06-06 21:52:45,021 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 760 |  Loss: (0.0605) | Acc: (97.98%) (47721/48704) | Learning rate: (0.0001)
2022-06-06 21:52:46,809 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 770 |  Loss: (0.0604) | Acc: (97.99%) (48350/49344) | Learning rate: (0.0001)
2022-06-06 21:52:48,598 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 780 |  Loss: (0.0603) | Acc: (97.99%) (48977/49984) | Learning rate: (0.0001)
2022-06-06 21:52:58,570 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1113) | Acc: (96.38%) (9638/10000)
2022-06-06 21:52:58,571 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:52:59,451 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 0 |  Loss: (0.0684) | Acc: (98.44%) (63/64) | Learning rate: (0.0001)
2022-06-06 21:53:01,271 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 10 |  Loss: (0.0468) | Acc: (98.58%) (694/704) | Learning rate: (0.0001)
2022-06-06 21:53:03,061 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 20 |  Loss: (0.0461) | Acc: (98.51%) (1324/1344) | Learning rate: (0.0001)
2022-06-06 21:53:04,853 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 30 |  Loss: (0.0450) | Acc: (98.59%) (1956/1984) | Learning rate: (0.0001)
2022-06-06 21:53:06,646 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 40 |  Loss: (0.0439) | Acc: (98.67%) (2589/2624) | Learning rate: (0.0001)
2022-06-06 21:53:08,438 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 50 |  Loss: (0.0417) | Acc: (98.81%) (3225/3264) | Learning rate: (0.0001)
2022-06-06 21:53:10,233 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 60 |  Loss: (0.0409) | Acc: (98.77%) (3856/3904) | Learning rate: (0.0001)
2022-06-06 21:53:12,028 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 70 |  Loss: (0.0420) | Acc: (98.64%) (4482/4544) | Learning rate: (0.0001)
2022-06-06 21:53:13,821 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 80 |  Loss: (0.0408) | Acc: (98.69%) (5116/5184) | Learning rate: (0.0001)
2022-06-06 21:53:15,614 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 90 |  Loss: (0.0402) | Acc: (98.70%) (5748/5824) | Learning rate: (0.0001)
2022-06-06 21:53:29,970 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1121) | Acc: (96.57%) (9657/10000)
2022-06-06 21:53:29,971 - CIFAR10 Classifier - INFO - Epoch time : 0:00:31
2022-06-06 21:53:30,850 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 0 |  Loss: (0.1200) | Acc: (95.31%) (61/64) | Learning rate: (1e-05)
2022-06-06 21:53:32,639 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 10 |  Loss: (0.0538) | Acc: (98.30%) (692/704) | Learning rate: (1e-05)
2022-06-06 21:53:34,427 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 20 |  Loss: (0.0460) | Acc: (98.36%) (1322/1344) | Learning rate: (1e-05)
2022-06-06 21:53:36,216 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 30 |  Loss: (0.0392) | Acc: (98.59%) (1956/1984) | Learning rate: (1e-05)
2022-06-06 21:53:38,007 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 40 |  Loss: (0.0428) | Acc: (98.40%) (2582/2624) | Learning rate: (1e-05)
2022-06-06 21:53:39,797 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 50 |  Loss: (0.0443) | Acc: (98.31%) (3209/3264) | Learning rate: (1e-05)
2022-06-06 21:53:41,588 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 60 |  Loss: (0.0422) | Acc: (98.39%) (3841/3904) | Learning rate: (1e-05)
2022-06-06 21:53:43,379 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 70 |  Loss: (0.0418) | Acc: (98.42%) (4472/4544) | Learning rate: (1e-05)
2022-06-06 21:53:45,172 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 80 |  Loss: (0.0444) | Acc: (98.36%) (5099/5184) | Learning rate: (1e-05)
2022-06-06 21:53:46,965 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 90 |  Loss: (0.0452) | Acc: (98.32%) (5726/5824) | Learning rate: (1e-05)
2022-06-06 21:53:48,761 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 100 |  Loss: (0.0455) | Acc: (98.33%) (6356/6464) | Learning rate: (1e-05)
2022-06-06 21:53:50,554 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 110 |  Loss: (0.0458) | Acc: (98.38%) (6989/7104) | Learning rate: (1e-05)
2022-06-06 21:53:52,348 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 120 |  Loss: (0.0457) | Acc: (98.41%) (7621/7744) | Learning rate: (1e-05)
2022-06-06 21:53:54,142 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 130 |  Loss: (0.0451) | Acc: (98.45%) (8254/8384) | Learning rate: (1e-05)
2022-06-06 21:53:55,937 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 140 |  Loss: (0.0440) | Acc: (98.49%) (8888/9024) | Learning rate: (1e-05)
2022-06-06 21:53:57,731 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 150 |  Loss: (0.0430) | Acc: (98.52%) (9521/9664) | Learning rate: (1e-05)
2022-06-06 21:53:59,525 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 160 |  Loss: (0.0422) | Acc: (98.53%) (10153/10304) | Learning rate: (1e-05)
2022-06-06 21:54:01,319 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 170 |  Loss: (0.0414) | Acc: (98.57%) (10787/10944) | Learning rate: (1e-05)
2022-06-06 21:54:03,116 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 180 |  Loss: (0.0413) | Acc: (98.58%) (11419/11584) | Learning rate: (1e-05)
2022-06-06 21:54:04,910 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 190 |  Loss: (0.0403) | Acc: (98.61%) (12054/12224) | Learning rate: (1e-05)
2022-06-06 21:54:06,704 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 200 |  Loss: (0.0409) | Acc: (98.60%) (12684/12864) | Learning rate: (1e-05)
2022-06-06 21:54:08,499 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 210 |  Loss: (0.0423) | Acc: (98.56%) (13309/13504) | Learning rate: (1e-05)
2022-06-06 21:54:10,294 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 220 |  Loss: (0.0419) | Acc: (98.56%) (13941/14144) | Learning rate: (1e-05)
2022-06-06 21:54:12,089 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 230 |  Loss: (0.0422) | Acc: (98.57%) (14572/14784) | Learning rate: (1e-05)
2022-06-06 21:54:13,884 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 240 |  Loss: (0.0424) | Acc: (98.57%) (15203/15424) | Learning rate: (1e-05)
2022-06-06 21:54:15,676 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 250 |  Loss: (0.0436) | Acc: (98.52%) (15826/16064) | Learning rate: (1e-05)
2022-06-06 21:54:17,473 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 260 |  Loss: (0.0430) | Acc: (98.54%) (16460/16704) | Learning rate: (1e-05)
2022-06-06 21:54:19,267 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 270 |  Loss: (0.0431) | Acc: (98.54%) (17090/17344) | Learning rate: (1e-05)
2022-06-06 21:54:21,062 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 280 |  Loss: (0.0423) | Acc: (98.58%) (17728/17984) | Learning rate: (1e-05)
2022-06-06 21:54:22,856 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 290 |  Loss: (0.0426) | Acc: (98.58%) (18359/18624) | Learning rate: (1e-05)
2022-06-06 21:54:24,651 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 300 |  Loss: (0.0427) | Acc: (98.56%) (18987/19264) | Learning rate: (1e-05)
2022-06-06 21:54:26,448 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 310 |  Loss: (0.0426) | Acc: (98.55%) (19616/19904) | Learning rate: (1e-05)
2022-06-06 21:54:28,243 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 320 |  Loss: (0.0424) | Acc: (98.56%) (20249/20544) | Learning rate: (1e-05)
2022-06-06 21:54:30,038 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 330 |  Loss: (0.0427) | Acc: (98.57%) (20881/21184) | Learning rate: (1e-05)
2022-06-06 21:54:31,833 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 340 |  Loss: (0.0425) | Acc: (98.57%) (21513/21824) | Learning rate: (1e-05)
2022-06-06 21:54:33,627 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 350 |  Loss: (0.0428) | Acc: (98.57%) (22142/22464) | Learning rate: (1e-05)
2022-06-06 21:54:35,423 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 360 |  Loss: (0.0429) | Acc: (98.56%) (22771/23104) | Learning rate: (1e-05)
2022-06-06 21:54:37,218 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 370 |  Loss: (0.0432) | Acc: (98.56%) (23403/23744) | Learning rate: (1e-05)
2022-06-06 21:54:39,012 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 380 |  Loss: (0.0429) | Acc: (98.58%) (24037/24384) | Learning rate: (1e-05)
2022-06-06 21:54:40,807 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 390 |  Loss: (0.0430) | Acc: (98.57%) (24666/25024) | Learning rate: (1e-05)
2022-06-06 21:54:42,604 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 400 |  Loss: (0.0431) | Acc: (98.57%) (25297/25664) | Learning rate: (1e-05)
2022-06-06 21:54:44,399 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 410 |  Loss: (0.0431) | Acc: (98.56%) (25924/26304) | Learning rate: (1e-05)
2022-06-06 21:54:46,193 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 420 |  Loss: (0.0430) | Acc: (98.55%) (26553/26944) | Learning rate: (1e-05)
2022-06-06 21:54:47,988 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 430 |  Loss: (0.0430) | Acc: (98.55%) (27183/27584) | Learning rate: (1e-05)
2022-06-06 21:54:49,782 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 440 |  Loss: (0.0431) | Acc: (98.53%) (27810/28224) | Learning rate: (1e-05)
2022-06-06 21:54:51,578 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 450 |  Loss: (0.0428) | Acc: (98.55%) (28445/28864) | Learning rate: (1e-05)
2022-06-06 21:54:53,374 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 460 |  Loss: (0.0425) | Acc: (98.57%) (29081/29504) | Learning rate: (1e-05)
2022-06-06 21:54:55,168 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 470 |  Loss: (0.0425) | Acc: (98.57%) (29713/30144) | Learning rate: (1e-05)
2022-06-06 21:54:56,962 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 480 |  Loss: (0.0425) | Acc: (98.57%) (30344/30784) | Learning rate: (1e-05)
2022-06-06 21:54:58,759 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 490 |  Loss: (0.0423) | Acc: (98.58%) (30977/31424) | Learning rate: (1e-05)
2022-06-06 21:55:00,555 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 500 |  Loss: (0.0422) | Acc: (98.58%) (31610/32064) | Learning rate: (1e-05)
2022-06-06 21:55:02,354 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 510 |  Loss: (0.0422) | Acc: (98.58%) (32241/32704) | Learning rate: (1e-05)
2022-06-06 21:55:04,150 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 520 |  Loss: (0.0419) | Acc: (98.60%) (32877/33344) | Learning rate: (1e-05)
2022-06-06 21:55:05,945 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 530 |  Loss: (0.0421) | Acc: (98.59%) (33505/33984) | Learning rate: (1e-05)
2022-06-06 21:55:07,741 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 540 |  Loss: (0.0422) | Acc: (98.58%) (34133/34624) | Learning rate: (1e-05)
2022-06-06 21:55:09,537 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 550 |  Loss: (0.0422) | Acc: (98.58%) (34764/35264) | Learning rate: (1e-05)
2022-06-06 21:55:11,337 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 560 |  Loss: (0.0420) | Acc: (98.59%) (35397/35904) | Learning rate: (1e-05)
2022-06-06 21:55:13,134 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 570 |  Loss: (0.0418) | Acc: (98.60%) (36032/36544) | Learning rate: (1e-05)
2022-06-06 21:55:14,931 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 580 |  Loss: (0.0418) | Acc: (98.60%) (36663/37184) | Learning rate: (1e-05)
2022-06-06 21:55:16,729 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 590 |  Loss: (0.0419) | Acc: (98.59%) (37290/37824) | Learning rate: (1e-05)
2022-06-06 21:55:18,526 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 600 |  Loss: (0.0416) | Acc: (98.60%) (37924/38464) | Learning rate: (1e-05)
2022-06-06 21:55:20,322 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 610 |  Loss: (0.0417) | Acc: (98.59%) (38552/39104) | Learning rate: (1e-05)
2022-06-06 21:55:22,118 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 620 |  Loss: (0.0415) | Acc: (98.60%) (39186/39744) | Learning rate: (1e-05)
2022-06-06 21:55:23,916 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 630 |  Loss: (0.0417) | Acc: (98.59%) (39814/40384) | Learning rate: (1e-05)
2022-06-06 21:55:25,712 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 640 |  Loss: (0.0418) | Acc: (98.59%) (40444/41024) | Learning rate: (1e-05)
2022-06-06 21:55:27,511 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 650 |  Loss: (0.0417) | Acc: (98.59%) (41076/41664) | Learning rate: (1e-05)
2022-06-06 21:55:29,310 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 660 |  Loss: (0.0416) | Acc: (98.59%) (41709/42304) | Learning rate: (1e-05)
2022-06-06 21:55:31,106 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 670 |  Loss: (0.0415) | Acc: (98.59%) (42337/42944) | Learning rate: (1e-05)
2022-06-06 21:55:32,905 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 680 |  Loss: (0.0414) | Acc: (98.60%) (42972/43584) | Learning rate: (1e-05)
2022-06-06 21:55:34,702 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 690 |  Loss: (0.0412) | Acc: (98.60%) (43606/44224) | Learning rate: (1e-05)
2022-06-06 21:55:36,501 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 700 |  Loss: (0.0411) | Acc: (98.60%) (44236/44864) | Learning rate: (1e-05)
2022-06-06 21:55:38,299 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 710 |  Loss: (0.0410) | Acc: (98.60%) (44868/45504) | Learning rate: (1e-05)
2022-06-06 21:55:40,098 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 720 |  Loss: (0.0410) | Acc: (98.60%) (45498/46144) | Learning rate: (1e-05)
2022-06-06 21:55:41,894 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 730 |  Loss: (0.0409) | Acc: (98.60%) (46130/46784) | Learning rate: (1e-05)
2022-06-06 21:55:43,690 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 740 |  Loss: (0.0408) | Acc: (98.60%) (46759/47424) | Learning rate: (1e-05)
2022-06-06 21:55:45,486 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 750 |  Loss: (0.0406) | Acc: (98.60%) (47393/48064) | Learning rate: (1e-05)
2022-06-06 21:55:47,285 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 760 |  Loss: (0.0407) | Acc: (98.60%) (48022/48704) | Learning rate: (1e-05)
2022-06-06 21:55:49,075 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 770 |  Loss: (0.0408) | Acc: (98.60%) (48653/49344) | Learning rate: (1e-05)
2022-06-06 21:55:50,862 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 780 |  Loss: (0.0408) | Acc: (98.60%) (49286/49984) | Learning rate: (1e-05)
2022-06-06 21:56:00,826 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1155) | Acc: (96.46%) (9646/10000)
2022-06-06 21:56:00,827 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:56:01,638 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 0 |  Loss: (0.0286) | Acc: (98.44%) (63/64) | Learning rate: (1e-05)
2022-06-06 21:56:03,449 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 10 |  Loss: (0.0365) | Acc: (98.86%) (696/704) | Learning rate: (1e-05)
2022-06-06 21:56:05,242 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 20 |  Loss: (0.0290) | Acc: (99.11%) (1332/1344) | Learning rate: (1e-05)
2022-06-06 21:56:07,035 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 30 |  Loss: (0.0353) | Acc: (98.79%) (1960/1984) | Learning rate: (1e-05)
2022-06-06 21:56:08,829 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 40 |  Loss: (0.0324) | Acc: (98.97%) (2597/2624) | Learning rate: (1e-05)
2022-06-06 21:56:10,624 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 50 |  Loss: (0.0338) | Acc: (98.96%) (3230/3264) | Learning rate: (1e-05)
2022-06-06 21:56:12,418 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 60 |  Loss: (0.0343) | Acc: (98.87%) (3860/3904) | Learning rate: (1e-05)
2022-06-06 21:56:14,214 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 70 |  Loss: (0.0324) | Acc: (98.94%) (4496/4544) | Learning rate: (1e-05)
2022-06-06 21:56:16,010 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 80 |  Loss: (0.0320) | Acc: (98.96%) (5130/5184) | Learning rate: (1e-05)
2022-06-06 21:56:17,805 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 90 |  Loss: (0.0344) | Acc: (98.90%) (5760/5824) | Learning rate: (1e-05)
2022-06-06 21:56:19,600 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 100 |  Loss: (0.0353) | Acc: (98.86%) (6390/6464) | Learning rate: (1e-05)
2022-06-06 21:56:21,395 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 110 |  Loss: (0.0333) | Acc: (98.94%) (7029/7104) | Learning rate: (1e-05)
2022-06-06 21:56:23,189 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 120 |  Loss: (0.0337) | Acc: (98.98%) (7665/7744) | Learning rate: (1e-05)
2022-06-06 21:56:24,985 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 130 |  Loss: (0.0336) | Acc: (99.00%) (8300/8384) | Learning rate: (1e-05)
2022-06-06 21:56:26,782 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 140 |  Loss: (0.0332) | Acc: (99.00%) (8934/9024) | Learning rate: (1e-05)
2022-06-06 21:56:28,575 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 150 |  Loss: (0.0325) | Acc: (99.04%) (9571/9664) | Learning rate: (1e-05)
2022-06-06 21:56:30,371 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 160 |  Loss: (0.0328) | Acc: (98.99%) (10200/10304) | Learning rate: (1e-05)
2022-06-06 21:56:32,166 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 170 |  Loss: (0.0327) | Acc: (98.99%) (10834/10944) | Learning rate: (1e-05)
2022-06-06 21:56:33,962 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 180 |  Loss: (0.0332) | Acc: (98.96%) (11464/11584) | Learning rate: (1e-05)
2022-06-06 21:56:35,757 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 190 |  Loss: (0.0334) | Acc: (98.95%) (12096/12224) | Learning rate: (1e-05)
2022-06-06 21:56:37,551 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 200 |  Loss: (0.0334) | Acc: (98.97%) (12731/12864) | Learning rate: (1e-05)
2022-06-06 21:56:39,347 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 210 |  Loss: (0.0335) | Acc: (98.97%) (13365/13504) | Learning rate: (1e-05)
2022-06-06 21:56:41,143 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 220 |  Loss: (0.0329) | Acc: (98.99%) (14001/14144) | Learning rate: (1e-05)
2022-06-06 21:56:42,939 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 230 |  Loss: (0.0327) | Acc: (99.01%) (14638/14784) | Learning rate: (1e-05)
2022-06-06 21:56:44,734 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 240 |  Loss: (0.0321) | Acc: (99.03%) (15275/15424) | Learning rate: (1e-05)
2022-06-06 21:56:46,528 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 250 |  Loss: (0.0327) | Acc: (99.02%) (15906/16064) | Learning rate: (1e-05)
2022-06-06 21:56:48,323 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 260 |  Loss: (0.0328) | Acc: (99.02%) (16540/16704) | Learning rate: (1e-05)
2022-06-06 21:56:50,119 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 270 |  Loss: (0.0330) | Acc: (99.01%) (17172/17344) | Learning rate: (1e-05)
2022-06-06 21:56:51,915 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 280 |  Loss: (0.0328) | Acc: (99.02%) (17808/17984) | Learning rate: (1e-05)
2022-06-06 21:56:53,710 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 290 |  Loss: (0.0322) | Acc: (99.04%) (18446/18624) | Learning rate: (1e-05)
2022-06-06 21:56:55,505 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 300 |  Loss: (0.0322) | Acc: (99.03%) (19078/19264) | Learning rate: (1e-05)
2022-06-06 21:56:57,301 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 310 |  Loss: (0.0322) | Acc: (99.04%) (19713/19904) | Learning rate: (1e-05)
2022-06-06 21:56:59,098 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 320 |  Loss: (0.0322) | Acc: (99.02%) (20343/20544) | Learning rate: (1e-05)
2022-06-06 21:57:00,893 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 330 |  Loss: (0.0319) | Acc: (99.03%) (20979/21184) | Learning rate: (1e-05)
2022-06-06 21:57:02,691 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 340 |  Loss: (0.0315) | Acc: (99.04%) (21614/21824) | Learning rate: (1e-05)
2022-06-06 21:57:04,486 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 350 |  Loss: (0.0319) | Acc: (99.03%) (22245/22464) | Learning rate: (1e-05)
2022-06-06 21:57:06,280 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 360 |  Loss: (0.0321) | Acc: (99.00%) (22873/23104) | Learning rate: (1e-05)
2022-06-06 21:57:08,077 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 370 |  Loss: (0.0320) | Acc: (99.01%) (23508/23744) | Learning rate: (1e-05)
2022-06-06 21:57:09,873 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 380 |  Loss: (0.0324) | Acc: (99.00%) (24139/24384) | Learning rate: (1e-05)
2022-06-06 21:57:11,669 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 390 |  Loss: (0.0327) | Acc: (98.98%) (24768/25024) | Learning rate: (1e-05)
2022-06-06 21:57:13,464 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 400 |  Loss: (0.0327) | Acc: (98.98%) (25401/25664) | Learning rate: (1e-05)
2022-06-06 21:57:15,260 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 410 |  Loss: (0.0324) | Acc: (98.97%) (26034/26304) | Learning rate: (1e-05)
2022-06-06 21:57:17,055 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 420 |  Loss: (0.0325) | Acc: (98.98%) (26668/26944) | Learning rate: (1e-05)
2022-06-06 21:57:18,852 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 430 |  Loss: (0.0322) | Acc: (98.98%) (27303/27584) | Learning rate: (1e-05)
2022-06-06 21:57:20,648 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 440 |  Loss: (0.0325) | Acc: (98.98%) (27937/28224) | Learning rate: (1e-05)
2022-06-06 21:57:22,444 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 450 |  Loss: (0.0327) | Acc: (98.97%) (28566/28864) | Learning rate: (1e-05)
2022-06-06 21:57:24,241 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 460 |  Loss: (0.0325) | Acc: (98.98%) (29203/29504) | Learning rate: (1e-05)
2022-06-06 21:57:26,034 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 470 |  Loss: (0.0325) | Acc: (98.98%) (29836/30144) | Learning rate: (1e-05)
2022-06-06 21:57:27,830 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 480 |  Loss: (0.0326) | Acc: (98.98%) (30469/30784) | Learning rate: (1e-05)
2022-06-06 21:57:29,627 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 490 |  Loss: (0.0327) | Acc: (98.97%) (31101/31424) | Learning rate: (1e-05)
2022-06-06 21:57:31,423 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 500 |  Loss: (0.0330) | Acc: (98.96%) (31731/32064) | Learning rate: (1e-05)
2022-06-06 21:57:33,222 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 510 |  Loss: (0.0330) | Acc: (98.96%) (32363/32704) | Learning rate: (1e-05)
2022-06-06 21:57:35,017 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 520 |  Loss: (0.0328) | Acc: (98.97%) (33000/33344) | Learning rate: (1e-05)
2022-06-06 21:57:36,813 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 530 |  Loss: (0.0329) | Acc: (98.96%) (33630/33984) | Learning rate: (1e-05)
2022-06-06 21:57:38,609 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 540 |  Loss: (0.0331) | Acc: (98.95%) (34259/34624) | Learning rate: (1e-05)
2022-06-06 21:57:40,405 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 550 |  Loss: (0.0329) | Acc: (98.95%) (34893/35264) | Learning rate: (1e-05)
2022-06-06 21:57:42,202 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 560 |  Loss: (0.0329) | Acc: (98.95%) (35527/35904) | Learning rate: (1e-05)
2022-06-06 21:57:43,999 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 570 |  Loss: (0.0331) | Acc: (98.93%) (36154/36544) | Learning rate: (1e-05)
2022-06-06 21:57:45,797 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 580 |  Loss: (0.0332) | Acc: (98.94%) (36789/37184) | Learning rate: (1e-05)
2022-06-06 21:57:47,594 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 590 |  Loss: (0.0334) | Acc: (98.92%) (37417/37824) | Learning rate: (1e-05)
2022-06-06 21:57:49,389 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 600 |  Loss: (0.0335) | Acc: (98.92%) (38048/38464) | Learning rate: (1e-05)
2022-06-06 21:57:51,184 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 610 |  Loss: (0.0337) | Acc: (98.91%) (38678/39104) | Learning rate: (1e-05)
2022-06-06 21:57:52,981 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 620 |  Loss: (0.0336) | Acc: (98.92%) (39313/39744) | Learning rate: (1e-05)
2022-06-06 21:57:54,777 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 630 |  Loss: (0.0336) | Acc: (98.91%) (39945/40384) | Learning rate: (1e-05)
2022-06-06 21:57:56,574 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 640 |  Loss: (0.0334) | Acc: (98.93%) (40583/41024) | Learning rate: (1e-05)
2022-06-06 21:57:58,370 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 650 |  Loss: (0.0334) | Acc: (98.92%) (41216/41664) | Learning rate: (1e-05)
2022-06-06 21:58:00,166 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 660 |  Loss: (0.0335) | Acc: (98.92%) (41848/42304) | Learning rate: (1e-05)
2022-06-06 21:58:01,961 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 670 |  Loss: (0.0332) | Acc: (98.93%) (42486/42944) | Learning rate: (1e-05)
2022-06-06 21:58:03,758 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 680 |  Loss: (0.0334) | Acc: (98.93%) (43117/43584) | Learning rate: (1e-05)
2022-06-06 21:58:05,556 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 690 |  Loss: (0.0335) | Acc: (98.92%) (43748/44224) | Learning rate: (1e-05)
2022-06-06 21:58:07,351 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 700 |  Loss: (0.0335) | Acc: (98.92%) (44379/44864) | Learning rate: (1e-05)
2022-06-06 21:58:09,150 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 710 |  Loss: (0.0336) | Acc: (98.91%) (45010/45504) | Learning rate: (1e-05)
2022-06-06 21:58:10,944 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 720 |  Loss: (0.0335) | Acc: (98.92%) (45645/46144) | Learning rate: (1e-05)
2022-06-06 21:58:12,740 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 730 |  Loss: (0.0334) | Acc: (98.92%) (46279/46784) | Learning rate: (1e-05)
2022-06-06 21:58:14,536 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 740 |  Loss: (0.0333) | Acc: (98.93%) (46915/47424) | Learning rate: (1e-05)
2022-06-06 21:58:16,332 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 750 |  Loss: (0.0333) | Acc: (98.93%) (47549/48064) | Learning rate: (1e-05)
2022-06-06 21:58:18,131 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 760 |  Loss: (0.0333) | Acc: (98.93%) (48182/48704) | Learning rate: (1e-05)
2022-06-06 21:58:19,919 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 770 |  Loss: (0.0334) | Acc: (98.92%) (48813/49344) | Learning rate: (1e-05)
2022-06-06 21:58:21,708 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 780 |  Loss: (0.0333) | Acc: (98.93%) (49450/49984) | Learning rate: (1e-05)
2022-06-06 21:58:31,695 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1079) | Acc: (96.82%) (9682/10000)
2022-06-06 21:58:31,696 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 21:58:32,685 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 0 |  Loss: (0.0359) | Acc: (98.44%) (63/64) | Learning rate: (1e-05)
2022-06-06 21:58:34,474 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 10 |  Loss: (0.0414) | Acc: (98.58%) (694/704) | Learning rate: (1e-05)
2022-06-06 21:58:36,266 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 20 |  Loss: (0.0402) | Acc: (98.51%) (1324/1344) | Learning rate: (1e-05)
2022-06-06 21:58:38,060 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 30 |  Loss: (0.0349) | Acc: (98.84%) (1961/1984) | Learning rate: (1e-05)
2022-06-06 21:58:39,853 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 40 |  Loss: (0.0368) | Acc: (98.78%) (2592/2624) | Learning rate: (1e-05)
2022-06-06 21:58:41,647 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 50 |  Loss: (0.0352) | Acc: (98.81%) (3225/3264) | Learning rate: (1e-05)
2022-06-06 21:58:43,444 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 60 |  Loss: (0.0347) | Acc: (98.87%) (3860/3904) | Learning rate: (1e-05)
2022-06-06 21:58:45,239 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 70 |  Loss: (0.0331) | Acc: (98.92%) (4495/4544) | Learning rate: (1e-05)
2022-06-06 21:58:47,034 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 80 |  Loss: (0.0330) | Acc: (98.90%) (5127/5184) | Learning rate: (1e-05)
2022-06-06 21:58:48,827 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 90 |  Loss: (0.0337) | Acc: (98.87%) (5758/5824) | Learning rate: (1e-05)
2022-06-06 21:58:50,622 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 100 |  Loss: (0.0330) | Acc: (98.87%) (6391/6464) | Learning rate: (1e-05)
2022-06-06 21:58:52,417 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 110 |  Loss: (0.0339) | Acc: (98.86%) (7023/7104) | Learning rate: (1e-05)
2022-06-06 21:58:54,211 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 120 |  Loss: (0.0347) | Acc: (98.81%) (7652/7744) | Learning rate: (1e-05)
2022-06-06 21:58:56,005 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 130 |  Loss: (0.0336) | Acc: (98.87%) (8289/8384) | Learning rate: (1e-05)
2022-06-06 21:58:57,801 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 140 |  Loss: (0.0334) | Acc: (98.87%) (8922/9024) | Learning rate: (1e-05)
2022-06-06 21:58:59,596 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 150 |  Loss: (0.0333) | Acc: (98.87%) (9555/9664) | Learning rate: (1e-05)
2022-06-06 21:59:01,392 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 160 |  Loss: (0.0335) | Acc: (98.85%) (10186/10304) | Learning rate: (1e-05)
2022-06-06 21:59:03,186 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 170 |  Loss: (0.0334) | Acc: (98.86%) (10819/10944) | Learning rate: (1e-05)
2022-06-06 21:59:04,982 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 180 |  Loss: (0.0327) | Acc: (98.87%) (11453/11584) | Learning rate: (1e-05)
2022-06-06 21:59:06,778 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 190 |  Loss: (0.0321) | Acc: (98.88%) (12087/12224) | Learning rate: (1e-05)
2022-06-06 21:59:08,574 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 200 |  Loss: (0.0318) | Acc: (98.88%) (12720/12864) | Learning rate: (1e-05)
2022-06-06 21:59:10,371 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 210 |  Loss: (0.0314) | Acc: (98.90%) (13355/13504) | Learning rate: (1e-05)
2022-06-06 21:59:12,167 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 220 |  Loss: (0.0313) | Acc: (98.90%) (13989/14144) | Learning rate: (1e-05)
2022-06-06 21:59:13,961 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 230 |  Loss: (0.0314) | Acc: (98.90%) (14622/14784) | Learning rate: (1e-05)
2022-06-06 21:59:15,755 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 240 |  Loss: (0.0315) | Acc: (98.91%) (15256/15424) | Learning rate: (1e-05)
2022-06-06 21:59:17,551 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 250 |  Loss: (0.0313) | Acc: (98.91%) (15889/16064) | Learning rate: (1e-05)
2022-06-06 21:59:19,348 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 260 |  Loss: (0.0314) | Acc: (98.89%) (16519/16704) | Learning rate: (1e-05)
2022-06-06 21:59:21,144 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 270 |  Loss: (0.0319) | Acc: (98.88%) (17149/17344) | Learning rate: (1e-05)
2022-06-06 21:59:22,939 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 280 |  Loss: (0.0318) | Acc: (98.89%) (17784/17984) | Learning rate: (1e-05)
2022-06-06 21:59:24,735 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 290 |  Loss: (0.0321) | Acc: (98.88%) (18416/18624) | Learning rate: (1e-05)
2022-06-06 21:59:26,530 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 300 |  Loss: (0.0323) | Acc: (98.89%) (19050/19264) | Learning rate: (1e-05)
2022-06-06 21:59:28,327 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 310 |  Loss: (0.0330) | Acc: (98.86%) (19677/19904) | Learning rate: (1e-05)
2022-06-06 21:59:30,122 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 320 |  Loss: (0.0327) | Acc: (98.87%) (20311/20544) | Learning rate: (1e-05)
2022-06-06 21:59:31,919 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 330 |  Loss: (0.0329) | Acc: (98.85%) (20940/21184) | Learning rate: (1e-05)
2022-06-06 21:59:33,714 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 340 |  Loss: (0.0328) | Acc: (98.85%) (21574/21824) | Learning rate: (1e-05)
2022-06-06 21:59:35,509 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 350 |  Loss: (0.0327) | Acc: (98.86%) (22207/22464) | Learning rate: (1e-05)
2022-06-06 21:59:37,306 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 360 |  Loss: (0.0324) | Acc: (98.87%) (22843/23104) | Learning rate: (1e-05)
2022-06-06 21:59:39,103 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 370 |  Loss: (0.0327) | Acc: (98.85%) (23471/23744) | Learning rate: (1e-05)
2022-06-06 21:59:40,899 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 380 |  Loss: (0.0333) | Acc: (98.84%) (24102/24384) | Learning rate: (1e-05)
2022-06-06 21:59:42,696 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 390 |  Loss: (0.0331) | Acc: (98.85%) (24737/25024) | Learning rate: (1e-05)
2022-06-06 21:59:44,490 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 400 |  Loss: (0.0333) | Acc: (98.85%) (25368/25664) | Learning rate: (1e-05)
2022-06-06 21:59:46,286 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 410 |  Loss: (0.0331) | Acc: (98.86%) (26004/26304) | Learning rate: (1e-05)
2022-06-06 21:59:48,082 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 420 |  Loss: (0.0329) | Acc: (98.87%) (26639/26944) | Learning rate: (1e-05)
2022-06-06 21:59:49,878 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 430 |  Loss: (0.0326) | Acc: (98.88%) (27274/27584) | Learning rate: (1e-05)
2022-06-06 21:59:51,673 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 440 |  Loss: (0.0329) | Acc: (98.87%) (27906/28224) | Learning rate: (1e-05)
2022-06-06 21:59:53,468 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 450 |  Loss: (0.0328) | Acc: (98.88%) (28541/28864) | Learning rate: (1e-05)
2022-06-06 21:59:55,263 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 460 |  Loss: (0.0327) | Acc: (98.89%) (29176/29504) | Learning rate: (1e-05)
2022-06-06 21:59:57,059 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 470 |  Loss: (0.0324) | Acc: (98.90%) (29813/30144) | Learning rate: (1e-05)
2022-06-06 21:59:58,856 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 480 |  Loss: (0.0327) | Acc: (98.90%) (30444/30784) | Learning rate: (1e-05)
2022-06-06 22:00:00,652 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 490 |  Loss: (0.0333) | Acc: (98.88%) (31072/31424) | Learning rate: (1e-05)
2022-06-06 22:00:02,448 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 500 |  Loss: (0.0332) | Acc: (98.89%) (31707/32064) | Learning rate: (1e-05)
2022-06-06 22:00:04,244 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 510 |  Loss: (0.0334) | Acc: (98.88%) (32338/32704) | Learning rate: (1e-05)
2022-06-06 22:00:06,038 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 520 |  Loss: (0.0338) | Acc: (98.87%) (32968/33344) | Learning rate: (1e-05)
2022-06-06 22:00:07,835 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 530 |  Loss: (0.0339) | Acc: (98.87%) (33601/33984) | Learning rate: (1e-05)
2022-06-06 22:00:09,632 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 540 |  Loss: (0.0342) | Acc: (98.86%) (34230/34624) | Learning rate: (1e-05)
2022-06-06 22:00:11,427 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 550 |  Loss: (0.0340) | Acc: (98.87%) (34866/35264) | Learning rate: (1e-05)
2022-06-06 22:00:13,225 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 560 |  Loss: (0.0344) | Acc: (98.86%) (35493/35904) | Learning rate: (1e-05)
2022-06-06 22:00:15,018 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 570 |  Loss: (0.0344) | Acc: (98.86%) (36127/36544) | Learning rate: (1e-05)
2022-06-06 22:00:16,815 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 580 |  Loss: (0.0344) | Acc: (98.85%) (36756/37184) | Learning rate: (1e-05)
2022-06-06 22:00:18,614 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 590 |  Loss: (0.0344) | Acc: (98.85%) (37389/37824) | Learning rate: (1e-05)
2022-06-06 22:00:20,410 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 600 |  Loss: (0.0343) | Acc: (98.86%) (38024/38464) | Learning rate: (1e-05)
2022-06-06 22:00:22,207 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 610 |  Loss: (0.0341) | Acc: (98.86%) (38659/39104) | Learning rate: (1e-05)
2022-06-06 22:00:24,003 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 620 |  Loss: (0.0342) | Acc: (98.86%) (39290/39744) | Learning rate: (1e-05)
2022-06-06 22:00:25,797 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 630 |  Loss: (0.0342) | Acc: (98.86%) (39922/40384) | Learning rate: (1e-05)
2022-06-06 22:00:27,592 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 640 |  Loss: (0.0344) | Acc: (98.84%) (40550/41024) | Learning rate: (1e-05)
2022-06-06 22:00:29,390 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 650 |  Loss: (0.0341) | Acc: (98.86%) (41188/41664) | Learning rate: (1e-05)
2022-06-06 22:00:31,188 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 660 |  Loss: (0.0341) | Acc: (98.86%) (41821/42304) | Learning rate: (1e-05)
2022-06-06 22:00:32,985 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 670 |  Loss: (0.0340) | Acc: (98.86%) (42455/42944) | Learning rate: (1e-05)
2022-06-06 22:00:34,781 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 680 |  Loss: (0.0340) | Acc: (98.86%) (43089/43584) | Learning rate: (1e-05)
2022-06-06 22:00:36,577 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 690 |  Loss: (0.0339) | Acc: (98.87%) (43725/44224) | Learning rate: (1e-05)
2022-06-06 22:00:38,371 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 700 |  Loss: (0.0340) | Acc: (98.87%) (44357/44864) | Learning rate: (1e-05)
2022-06-06 22:00:40,168 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 710 |  Loss: (0.0340) | Acc: (98.86%) (44987/45504) | Learning rate: (1e-05)
2022-06-06 22:00:41,965 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 720 |  Loss: (0.0339) | Acc: (98.87%) (45621/46144) | Learning rate: (1e-05)
2022-06-06 22:00:43,762 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 730 |  Loss: (0.0340) | Acc: (98.86%) (46253/46784) | Learning rate: (1e-05)
2022-06-06 22:00:45,559 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 740 |  Loss: (0.0341) | Acc: (98.87%) (46886/47424) | Learning rate: (1e-05)
2022-06-06 22:00:47,354 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 750 |  Loss: (0.0342) | Acc: (98.87%) (47519/48064) | Learning rate: (1e-05)
2022-06-06 22:00:49,151 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 760 |  Loss: (0.0340) | Acc: (98.87%) (48155/48704) | Learning rate: (1e-05)
2022-06-06 22:00:50,940 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 770 |  Loss: (0.0342) | Acc: (98.87%) (48784/49344) | Learning rate: (1e-05)
2022-06-06 22:00:52,727 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 780 |  Loss: (0.0342) | Acc: (98.87%) (49418/49984) | Learning rate: (1e-05)
2022-06-06 22:01:02,700 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.1100) | Acc: (96.85%) (9685/10000)
2022-06-06 22:01:02,701 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:01:03,521 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 0 |  Loss: (0.0259) | Acc: (100.00%) (64/64) | Learning rate: (1e-05)
2022-06-06 22:01:05,336 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 10 |  Loss: (0.0353) | Acc: (99.43%) (700/704) | Learning rate: (1e-05)
2022-06-06 22:01:07,127 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 20 |  Loss: (0.0286) | Acc: (99.33%) (1335/1344) | Learning rate: (1e-05)
2022-06-06 22:01:08,917 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 30 |  Loss: (0.0248) | Acc: (99.45%) (1973/1984) | Learning rate: (1e-05)
2022-06-06 22:01:10,712 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 40 |  Loss: (0.0254) | Acc: (99.35%) (2607/2624) | Learning rate: (1e-05)
2022-06-06 22:01:12,505 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 50 |  Loss: (0.0252) | Acc: (99.30%) (3241/3264) | Learning rate: (1e-05)
2022-06-06 22:01:14,298 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 60 |  Loss: (0.0258) | Acc: (99.28%) (3876/3904) | Learning rate: (1e-05)
2022-06-06 22:01:16,093 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 70 |  Loss: (0.0255) | Acc: (99.30%) (4512/4544) | Learning rate: (1e-05)
2022-06-06 22:01:17,887 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 80 |  Loss: (0.0252) | Acc: (99.31%) (5148/5184) | Learning rate: (1e-05)
2022-06-06 22:01:19,681 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 90 |  Loss: (0.0251) | Acc: (99.28%) (5782/5824) | Learning rate: (1e-05)
2022-06-06 22:01:21,474 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 100 |  Loss: (0.0254) | Acc: (99.23%) (6414/6464) | Learning rate: (1e-05)
2022-06-06 22:01:23,270 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 110 |  Loss: (0.0258) | Acc: (99.20%) (7047/7104) | Learning rate: (1e-05)
2022-06-06 22:01:25,065 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 120 |  Loss: (0.0254) | Acc: (99.23%) (7684/7744) | Learning rate: (1e-05)
2022-06-06 22:01:26,858 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 130 |  Loss: (0.0249) | Acc: (99.24%) (8320/8384) | Learning rate: (1e-05)
2022-06-06 22:01:28,652 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 140 |  Loss: (0.0248) | Acc: (99.24%) (8955/9024) | Learning rate: (1e-05)
2022-06-06 22:01:30,448 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 150 |  Loss: (0.0258) | Acc: (99.19%) (9586/9664) | Learning rate: (1e-05)
2022-06-06 22:01:32,243 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 160 |  Loss: (0.0258) | Acc: (99.18%) (10220/10304) | Learning rate: (1e-05)
2022-06-06 22:01:34,037 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 170 |  Loss: (0.0257) | Acc: (99.19%) (10855/10944) | Learning rate: (1e-05)
2022-06-06 22:01:35,830 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 180 |  Loss: (0.0251) | Acc: (99.21%) (11492/11584) | Learning rate: (1e-05)
2022-06-06 22:01:37,625 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 190 |  Loss: (0.0253) | Acc: (99.20%) (12126/12224) | Learning rate: (1e-05)
2022-06-06 22:01:39,422 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 200 |  Loss: (0.0252) | Acc: (99.18%) (12759/12864) | Learning rate: (1e-05)
2022-06-06 22:01:41,217 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 210 |  Loss: (0.0252) | Acc: (99.19%) (13395/13504) | Learning rate: (1e-05)
2022-06-06 22:01:43,011 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 220 |  Loss: (0.0254) | Acc: (99.19%) (14029/14144) | Learning rate: (1e-05)
2022-06-06 22:01:44,806 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 230 |  Loss: (0.0252) | Acc: (99.18%) (14663/14784) | Learning rate: (1e-05)
2022-06-06 22:01:46,601 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 240 |  Loss: (0.0251) | Acc: (99.18%) (15297/15424) | Learning rate: (1e-05)
2022-06-06 22:01:48,395 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 250 |  Loss: (0.0252) | Acc: (99.16%) (15929/16064) | Learning rate: (1e-05)
2022-06-06 22:01:50,189 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 260 |  Loss: (0.0255) | Acc: (99.16%) (16563/16704) | Learning rate: (1e-05)
2022-06-06 22:01:51,983 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 270 |  Loss: (0.0258) | Acc: (99.14%) (17194/17344) | Learning rate: (1e-05)
2022-06-06 22:01:53,779 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 280 |  Loss: (0.0262) | Acc: (99.13%) (17827/17984) | Learning rate: (1e-05)
2022-06-06 22:01:55,575 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 290 |  Loss: (0.0262) | Acc: (99.13%) (18462/18624) | Learning rate: (1e-05)
2022-06-06 22:01:57,368 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 300 |  Loss: (0.0270) | Acc: (99.11%) (19092/19264) | Learning rate: (1e-05)
2022-06-06 22:01:59,163 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 310 |  Loss: (0.0267) | Acc: (99.12%) (19728/19904) | Learning rate: (1e-05)
2022-06-06 22:02:00,958 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 320 |  Loss: (0.0265) | Acc: (99.12%) (20363/20544) | Learning rate: (1e-05)
2022-06-06 22:02:02,753 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 330 |  Loss: (0.0266) | Acc: (99.10%) (20994/21184) | Learning rate: (1e-05)
2022-06-06 22:02:04,549 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 340 |  Loss: (0.0268) | Acc: (99.10%) (21628/21824) | Learning rate: (1e-05)
2022-06-06 22:02:06,343 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 350 |  Loss: (0.0268) | Acc: (99.10%) (22262/22464) | Learning rate: (1e-05)
2022-06-06 22:02:08,139 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 360 |  Loss: (0.0269) | Acc: (99.10%) (22896/23104) | Learning rate: (1e-05)
2022-06-06 22:02:09,935 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 370 |  Loss: (0.0268) | Acc: (99.10%) (23530/23744) | Learning rate: (1e-05)
2022-06-06 22:02:11,730 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 380 |  Loss: (0.0271) | Acc: (99.09%) (24162/24384) | Learning rate: (1e-05)
2022-06-06 22:02:56,414 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 22:02:56,416 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 22:02:56,417 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 22:02:56,417 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 22:02:56,417 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 22:02:57,430 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (1.1109) | Acc: (78.12%) (50/64) | Learning rate: (1e-05)
2022-06-06 22:03:29,001 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 22:03:29,003 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 22:03:29,005 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 22:03:29,005 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 22:03:29,005 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 22:05:42,325 - CIFAR10 Classifier - INFO - Experiment (Training Phase): CIFAR10 Classifier
2022-06-06 22:05:42,327 - CIFAR10 Classifier - INFO - Model : 
EfficientNetWrapper(
  (efficientnet): EfficientNet(
    (features): Sequential(
      (0): ConvNormActivation(
        (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (1): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.0, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (2): ConvNormActivation(
              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)
        )
      )
      (2): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)
        )
      )
      (3): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)
        )
      )
      (4): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)
        )
      )
      (5): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)
        )
      )
      (6): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)
              (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)
        )
        (2): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)
        )
        (3): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)
        )
        (4): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)
        )
        (5): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)
        )
      )
      (7): Sequential(
        (0): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)
              (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)
        )
        (1): MBConv(
          (block): Sequential(
            (0): ConvNormActivation(
              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (1): ConvNormActivation(
              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
              (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): SiLU(inplace=True)
            )
            (2): SqueezeExcitation(
              (avgpool): AdaptiveAvgPool2d(output_size=1)
              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))
              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))
              (activation): SiLU(inplace=True)
              (scale_activation): Sigmoid()
            )
            (3): ConvNormActivation(
              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)
        )
      )
      (8): ConvNormActivation(
        (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1536, out_features=10, bias=True)
    )
  )
)
2022-06-06 22:05:42,328 - CIFAR10 Classifier - INFO - Devices : cuda:0
2022-06-06 22:05:42,328 - CIFAR10 Classifier - INFO - Devices ID : [0]
2022-06-06 22:05:42,328 - CIFAR10 Classifier - INFO - See detail of experiment at saved/CIFAR10 Classifier/EfficientNetWrapper/train/config.json
2022-06-06 22:05:43,393 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 0 |  Loss: (0.0297) | Acc: (98.44%) (63/64) | Learning rate: (1e-05)
2022-06-06 22:05:45,162 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 10 |  Loss: (0.0102) | Acc: (99.43%) (700/704) | Learning rate: (1e-05)
2022-06-06 22:05:46,933 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 20 |  Loss: (0.0120) | Acc: (99.48%) (1337/1344) | Learning rate: (1e-05)
2022-06-06 22:05:48,698 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 30 |  Loss: (0.0094) | Acc: (99.55%) (1975/1984) | Learning rate: (1e-05)
2022-06-06 22:05:50,464 - CIFAR10 Classifier - INFO - Epoch: 0 | Batch_idx: 40 |  Loss: (0.0099) | Acc: (99.62%) (2614/2624) | Learning rate: (1e-05)
2022-06-06 22:06:06,000 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0818) | Acc: (97.91%) (9791/10000)
2022-06-06 22:06:06,001 - CIFAR10 Classifier - INFO - Epoch time : 0:00:23
2022-06-06 22:06:07,084 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 0 |  Loss: (0.0008) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:06:08,852 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 10 |  Loss: (0.0018) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:06:10,621 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 20 |  Loss: (0.0079) | Acc: (99.70%) (1340/1344) | Learning rate: (1e-06)
2022-06-06 22:06:12,391 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 30 |  Loss: (0.0068) | Acc: (99.75%) (1979/1984) | Learning rate: (1e-06)
2022-06-06 22:06:14,165 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 40 |  Loss: (0.0063) | Acc: (99.77%) (2618/2624) | Learning rate: (1e-06)
2022-06-06 22:06:15,937 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 50 |  Loss: (0.0053) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-06)
2022-06-06 22:06:17,713 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 60 |  Loss: (0.0058) | Acc: (99.77%) (3895/3904) | Learning rate: (1e-06)
2022-06-06 22:06:19,487 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 70 |  Loss: (0.0056) | Acc: (99.78%) (4534/4544) | Learning rate: (1e-06)
2022-06-06 22:06:21,260 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 80 |  Loss: (0.0053) | Acc: (99.81%) (5174/5184) | Learning rate: (1e-06)
2022-06-06 22:06:23,034 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 90 |  Loss: (0.0051) | Acc: (99.81%) (5813/5824) | Learning rate: (1e-06)
2022-06-06 22:06:24,811 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 100 |  Loss: (0.0059) | Acc: (99.80%) (6451/6464) | Learning rate: (1e-06)
2022-06-06 22:06:26,588 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 110 |  Loss: (0.0065) | Acc: (99.75%) (7086/7104) | Learning rate: (1e-06)
2022-06-06 22:06:28,366 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 120 |  Loss: (0.0060) | Acc: (99.77%) (7726/7744) | Learning rate: (1e-06)
2022-06-06 22:06:30,145 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 130 |  Loss: (0.0063) | Acc: (99.76%) (8364/8384) | Learning rate: (1e-06)
2022-06-06 22:06:31,923 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 140 |  Loss: (0.0066) | Acc: (99.76%) (9002/9024) | Learning rate: (1e-06)
2022-06-06 22:06:33,701 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 150 |  Loss: (0.0071) | Acc: (99.73%) (9638/9664) | Learning rate: (1e-06)
2022-06-06 22:06:35,480 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 160 |  Loss: (0.0069) | Acc: (99.74%) (10277/10304) | Learning rate: (1e-06)
2022-06-06 22:06:37,260 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 170 |  Loss: (0.0069) | Acc: (99.74%) (10915/10944) | Learning rate: (1e-06)
2022-06-06 22:06:39,040 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 180 |  Loss: (0.0067) | Acc: (99.75%) (11555/11584) | Learning rate: (1e-06)
2022-06-06 22:06:40,819 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 190 |  Loss: (0.0070) | Acc: (99.75%) (12193/12224) | Learning rate: (1e-06)
2022-06-06 22:06:42,599 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 200 |  Loss: (0.0067) | Acc: (99.76%) (12833/12864) | Learning rate: (1e-06)
2022-06-06 22:06:44,379 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 210 |  Loss: (0.0065) | Acc: (99.77%) (13473/13504) | Learning rate: (1e-06)
2022-06-06 22:06:46,159 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 220 |  Loss: (0.0063) | Acc: (99.77%) (14112/14144) | Learning rate: (1e-06)
2022-06-06 22:06:47,941 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 230 |  Loss: (0.0062) | Acc: (99.78%) (14751/14784) | Learning rate: (1e-06)
2022-06-06 22:06:49,724 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 240 |  Loss: (0.0059) | Acc: (99.79%) (15391/15424) | Learning rate: (1e-06)
2022-06-06 22:06:51,508 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 250 |  Loss: (0.0058) | Acc: (99.79%) (16031/16064) | Learning rate: (1e-06)
2022-06-06 22:06:53,294 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 260 |  Loss: (0.0056) | Acc: (99.80%) (16671/16704) | Learning rate: (1e-06)
2022-06-06 22:06:55,080 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 270 |  Loss: (0.0056) | Acc: (99.80%) (17310/17344) | Learning rate: (1e-06)
2022-06-06 22:06:56,865 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.81%) (17950/17984) | Learning rate: (1e-06)
2022-06-06 22:06:58,652 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 290 |  Loss: (0.0054) | Acc: (99.81%) (18589/18624) | Learning rate: (1e-06)
2022-06-06 22:07:00,439 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.81%) (19227/19264) | Learning rate: (1e-06)
2022-06-06 22:07:02,224 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 310 |  Loss: (0.0055) | Acc: (99.81%) (19867/19904) | Learning rate: (1e-06)
2022-06-06 22:07:04,010 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 320 |  Loss: (0.0055) | Acc: (99.82%) (20506/20544) | Learning rate: (1e-06)
2022-06-06 22:07:05,796 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.82%) (21146/21184) | Learning rate: (1e-06)
2022-06-06 22:07:07,582 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 340 |  Loss: (0.0054) | Acc: (99.82%) (21785/21824) | Learning rate: (1e-06)
2022-06-06 22:07:09,369 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 350 |  Loss: (0.0055) | Acc: (99.81%) (22422/22464) | Learning rate: (1e-06)
2022-06-06 22:07:11,155 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.81%) (23061/23104) | Learning rate: (1e-06)
2022-06-06 22:07:12,943 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 370 |  Loss: (0.0053) | Acc: (99.82%) (23701/23744) | Learning rate: (1e-06)
2022-06-06 22:07:14,730 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.82%) (24340/24384) | Learning rate: (1e-06)
2022-06-06 22:07:16,517 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.82%) (24978/25024) | Learning rate: (1e-06)
2022-06-06 22:07:18,305 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 400 |  Loss: (0.0054) | Acc: (99.82%) (25617/25664) | Learning rate: (1e-06)
2022-06-06 22:07:20,093 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 410 |  Loss: (0.0053) | Acc: (99.82%) (26256/26304) | Learning rate: (1e-06)
2022-06-06 22:07:21,880 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 420 |  Loss: (0.0053) | Acc: (99.82%) (26895/26944) | Learning rate: (1e-06)
2022-06-06 22:07:23,669 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 430 |  Loss: (0.0055) | Acc: (99.82%) (27534/27584) | Learning rate: (1e-06)
2022-06-06 22:07:25,457 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 440 |  Loss: (0.0054) | Acc: (99.82%) (28174/28224) | Learning rate: (1e-06)
2022-06-06 22:07:27,245 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 450 |  Loss: (0.0055) | Acc: (99.82%) (28813/28864) | Learning rate: (1e-06)
2022-06-06 22:07:29,033 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 460 |  Loss: (0.0055) | Acc: (99.82%) (29452/29504) | Learning rate: (1e-06)
2022-06-06 22:07:30,822 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 470 |  Loss: (0.0054) | Acc: (99.82%) (30091/30144) | Learning rate: (1e-06)
2022-06-06 22:07:32,611 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 480 |  Loss: (0.0054) | Acc: (99.83%) (30731/30784) | Learning rate: (1e-06)
2022-06-06 22:07:34,401 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 490 |  Loss: (0.0053) | Acc: (99.83%) (31371/31424) | Learning rate: (1e-06)
2022-06-06 22:07:36,192 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 500 |  Loss: (0.0053) | Acc: (99.83%) (32011/32064) | Learning rate: (1e-06)
2022-06-06 22:07:37,984 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 510 |  Loss: (0.0053) | Acc: (99.83%) (32650/32704) | Learning rate: (1e-06)
2022-06-06 22:07:39,772 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 520 |  Loss: (0.0052) | Acc: (99.84%) (33290/33344) | Learning rate: (1e-06)
2022-06-06 22:07:41,563 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 530 |  Loss: (0.0052) | Acc: (99.84%) (33929/33984) | Learning rate: (1e-06)
2022-06-06 22:07:43,355 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 540 |  Loss: (0.0053) | Acc: (99.84%) (34567/34624) | Learning rate: (1e-06)
2022-06-06 22:07:45,146 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 550 |  Loss: (0.0053) | Acc: (99.84%) (35206/35264) | Learning rate: (1e-06)
2022-06-06 22:07:46,937 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 560 |  Loss: (0.0052) | Acc: (99.84%) (35846/35904) | Learning rate: (1e-06)
2022-06-06 22:07:48,728 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 570 |  Loss: (0.0053) | Acc: (99.84%) (36484/36544) | Learning rate: (1e-06)
2022-06-06 22:07:50,519 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 580 |  Loss: (0.0052) | Acc: (99.84%) (37123/37184) | Learning rate: (1e-06)
2022-06-06 22:07:52,308 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 590 |  Loss: (0.0053) | Acc: (99.83%) (37761/37824) | Learning rate: (1e-06)
2022-06-06 22:07:54,101 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 600 |  Loss: (0.0053) | Acc: (99.83%) (38399/38464) | Learning rate: (1e-06)
2022-06-06 22:07:55,893 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 610 |  Loss: (0.0052) | Acc: (99.83%) (39039/39104) | Learning rate: (1e-06)
2022-06-06 22:07:57,684 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 620 |  Loss: (0.0053) | Acc: (99.83%) (39676/39744) | Learning rate: (1e-06)
2022-06-06 22:07:59,476 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 630 |  Loss: (0.0054) | Acc: (99.83%) (40314/40384) | Learning rate: (1e-06)
2022-06-06 22:08:01,266 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 640 |  Loss: (0.0053) | Acc: (99.83%) (40954/41024) | Learning rate: (1e-06)
2022-06-06 22:08:03,057 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 650 |  Loss: (0.0053) | Acc: (99.83%) (41594/41664) | Learning rate: (1e-06)
2022-06-06 22:08:04,849 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 660 |  Loss: (0.0054) | Acc: (99.83%) (42231/42304) | Learning rate: (1e-06)
2022-06-06 22:08:06,640 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 670 |  Loss: (0.0053) | Acc: (99.83%) (42871/42944) | Learning rate: (1e-06)
2022-06-06 22:08:08,433 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 680 |  Loss: (0.0053) | Acc: (99.83%) (43510/43584) | Learning rate: (1e-06)
2022-06-06 22:08:10,226 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 690 |  Loss: (0.0053) | Acc: (99.83%) (44149/44224) | Learning rate: (1e-06)
2022-06-06 22:08:12,017 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 700 |  Loss: (0.0053) | Acc: (99.83%) (44788/44864) | Learning rate: (1e-06)
2022-06-06 22:08:13,810 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 710 |  Loss: (0.0053) | Acc: (99.83%) (45428/45504) | Learning rate: (1e-06)
2022-06-06 22:08:15,602 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 720 |  Loss: (0.0053) | Acc: (99.83%) (46067/46144) | Learning rate: (1e-06)
2022-06-06 22:08:17,394 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 730 |  Loss: (0.0052) | Acc: (99.84%) (46707/46784) | Learning rate: (1e-06)
2022-06-06 22:08:19,188 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 740 |  Loss: (0.0052) | Acc: (99.84%) (47347/47424) | Learning rate: (1e-06)
2022-06-06 22:08:20,979 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 750 |  Loss: (0.0053) | Acc: (99.83%) (47983/48064) | Learning rate: (1e-06)
2022-06-06 22:08:22,772 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 760 |  Loss: (0.0052) | Acc: (99.83%) (48623/48704) | Learning rate: (1e-06)
2022-06-06 22:08:24,557 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 770 |  Loss: (0.0052) | Acc: (99.83%) (49261/49344) | Learning rate: (1e-06)
2022-06-06 22:08:26,342 - CIFAR10 Classifier - INFO - Epoch: 1 | Batch_idx: 780 |  Loss: (0.0052) | Acc: (99.83%) (49901/49984) | Learning rate: (1e-06)
2022-06-06 22:08:36,246 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0794) | Acc: (98.01%) (9801/10000)
2022-06-06 22:08:36,247 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:08:37,363 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 0 |  Loss: (0.0050) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:08:39,169 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 10 |  Loss: (0.0037) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:08:40,956 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 20 |  Loss: (0.0040) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 22:08:42,745 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 30 |  Loss: (0.0065) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 22:08:44,535 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 22:08:46,324 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 22:08:48,116 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 60 |  Loss: (0.0052) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-06)
2022-06-06 22:08:49,907 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 70 |  Loss: (0.0048) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-06)
2022-06-06 22:08:51,699 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 22:08:53,489 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 90 |  Loss: (0.0045) | Acc: (99.90%) (5818/5824) | Learning rate: (1e-06)
2022-06-06 22:08:55,281 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-06)
2022-06-06 22:08:57,074 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-06)
2022-06-06 22:08:58,866 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 120 |  Loss: (0.0046) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 22:09:00,658 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 130 |  Loss: (0.0052) | Acc: (99.86%) (8372/8384) | Learning rate: (1e-06)
2022-06-06 22:09:02,450 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 140 |  Loss: (0.0052) | Acc: (99.86%) (9011/9024) | Learning rate: (1e-06)
2022-06-06 22:09:04,241 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 150 |  Loss: (0.0052) | Acc: (99.86%) (9650/9664) | Learning rate: (1e-06)
2022-06-06 22:09:06,033 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 22:09:07,827 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.84%) (10926/10944) | Learning rate: (1e-06)
2022-06-06 22:09:09,621 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 180 |  Loss: (0.0053) | Acc: (99.84%) (11565/11584) | Learning rate: (1e-06)
2022-06-06 22:09:11,416 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.84%) (12205/12224) | Learning rate: (1e-06)
2022-06-06 22:09:13,212 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 200 |  Loss: (0.0052) | Acc: (99.85%) (12845/12864) | Learning rate: (1e-06)
2022-06-06 22:09:15,007 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.85%) (13484/13504) | Learning rate: (1e-06)
2022-06-06 22:09:16,802 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.85%) (14123/14144) | Learning rate: (1e-06)
2022-06-06 22:09:18,597 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.85%) (14762/14784) | Learning rate: (1e-06)
2022-06-06 22:09:20,391 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 240 |  Loss: (0.0050) | Acc: (99.86%) (15402/15424) | Learning rate: (1e-06)
2022-06-06 22:09:22,187 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 250 |  Loss: (0.0049) | Acc: (99.86%) (16041/16064) | Learning rate: (1e-06)
2022-06-06 22:09:23,984 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-06)
2022-06-06 22:09:25,779 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 270 |  Loss: (0.0049) | Acc: (99.86%) (17319/17344) | Learning rate: (1e-06)
2022-06-06 22:09:27,575 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 280 |  Loss: (0.0048) | Acc: (99.86%) (17958/17984) | Learning rate: (1e-06)
2022-06-06 22:09:29,370 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.86%) (18597/18624) | Learning rate: (1e-06)
2022-06-06 22:09:31,165 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.85%) (19236/19264) | Learning rate: (1e-06)
2022-06-06 22:09:32,960 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.85%) (19874/19904) | Learning rate: (1e-06)
2022-06-06 22:09:34,755 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 320 |  Loss: (0.0049) | Acc: (99.85%) (20514/20544) | Learning rate: (1e-06)
2022-06-06 22:09:36,551 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.85%) (21153/21184) | Learning rate: (1e-06)
2022-06-06 22:09:38,350 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 340 |  Loss: (0.0049) | Acc: (99.85%) (21792/21824) | Learning rate: (1e-06)
2022-06-06 22:09:40,147 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.85%) (22430/22464) | Learning rate: (1e-06)
2022-06-06 22:09:41,944 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.85%) (23070/23104) | Learning rate: (1e-06)
2022-06-06 22:09:43,741 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 370 |  Loss: (0.0049) | Acc: (99.86%) (23710/23744) | Learning rate: (1e-06)
2022-06-06 22:09:45,540 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 380 |  Loss: (0.0048) | Acc: (99.86%) (24350/24384) | Learning rate: (1e-06)
2022-06-06 22:09:47,338 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 390 |  Loss: (0.0048) | Acc: (99.86%) (24989/25024) | Learning rate: (1e-06)
2022-06-06 22:09:49,133 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 400 |  Loss: (0.0047) | Acc: (99.86%) (25629/25664) | Learning rate: (1e-06)
2022-06-06 22:09:50,931 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 410 |  Loss: (0.0047) | Acc: (99.86%) (26268/26304) | Learning rate: (1e-06)
2022-06-06 22:09:52,731 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 420 |  Loss: (0.0046) | Acc: (99.87%) (26908/26944) | Learning rate: (1e-06)
2022-06-06 22:09:54,527 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 430 |  Loss: (0.0046) | Acc: (99.87%) (27548/27584) | Learning rate: (1e-06)
2022-06-06 22:09:56,325 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 440 |  Loss: (0.0046) | Acc: (99.87%) (28188/28224) | Learning rate: (1e-06)
2022-06-06 22:09:58,122 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 450 |  Loss: (0.0046) | Acc: (99.87%) (28827/28864) | Learning rate: (1e-06)
2022-06-06 22:09:59,920 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 460 |  Loss: (0.0048) | Acc: (99.87%) (29466/29504) | Learning rate: (1e-06)
2022-06-06 22:10:01,716 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 470 |  Loss: (0.0048) | Acc: (99.87%) (30105/30144) | Learning rate: (1e-06)
2022-06-06 22:10:03,514 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 480 |  Loss: (0.0047) | Acc: (99.87%) (30745/30784) | Learning rate: (1e-06)
2022-06-06 22:10:05,310 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 490 |  Loss: (0.0049) | Acc: (99.87%) (31384/31424) | Learning rate: (1e-06)
2022-06-06 22:10:07,105 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 500 |  Loss: (0.0048) | Acc: (99.87%) (32023/32064) | Learning rate: (1e-06)
2022-06-06 22:10:08,901 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 510 |  Loss: (0.0048) | Acc: (99.87%) (32662/32704) | Learning rate: (1e-06)
2022-06-06 22:10:10,699 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 520 |  Loss: (0.0048) | Acc: (99.87%) (33302/33344) | Learning rate: (1e-06)
2022-06-06 22:10:12,496 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 530 |  Loss: (0.0048) | Acc: (99.87%) (33941/33984) | Learning rate: (1e-06)
2022-06-06 22:10:14,292 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 540 |  Loss: (0.0049) | Acc: (99.87%) (34578/34624) | Learning rate: (1e-06)
2022-06-06 22:10:16,089 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 550 |  Loss: (0.0048) | Acc: (99.87%) (35218/35264) | Learning rate: (1e-06)
2022-06-06 22:10:17,885 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 560 |  Loss: (0.0048) | Acc: (99.87%) (35858/35904) | Learning rate: (1e-06)
2022-06-06 22:10:19,680 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 570 |  Loss: (0.0048) | Acc: (99.87%) (36496/36544) | Learning rate: (1e-06)
2022-06-06 22:10:21,477 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 580 |  Loss: (0.0049) | Acc: (99.87%) (37135/37184) | Learning rate: (1e-06)
2022-06-06 22:10:23,275 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 590 |  Loss: (0.0049) | Acc: (99.87%) (37774/37824) | Learning rate: (1e-06)
2022-06-06 22:10:25,074 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 600 |  Loss: (0.0048) | Acc: (99.87%) (38414/38464) | Learning rate: (1e-06)
2022-06-06 22:10:26,871 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 610 |  Loss: (0.0048) | Acc: (99.87%) (39054/39104) | Learning rate: (1e-06)
2022-06-06 22:10:28,669 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 620 |  Loss: (0.0048) | Acc: (99.87%) (39692/39744) | Learning rate: (1e-06)
2022-06-06 22:10:30,467 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 630 |  Loss: (0.0049) | Acc: (99.87%) (40332/40384) | Learning rate: (1e-06)
2022-06-06 22:10:32,264 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 640 |  Loss: (0.0048) | Acc: (99.87%) (40972/41024) | Learning rate: (1e-06)
2022-06-06 22:10:34,060 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 650 |  Loss: (0.0048) | Acc: (99.88%) (41612/41664) | Learning rate: (1e-06)
2022-06-06 22:10:35,857 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 660 |  Loss: (0.0048) | Acc: (99.87%) (42251/42304) | Learning rate: (1e-06)
2022-06-06 22:10:37,653 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 670 |  Loss: (0.0049) | Acc: (99.87%) (42890/42944) | Learning rate: (1e-06)
2022-06-06 22:10:39,451 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 680 |  Loss: (0.0048) | Acc: (99.87%) (43529/43584) | Learning rate: (1e-06)
2022-06-06 22:10:41,249 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 690 |  Loss: (0.0049) | Acc: (99.87%) (44168/44224) | Learning rate: (1e-06)
2022-06-06 22:10:43,049 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 700 |  Loss: (0.0049) | Acc: (99.87%) (44807/44864) | Learning rate: (1e-06)
2022-06-06 22:10:44,849 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 710 |  Loss: (0.0049) | Acc: (99.87%) (45446/45504) | Learning rate: (1e-06)
2022-06-06 22:10:46,647 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 720 |  Loss: (0.0049) | Acc: (99.87%) (46085/46144) | Learning rate: (1e-06)
2022-06-06 22:10:48,447 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 730 |  Loss: (0.0048) | Acc: (99.87%) (46725/46784) | Learning rate: (1e-06)
2022-06-06 22:10:50,246 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 740 |  Loss: (0.0048) | Acc: (99.88%) (47365/47424) | Learning rate: (1e-06)
2022-06-06 22:10:52,046 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 750 |  Loss: (0.0048) | Acc: (99.87%) (48003/48064) | Learning rate: (1e-06)
2022-06-06 22:10:53,845 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 760 |  Loss: (0.0048) | Acc: (99.87%) (48642/48704) | Learning rate: (1e-06)
2022-06-06 22:10:55,635 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 770 |  Loss: (0.0048) | Acc: (99.87%) (49282/49344) | Learning rate: (1e-06)
2022-06-06 22:10:57,425 - CIFAR10 Classifier - INFO - Epoch: 2 | Batch_idx: 780 |  Loss: (0.0047) | Acc: (99.88%) (49922/49984) | Learning rate: (1e-06)
2022-06-06 22:11:07,356 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0817) | Acc: (97.97%) (9797/10000)
2022-06-06 22:11:07,357 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:11:08,397 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 0 |  Loss: (0.0064) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:11:10,182 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 10 |  Loss: (0.0043) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:11:11,974 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 20 |  Loss: (0.0033) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 22:11:13,769 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 30 |  Loss: (0.0028) | Acc: (100.00%) (1984/1984) | Learning rate: (1e-06)
2022-06-06 22:11:15,563 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 22:11:17,358 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 50 |  Loss: (0.0047) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 22:11:19,155 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 60 |  Loss: (0.0048) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 22:11:20,950 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 70 |  Loss: (0.0051) | Acc: (99.85%) (4537/4544) | Learning rate: (1e-06)
2022-06-06 22:11:22,746 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.85%) (5176/5184) | Learning rate: (1e-06)
2022-06-06 22:11:24,541 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.83%) (5814/5824) | Learning rate: (1e-06)
2022-06-06 22:11:26,335 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 100 |  Loss: (0.0047) | Acc: (99.85%) (6454/6464) | Learning rate: (1e-06)
2022-06-06 22:11:28,133 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 110 |  Loss: (0.0046) | Acc: (99.86%) (7094/7104) | Learning rate: (1e-06)
2022-06-06 22:11:29,930 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.86%) (7733/7744) | Learning rate: (1e-06)
2022-06-06 22:11:31,726 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 130 |  Loss: (0.0048) | Acc: (99.86%) (8372/8384) | Learning rate: (1e-06)
2022-06-06 22:11:33,522 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 140 |  Loss: (0.0048) | Acc: (99.86%) (9011/9024) | Learning rate: (1e-06)
2022-06-06 22:11:35,316 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 150 |  Loss: (0.0047) | Acc: (99.87%) (9651/9664) | Learning rate: (1e-06)
2022-06-06 22:11:37,112 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 160 |  Loss: (0.0045) | Acc: (99.87%) (10291/10304) | Learning rate: (1e-06)
2022-06-06 22:11:38,908 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 170 |  Loss: (0.0044) | Acc: (99.88%) (10931/10944) | Learning rate: (1e-06)
2022-06-06 22:11:40,705 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 180 |  Loss: (0.0042) | Acc: (99.89%) (11571/11584) | Learning rate: (1e-06)
2022-06-06 22:11:42,502 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 190 |  Loss: (0.0041) | Acc: (99.89%) (12211/12224) | Learning rate: (1e-06)
2022-06-06 22:11:44,297 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 200 |  Loss: (0.0041) | Acc: (99.89%) (12850/12864) | Learning rate: (1e-06)
2022-06-06 22:11:46,092 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 210 |  Loss: (0.0040) | Acc: (99.89%) (13489/13504) | Learning rate: (1e-06)
2022-06-06 22:11:47,885 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 220 |  Loss: (0.0041) | Acc: (99.88%) (14127/14144) | Learning rate: (1e-06)
2022-06-06 22:11:49,680 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 230 |  Loss: (0.0041) | Acc: (99.88%) (14766/14784) | Learning rate: (1e-06)
2022-06-06 22:11:51,474 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 240 |  Loss: (0.0041) | Acc: (99.87%) (15404/15424) | Learning rate: (1e-06)
2022-06-06 22:11:53,268 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 250 |  Loss: (0.0041) | Acc: (99.88%) (16044/16064) | Learning rate: (1e-06)
2022-06-06 22:11:55,063 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 260 |  Loss: (0.0042) | Acc: (99.87%) (16682/16704) | Learning rate: (1e-06)
2022-06-06 22:11:56,858 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 270 |  Loss: (0.0042) | Acc: (99.87%) (17321/17344) | Learning rate: (1e-06)
2022-06-06 22:11:58,652 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 280 |  Loss: (0.0041) | Acc: (99.87%) (17960/17984) | Learning rate: (1e-06)
2022-06-06 22:12:00,445 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 290 |  Loss: (0.0041) | Acc: (99.87%) (18600/18624) | Learning rate: (1e-06)
2022-06-06 22:12:02,242 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 300 |  Loss: (0.0041) | Acc: (99.88%) (19240/19264) | Learning rate: (1e-06)
2022-06-06 22:12:04,037 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 310 |  Loss: (0.0040) | Acc: (99.88%) (19880/19904) | Learning rate: (1e-06)
2022-06-06 22:12:05,831 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 320 |  Loss: (0.0040) | Acc: (99.88%) (20520/20544) | Learning rate: (1e-06)
2022-06-06 22:12:07,624 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 330 |  Loss: (0.0039) | Acc: (99.89%) (21160/21184) | Learning rate: (1e-06)
2022-06-06 22:12:09,420 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 340 |  Loss: (0.0038) | Acc: (99.89%) (21800/21824) | Learning rate: (1e-06)
2022-06-06 22:12:11,216 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.89%) (22440/22464) | Learning rate: (1e-06)
2022-06-06 22:12:13,012 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 360 |  Loss: (0.0037) | Acc: (99.90%) (23080/23104) | Learning rate: (1e-06)
2022-06-06 22:12:14,810 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 370 |  Loss: (0.0037) | Acc: (99.89%) (23719/23744) | Learning rate: (1e-06)
2022-06-06 22:12:16,607 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 380 |  Loss: (0.0036) | Acc: (99.90%) (24359/24384) | Learning rate: (1e-06)
2022-06-06 22:12:18,401 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 390 |  Loss: (0.0037) | Acc: (99.90%) (24998/25024) | Learning rate: (1e-06)
2022-06-06 22:12:20,197 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 400 |  Loss: (0.0037) | Acc: (99.89%) (25637/25664) | Learning rate: (1e-06)
2022-06-06 22:12:21,994 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 410 |  Loss: (0.0037) | Acc: (99.89%) (26276/26304) | Learning rate: (1e-06)
2022-06-06 22:12:23,791 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 420 |  Loss: (0.0038) | Acc: (99.89%) (26914/26944) | Learning rate: (1e-06)
2022-06-06 22:12:25,586 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 430 |  Loss: (0.0038) | Acc: (99.89%) (27554/27584) | Learning rate: (1e-06)
2022-06-06 22:12:27,383 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 440 |  Loss: (0.0038) | Acc: (99.89%) (28194/28224) | Learning rate: (1e-06)
2022-06-06 22:12:29,178 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 450 |  Loss: (0.0037) | Acc: (99.90%) (28834/28864) | Learning rate: (1e-06)
2022-06-06 22:12:30,976 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 460 |  Loss: (0.0037) | Acc: (99.89%) (29472/29504) | Learning rate: (1e-06)
2022-06-06 22:12:32,773 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 470 |  Loss: (0.0037) | Acc: (99.89%) (30112/30144) | Learning rate: (1e-06)
2022-06-06 22:12:34,572 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 480 |  Loss: (0.0037) | Acc: (99.90%) (30752/30784) | Learning rate: (1e-06)
2022-06-06 22:12:36,369 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 490 |  Loss: (0.0038) | Acc: (99.89%) (31390/31424) | Learning rate: (1e-06)
2022-06-06 22:12:38,165 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 500 |  Loss: (0.0037) | Acc: (99.89%) (32030/32064) | Learning rate: (1e-06)
2022-06-06 22:12:39,962 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 510 |  Loss: (0.0037) | Acc: (99.90%) (32670/32704) | Learning rate: (1e-06)
2022-06-06 22:12:41,756 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 520 |  Loss: (0.0037) | Acc: (99.90%) (33310/33344) | Learning rate: (1e-06)
2022-06-06 22:12:43,554 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 530 |  Loss: (0.0037) | Acc: (99.90%) (33949/33984) | Learning rate: (1e-06)
2022-06-06 22:12:45,349 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 540 |  Loss: (0.0037) | Acc: (99.90%) (34589/34624) | Learning rate: (1e-06)
2022-06-06 22:12:47,146 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 550 |  Loss: (0.0036) | Acc: (99.90%) (35229/35264) | Learning rate: (1e-06)
2022-06-06 22:12:48,944 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 560 |  Loss: (0.0038) | Acc: (99.90%) (35867/35904) | Learning rate: (1e-06)
2022-06-06 22:12:50,739 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 570 |  Loss: (0.0038) | Acc: (99.90%) (36506/36544) | Learning rate: (1e-06)
2022-06-06 22:12:52,537 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 580 |  Loss: (0.0038) | Acc: (99.90%) (37146/37184) | Learning rate: (1e-06)
2022-06-06 22:12:54,331 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 590 |  Loss: (0.0038) | Acc: (99.89%) (37784/37824) | Learning rate: (1e-06)
2022-06-06 22:12:56,126 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 600 |  Loss: (0.0039) | Acc: (99.89%) (38422/38464) | Learning rate: (1e-06)
2022-06-06 22:12:57,924 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 610 |  Loss: (0.0039) | Acc: (99.89%) (39062/39104) | Learning rate: (1e-06)
2022-06-06 22:12:59,719 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 620 |  Loss: (0.0039) | Acc: (99.89%) (39701/39744) | Learning rate: (1e-06)
2022-06-06 22:13:01,515 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 630 |  Loss: (0.0039) | Acc: (99.89%) (40340/40384) | Learning rate: (1e-06)
2022-06-06 22:13:03,310 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 640 |  Loss: (0.0038) | Acc: (99.89%) (40980/41024) | Learning rate: (1e-06)
2022-06-06 22:13:05,106 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 650 |  Loss: (0.0039) | Acc: (99.89%) (41618/41664) | Learning rate: (1e-06)
2022-06-06 22:13:06,903 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 660 |  Loss: (0.0039) | Acc: (99.89%) (42257/42304) | Learning rate: (1e-06)
2022-06-06 22:13:08,701 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 670 |  Loss: (0.0041) | Acc: (99.89%) (42895/42944) | Learning rate: (1e-06)
2022-06-06 22:13:10,496 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 680 |  Loss: (0.0041) | Acc: (99.89%) (43535/43584) | Learning rate: (1e-06)
2022-06-06 22:13:12,295 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 690 |  Loss: (0.0041) | Acc: (99.88%) (44173/44224) | Learning rate: (1e-06)
2022-06-06 22:13:14,093 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 700 |  Loss: (0.0041) | Acc: (99.88%) (44812/44864) | Learning rate: (1e-06)
2022-06-06 22:13:15,892 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 710 |  Loss: (0.0041) | Acc: (99.88%) (45451/45504) | Learning rate: (1e-06)
2022-06-06 22:13:17,691 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 720 |  Loss: (0.0042) | Acc: (99.88%) (46089/46144) | Learning rate: (1e-06)
2022-06-06 22:13:19,489 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 730 |  Loss: (0.0043) | Acc: (99.88%) (46727/46784) | Learning rate: (1e-06)
2022-06-06 22:13:21,286 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 740 |  Loss: (0.0043) | Acc: (99.88%) (47367/47424) | Learning rate: (1e-06)
2022-06-06 22:13:23,082 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 750 |  Loss: (0.0043) | Acc: (99.88%) (48005/48064) | Learning rate: (1e-06)
2022-06-06 22:13:24,881 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 760 |  Loss: (0.0043) | Acc: (99.88%) (48645/48704) | Learning rate: (1e-06)
2022-06-06 22:13:26,670 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 770 |  Loss: (0.0042) | Acc: (99.88%) (49284/49344) | Learning rate: (1e-06)
2022-06-06 22:13:28,460 - CIFAR10 Classifier - INFO - Epoch: 3 | Batch_idx: 780 |  Loss: (0.0042) | Acc: (99.88%) (49924/49984) | Learning rate: (1e-06)
2022-06-06 22:13:38,404 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0825) | Acc: (97.92%) (9792/10000)
2022-06-06 22:13:38,405 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:13:39,424 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 0 |  Loss: (0.0006) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:13:41,213 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 10 |  Loss: (0.0017) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:13:43,008 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 20 |  Loss: (0.0018) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 22:13:44,803 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 30 |  Loss: (0.0037) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 22:13:46,599 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 40 |  Loss: (0.0037) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 22:13:48,394 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 50 |  Loss: (0.0036) | Acc: (99.88%) (3260/3264) | Learning rate: (1e-06)
2022-06-06 22:13:50,190 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 60 |  Loss: (0.0037) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 22:13:51,986 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-06)
2022-06-06 22:13:53,783 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 80 |  Loss: (0.0059) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-06)
2022-06-06 22:13:55,579 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 90 |  Loss: (0.0057) | Acc: (99.86%) (5816/5824) | Learning rate: (1e-06)
2022-06-06 22:13:57,376 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 100 |  Loss: (0.0058) | Acc: (99.86%) (6455/6464) | Learning rate: (1e-06)
2022-06-06 22:13:59,173 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 110 |  Loss: (0.0057) | Acc: (99.86%) (7094/7104) | Learning rate: (1e-06)
2022-06-06 22:14:00,969 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.85%) (7732/7744) | Learning rate: (1e-06)
2022-06-06 22:14:02,765 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 130 |  Loss: (0.0054) | Acc: (99.84%) (8371/8384) | Learning rate: (1e-06)
2022-06-06 22:14:04,561 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 140 |  Loss: (0.0053) | Acc: (99.84%) (9010/9024) | Learning rate: (1e-06)
2022-06-06 22:14:06,356 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 150 |  Loss: (0.0050) | Acc: (99.86%) (9650/9664) | Learning rate: (1e-06)
2022-06-06 22:14:08,153 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 22:14:09,948 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.84%) (10927/10944) | Learning rate: (1e-06)
2022-06-06 22:14:11,743 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 180 |  Loss: (0.0059) | Acc: (99.83%) (11564/11584) | Learning rate: (1e-06)
2022-06-06 22:14:13,539 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 190 |  Loss: (0.0057) | Acc: (99.84%) (12204/12224) | Learning rate: (1e-06)
2022-06-06 22:14:15,336 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.84%) (12844/12864) | Learning rate: (1e-06)
2022-06-06 22:14:17,135 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.85%) (13484/13504) | Learning rate: (1e-06)
2022-06-06 22:14:18,931 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 220 |  Loss: (0.0053) | Acc: (99.86%) (14124/14144) | Learning rate: (1e-06)
2022-06-06 22:14:20,727 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.86%) (14763/14784) | Learning rate: (1e-06)
2022-06-06 22:14:22,523 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.86%) (15403/15424) | Learning rate: (1e-06)
2022-06-06 22:14:24,316 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 250 |  Loss: (0.0051) | Acc: (99.86%) (16042/16064) | Learning rate: (1e-06)
2022-06-06 22:14:26,115 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 260 |  Loss: (0.0050) | Acc: (99.87%) (16682/16704) | Learning rate: (1e-06)
2022-06-06 22:14:27,912 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 270 |  Loss: (0.0050) | Acc: (99.87%) (17321/17344) | Learning rate: (1e-06)
2022-06-06 22:14:29,708 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 280 |  Loss: (0.0051) | Acc: (99.86%) (17959/17984) | Learning rate: (1e-06)
2022-06-06 22:14:31,506 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 290 |  Loss: (0.0051) | Acc: (99.86%) (18598/18624) | Learning rate: (1e-06)
2022-06-06 22:14:33,301 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 300 |  Loss: (0.0050) | Acc: (99.87%) (19238/19264) | Learning rate: (1e-06)
2022-06-06 22:14:35,096 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.87%) (19878/19904) | Learning rate: (1e-06)
2022-06-06 22:14:36,891 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 320 |  Loss: (0.0049) | Acc: (99.87%) (20517/20544) | Learning rate: (1e-06)
2022-06-06 22:14:38,689 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.86%) (21154/21184) | Learning rate: (1e-06)
2022-06-06 22:14:40,486 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 340 |  Loss: (0.0051) | Acc: (99.86%) (21793/21824) | Learning rate: (1e-06)
2022-06-06 22:14:42,282 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 350 |  Loss: (0.0051) | Acc: (99.86%) (22432/22464) | Learning rate: (1e-06)
2022-06-06 22:14:44,079 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 360 |  Loss: (0.0052) | Acc: (99.86%) (23071/23104) | Learning rate: (1e-06)
2022-06-06 22:14:45,874 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 370 |  Loss: (0.0052) | Acc: (99.86%) (23710/23744) | Learning rate: (1e-06)
2022-06-06 22:14:47,670 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 380 |  Loss: (0.0052) | Acc: (99.85%) (24348/24384) | Learning rate: (1e-06)
2022-06-06 22:14:49,467 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.85%) (24987/25024) | Learning rate: (1e-06)
2022-06-06 22:14:51,264 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 400 |  Loss: (0.0051) | Acc: (99.85%) (25625/25664) | Learning rate: (1e-06)
2022-06-06 22:14:53,063 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 410 |  Loss: (0.0052) | Acc: (99.85%) (26264/26304) | Learning rate: (1e-06)
2022-06-06 22:14:54,859 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 420 |  Loss: (0.0054) | Acc: (99.84%) (26902/26944) | Learning rate: (1e-06)
2022-06-06 22:14:56,658 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 430 |  Loss: (0.0053) | Acc: (99.85%) (27542/27584) | Learning rate: (1e-06)
2022-06-06 22:14:58,456 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 440 |  Loss: (0.0053) | Acc: (99.84%) (28180/28224) | Learning rate: (1e-06)
2022-06-06 22:15:00,253 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 450 |  Loss: (0.0055) | Acc: (99.84%) (28819/28864) | Learning rate: (1e-06)
2022-06-06 22:15:02,052 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 460 |  Loss: (0.0054) | Acc: (99.85%) (29459/29504) | Learning rate: (1e-06)
2022-06-06 22:15:03,847 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 470 |  Loss: (0.0053) | Acc: (99.85%) (30099/30144) | Learning rate: (1e-06)
2022-06-06 22:15:05,642 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 480 |  Loss: (0.0055) | Acc: (99.84%) (30734/30784) | Learning rate: (1e-06)
2022-06-06 22:15:07,441 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 490 |  Loss: (0.0056) | Acc: (99.83%) (31371/31424) | Learning rate: (1e-06)
2022-06-06 22:15:09,237 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 500 |  Loss: (0.0056) | Acc: (99.83%) (32010/32064) | Learning rate: (1e-06)
2022-06-06 22:15:11,036 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 510 |  Loss: (0.0055) | Acc: (99.83%) (32650/32704) | Learning rate: (1e-06)
2022-06-06 22:15:12,833 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 520 |  Loss: (0.0055) | Acc: (99.83%) (33287/33344) | Learning rate: (1e-06)
2022-06-06 22:15:14,631 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 530 |  Loss: (0.0055) | Acc: (99.83%) (33927/33984) | Learning rate: (1e-06)
2022-06-06 22:15:16,429 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 540 |  Loss: (0.0055) | Acc: (99.83%) (34564/34624) | Learning rate: (1e-06)
2022-06-06 22:15:18,223 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 550 |  Loss: (0.0055) | Acc: (99.83%) (35203/35264) | Learning rate: (1e-06)
2022-06-06 22:15:20,019 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 560 |  Loss: (0.0055) | Acc: (99.83%) (35842/35904) | Learning rate: (1e-06)
2022-06-06 22:15:21,816 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 570 |  Loss: (0.0056) | Acc: (99.82%) (36480/36544) | Learning rate: (1e-06)
2022-06-06 22:15:23,613 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 580 |  Loss: (0.0055) | Acc: (99.83%) (37119/37184) | Learning rate: (1e-06)
2022-06-06 22:15:25,411 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 590 |  Loss: (0.0055) | Acc: (99.83%) (37758/37824) | Learning rate: (1e-06)
2022-06-06 22:15:27,208 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 600 |  Loss: (0.0055) | Acc: (99.83%) (38398/38464) | Learning rate: (1e-06)
2022-06-06 22:15:29,008 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 610 |  Loss: (0.0056) | Acc: (99.83%) (39036/39104) | Learning rate: (1e-06)
2022-06-06 22:15:30,804 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 620 |  Loss: (0.0056) | Acc: (99.83%) (39675/39744) | Learning rate: (1e-06)
2022-06-06 22:15:32,600 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 630 |  Loss: (0.0055) | Acc: (99.83%) (40315/40384) | Learning rate: (1e-06)
2022-06-06 22:15:34,395 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 640 |  Loss: (0.0056) | Acc: (99.82%) (40952/41024) | Learning rate: (1e-06)
2022-06-06 22:15:36,192 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 650 |  Loss: (0.0056) | Acc: (99.83%) (41592/41664) | Learning rate: (1e-06)
2022-06-06 22:15:37,992 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 660 |  Loss: (0.0056) | Acc: (99.83%) (42231/42304) | Learning rate: (1e-06)
2022-06-06 22:15:39,789 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 670 |  Loss: (0.0055) | Acc: (99.83%) (42871/42944) | Learning rate: (1e-06)
2022-06-06 22:15:41,588 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 680 |  Loss: (0.0055) | Acc: (99.83%) (43510/43584) | Learning rate: (1e-06)
2022-06-06 22:15:43,384 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 690 |  Loss: (0.0055) | Acc: (99.83%) (44150/44224) | Learning rate: (1e-06)
2022-06-06 22:15:45,182 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 700 |  Loss: (0.0054) | Acc: (99.84%) (44790/44864) | Learning rate: (1e-06)
2022-06-06 22:15:46,980 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 710 |  Loss: (0.0054) | Acc: (99.84%) (45430/45504) | Learning rate: (1e-06)
2022-06-06 22:15:48,778 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 720 |  Loss: (0.0053) | Acc: (99.84%) (46070/46144) | Learning rate: (1e-06)
2022-06-06 22:15:50,575 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 730 |  Loss: (0.0053) | Acc: (99.84%) (46709/46784) | Learning rate: (1e-06)
2022-06-06 22:15:52,372 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 740 |  Loss: (0.0053) | Acc: (99.84%) (47348/47424) | Learning rate: (1e-06)
2022-06-06 22:15:54,167 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 750 |  Loss: (0.0052) | Acc: (99.84%) (47988/48064) | Learning rate: (1e-06)
2022-06-06 22:15:55,966 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 760 |  Loss: (0.0052) | Acc: (99.84%) (48628/48704) | Learning rate: (1e-06)
2022-06-06 22:15:57,757 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 770 |  Loss: (0.0052) | Acc: (99.84%) (49267/49344) | Learning rate: (1e-06)
2022-06-06 22:15:59,546 - CIFAR10 Classifier - INFO - Epoch: 4 | Batch_idx: 780 |  Loss: (0.0051) | Acc: (99.85%) (49907/49984) | Learning rate: (1e-06)
2022-06-06 22:16:09,515 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0821) | Acc: (97.98%) (9798/10000)
2022-06-06 22:16:09,516 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:16:10,456 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 0 |  Loss: (0.0026) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:16:12,278 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 10 |  Loss: (0.0019) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:16:14,072 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 20 |  Loss: (0.0019) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 22:16:15,863 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 30 |  Loss: (0.0023) | Acc: (100.00%) (1984/1984) | Learning rate: (1e-06)
2022-06-06 22:16:17,659 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 40 |  Loss: (0.0038) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 22:16:19,455 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 50 |  Loss: (0.0036) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-06)
2022-06-06 22:16:21,251 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 60 |  Loss: (0.0038) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 22:16:23,047 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 70 |  Loss: (0.0037) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-06)
2022-06-06 22:16:24,843 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 80 |  Loss: (0.0036) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-06)
2022-06-06 22:16:26,640 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 90 |  Loss: (0.0037) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 22:16:28,435 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-06)
2022-06-06 22:16:30,234 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.90%) (7097/7104) | Learning rate: (1e-06)
2022-06-06 22:16:32,032 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 120 |  Loss: (0.0042) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-06)
2022-06-06 22:16:33,829 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 130 |  Loss: (0.0040) | Acc: (99.92%) (8377/8384) | Learning rate: (1e-06)
2022-06-06 22:16:35,626 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 140 |  Loss: (0.0044) | Acc: (99.91%) (9016/9024) | Learning rate: (1e-06)
2022-06-06 22:16:37,421 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 150 |  Loss: (0.0046) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-06)
2022-06-06 22:16:39,217 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 160 |  Loss: (0.0048) | Acc: (99.88%) (10292/10304) | Learning rate: (1e-06)
2022-06-06 22:16:41,013 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.86%) (10929/10944) | Learning rate: (1e-06)
2022-06-06 22:16:42,810 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 180 |  Loss: (0.0050) | Acc: (99.87%) (11569/11584) | Learning rate: (1e-06)
2022-06-06 22:16:44,609 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 190 |  Loss: (0.0049) | Acc: (99.88%) (12209/12224) | Learning rate: (1e-06)
2022-06-06 22:16:46,407 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 200 |  Loss: (0.0050) | Acc: (99.88%) (12848/12864) | Learning rate: (1e-06)
2022-06-06 22:16:48,205 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 210 |  Loss: (0.0050) | Acc: (99.87%) (13486/13504) | Learning rate: (1e-06)
2022-06-06 22:16:50,005 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.87%) (14125/14144) | Learning rate: (1e-06)
2022-06-06 22:16:51,804 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 230 |  Loss: (0.0050) | Acc: (99.87%) (14765/14784) | Learning rate: (1e-06)
2022-06-06 22:16:53,600 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 240 |  Loss: (0.0050) | Acc: (99.87%) (15404/15424) | Learning rate: (1e-06)
2022-06-06 22:16:55,397 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.88%) (16044/16064) | Learning rate: (1e-06)
2022-06-06 22:16:57,193 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.88%) (16684/16704) | Learning rate: (1e-06)
2022-06-06 22:16:58,989 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 270 |  Loss: (0.0047) | Acc: (99.88%) (17324/17344) | Learning rate: (1e-06)
2022-06-06 22:17:00,785 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 280 |  Loss: (0.0046) | Acc: (99.89%) (17964/17984) | Learning rate: (1e-06)
2022-06-06 22:17:02,584 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.88%) (18602/18624) | Learning rate: (1e-06)
2022-06-06 22:17:04,380 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 300 |  Loss: (0.0047) | Acc: (99.88%) (19241/19264) | Learning rate: (1e-06)
2022-06-06 22:17:06,177 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 310 |  Loss: (0.0046) | Acc: (99.88%) (19881/19904) | Learning rate: (1e-06)
2022-06-06 22:17:07,976 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 320 |  Loss: (0.0046) | Acc: (99.88%) (20520/20544) | Learning rate: (1e-06)
2022-06-06 22:17:09,774 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 330 |  Loss: (0.0045) | Acc: (99.89%) (21160/21184) | Learning rate: (1e-06)
2022-06-06 22:17:11,573 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 340 |  Loss: (0.0046) | Acc: (99.88%) (21798/21824) | Learning rate: (1e-06)
2022-06-06 22:17:13,371 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 350 |  Loss: (0.0045) | Acc: (99.88%) (22438/22464) | Learning rate: (1e-06)
2022-06-06 22:17:15,167 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 360 |  Loss: (0.0046) | Acc: (99.87%) (23075/23104) | Learning rate: (1e-06)
2022-06-06 22:17:16,966 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 370 |  Loss: (0.0046) | Acc: (99.87%) (23714/23744) | Learning rate: (1e-06)
2022-06-06 22:17:18,761 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 380 |  Loss: (0.0048) | Acc: (99.86%) (24351/24384) | Learning rate: (1e-06)
2022-06-06 22:17:20,557 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 390 |  Loss: (0.0048) | Acc: (99.86%) (24990/25024) | Learning rate: (1e-06)
2022-06-06 22:17:22,356 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 400 |  Loss: (0.0048) | Acc: (99.86%) (25629/25664) | Learning rate: (1e-06)
2022-06-06 22:17:24,157 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 410 |  Loss: (0.0047) | Acc: (99.87%) (26269/26304) | Learning rate: (1e-06)
2022-06-06 22:17:25,954 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 420 |  Loss: (0.0047) | Acc: (99.87%) (26909/26944) | Learning rate: (1e-06)
2022-06-06 22:17:27,752 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 430 |  Loss: (0.0047) | Acc: (99.87%) (27548/27584) | Learning rate: (1e-06)
2022-06-06 22:17:29,549 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 440 |  Loss: (0.0047) | Acc: (99.87%) (28186/28224) | Learning rate: (1e-06)
2022-06-06 22:17:31,346 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 450 |  Loss: (0.0049) | Acc: (99.86%) (28824/28864) | Learning rate: (1e-06)
2022-06-06 22:17:33,143 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 460 |  Loss: (0.0050) | Acc: (99.86%) (29463/29504) | Learning rate: (1e-06)
2022-06-06 22:17:34,938 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 470 |  Loss: (0.0049) | Acc: (99.86%) (30103/30144) | Learning rate: (1e-06)
2022-06-06 22:17:36,734 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 480 |  Loss: (0.0049) | Acc: (99.87%) (30743/30784) | Learning rate: (1e-06)
2022-06-06 22:17:38,530 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 490 |  Loss: (0.0050) | Acc: (99.86%) (31381/31424) | Learning rate: (1e-06)
2022-06-06 22:17:40,327 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 500 |  Loss: (0.0050) | Acc: (99.86%) (32020/32064) | Learning rate: (1e-06)
2022-06-06 22:17:42,123 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 510 |  Loss: (0.0050) | Acc: (99.87%) (32660/32704) | Learning rate: (1e-06)
2022-06-06 22:17:43,920 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 520 |  Loss: (0.0050) | Acc: (99.86%) (33298/33344) | Learning rate: (1e-06)
2022-06-06 22:17:45,716 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 530 |  Loss: (0.0052) | Acc: (99.86%) (33935/33984) | Learning rate: (1e-06)
2022-06-06 22:17:47,512 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 540 |  Loss: (0.0051) | Acc: (99.86%) (34575/34624) | Learning rate: (1e-06)
2022-06-06 22:17:49,307 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 550 |  Loss: (0.0051) | Acc: (99.86%) (35215/35264) | Learning rate: (1e-06)
2022-06-06 22:17:51,104 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 560 |  Loss: (0.0051) | Acc: (99.86%) (35854/35904) | Learning rate: (1e-06)
2022-06-06 22:17:52,901 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 570 |  Loss: (0.0051) | Acc: (99.85%) (36491/36544) | Learning rate: (1e-06)
2022-06-06 22:17:54,698 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 580 |  Loss: (0.0051) | Acc: (99.85%) (37130/37184) | Learning rate: (1e-06)
2022-06-06 22:17:56,494 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 590 |  Loss: (0.0051) | Acc: (99.86%) (37770/37824) | Learning rate: (1e-06)
2022-06-06 22:17:58,289 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 600 |  Loss: (0.0051) | Acc: (99.86%) (38410/38464) | Learning rate: (1e-06)
2022-06-06 22:18:00,084 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 610 |  Loss: (0.0050) | Acc: (99.86%) (39050/39104) | Learning rate: (1e-06)
2022-06-06 22:18:01,883 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 620 |  Loss: (0.0051) | Acc: (99.86%) (39689/39744) | Learning rate: (1e-06)
2022-06-06 22:18:03,679 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 630 |  Loss: (0.0050) | Acc: (99.86%) (40328/40384) | Learning rate: (1e-06)
2022-06-06 22:18:05,476 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 640 |  Loss: (0.0050) | Acc: (99.86%) (40967/41024) | Learning rate: (1e-06)
2022-06-06 22:18:07,273 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 650 |  Loss: (0.0050) | Acc: (99.86%) (41606/41664) | Learning rate: (1e-06)
2022-06-06 22:18:09,070 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 660 |  Loss: (0.0050) | Acc: (99.86%) (42246/42304) | Learning rate: (1e-06)
2022-06-06 22:18:10,865 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 670 |  Loss: (0.0050) | Acc: (99.86%) (42885/42944) | Learning rate: (1e-06)
2022-06-06 22:18:12,661 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 680 |  Loss: (0.0050) | Acc: (99.86%) (43525/43584) | Learning rate: (1e-06)
2022-06-06 22:18:14,459 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 690 |  Loss: (0.0050) | Acc: (99.86%) (44164/44224) | Learning rate: (1e-06)
2022-06-06 22:18:16,258 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 700 |  Loss: (0.0050) | Acc: (99.86%) (44802/44864) | Learning rate: (1e-06)
2022-06-06 22:18:18,056 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 710 |  Loss: (0.0050) | Acc: (99.86%) (45439/45504) | Learning rate: (1e-06)
2022-06-06 22:18:19,853 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 720 |  Loss: (0.0050) | Acc: (99.86%) (46079/46144) | Learning rate: (1e-06)
2022-06-06 22:18:21,650 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 730 |  Loss: (0.0051) | Acc: (99.86%) (46717/46784) | Learning rate: (1e-06)
2022-06-06 22:18:23,448 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 740 |  Loss: (0.0051) | Acc: (99.86%) (47356/47424) | Learning rate: (1e-06)
2022-06-06 22:18:25,246 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 750 |  Loss: (0.0051) | Acc: (99.86%) (47995/48064) | Learning rate: (1e-06)
2022-06-06 22:18:27,042 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 760 |  Loss: (0.0051) | Acc: (99.86%) (48634/48704) | Learning rate: (1e-06)
2022-06-06 22:18:28,832 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 770 |  Loss: (0.0051) | Acc: (99.86%) (49274/49344) | Learning rate: (1e-06)
2022-06-06 22:18:30,623 - CIFAR10 Classifier - INFO - Epoch: 5 | Batch_idx: 780 |  Loss: (0.0051) | Acc: (99.86%) (49912/49984) | Learning rate: (1e-06)
2022-06-06 22:18:40,560 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0802) | Acc: (98.07%) (9807/10000)
2022-06-06 22:18:40,561 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:18:41,610 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 0 |  Loss: (0.0006) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:18:43,403 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 10 |  Loss: (0.0058) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:18:45,195 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 20 |  Loss: (0.0083) | Acc: (99.78%) (1341/1344) | Learning rate: (1e-06)
2022-06-06 22:18:46,988 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 30 |  Loss: (0.0074) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-06)
2022-06-06 22:18:48,783 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 40 |  Loss: (0.0063) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-06)
2022-06-06 22:18:50,579 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 22:18:52,377 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 60 |  Loss: (0.0052) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-06)
2022-06-06 22:18:54,170 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 70 |  Loss: (0.0049) | Acc: (99.85%) (4537/4544) | Learning rate: (1e-06)
2022-06-06 22:18:55,966 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 80 |  Loss: (0.0049) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-06)
2022-06-06 22:18:57,765 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 90 |  Loss: (0.0051) | Acc: (99.85%) (5815/5824) | Learning rate: (1e-06)
2022-06-06 22:18:59,561 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 100 |  Loss: (0.0048) | Acc: (99.85%) (6454/6464) | Learning rate: (1e-06)
2022-06-06 22:19:01,358 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 110 |  Loss: (0.0048) | Acc: (99.86%) (7094/7104) | Learning rate: (1e-06)
2022-06-06 22:19:03,155 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.81%) (7729/7744) | Learning rate: (1e-06)
2022-06-06 22:19:04,949 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 130 |  Loss: (0.0063) | Acc: (99.77%) (8365/8384) | Learning rate: (1e-06)
2022-06-06 22:19:06,744 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 140 |  Loss: (0.0061) | Acc: (99.79%) (9005/9024) | Learning rate: (1e-06)
2022-06-06 22:19:08,539 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.80%) (9645/9664) | Learning rate: (1e-06)
2022-06-06 22:19:10,335 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 160 |  Loss: (0.0056) | Acc: (99.81%) (10284/10304) | Learning rate: (1e-06)
2022-06-06 22:19:12,132 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.82%) (10924/10944) | Learning rate: (1e-06)
2022-06-06 22:19:13,926 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 180 |  Loss: (0.0052) | Acc: (99.81%) (11562/11584) | Learning rate: (1e-06)
2022-06-06 22:19:15,720 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 190 |  Loss: (0.0051) | Acc: (99.82%) (12202/12224) | Learning rate: (1e-06)
2022-06-06 22:19:17,515 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.81%) (12840/12864) | Learning rate: (1e-06)
2022-06-06 22:19:19,310 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 210 |  Loss: (0.0054) | Acc: (99.81%) (13478/13504) | Learning rate: (1e-06)
2022-06-06 22:19:21,103 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 220 |  Loss: (0.0056) | Acc: (99.79%) (14115/14144) | Learning rate: (1e-06)
2022-06-06 22:19:22,897 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.80%) (14755/14784) | Learning rate: (1e-06)
2022-06-06 22:19:24,693 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 240 |  Loss: (0.0054) | Acc: (99.81%) (15394/15424) | Learning rate: (1e-06)
2022-06-06 22:19:26,488 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 250 |  Loss: (0.0052) | Acc: (99.81%) (16034/16064) | Learning rate: (1e-06)
2022-06-06 22:19:28,286 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 260 |  Loss: (0.0051) | Acc: (99.81%) (16673/16704) | Learning rate: (1e-06)
2022-06-06 22:19:30,079 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 270 |  Loss: (0.0050) | Acc: (99.82%) (17313/17344) | Learning rate: (1e-06)
2022-06-06 22:19:31,874 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 280 |  Loss: (0.0050) | Acc: (99.81%) (17950/17984) | Learning rate: (1e-06)
2022-06-06 22:19:33,670 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 290 |  Loss: (0.0051) | Acc: (99.81%) (18589/18624) | Learning rate: (1e-06)
2022-06-06 22:19:35,464 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 300 |  Loss: (0.0051) | Acc: (99.81%) (19227/19264) | Learning rate: (1e-06)
2022-06-06 22:19:37,260 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.81%) (19867/19904) | Learning rate: (1e-06)
2022-06-06 22:19:39,054 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 320 |  Loss: (0.0051) | Acc: (99.81%) (20505/20544) | Learning rate: (1e-06)
2022-06-06 22:19:40,850 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.81%) (21144/21184) | Learning rate: (1e-06)
2022-06-06 22:19:42,648 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 340 |  Loss: (0.0050) | Acc: (99.81%) (21783/21824) | Learning rate: (1e-06)
2022-06-06 22:19:44,444 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.81%) (22422/22464) | Learning rate: (1e-06)
2022-06-06 22:19:46,240 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 360 |  Loss: (0.0051) | Acc: (99.81%) (23061/23104) | Learning rate: (1e-06)
2022-06-06 22:19:48,036 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.82%) (23701/23744) | Learning rate: (1e-06)
2022-06-06 22:19:49,830 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 380 |  Loss: (0.0050) | Acc: (99.82%) (24341/24384) | Learning rate: (1e-06)
2022-06-06 22:19:51,626 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.82%) (24979/25024) | Learning rate: (1e-06)
2022-06-06 22:19:53,421 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 400 |  Loss: (0.0053) | Acc: (99.82%) (25617/25664) | Learning rate: (1e-06)
2022-06-06 22:19:55,218 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 410 |  Loss: (0.0054) | Acc: (99.81%) (26255/26304) | Learning rate: (1e-06)
2022-06-06 22:19:57,014 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 420 |  Loss: (0.0053) | Acc: (99.81%) (26894/26944) | Learning rate: (1e-06)
2022-06-06 22:19:58,808 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 430 |  Loss: (0.0054) | Acc: (99.82%) (27533/27584) | Learning rate: (1e-06)
2022-06-06 22:20:00,604 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 440 |  Loss: (0.0053) | Acc: (99.82%) (28172/28224) | Learning rate: (1e-06)
2022-06-06 22:20:02,402 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 450 |  Loss: (0.0053) | Acc: (99.82%) (28812/28864) | Learning rate: (1e-06)
2022-06-06 22:20:04,201 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 460 |  Loss: (0.0052) | Acc: (99.82%) (29452/29504) | Learning rate: (1e-06)
2022-06-06 22:20:05,997 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 470 |  Loss: (0.0052) | Acc: (99.82%) (30091/30144) | Learning rate: (1e-06)
2022-06-06 22:20:07,794 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 480 |  Loss: (0.0052) | Acc: (99.82%) (30730/30784) | Learning rate: (1e-06)
2022-06-06 22:20:09,590 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 490 |  Loss: (0.0052) | Acc: (99.83%) (31370/31424) | Learning rate: (1e-06)
2022-06-06 22:20:11,384 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 500 |  Loss: (0.0054) | Acc: (99.82%) (32006/32064) | Learning rate: (1e-06)
2022-06-06 22:20:13,181 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 510 |  Loss: (0.0054) | Acc: (99.82%) (32645/32704) | Learning rate: (1e-06)
2022-06-06 22:20:14,977 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 520 |  Loss: (0.0053) | Acc: (99.82%) (33284/33344) | Learning rate: (1e-06)
2022-06-06 22:20:16,775 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 530 |  Loss: (0.0053) | Acc: (99.82%) (33922/33984) | Learning rate: (1e-06)
2022-06-06 22:20:18,572 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 540 |  Loss: (0.0053) | Acc: (99.82%) (34562/34624) | Learning rate: (1e-06)
2022-06-06 22:20:20,367 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 550 |  Loss: (0.0053) | Acc: (99.82%) (35201/35264) | Learning rate: (1e-06)
2022-06-06 22:20:22,163 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 560 |  Loss: (0.0052) | Acc: (99.82%) (35841/35904) | Learning rate: (1e-06)
2022-06-06 22:20:23,957 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 570 |  Loss: (0.0051) | Acc: (99.83%) (36481/36544) | Learning rate: (1e-06)
2022-06-06 22:20:25,754 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 580 |  Loss: (0.0052) | Acc: (99.83%) (37120/37184) | Learning rate: (1e-06)
2022-06-06 22:20:27,550 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 590 |  Loss: (0.0052) | Acc: (99.83%) (37758/37824) | Learning rate: (1e-06)
2022-06-06 22:20:29,345 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 600 |  Loss: (0.0052) | Acc: (99.83%) (38397/38464) | Learning rate: (1e-06)
2022-06-06 22:20:31,140 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 610 |  Loss: (0.0053) | Acc: (99.83%) (39036/39104) | Learning rate: (1e-06)
2022-06-06 22:20:32,935 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 620 |  Loss: (0.0053) | Acc: (99.83%) (39675/39744) | Learning rate: (1e-06)
2022-06-06 22:20:34,732 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 630 |  Loss: (0.0054) | Acc: (99.82%) (40312/40384) | Learning rate: (1e-06)
2022-06-06 22:20:36,528 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 640 |  Loss: (0.0054) | Acc: (99.82%) (40951/41024) | Learning rate: (1e-06)
2022-06-06 22:20:38,325 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 650 |  Loss: (0.0054) | Acc: (99.82%) (41590/41664) | Learning rate: (1e-06)
2022-06-06 22:20:40,121 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 660 |  Loss: (0.0053) | Acc: (99.82%) (42229/42304) | Learning rate: (1e-06)
2022-06-06 22:20:41,915 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 670 |  Loss: (0.0053) | Acc: (99.82%) (42868/42944) | Learning rate: (1e-06)
2022-06-06 22:20:43,710 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 680 |  Loss: (0.0053) | Acc: (99.83%) (43508/43584) | Learning rate: (1e-06)
2022-06-06 22:20:45,508 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 690 |  Loss: (0.0053) | Acc: (99.82%) (44146/44224) | Learning rate: (1e-06)
2022-06-06 22:20:47,304 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 700 |  Loss: (0.0053) | Acc: (99.82%) (44785/44864) | Learning rate: (1e-06)
2022-06-06 22:20:49,102 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 710 |  Loss: (0.0053) | Acc: (99.82%) (45424/45504) | Learning rate: (1e-06)
2022-06-06 22:20:50,898 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 720 |  Loss: (0.0053) | Acc: (99.82%) (46063/46144) | Learning rate: (1e-06)
2022-06-06 22:20:52,692 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 730 |  Loss: (0.0052) | Acc: (99.83%) (46703/46784) | Learning rate: (1e-06)
2022-06-06 22:20:54,487 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 740 |  Loss: (0.0052) | Acc: (99.83%) (47343/47424) | Learning rate: (1e-06)
2022-06-06 22:20:56,283 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 750 |  Loss: (0.0052) | Acc: (99.83%) (47983/48064) | Learning rate: (1e-06)
2022-06-06 22:20:58,082 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 760 |  Loss: (0.0051) | Acc: (99.83%) (48622/48704) | Learning rate: (1e-06)
2022-06-06 22:20:59,872 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 770 |  Loss: (0.0051) | Acc: (99.83%) (49262/49344) | Learning rate: (1e-06)
2022-06-06 22:21:01,661 - CIFAR10 Classifier - INFO - Epoch: 6 | Batch_idx: 780 |  Loss: (0.0051) | Acc: (99.84%) (49902/49984) | Learning rate: (1e-06)
2022-06-06 22:21:11,602 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0826) | Acc: (97.97%) (9797/10000)
2022-06-06 22:21:11,603 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:21:12,649 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 0 |  Loss: (0.0015) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:21:14,436 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 10 |  Loss: (0.0116) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:21:16,227 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 20 |  Loss: (0.0067) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 22:21:18,020 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 30 |  Loss: (0.0051) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 22:21:19,814 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 22:21:21,607 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 50 |  Loss: (0.0052) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 22:21:23,400 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 60 |  Loss: (0.0054) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 22:21:25,193 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 70 |  Loss: (0.0057) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-06)
2022-06-06 22:21:26,986 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 80 |  Loss: (0.0053) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 22:21:28,783 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 90 |  Loss: (0.0048) | Acc: (99.90%) (5818/5824) | Learning rate: (1e-06)
2022-06-06 22:21:30,574 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 100 |  Loss: (0.0046) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-06)
2022-06-06 22:21:32,369 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 110 |  Loss: (0.0044) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-06)
2022-06-06 22:21:34,165 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 120 |  Loss: (0.0044) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-06)
2022-06-06 22:21:35,958 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 130 |  Loss: (0.0044) | Acc: (99.92%) (8377/8384) | Learning rate: (1e-06)
2022-06-06 22:21:37,752 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 140 |  Loss: (0.0043) | Acc: (99.91%) (9016/9024) | Learning rate: (1e-06)
2022-06-06 22:21:39,546 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 150 |  Loss: (0.0050) | Acc: (99.88%) (9652/9664) | Learning rate: (1e-06)
2022-06-06 22:21:41,340 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.87%) (10291/10304) | Learning rate: (1e-06)
2022-06-06 22:21:43,133 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 170 |  Loss: (0.0051) | Acc: (99.87%) (10930/10944) | Learning rate: (1e-06)
2022-06-06 22:21:44,928 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 180 |  Loss: (0.0048) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-06)
2022-06-06 22:21:46,723 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 190 |  Loss: (0.0046) | Acc: (99.89%) (12210/12224) | Learning rate: (1e-06)
2022-06-06 22:21:48,518 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 200 |  Loss: (0.0046) | Acc: (99.88%) (12849/12864) | Learning rate: (1e-06)
2022-06-06 22:21:50,312 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 210 |  Loss: (0.0044) | Acc: (99.89%) (13489/13504) | Learning rate: (1e-06)
2022-06-06 22:21:52,105 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 220 |  Loss: (0.0043) | Acc: (99.89%) (14129/14144) | Learning rate: (1e-06)
2022-06-06 22:21:53,901 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 230 |  Loss: (0.0045) | Acc: (99.87%) (14765/14784) | Learning rate: (1e-06)
2022-06-06 22:21:55,697 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 240 |  Loss: (0.0046) | Acc: (99.86%) (15403/15424) | Learning rate: (1e-06)
2022-06-06 22:21:57,491 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 250 |  Loss: (0.0045) | Acc: (99.87%) (16043/16064) | Learning rate: (1e-06)
2022-06-06 22:21:59,286 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 260 |  Loss: (0.0047) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-06)
2022-06-06 22:22:01,082 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 270 |  Loss: (0.0047) | Acc: (99.86%) (17319/17344) | Learning rate: (1e-06)
2022-06-06 22:22:02,879 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 280 |  Loss: (0.0046) | Acc: (99.86%) (17959/17984) | Learning rate: (1e-06)
2022-06-06 22:22:04,675 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.85%) (18596/18624) | Learning rate: (1e-06)
2022-06-06 22:22:06,469 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 300 |  Loss: (0.0048) | Acc: (99.85%) (19235/19264) | Learning rate: (1e-06)
2022-06-06 22:22:08,263 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.84%) (19873/19904) | Learning rate: (1e-06)
2022-06-06 22:22:10,059 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 320 |  Loss: (0.0050) | Acc: (99.84%) (20511/20544) | Learning rate: (1e-06)
2022-06-06 22:22:11,854 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.84%) (21150/21184) | Learning rate: (1e-06)
2022-06-06 22:22:13,651 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 340 |  Loss: (0.0049) | Acc: (99.84%) (21790/21824) | Learning rate: (1e-06)
2022-06-06 22:22:15,448 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 350 |  Loss: (0.0049) | Acc: (99.84%) (22429/22464) | Learning rate: (1e-06)
2022-06-06 22:22:17,245 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 360 |  Loss: (0.0048) | Acc: (99.85%) (23069/23104) | Learning rate: (1e-06)
2022-06-06 22:22:19,040 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 370 |  Loss: (0.0048) | Acc: (99.85%) (23709/23744) | Learning rate: (1e-06)
2022-06-06 22:22:20,837 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 380 |  Loss: (0.0047) | Acc: (99.86%) (24349/24384) | Learning rate: (1e-06)
2022-06-06 22:22:22,635 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 390 |  Loss: (0.0047) | Acc: (99.86%) (24988/25024) | Learning rate: (1e-06)
2022-06-06 22:22:24,432 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 400 |  Loss: (0.0046) | Acc: (99.86%) (25628/25664) | Learning rate: (1e-06)
2022-06-06 22:22:26,230 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 410 |  Loss: (0.0046) | Acc: (99.86%) (26266/26304) | Learning rate: (1e-06)
2022-06-06 22:22:28,026 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 420 |  Loss: (0.0047) | Acc: (99.85%) (26904/26944) | Learning rate: (1e-06)
2022-06-06 22:22:29,823 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 430 |  Loss: (0.0048) | Acc: (99.85%) (27542/27584) | Learning rate: (1e-06)
2022-06-06 22:22:31,619 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 440 |  Loss: (0.0048) | Acc: (99.85%) (28181/28224) | Learning rate: (1e-06)
2022-06-06 22:22:33,414 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 450 |  Loss: (0.0049) | Acc: (99.84%) (28819/28864) | Learning rate: (1e-06)
2022-06-06 22:22:35,212 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 460 |  Loss: (0.0048) | Acc: (99.85%) (29459/29504) | Learning rate: (1e-06)
2022-06-06 22:22:37,008 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 470 |  Loss: (0.0048) | Acc: (99.85%) (30098/30144) | Learning rate: (1e-06)
2022-06-06 22:22:38,808 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 480 |  Loss: (0.0049) | Acc: (99.84%) (30736/30784) | Learning rate: (1e-06)
2022-06-06 22:22:40,604 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 490 |  Loss: (0.0049) | Acc: (99.84%) (31375/31424) | Learning rate: (1e-06)
2022-06-06 22:22:42,400 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 500 |  Loss: (0.0048) | Acc: (99.85%) (32015/32064) | Learning rate: (1e-06)
2022-06-06 22:22:44,199 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 510 |  Loss: (0.0048) | Acc: (99.85%) (32655/32704) | Learning rate: (1e-06)
2022-06-06 22:22:45,994 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 520 |  Loss: (0.0048) | Acc: (99.85%) (33294/33344) | Learning rate: (1e-06)
2022-06-06 22:22:47,791 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 530 |  Loss: (0.0047) | Acc: (99.85%) (33934/33984) | Learning rate: (1e-06)
2022-06-06 22:22:49,587 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 540 |  Loss: (0.0047) | Acc: (99.85%) (34573/34624) | Learning rate: (1e-06)
2022-06-06 22:22:51,383 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 550 |  Loss: (0.0047) | Acc: (99.86%) (35213/35264) | Learning rate: (1e-06)
2022-06-06 22:22:53,180 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 560 |  Loss: (0.0047) | Acc: (99.86%) (35852/35904) | Learning rate: (1e-06)
2022-06-06 22:22:54,975 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 570 |  Loss: (0.0046) | Acc: (99.86%) (36492/36544) | Learning rate: (1e-06)
2022-06-06 22:22:56,769 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 580 |  Loss: (0.0046) | Acc: (99.86%) (37131/37184) | Learning rate: (1e-06)
2022-06-06 22:22:58,566 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 590 |  Loss: (0.0046) | Acc: (99.86%) (37771/37824) | Learning rate: (1e-06)
2022-06-06 22:23:00,362 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 600 |  Loss: (0.0045) | Acc: (99.86%) (38410/38464) | Learning rate: (1e-06)
2022-06-06 22:23:02,159 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 610 |  Loss: (0.0046) | Acc: (99.86%) (39048/39104) | Learning rate: (1e-06)
2022-06-06 22:23:03,956 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 620 |  Loss: (0.0045) | Acc: (99.86%) (39687/39744) | Learning rate: (1e-06)
2022-06-06 22:23:05,752 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 630 |  Loss: (0.0045) | Acc: (99.86%) (40327/40384) | Learning rate: (1e-06)
2022-06-06 22:23:07,548 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 640 |  Loss: (0.0046) | Acc: (99.86%) (40965/41024) | Learning rate: (1e-06)
2022-06-06 22:23:09,343 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 650 |  Loss: (0.0046) | Acc: (99.86%) (41604/41664) | Learning rate: (1e-06)
2022-06-06 22:23:11,140 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 660 |  Loss: (0.0046) | Acc: (99.86%) (42244/42304) | Learning rate: (1e-06)
2022-06-06 22:23:12,937 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 670 |  Loss: (0.0046) | Acc: (99.86%) (42883/42944) | Learning rate: (1e-06)
2022-06-06 22:23:14,735 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 680 |  Loss: (0.0046) | Acc: (99.86%) (43521/43584) | Learning rate: (1e-06)
2022-06-06 22:23:16,531 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 690 |  Loss: (0.0046) | Acc: (99.86%) (44160/44224) | Learning rate: (1e-06)
2022-06-06 22:23:18,330 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 700 |  Loss: (0.0046) | Acc: (99.85%) (44798/44864) | Learning rate: (1e-06)
2022-06-06 22:23:20,127 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 710 |  Loss: (0.0046) | Acc: (99.85%) (45438/45504) | Learning rate: (1e-06)
2022-06-06 22:23:21,922 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 720 |  Loss: (0.0045) | Acc: (99.86%) (46078/46144) | Learning rate: (1e-06)
2022-06-06 22:23:23,720 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 730 |  Loss: (0.0046) | Acc: (99.86%) (46717/46784) | Learning rate: (1e-06)
2022-06-06 22:23:25,517 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 740 |  Loss: (0.0046) | Acc: (99.85%) (47355/47424) | Learning rate: (1e-06)
2022-06-06 22:23:27,315 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 750 |  Loss: (0.0046) | Acc: (99.85%) (47994/48064) | Learning rate: (1e-06)
2022-06-06 22:23:29,114 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 760 |  Loss: (0.0047) | Acc: (99.85%) (48632/48704) | Learning rate: (1e-06)
2022-06-06 22:23:30,902 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 770 |  Loss: (0.0047) | Acc: (99.85%) (49271/49344) | Learning rate: (1e-06)
2022-06-06 22:23:32,691 - CIFAR10 Classifier - INFO - Epoch: 7 | Batch_idx: 780 |  Loss: (0.0047) | Acc: (99.85%) (49910/49984) | Learning rate: (1e-06)
2022-06-06 22:23:42,633 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0813) | Acc: (98.06%) (9806/10000)
2022-06-06 22:23:42,634 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:23:43,560 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:23:45,394 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 10 |  Loss: (0.0032) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:23:47,185 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 20 |  Loss: (0.0059) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:23:48,978 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 30 |  Loss: (0.0080) | Acc: (99.75%) (1979/1984) | Learning rate: (1e-06)
2022-06-06 22:23:50,772 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 40 |  Loss: (0.0067) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-06)
2022-06-06 22:23:52,567 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 22:23:54,364 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 60 |  Loss: (0.0051) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 22:23:56,160 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 70 |  Loss: (0.0049) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-06)
2022-06-06 22:23:57,956 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 80 |  Loss: (0.0046) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 22:23:59,752 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 90 |  Loss: (0.0047) | Acc: (99.86%) (5816/5824) | Learning rate: (1e-06)
2022-06-06 22:24:01,545 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 100 |  Loss: (0.0048) | Acc: (99.86%) (6455/6464) | Learning rate: (1e-06)
2022-06-06 22:24:03,342 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 110 |  Loss: (0.0049) | Acc: (99.86%) (7094/7104) | Learning rate: (1e-06)
2022-06-06 22:24:05,138 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 120 |  Loss: (0.0052) | Acc: (99.85%) (7732/7744) | Learning rate: (1e-06)
2022-06-06 22:24:06,934 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 130 |  Loss: (0.0050) | Acc: (99.84%) (8371/8384) | Learning rate: (1e-06)
2022-06-06 22:24:08,730 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 140 |  Loss: (0.0049) | Acc: (99.84%) (9010/9024) | Learning rate: (1e-06)
2022-06-06 22:24:10,524 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 150 |  Loss: (0.0047) | Acc: (99.86%) (9650/9664) | Learning rate: (1e-06)
2022-06-06 22:24:12,319 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 160 |  Loss: (0.0046) | Acc: (99.86%) (10290/10304) | Learning rate: (1e-06)
2022-06-06 22:24:14,117 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 170 |  Loss: (0.0045) | Acc: (99.87%) (10930/10944) | Learning rate: (1e-06)
2022-06-06 22:24:15,914 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 180 |  Loss: (0.0043) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-06)
2022-06-06 22:24:17,710 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 190 |  Loss: (0.0044) | Acc: (99.89%) (12210/12224) | Learning rate: (1e-06)
2022-06-06 22:24:19,503 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 200 |  Loss: (0.0043) | Acc: (99.89%) (12850/12864) | Learning rate: (1e-06)
2022-06-06 22:24:21,299 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 210 |  Loss: (0.0048) | Acc: (99.89%) (13489/13504) | Learning rate: (1e-06)
2022-06-06 22:24:23,095 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 220 |  Loss: (0.0048) | Acc: (99.88%) (14127/14144) | Learning rate: (1e-06)
2022-06-06 22:24:24,891 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 230 |  Loss: (0.0048) | Acc: (99.88%) (14766/14784) | Learning rate: (1e-06)
2022-06-06 22:24:26,688 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 240 |  Loss: (0.0050) | Acc: (99.86%) (15403/15424) | Learning rate: (1e-06)
2022-06-06 22:24:28,486 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 250 |  Loss: (0.0051) | Acc: (99.86%) (16041/16064) | Learning rate: (1e-06)
2022-06-06 22:24:30,283 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 260 |  Loss: (0.0051) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-06)
2022-06-06 22:24:32,077 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 270 |  Loss: (0.0050) | Acc: (99.86%) (17320/17344) | Learning rate: (1e-06)
2022-06-06 22:24:33,874 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 280 |  Loss: (0.0048) | Acc: (99.87%) (17960/17984) | Learning rate: (1e-06)
2022-06-06 22:24:35,670 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 290 |  Loss: (0.0047) | Acc: (99.87%) (18600/18624) | Learning rate: (1e-06)
2022-06-06 22:24:37,465 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.87%) (19238/19264) | Learning rate: (1e-06)
2022-06-06 22:24:39,261 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.86%) (19876/19904) | Learning rate: (1e-06)
2022-06-06 22:24:41,055 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 320 |  Loss: (0.0048) | Acc: (99.86%) (20516/20544) | Learning rate: (1e-06)
2022-06-06 22:24:42,850 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 330 |  Loss: (0.0048) | Acc: (99.86%) (21154/21184) | Learning rate: (1e-06)
2022-06-06 22:24:44,646 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 340 |  Loss: (0.0048) | Acc: (99.85%) (21792/21824) | Learning rate: (1e-06)
2022-06-06 22:24:46,441 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 350 |  Loss: (0.0048) | Acc: (99.85%) (22431/22464) | Learning rate: (1e-06)
2022-06-06 22:24:48,238 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 360 |  Loss: (0.0048) | Acc: (99.85%) (23070/23104) | Learning rate: (1e-06)
2022-06-06 22:24:50,033 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 370 |  Loss: (0.0048) | Acc: (99.85%) (23709/23744) | Learning rate: (1e-06)
2022-06-06 22:24:51,827 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 380 |  Loss: (0.0047) | Acc: (99.85%) (24348/24384) | Learning rate: (1e-06)
2022-06-06 22:24:53,624 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 390 |  Loss: (0.0047) | Acc: (99.85%) (24987/25024) | Learning rate: (1e-06)
2022-06-06 22:24:55,420 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 400 |  Loss: (0.0047) | Acc: (99.86%) (25627/25664) | Learning rate: (1e-06)
2022-06-06 22:24:57,215 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 410 |  Loss: (0.0048) | Acc: (99.86%) (26266/26304) | Learning rate: (1e-06)
2022-06-06 22:24:59,011 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 420 |  Loss: (0.0048) | Acc: (99.85%) (26904/26944) | Learning rate: (1e-06)
2022-06-06 22:25:00,805 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 430 |  Loss: (0.0048) | Acc: (99.85%) (27544/27584) | Learning rate: (1e-06)
2022-06-06 22:25:02,602 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 440 |  Loss: (0.0047) | Acc: (99.86%) (28184/28224) | Learning rate: (1e-06)
2022-06-06 22:25:04,398 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 450 |  Loss: (0.0047) | Acc: (99.86%) (28824/28864) | Learning rate: (1e-06)
2022-06-06 22:25:06,196 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 460 |  Loss: (0.0046) | Acc: (99.86%) (29464/29504) | Learning rate: (1e-06)
2022-06-06 22:25:07,991 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 470 |  Loss: (0.0046) | Acc: (99.87%) (30104/30144) | Learning rate: (1e-06)
2022-06-06 22:25:09,786 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 480 |  Loss: (0.0046) | Acc: (99.86%) (30742/30784) | Learning rate: (1e-06)
2022-06-06 22:25:11,582 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 490 |  Loss: (0.0047) | Acc: (99.86%) (31381/31424) | Learning rate: (1e-06)
2022-06-06 22:25:13,378 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 500 |  Loss: (0.0048) | Acc: (99.86%) (32018/32064) | Learning rate: (1e-06)
2022-06-06 22:25:15,175 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 510 |  Loss: (0.0048) | Acc: (99.86%) (32657/32704) | Learning rate: (1e-06)
2022-06-06 22:25:16,971 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 520 |  Loss: (0.0048) | Acc: (99.86%) (33297/33344) | Learning rate: (1e-06)
2022-06-06 22:25:18,768 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 530 |  Loss: (0.0047) | Acc: (99.86%) (33937/33984) | Learning rate: (1e-06)
2022-06-06 22:25:20,565 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 540 |  Loss: (0.0046) | Acc: (99.86%) (34577/34624) | Learning rate: (1e-06)
2022-06-06 22:25:22,359 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 550 |  Loss: (0.0046) | Acc: (99.86%) (35216/35264) | Learning rate: (1e-06)
2022-06-06 22:25:24,155 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 560 |  Loss: (0.0046) | Acc: (99.86%) (35854/35904) | Learning rate: (1e-06)
2022-06-06 22:25:25,953 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 570 |  Loss: (0.0046) | Acc: (99.86%) (36494/36544) | Learning rate: (1e-06)
2022-06-06 22:25:27,749 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 580 |  Loss: (0.0045) | Acc: (99.87%) (37134/37184) | Learning rate: (1e-06)
2022-06-06 22:25:29,547 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 590 |  Loss: (0.0047) | Acc: (99.86%) (37771/37824) | Learning rate: (1e-06)
2022-06-06 22:25:31,345 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 600 |  Loss: (0.0047) | Acc: (99.86%) (38410/38464) | Learning rate: (1e-06)
2022-06-06 22:25:33,142 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 610 |  Loss: (0.0048) | Acc: (99.86%) (39048/39104) | Learning rate: (1e-06)
2022-06-06 22:25:34,938 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 620 |  Loss: (0.0047) | Acc: (99.86%) (39688/39744) | Learning rate: (1e-06)
2022-06-06 22:25:36,733 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 630 |  Loss: (0.0047) | Acc: (99.86%) (40326/40384) | Learning rate: (1e-06)
2022-06-06 22:25:38,531 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 640 |  Loss: (0.0047) | Acc: (99.86%) (40966/41024) | Learning rate: (1e-06)
2022-06-06 22:25:40,329 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 650 |  Loss: (0.0046) | Acc: (99.86%) (41606/41664) | Learning rate: (1e-06)
2022-06-06 22:25:42,126 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 660 |  Loss: (0.0046) | Acc: (99.86%) (42246/42304) | Learning rate: (1e-06)
2022-06-06 22:25:43,925 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 670 |  Loss: (0.0046) | Acc: (99.86%) (42885/42944) | Learning rate: (1e-06)
2022-06-06 22:25:45,722 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 680 |  Loss: (0.0046) | Acc: (99.86%) (43523/43584) | Learning rate: (1e-06)
2022-06-06 22:25:47,518 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 690 |  Loss: (0.0046) | Acc: (99.86%) (44162/44224) | Learning rate: (1e-06)
2022-06-06 22:25:49,313 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 700 |  Loss: (0.0047) | Acc: (99.86%) (44800/44864) | Learning rate: (1e-06)
2022-06-06 22:25:51,110 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 710 |  Loss: (0.0046) | Acc: (99.86%) (45440/45504) | Learning rate: (1e-06)
2022-06-06 22:25:52,907 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 720 |  Loss: (0.0046) | Acc: (99.86%) (46079/46144) | Learning rate: (1e-06)
2022-06-06 22:25:54,704 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 730 |  Loss: (0.0047) | Acc: (99.86%) (46717/46784) | Learning rate: (1e-06)
2022-06-06 22:25:56,503 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 740 |  Loss: (0.0047) | Acc: (99.86%) (47356/47424) | Learning rate: (1e-06)
2022-06-06 22:25:58,301 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 750 |  Loss: (0.0047) | Acc: (99.86%) (47996/48064) | Learning rate: (1e-06)
2022-06-06 22:26:00,100 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 760 |  Loss: (0.0047) | Acc: (99.86%) (48635/48704) | Learning rate: (1e-06)
2022-06-06 22:26:01,889 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 770 |  Loss: (0.0048) | Acc: (99.86%) (49273/49344) | Learning rate: (1e-06)
2022-06-06 22:26:03,680 - CIFAR10 Classifier - INFO - Epoch: 8 | Batch_idx: 780 |  Loss: (0.0047) | Acc: (99.86%) (49913/49984) | Learning rate: (1e-06)
2022-06-06 22:26:13,627 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0810) | Acc: (97.95%) (9795/10000)
2022-06-06 22:26:13,628 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:26:14,544 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 0 |  Loss: (0.0024) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:26:16,376 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 10 |  Loss: (0.0059) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:26:18,174 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 20 |  Loss: (0.0058) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:26:19,978 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 30 |  Loss: (0.0044) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 22:26:21,777 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 40 |  Loss: (0.0086) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 22:26:23,575 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 50 |  Loss: (0.0076) | Acc: (99.88%) (3260/3264) | Learning rate: (1e-06)
2022-06-06 22:26:25,371 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 60 |  Loss: (0.0079) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 22:26:27,167 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 70 |  Loss: (0.0077) | Acc: (99.85%) (4537/4544) | Learning rate: (1e-06)
2022-06-06 22:26:28,965 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 80 |  Loss: (0.0080) | Acc: (99.83%) (5175/5184) | Learning rate: (1e-06)
2022-06-06 22:26:30,762 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 90 |  Loss: (0.0089) | Acc: (99.81%) (5813/5824) | Learning rate: (1e-06)
2022-06-06 22:26:32,559 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 100 |  Loss: (0.0081) | Acc: (99.83%) (6453/6464) | Learning rate: (1e-06)
2022-06-06 22:26:34,357 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 110 |  Loss: (0.0084) | Acc: (99.80%) (7090/7104) | Learning rate: (1e-06)
2022-06-06 22:26:36,152 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 120 |  Loss: (0.0082) | Acc: (99.81%) (7729/7744) | Learning rate: (1e-06)
2022-06-06 22:26:37,950 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 130 |  Loss: (0.0082) | Acc: (99.79%) (8366/8384) | Learning rate: (1e-06)
2022-06-06 22:26:39,748 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 140 |  Loss: (0.0078) | Acc: (99.80%) (9006/9024) | Learning rate: (1e-06)
2022-06-06 22:26:41,546 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 150 |  Loss: (0.0078) | Acc: (99.80%) (9645/9664) | Learning rate: (1e-06)
2022-06-06 22:26:43,342 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 160 |  Loss: (0.0076) | Acc: (99.81%) (10284/10304) | Learning rate: (1e-06)
2022-06-06 22:26:45,138 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 170 |  Loss: (0.0073) | Acc: (99.82%) (10924/10944) | Learning rate: (1e-06)
2022-06-06 22:26:46,933 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 180 |  Loss: (0.0074) | Acc: (99.81%) (11562/11584) | Learning rate: (1e-06)
2022-06-06 22:26:48,729 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 190 |  Loss: (0.0072) | Acc: (99.82%) (12202/12224) | Learning rate: (1e-06)
2022-06-06 22:26:50,525 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 200 |  Loss: (0.0070) | Acc: (99.83%) (12842/12864) | Learning rate: (1e-06)
2022-06-06 22:26:52,322 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 210 |  Loss: (0.0068) | Acc: (99.84%) (13482/13504) | Learning rate: (1e-06)
2022-06-06 22:26:54,120 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 220 |  Loss: (0.0065) | Acc: (99.84%) (14122/14144) | Learning rate: (1e-06)
2022-06-06 22:26:55,919 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 230 |  Loss: (0.0063) | Acc: (99.85%) (14762/14784) | Learning rate: (1e-06)
2022-06-06 22:26:57,716 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 240 |  Loss: (0.0065) | Acc: (99.84%) (15400/15424) | Learning rate: (1e-06)
2022-06-06 22:26:59,513 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 250 |  Loss: (0.0063) | Acc: (99.85%) (16040/16064) | Learning rate: (1e-06)
2022-06-06 22:27:01,308 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 260 |  Loss: (0.0069) | Acc: (99.84%) (16677/16704) | Learning rate: (1e-06)
2022-06-06 22:27:03,105 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 270 |  Loss: (0.0067) | Acc: (99.84%) (17317/17344) | Learning rate: (1e-06)
2022-06-06 22:27:04,904 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 280 |  Loss: (0.0066) | Acc: (99.84%) (17956/17984) | Learning rate: (1e-06)
2022-06-06 22:27:06,703 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.85%) (18596/18624) | Learning rate: (1e-06)
2022-06-06 22:27:08,499 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 300 |  Loss: (0.0064) | Acc: (99.85%) (19236/19264) | Learning rate: (1e-06)
2022-06-06 22:27:10,299 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 310 |  Loss: (0.0064) | Acc: (99.85%) (19875/19904) | Learning rate: (1e-06)
2022-06-06 22:27:12,098 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 320 |  Loss: (0.0063) | Acc: (99.86%) (20515/20544) | Learning rate: (1e-06)
2022-06-06 22:27:13,898 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 330 |  Loss: (0.0063) | Acc: (99.84%) (21151/21184) | Learning rate: (1e-06)
2022-06-06 22:27:15,695 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 340 |  Loss: (0.0062) | Acc: (99.85%) (21791/21824) | Learning rate: (1e-06)
2022-06-06 22:27:17,492 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 350 |  Loss: (0.0061) | Acc: (99.85%) (22430/22464) | Learning rate: (1e-06)
2022-06-06 22:27:19,289 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 360 |  Loss: (0.0060) | Acc: (99.85%) (23070/23104) | Learning rate: (1e-06)
2022-06-06 22:27:21,085 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 370 |  Loss: (0.0060) | Acc: (99.85%) (23708/23744) | Learning rate: (1e-06)
2022-06-06 22:27:22,881 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 380 |  Loss: (0.0059) | Acc: (99.85%) (24348/24384) | Learning rate: (1e-06)
2022-06-06 22:27:24,680 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 390 |  Loss: (0.0059) | Acc: (99.84%) (24985/25024) | Learning rate: (1e-06)
2022-06-06 22:27:26,477 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 400 |  Loss: (0.0058) | Acc: (99.85%) (25625/25664) | Learning rate: (1e-06)
2022-06-06 22:27:28,276 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 410 |  Loss: (0.0058) | Acc: (99.85%) (26265/26304) | Learning rate: (1e-06)
2022-06-06 22:27:30,073 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 420 |  Loss: (0.0057) | Acc: (99.86%) (26905/26944) | Learning rate: (1e-06)
2022-06-06 22:27:31,873 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 430 |  Loss: (0.0058) | Acc: (99.85%) (27543/27584) | Learning rate: (1e-06)
2022-06-06 22:27:33,672 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 440 |  Loss: (0.0058) | Acc: (99.85%) (28181/28224) | Learning rate: (1e-06)
2022-06-06 22:27:35,471 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 450 |  Loss: (0.0059) | Acc: (99.84%) (28819/28864) | Learning rate: (1e-06)
2022-06-06 22:27:37,269 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 460 |  Loss: (0.0058) | Acc: (99.85%) (29459/29504) | Learning rate: (1e-06)
2022-06-06 22:27:39,067 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 470 |  Loss: (0.0057) | Acc: (99.85%) (30098/30144) | Learning rate: (1e-06)
2022-06-06 22:27:40,864 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 480 |  Loss: (0.0056) | Acc: (99.85%) (30738/30784) | Learning rate: (1e-06)
2022-06-06 22:27:42,662 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 490 |  Loss: (0.0056) | Acc: (99.85%) (31378/31424) | Learning rate: (1e-06)
2022-06-06 22:27:44,458 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 500 |  Loss: (0.0055) | Acc: (99.85%) (32017/32064) | Learning rate: (1e-06)
2022-06-06 22:27:46,254 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 510 |  Loss: (0.0055) | Acc: (99.85%) (32656/32704) | Learning rate: (1e-06)
2022-06-06 22:27:48,049 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 520 |  Loss: (0.0055) | Acc: (99.86%) (33296/33344) | Learning rate: (1e-06)
2022-06-06 22:27:49,848 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 530 |  Loss: (0.0055) | Acc: (99.86%) (33935/33984) | Learning rate: (1e-06)
2022-06-06 22:27:51,646 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 540 |  Loss: (0.0056) | Acc: (99.85%) (34571/34624) | Learning rate: (1e-06)
2022-06-06 22:27:53,443 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 550 |  Loss: (0.0056) | Acc: (99.85%) (35210/35264) | Learning rate: (1e-06)
2022-06-06 22:27:55,241 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 560 |  Loss: (0.0056) | Acc: (99.85%) (35849/35904) | Learning rate: (1e-06)
2022-06-06 22:27:57,038 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 570 |  Loss: (0.0056) | Acc: (99.85%) (36488/36544) | Learning rate: (1e-06)
2022-06-06 22:27:58,835 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 580 |  Loss: (0.0055) | Acc: (99.85%) (37128/37184) | Learning rate: (1e-06)
2022-06-06 22:28:00,632 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 590 |  Loss: (0.0055) | Acc: (99.85%) (37766/37824) | Learning rate: (1e-06)
2022-06-06 22:28:02,427 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 600 |  Loss: (0.0056) | Acc: (99.84%) (38404/38464) | Learning rate: (1e-06)
2022-06-06 22:28:04,225 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 610 |  Loss: (0.0057) | Acc: (99.84%) (39041/39104) | Learning rate: (1e-06)
2022-06-06 22:28:06,022 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 620 |  Loss: (0.0056) | Acc: (99.84%) (39681/39744) | Learning rate: (1e-06)
2022-06-06 22:28:07,822 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 630 |  Loss: (0.0056) | Acc: (99.84%) (40321/40384) | Learning rate: (1e-06)
2022-06-06 22:28:09,620 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 640 |  Loss: (0.0056) | Acc: (99.84%) (40960/41024) | Learning rate: (1e-06)
2022-06-06 22:28:11,420 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 650 |  Loss: (0.0057) | Acc: (99.84%) (41598/41664) | Learning rate: (1e-06)
2022-06-06 22:28:13,218 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 660 |  Loss: (0.0057) | Acc: (99.84%) (42238/42304) | Learning rate: (1e-06)
2022-06-06 22:28:15,017 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 670 |  Loss: (0.0057) | Acc: (99.84%) (42877/42944) | Learning rate: (1e-06)
2022-06-06 22:28:16,815 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 680 |  Loss: (0.0057) | Acc: (99.84%) (43514/43584) | Learning rate: (1e-06)
2022-06-06 22:28:18,612 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 690 |  Loss: (0.0057) | Acc: (99.84%) (44153/44224) | Learning rate: (1e-06)
2022-06-06 22:28:20,411 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 700 |  Loss: (0.0056) | Acc: (99.84%) (44793/44864) | Learning rate: (1e-06)
2022-06-06 22:28:22,208 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 710 |  Loss: (0.0058) | Acc: (99.84%) (45431/45504) | Learning rate: (1e-06)
2022-06-06 22:28:24,005 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 720 |  Loss: (0.0058) | Acc: (99.84%) (46069/46144) | Learning rate: (1e-06)
2022-06-06 22:28:25,802 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 730 |  Loss: (0.0058) | Acc: (99.84%) (46709/46784) | Learning rate: (1e-06)
2022-06-06 22:28:27,599 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 740 |  Loss: (0.0058) | Acc: (99.84%) (47347/47424) | Learning rate: (1e-06)
2022-06-06 22:28:29,396 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 750 |  Loss: (0.0057) | Acc: (99.84%) (47987/48064) | Learning rate: (1e-06)
2022-06-06 22:28:31,196 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 760 |  Loss: (0.0057) | Acc: (99.84%) (48626/48704) | Learning rate: (1e-06)
2022-06-06 22:28:32,988 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 770 |  Loss: (0.0057) | Acc: (99.84%) (49265/49344) | Learning rate: (1e-06)
2022-06-06 22:28:34,778 - CIFAR10 Classifier - INFO - Epoch: 9 | Batch_idx: 780 |  Loss: (0.0057) | Acc: (99.84%) (49905/49984) | Learning rate: (1e-06)
2022-06-06 22:28:44,725 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0845) | Acc: (98.00%) (9800/10000)
2022-06-06 22:28:44,725 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:28:45,615 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 0 |  Loss: (0.0003) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:28:47,406 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 10 |  Loss: (0.0059) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 22:28:49,199 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 20 |  Loss: (0.0038) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:28:50,990 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 30 |  Loss: (0.0061) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-06)
2022-06-06 22:28:52,786 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 40 |  Loss: (0.0052) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 22:28:54,580 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 50 |  Loss: (0.0045) | Acc: (99.88%) (3260/3264) | Learning rate: (1e-06)
2022-06-06 22:28:56,377 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 60 |  Loss: (0.0041) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 22:28:58,172 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 70 |  Loss: (0.0038) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-06)
2022-06-06 22:28:59,966 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 80 |  Loss: (0.0037) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-06)
2022-06-06 22:29:01,763 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 90 |  Loss: (0.0035) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 22:29:03,557 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 100 |  Loss: (0.0048) | Acc: (99.88%) (6456/6464) | Learning rate: (1e-06)
2022-06-06 22:29:05,354 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 110 |  Loss: (0.0048) | Acc: (99.86%) (7094/7104) | Learning rate: (1e-06)
2022-06-06 22:29:07,149 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 120 |  Loss: (0.0048) | Acc: (99.86%) (7733/7744) | Learning rate: (1e-06)
2022-06-06 22:29:08,944 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.86%) (8372/8384) | Learning rate: (1e-06)
2022-06-06 22:29:10,740 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 140 |  Loss: (0.0047) | Acc: (99.87%) (9012/9024) | Learning rate: (1e-06)
2022-06-06 22:29:12,535 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 150 |  Loss: (0.0047) | Acc: (99.88%) (9652/9664) | Learning rate: (1e-06)
2022-06-06 22:29:14,332 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 160 |  Loss: (0.0045) | Acc: (99.88%) (10292/10304) | Learning rate: (1e-06)
2022-06-06 22:29:16,127 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 170 |  Loss: (0.0046) | Acc: (99.88%) (10931/10944) | Learning rate: (1e-06)
2022-06-06 22:29:17,921 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 180 |  Loss: (0.0046) | Acc: (99.87%) (11569/11584) | Learning rate: (1e-06)
2022-06-06 22:29:19,716 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 190 |  Loss: (0.0049) | Acc: (99.86%) (12207/12224) | Learning rate: (1e-06)
2022-06-06 22:29:21,511 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 200 |  Loss: (0.0047) | Acc: (99.87%) (12847/12864) | Learning rate: (1e-06)
2022-06-06 22:29:23,308 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 210 |  Loss: (0.0048) | Acc: (99.87%) (13486/13504) | Learning rate: (1e-06)
2022-06-06 22:29:25,104 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 220 |  Loss: (0.0047) | Acc: (99.87%) (14126/14144) | Learning rate: (1e-06)
2022-06-06 22:29:26,898 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 230 |  Loss: (0.0047) | Acc: (99.87%) (14765/14784) | Learning rate: (1e-06)
2022-06-06 22:29:28,695 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 240 |  Loss: (0.0047) | Acc: (99.87%) (15404/15424) | Learning rate: (1e-06)
2022-06-06 22:29:30,491 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 250 |  Loss: (0.0047) | Acc: (99.87%) (16043/16064) | Learning rate: (1e-06)
2022-06-06 22:29:32,287 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 260 |  Loss: (0.0046) | Acc: (99.87%) (16683/16704) | Learning rate: (1e-06)
2022-06-06 22:29:34,083 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 270 |  Loss: (0.0046) | Acc: (99.87%) (17322/17344) | Learning rate: (1e-06)
2022-06-06 22:29:35,878 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.87%) (17960/17984) | Learning rate: (1e-06)
2022-06-06 22:29:37,674 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 290 |  Loss: (0.0047) | Acc: (99.87%) (18600/18624) | Learning rate: (1e-06)
2022-06-06 22:29:39,470 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 300 |  Loss: (0.0047) | Acc: (99.87%) (19239/19264) | Learning rate: (1e-06)
2022-06-06 22:29:41,266 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.86%) (19876/19904) | Learning rate: (1e-06)
2022-06-06 22:29:43,062 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 320 |  Loss: (0.0051) | Acc: (99.85%) (20514/20544) | Learning rate: (1e-06)
2022-06-06 22:29:44,856 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 330 |  Loss: (0.0049) | Acc: (99.86%) (21154/21184) | Learning rate: (1e-06)
2022-06-06 22:29:46,651 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 340 |  Loss: (0.0049) | Acc: (99.86%) (21794/21824) | Learning rate: (1e-06)
2022-06-06 22:29:48,446 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 350 |  Loss: (0.0048) | Acc: (99.86%) (22433/22464) | Learning rate: (1e-06)
2022-06-06 22:29:50,242 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 360 |  Loss: (0.0048) | Acc: (99.86%) (23072/23104) | Learning rate: (1e-06)
2022-06-06 22:29:52,038 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 370 |  Loss: (0.0048) | Acc: (99.86%) (23711/23744) | Learning rate: (1e-06)
2022-06-06 22:29:53,831 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 380 |  Loss: (0.0047) | Acc: (99.86%) (24351/24384) | Learning rate: (1e-06)
2022-06-06 22:29:55,627 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 390 |  Loss: (0.0048) | Acc: (99.86%) (24989/25024) | Learning rate: (1e-06)
2022-06-06 22:29:57,423 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 400 |  Loss: (0.0048) | Acc: (99.86%) (25628/25664) | Learning rate: (1e-06)
2022-06-06 22:29:59,220 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 410 |  Loss: (0.0048) | Acc: (99.86%) (26268/26304) | Learning rate: (1e-06)
2022-06-06 22:30:01,016 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 420 |  Loss: (0.0047) | Acc: (99.87%) (26908/26944) | Learning rate: (1e-06)
2022-06-06 22:30:02,811 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 430 |  Loss: (0.0047) | Acc: (99.87%) (27547/27584) | Learning rate: (1e-06)
2022-06-06 22:30:04,607 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 440 |  Loss: (0.0047) | Acc: (99.87%) (28187/28224) | Learning rate: (1e-06)
2022-06-06 22:30:06,402 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 450 |  Loss: (0.0048) | Acc: (99.86%) (28825/28864) | Learning rate: (1e-06)
2022-06-06 22:30:08,200 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 460 |  Loss: (0.0047) | Acc: (99.87%) (29465/29504) | Learning rate: (1e-06)
2022-06-06 22:30:09,996 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 470 |  Loss: (0.0047) | Acc: (99.87%) (30104/30144) | Learning rate: (1e-06)
2022-06-06 22:30:11,792 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 480 |  Loss: (0.0047) | Acc: (99.87%) (30743/30784) | Learning rate: (1e-06)
2022-06-06 22:30:13,589 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 490 |  Loss: (0.0047) | Acc: (99.87%) (31383/31424) | Learning rate: (1e-06)
2022-06-06 22:30:15,383 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 500 |  Loss: (0.0049) | Acc: (99.87%) (32021/32064) | Learning rate: (1e-06)
2022-06-06 22:30:17,180 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 510 |  Loss: (0.0048) | Acc: (99.87%) (32660/32704) | Learning rate: (1e-06)
2022-06-06 22:30:18,976 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 520 |  Loss: (0.0048) | Acc: (99.87%) (33300/33344) | Learning rate: (1e-06)
2022-06-06 22:30:20,773 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 530 |  Loss: (0.0048) | Acc: (99.87%) (33939/33984) | Learning rate: (1e-06)
2022-06-06 22:30:22,570 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 540 |  Loss: (0.0049) | Acc: (99.86%) (34576/34624) | Learning rate: (1e-06)
2022-06-06 22:30:24,367 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 550 |  Loss: (0.0049) | Acc: (99.86%) (35215/35264) | Learning rate: (1e-06)
2022-06-06 22:30:26,164 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 560 |  Loss: (0.0049) | Acc: (99.86%) (35854/35904) | Learning rate: (1e-06)
2022-06-06 22:30:27,960 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 570 |  Loss: (0.0049) | Acc: (99.86%) (36493/36544) | Learning rate: (1e-06)
2022-06-06 22:30:29,755 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 580 |  Loss: (0.0049) | Acc: (99.86%) (37133/37184) | Learning rate: (1e-06)
2022-06-06 22:30:31,553 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 590 |  Loss: (0.0049) | Acc: (99.86%) (37772/37824) | Learning rate: (1e-06)
2022-06-06 22:30:33,349 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 600 |  Loss: (0.0049) | Acc: (99.86%) (38411/38464) | Learning rate: (1e-06)
2022-06-06 22:30:35,147 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 610 |  Loss: (0.0048) | Acc: (99.86%) (39051/39104) | Learning rate: (1e-06)
2022-06-06 22:30:36,944 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 620 |  Loss: (0.0048) | Acc: (99.87%) (39691/39744) | Learning rate: (1e-06)
2022-06-06 22:30:38,739 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 630 |  Loss: (0.0047) | Acc: (99.87%) (40331/40384) | Learning rate: (1e-06)
2022-06-06 22:30:40,535 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 640 |  Loss: (0.0049) | Acc: (99.87%) (40969/41024) | Learning rate: (1e-06)
2022-06-06 22:30:42,330 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 650 |  Loss: (0.0049) | Acc: (99.87%) (41608/41664) | Learning rate: (1e-06)
2022-06-06 22:30:44,128 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 660 |  Loss: (0.0049) | Acc: (99.87%) (42247/42304) | Learning rate: (1e-06)
2022-06-06 22:30:45,925 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 670 |  Loss: (0.0049) | Acc: (99.86%) (42885/42944) | Learning rate: (1e-06)
2022-06-06 22:30:47,722 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 680 |  Loss: (0.0049) | Acc: (99.86%) (43525/43584) | Learning rate: (1e-06)
2022-06-06 22:30:49,519 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 690 |  Loss: (0.0048) | Acc: (99.87%) (44165/44224) | Learning rate: (1e-06)
2022-06-06 22:30:51,315 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 700 |  Loss: (0.0048) | Acc: (99.86%) (44803/44864) | Learning rate: (1e-06)
2022-06-06 22:30:53,111 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 710 |  Loss: (0.0048) | Acc: (99.86%) (45440/45504) | Learning rate: (1e-06)
2022-06-06 22:30:54,907 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 720 |  Loss: (0.0048) | Acc: (99.86%) (46079/46144) | Learning rate: (1e-06)
2022-06-06 22:30:56,705 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 730 |  Loss: (0.0048) | Acc: (99.86%) (46719/46784) | Learning rate: (1e-06)
2022-06-06 22:30:58,504 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 740 |  Loss: (0.0049) | Acc: (99.86%) (47357/47424) | Learning rate: (1e-06)
2022-06-06 22:31:00,301 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 750 |  Loss: (0.0049) | Acc: (99.86%) (47996/48064) | Learning rate: (1e-06)
2022-06-06 22:31:02,098 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 760 |  Loss: (0.0048) | Acc: (99.86%) (48636/48704) | Learning rate: (1e-06)
2022-06-06 22:31:03,888 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 770 |  Loss: (0.0048) | Acc: (99.86%) (49275/49344) | Learning rate: (1e-06)
2022-06-06 22:31:05,678 - CIFAR10 Classifier - INFO - Epoch: 10 | Batch_idx: 780 |  Loss: (0.0048) | Acc: (99.86%) (49915/49984) | Learning rate: (1e-06)
2022-06-06 22:31:15,622 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0799) | Acc: (98.05%) (9805/10000)
2022-06-06 22:31:15,623 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:31:16,484 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 0 |  Loss: (0.0292) | Acc: (98.44%) (63/64) | Learning rate: (1e-06)
2022-06-06 22:31:18,278 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 10 |  Loss: (0.0053) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:31:20,072 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 20 |  Loss: (0.0036) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 22:31:21,864 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 30 |  Loss: (0.0036) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 22:31:23,657 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 40 |  Loss: (0.0031) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 22:31:25,454 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 50 |  Loss: (0.0035) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 22:31:27,250 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 60 |  Loss: (0.0032) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 22:31:29,045 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 70 |  Loss: (0.0034) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-06)
2022-06-06 22:31:30,838 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 80 |  Loss: (0.0032) | Acc: (99.92%) (5180/5184) | Learning rate: (1e-06)
2022-06-06 22:31:32,633 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 90 |  Loss: (0.0031) | Acc: (99.93%) (5820/5824) | Learning rate: (1e-06)
2022-06-06 22:31:34,428 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 100 |  Loss: (0.0034) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-06)
2022-06-06 22:31:36,223 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 110 |  Loss: (0.0036) | Acc: (99.90%) (7097/7104) | Learning rate: (1e-06)
2022-06-06 22:31:38,019 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 120 |  Loss: (0.0037) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 22:31:39,813 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 130 |  Loss: (0.0038) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-06)
2022-06-06 22:31:41,609 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 140 |  Loss: (0.0042) | Acc: (99.89%) (9014/9024) | Learning rate: (1e-06)
2022-06-06 22:31:43,404 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 150 |  Loss: (0.0040) | Acc: (99.90%) (9654/9664) | Learning rate: (1e-06)
2022-06-06 22:31:45,204 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 160 |  Loss: (0.0040) | Acc: (99.89%) (10293/10304) | Learning rate: (1e-06)
2022-06-06 22:31:47,000 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 170 |  Loss: (0.0040) | Acc: (99.89%) (10932/10944) | Learning rate: (1e-06)
2022-06-06 22:31:48,794 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 180 |  Loss: (0.0042) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-06)
2022-06-06 22:31:50,589 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 190 |  Loss: (0.0041) | Acc: (99.88%) (12209/12224) | Learning rate: (1e-06)
2022-06-06 22:31:52,385 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 200 |  Loss: (0.0041) | Acc: (99.88%) (12848/12864) | Learning rate: (1e-06)
2022-06-06 22:31:54,183 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 210 |  Loss: (0.0042) | Acc: (99.87%) (13487/13504) | Learning rate: (1e-06)
2022-06-06 22:31:55,978 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 220 |  Loss: (0.0042) | Acc: (99.87%) (14126/14144) | Learning rate: (1e-06)
2022-06-06 22:31:57,776 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 230 |  Loss: (0.0040) | Acc: (99.88%) (14766/14784) | Learning rate: (1e-06)
2022-06-06 22:31:59,572 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 240 |  Loss: (0.0039) | Acc: (99.88%) (15406/15424) | Learning rate: (1e-06)
2022-06-06 22:32:01,365 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 250 |  Loss: (0.0043) | Acc: (99.88%) (16044/16064) | Learning rate: (1e-06)
2022-06-06 22:32:03,163 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 260 |  Loss: (0.0042) | Acc: (99.88%) (16684/16704) | Learning rate: (1e-06)
2022-06-06 22:32:04,960 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 270 |  Loss: (0.0041) | Acc: (99.88%) (17324/17344) | Learning rate: (1e-06)
2022-06-06 22:32:06,756 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 280 |  Loss: (0.0040) | Acc: (99.89%) (17964/17984) | Learning rate: (1e-06)
2022-06-06 22:32:08,555 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 290 |  Loss: (0.0040) | Acc: (99.89%) (18603/18624) | Learning rate: (1e-06)
2022-06-06 22:32:10,350 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 300 |  Loss: (0.0040) | Acc: (99.89%) (19243/19264) | Learning rate: (1e-06)
2022-06-06 22:32:12,145 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 310 |  Loss: (0.0039) | Acc: (99.89%) (19882/19904) | Learning rate: (1e-06)
2022-06-06 22:32:13,940 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 320 |  Loss: (0.0041) | Acc: (99.88%) (20520/20544) | Learning rate: (1e-06)
2022-06-06 22:32:15,736 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 330 |  Loss: (0.0041) | Acc: (99.88%) (21159/21184) | Learning rate: (1e-06)
2022-06-06 22:32:17,534 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 340 |  Loss: (0.0041) | Acc: (99.88%) (21797/21824) | Learning rate: (1e-06)
2022-06-06 22:32:19,329 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 350 |  Loss: (0.0041) | Acc: (99.88%) (22436/22464) | Learning rate: (1e-06)
2022-06-06 22:32:21,125 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 360 |  Loss: (0.0040) | Acc: (99.88%) (23076/23104) | Learning rate: (1e-06)
2022-06-06 22:32:22,921 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 370 |  Loss: (0.0040) | Acc: (99.88%) (23716/23744) | Learning rate: (1e-06)
2022-06-06 22:32:24,716 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 380 |  Loss: (0.0039) | Acc: (99.89%) (24356/24384) | Learning rate: (1e-06)
2022-06-06 22:32:26,514 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 390 |  Loss: (0.0039) | Acc: (99.88%) (24995/25024) | Learning rate: (1e-06)
2022-06-06 22:32:28,312 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 400 |  Loss: (0.0039) | Acc: (99.89%) (25635/25664) | Learning rate: (1e-06)
2022-06-06 22:32:30,109 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 410 |  Loss: (0.0038) | Acc: (99.89%) (26275/26304) | Learning rate: (1e-06)
2022-06-06 22:32:31,905 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 420 |  Loss: (0.0038) | Acc: (99.89%) (26914/26944) | Learning rate: (1e-06)
2022-06-06 22:32:33,699 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 430 |  Loss: (0.0038) | Acc: (99.89%) (27554/27584) | Learning rate: (1e-06)
2022-06-06 22:32:35,494 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 440 |  Loss: (0.0039) | Acc: (99.89%) (28192/28224) | Learning rate: (1e-06)
2022-06-06 22:32:37,290 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 450 |  Loss: (0.0039) | Acc: (99.89%) (28832/28864) | Learning rate: (1e-06)
2022-06-06 22:32:39,089 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 460 |  Loss: (0.0039) | Acc: (99.89%) (29472/29504) | Learning rate: (1e-06)
2022-06-06 22:32:40,886 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 470 |  Loss: (0.0039) | Acc: (99.89%) (30112/30144) | Learning rate: (1e-06)
2022-06-06 22:32:42,683 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 480 |  Loss: (0.0039) | Acc: (99.90%) (30752/30784) | Learning rate: (1e-06)
2022-06-06 22:32:44,481 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 490 |  Loss: (0.0040) | Acc: (99.89%) (31391/31424) | Learning rate: (1e-06)
2022-06-06 22:32:46,276 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 500 |  Loss: (0.0041) | Acc: (99.89%) (32029/32064) | Learning rate: (1e-06)
2022-06-06 22:32:48,072 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 510 |  Loss: (0.0041) | Acc: (99.89%) (32668/32704) | Learning rate: (1e-06)
2022-06-06 22:32:49,868 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 520 |  Loss: (0.0040) | Acc: (99.89%) (33308/33344) | Learning rate: (1e-06)
2022-06-06 22:32:51,664 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 530 |  Loss: (0.0041) | Acc: (99.89%) (33945/33984) | Learning rate: (1e-06)
2022-06-06 22:32:53,462 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 540 |  Loss: (0.0041) | Acc: (99.88%) (34584/34624) | Learning rate: (1e-06)
2022-06-06 22:32:55,258 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 550 |  Loss: (0.0041) | Acc: (99.88%) (35223/35264) | Learning rate: (1e-06)
2022-06-06 22:32:57,055 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 560 |  Loss: (0.0042) | Acc: (99.88%) (35862/35904) | Learning rate: (1e-06)
2022-06-06 22:32:58,852 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 570 |  Loss: (0.0041) | Acc: (99.89%) (36502/36544) | Learning rate: (1e-06)
2022-06-06 22:33:00,647 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 580 |  Loss: (0.0041) | Acc: (99.88%) (37141/37184) | Learning rate: (1e-06)
2022-06-06 22:33:02,443 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 590 |  Loss: (0.0041) | Acc: (99.89%) (37781/37824) | Learning rate: (1e-06)
2022-06-06 22:33:04,239 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 600 |  Loss: (0.0041) | Acc: (99.88%) (38419/38464) | Learning rate: (1e-06)
2022-06-06 22:33:06,036 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 610 |  Loss: (0.0041) | Acc: (99.88%) (39059/39104) | Learning rate: (1e-06)
2022-06-06 22:33:07,835 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 620 |  Loss: (0.0041) | Acc: (99.88%) (39698/39744) | Learning rate: (1e-06)
2022-06-06 22:33:09,631 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 630 |  Loss: (0.0041) | Acc: (99.88%) (40337/40384) | Learning rate: (1e-06)
2022-06-06 22:33:11,427 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 640 |  Loss: (0.0041) | Acc: (99.89%) (40977/41024) | Learning rate: (1e-06)
2022-06-06 22:33:13,223 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 650 |  Loss: (0.0041) | Acc: (99.89%) (41617/41664) | Learning rate: (1e-06)
2022-06-06 22:33:15,019 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 660 |  Loss: (0.0040) | Acc: (99.89%) (42257/42304) | Learning rate: (1e-06)
2022-06-06 22:33:16,818 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 670 |  Loss: (0.0040) | Acc: (99.89%) (42897/42944) | Learning rate: (1e-06)
2022-06-06 22:33:18,616 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 680 |  Loss: (0.0040) | Acc: (99.89%) (43537/43584) | Learning rate: (1e-06)
2022-06-06 22:33:20,414 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 690 |  Loss: (0.0040) | Acc: (99.89%) (44176/44224) | Learning rate: (1e-06)
2022-06-06 22:33:22,212 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 700 |  Loss: (0.0040) | Acc: (99.89%) (44814/44864) | Learning rate: (1e-06)
2022-06-06 22:33:24,009 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 710 |  Loss: (0.0040) | Acc: (99.89%) (45453/45504) | Learning rate: (1e-06)
2022-06-06 22:33:25,806 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 720 |  Loss: (0.0040) | Acc: (99.89%) (46092/46144) | Learning rate: (1e-06)
2022-06-06 22:33:27,603 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 730 |  Loss: (0.0041) | Acc: (99.89%) (46731/46784) | Learning rate: (1e-06)
2022-06-06 22:33:29,399 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 740 |  Loss: (0.0041) | Acc: (99.89%) (47370/47424) | Learning rate: (1e-06)
2022-06-06 22:33:31,193 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 750 |  Loss: (0.0041) | Acc: (99.89%) (48010/48064) | Learning rate: (1e-06)
2022-06-06 22:33:32,991 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 760 |  Loss: (0.0040) | Acc: (99.89%) (48649/48704) | Learning rate: (1e-06)
2022-06-06 22:33:34,779 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 770 |  Loss: (0.0040) | Acc: (99.89%) (49288/49344) | Learning rate: (1e-06)
2022-06-06 22:33:36,568 - CIFAR10 Classifier - INFO - Epoch: 11 | Batch_idx: 780 |  Loss: (0.0041) | Acc: (99.89%) (49927/49984) | Learning rate: (1e-06)
2022-06-06 22:33:46,484 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0800) | Acc: (98.06%) (9806/10000)
2022-06-06 22:33:46,485 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:33:47,382 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 0 |  Loss: (0.0008) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:33:49,175 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 10 |  Loss: (0.0014) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:33:50,966 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 20 |  Loss: (0.0035) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:33:52,759 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 30 |  Loss: (0.0032) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 22:33:54,555 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 40 |  Loss: (0.0040) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 22:33:56,350 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 50 |  Loss: (0.0037) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 22:33:58,147 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 60 |  Loss: (0.0046) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 22:33:59,942 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 70 |  Loss: (0.0058) | Acc: (99.85%) (4537/4544) | Learning rate: (1e-06)
2022-06-06 22:34:01,737 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 80 |  Loss: (0.0053) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-06)
2022-06-06 22:34:03,533 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.86%) (5816/5824) | Learning rate: (1e-06)
2022-06-06 22:34:05,327 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 100 |  Loss: (0.0050) | Acc: (99.86%) (6455/6464) | Learning rate: (1e-06)
2022-06-06 22:34:07,122 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 110 |  Loss: (0.0053) | Acc: (99.83%) (7092/7104) | Learning rate: (1e-06)
2022-06-06 22:34:08,919 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 120 |  Loss: (0.0051) | Acc: (99.83%) (7731/7744) | Learning rate: (1e-06)
2022-06-06 22:34:10,717 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 130 |  Loss: (0.0061) | Acc: (99.82%) (8369/8384) | Learning rate: (1e-06)
2022-06-06 22:34:12,513 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 140 |  Loss: (0.0062) | Acc: (99.82%) (9008/9024) | Learning rate: (1e-06)
2022-06-06 22:34:14,307 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 150 |  Loss: (0.0059) | Acc: (99.83%) (9648/9664) | Learning rate: (1e-06)
2022-06-06 22:34:16,102 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 160 |  Loss: (0.0056) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 22:34:17,897 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.85%) (10928/10944) | Learning rate: (1e-06)
2022-06-06 22:34:19,694 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 180 |  Loss: (0.0052) | Acc: (99.86%) (11568/11584) | Learning rate: (1e-06)
2022-06-06 22:34:21,491 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 190 |  Loss: (0.0051) | Acc: (99.86%) (12207/12224) | Learning rate: (1e-06)
2022-06-06 22:34:23,287 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 200 |  Loss: (0.0050) | Acc: (99.87%) (12847/12864) | Learning rate: (1e-06)
2022-06-06 22:34:25,085 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.87%) (13486/13504) | Learning rate: (1e-06)
2022-06-06 22:34:26,881 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 220 |  Loss: (0.0050) | Acc: (99.87%) (14125/14144) | Learning rate: (1e-06)
2022-06-06 22:34:28,677 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.85%) (14762/14784) | Learning rate: (1e-06)
2022-06-06 22:34:30,474 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 240 |  Loss: (0.0050) | Acc: (99.86%) (15402/15424) | Learning rate: (1e-06)
2022-06-06 22:34:32,270 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 250 |  Loss: (0.0050) | Acc: (99.86%) (16041/16064) | Learning rate: (1e-06)
2022-06-06 22:34:34,067 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 260 |  Loss: (0.0049) | Acc: (99.86%) (16680/16704) | Learning rate: (1e-06)
2022-06-06 22:34:35,864 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 270 |  Loss: (0.0050) | Acc: (99.86%) (17319/17344) | Learning rate: (1e-06)
2022-06-06 22:34:37,660 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 280 |  Loss: (0.0050) | Acc: (99.86%) (17958/17984) | Learning rate: (1e-06)
2022-06-06 22:34:39,456 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 290 |  Loss: (0.0050) | Acc: (99.86%) (18597/18624) | Learning rate: (1e-06)
2022-06-06 22:34:41,250 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.86%) (19237/19264) | Learning rate: (1e-06)
2022-06-06 22:34:43,048 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.86%) (19876/19904) | Learning rate: (1e-06)
2022-06-06 22:34:44,848 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 320 |  Loss: (0.0052) | Acc: (99.85%) (20514/20544) | Learning rate: (1e-06)
2022-06-06 22:34:46,647 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 330 |  Loss: (0.0052) | Acc: (99.85%) (21152/21184) | Learning rate: (1e-06)
2022-06-06 22:34:48,446 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 340 |  Loss: (0.0051) | Acc: (99.85%) (21791/21824) | Learning rate: (1e-06)
2022-06-06 22:34:50,242 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.85%) (22430/22464) | Learning rate: (1e-06)
2022-06-06 22:34:52,040 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.84%) (23068/23104) | Learning rate: (1e-06)
2022-06-06 22:34:53,837 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.84%) (23707/23744) | Learning rate: (1e-06)
2022-06-06 22:34:55,634 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 380 |  Loss: (0.0051) | Acc: (99.84%) (24345/24384) | Learning rate: (1e-06)
2022-06-06 22:34:57,429 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.84%) (24983/25024) | Learning rate: (1e-06)
2022-06-06 22:34:59,227 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 400 |  Loss: (0.0051) | Acc: (99.84%) (25622/25664) | Learning rate: (1e-06)
2022-06-06 22:35:01,024 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 410 |  Loss: (0.0051) | Acc: (99.84%) (26261/26304) | Learning rate: (1e-06)
2022-06-06 22:35:02,822 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 420 |  Loss: (0.0052) | Acc: (99.83%) (26898/26944) | Learning rate: (1e-06)
2022-06-06 22:35:04,619 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 430 |  Loss: (0.0051) | Acc: (99.83%) (27538/27584) | Learning rate: (1e-06)
2022-06-06 22:35:06,417 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 440 |  Loss: (0.0050) | Acc: (99.84%) (28178/28224) | Learning rate: (1e-06)
2022-06-06 22:35:08,217 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 450 |  Loss: (0.0051) | Acc: (99.84%) (28817/28864) | Learning rate: (1e-06)
2022-06-06 22:35:10,016 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 460 |  Loss: (0.0053) | Acc: (99.83%) (29454/29504) | Learning rate: (1e-06)
2022-06-06 22:35:11,813 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 470 |  Loss: (0.0055) | Acc: (99.82%) (30091/30144) | Learning rate: (1e-06)
2022-06-06 22:35:13,610 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 480 |  Loss: (0.0055) | Acc: (99.82%) (30730/30784) | Learning rate: (1e-06)
2022-06-06 22:35:15,407 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 490 |  Loss: (0.0054) | Acc: (99.83%) (31370/31424) | Learning rate: (1e-06)
2022-06-06 22:35:17,204 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 500 |  Loss: (0.0054) | Acc: (99.83%) (32009/32064) | Learning rate: (1e-06)
2022-06-06 22:35:19,000 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 510 |  Loss: (0.0053) | Acc: (99.83%) (32649/32704) | Learning rate: (1e-06)
2022-06-06 22:35:20,797 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 520 |  Loss: (0.0052) | Acc: (99.84%) (33289/33344) | Learning rate: (1e-06)
2022-06-06 22:35:22,597 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 530 |  Loss: (0.0052) | Acc: (99.84%) (33928/33984) | Learning rate: (1e-06)
2022-06-06 22:35:24,395 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 540 |  Loss: (0.0053) | Acc: (99.84%) (34567/34624) | Learning rate: (1e-06)
2022-06-06 22:35:26,193 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 550 |  Loss: (0.0052) | Acc: (99.84%) (35206/35264) | Learning rate: (1e-06)
2022-06-06 22:35:27,991 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 560 |  Loss: (0.0052) | Acc: (99.84%) (35845/35904) | Learning rate: (1e-06)
2022-06-06 22:35:29,789 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 570 |  Loss: (0.0052) | Acc: (99.83%) (36483/36544) | Learning rate: (1e-06)
2022-06-06 22:35:31,587 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 580 |  Loss: (0.0052) | Acc: (99.84%) (37123/37184) | Learning rate: (1e-06)
2022-06-06 22:35:33,386 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 590 |  Loss: (0.0052) | Acc: (99.84%) (37762/37824) | Learning rate: (1e-06)
2022-06-06 22:35:35,183 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 600 |  Loss: (0.0052) | Acc: (99.84%) (38401/38464) | Learning rate: (1e-06)
2022-06-06 22:35:36,980 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 610 |  Loss: (0.0052) | Acc: (99.83%) (39039/39104) | Learning rate: (1e-06)
2022-06-06 22:35:38,777 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 620 |  Loss: (0.0052) | Acc: (99.84%) (39679/39744) | Learning rate: (1e-06)
2022-06-06 22:35:40,572 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 630 |  Loss: (0.0051) | Acc: (99.84%) (40319/40384) | Learning rate: (1e-06)
2022-06-06 22:35:42,369 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 640 |  Loss: (0.0051) | Acc: (99.84%) (40958/41024) | Learning rate: (1e-06)
2022-06-06 22:35:44,169 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 650 |  Loss: (0.0051) | Acc: (99.84%) (41598/41664) | Learning rate: (1e-06)
2022-06-06 22:35:45,968 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 660 |  Loss: (0.0050) | Acc: (99.84%) (42238/42304) | Learning rate: (1e-06)
2022-06-06 22:35:47,768 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 670 |  Loss: (0.0051) | Acc: (99.84%) (42876/42944) | Learning rate: (1e-06)
2022-06-06 22:35:49,566 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 680 |  Loss: (0.0050) | Acc: (99.84%) (43516/43584) | Learning rate: (1e-06)
2022-06-06 22:35:51,365 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 690 |  Loss: (0.0050) | Acc: (99.84%) (44155/44224) | Learning rate: (1e-06)
2022-06-06 22:35:53,165 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 700 |  Loss: (0.0050) | Acc: (99.85%) (44795/44864) | Learning rate: (1e-06)
2022-06-06 22:35:54,965 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 710 |  Loss: (0.0050) | Acc: (99.85%) (45434/45504) | Learning rate: (1e-06)
2022-06-06 22:35:56,763 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 720 |  Loss: (0.0049) | Acc: (99.85%) (46074/46144) | Learning rate: (1e-06)
2022-06-06 22:35:58,564 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 730 |  Loss: (0.0050) | Acc: (99.85%) (46712/46784) | Learning rate: (1e-06)
2022-06-06 22:36:00,363 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 740 |  Loss: (0.0049) | Acc: (99.84%) (47350/47424) | Learning rate: (1e-06)
2022-06-06 22:36:02,162 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 750 |  Loss: (0.0049) | Acc: (99.84%) (47989/48064) | Learning rate: (1e-06)
2022-06-06 22:36:03,961 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 760 |  Loss: (0.0049) | Acc: (99.84%) (48628/48704) | Learning rate: (1e-06)
2022-06-06 22:36:05,750 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 770 |  Loss: (0.0049) | Acc: (99.85%) (49268/49344) | Learning rate: (1e-06)
2022-06-06 22:36:07,538 - CIFAR10 Classifier - INFO - Epoch: 12 | Batch_idx: 780 |  Loss: (0.0049) | Acc: (99.84%) (49906/49984) | Learning rate: (1e-06)
2022-06-06 22:36:17,492 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0804) | Acc: (97.96%) (9796/10000)
2022-06-06 22:36:17,493 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:36:18,314 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 0 |  Loss: (0.0013) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:36:20,147 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 10 |  Loss: (0.0042) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:36:21,939 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 20 |  Loss: (0.0032) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 22:36:23,736 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 30 |  Loss: (0.0031) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 22:36:25,532 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 40 |  Loss: (0.0029) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 22:36:27,328 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 50 |  Loss: (0.0029) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-06)
2022-06-06 22:36:29,125 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 60 |  Loss: (0.0051) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 22:36:30,922 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 70 |  Loss: (0.0049) | Acc: (99.93%) (4541/4544) | Learning rate: (1e-06)
2022-06-06 22:36:32,717 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.94%) (5181/5184) | Learning rate: (1e-06)
2022-06-06 22:36:34,513 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.93%) (5820/5824) | Learning rate: (1e-06)
2022-06-06 22:36:36,310 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 100 |  Loss: (0.0047) | Acc: (99.92%) (6459/6464) | Learning rate: (1e-06)
2022-06-06 22:36:38,110 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 110 |  Loss: (0.0046) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-06)
2022-06-06 22:36:39,908 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 120 |  Loss: (0.0046) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-06)
2022-06-06 22:36:41,705 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.90%) (8376/8384) | Learning rate: (1e-06)
2022-06-06 22:36:43,503 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 140 |  Loss: (0.0049) | Acc: (99.90%) (9015/9024) | Learning rate: (1e-06)
2022-06-06 22:36:45,299 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 150 |  Loss: (0.0046) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-06)
2022-06-06 22:36:47,093 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 160 |  Loss: (0.0044) | Acc: (99.91%) (10295/10304) | Learning rate: (1e-06)
2022-06-06 22:36:48,888 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 170 |  Loss: (0.0047) | Acc: (99.89%) (10932/10944) | Learning rate: (1e-06)
2022-06-06 22:36:50,684 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 180 |  Loss: (0.0045) | Acc: (99.90%) (11572/11584) | Learning rate: (1e-06)
2022-06-06 22:36:52,480 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 190 |  Loss: (0.0043) | Acc: (99.90%) (12212/12224) | Learning rate: (1e-06)
2022-06-06 22:36:54,275 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 200 |  Loss: (0.0044) | Acc: (99.89%) (12850/12864) | Learning rate: (1e-06)
2022-06-06 22:36:56,071 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 210 |  Loss: (0.0044) | Acc: (99.89%) (13489/13504) | Learning rate: (1e-06)
2022-06-06 22:36:57,866 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 220 |  Loss: (0.0044) | Acc: (99.89%) (14128/14144) | Learning rate: (1e-06)
2022-06-06 22:36:59,663 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 230 |  Loss: (0.0043) | Acc: (99.89%) (14768/14784) | Learning rate: (1e-06)
2022-06-06 22:37:01,461 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 240 |  Loss: (0.0042) | Acc: (99.90%) (15408/15424) | Learning rate: (1e-06)
2022-06-06 22:37:03,256 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 250 |  Loss: (0.0042) | Acc: (99.89%) (16047/16064) | Learning rate: (1e-06)
2022-06-06 22:37:05,053 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 260 |  Loss: (0.0045) | Acc: (99.88%) (16684/16704) | Learning rate: (1e-06)
2022-06-06 22:37:06,847 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 270 |  Loss: (0.0045) | Acc: (99.88%) (17323/17344) | Learning rate: (1e-06)
2022-06-06 22:37:08,642 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 280 |  Loss: (0.0044) | Acc: (99.88%) (17963/17984) | Learning rate: (1e-06)
2022-06-06 22:37:10,438 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 290 |  Loss: (0.0045) | Acc: (99.88%) (18601/18624) | Learning rate: (1e-06)
2022-06-06 22:37:12,233 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.88%) (19241/19264) | Learning rate: (1e-06)
2022-06-06 22:37:14,031 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 310 |  Loss: (0.0044) | Acc: (99.88%) (19880/19904) | Learning rate: (1e-06)
2022-06-06 22:37:15,826 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 320 |  Loss: (0.0043) | Acc: (99.88%) (20520/20544) | Learning rate: (1e-06)
2022-06-06 22:37:17,622 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 330 |  Loss: (0.0045) | Acc: (99.87%) (21156/21184) | Learning rate: (1e-06)
2022-06-06 22:37:19,417 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 340 |  Loss: (0.0045) | Acc: (99.87%) (21795/21824) | Learning rate: (1e-06)
2022-06-06 22:37:21,215 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 350 |  Loss: (0.0045) | Acc: (99.87%) (22434/22464) | Learning rate: (1e-06)
2022-06-06 22:37:23,013 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 360 |  Loss: (0.0045) | Acc: (99.86%) (23072/23104) | Learning rate: (1e-06)
2022-06-06 22:37:24,810 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 370 |  Loss: (0.0045) | Acc: (99.85%) (23709/23744) | Learning rate: (1e-06)
2022-06-06 22:37:26,604 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 380 |  Loss: (0.0044) | Acc: (99.86%) (24349/24384) | Learning rate: (1e-06)
2022-06-06 22:37:28,399 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 390 |  Loss: (0.0045) | Acc: (99.85%) (24987/25024) | Learning rate: (1e-06)
2022-06-06 22:37:30,192 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 400 |  Loss: (0.0046) | Acc: (99.85%) (25625/25664) | Learning rate: (1e-06)
2022-06-06 22:37:31,986 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 410 |  Loss: (0.0046) | Acc: (99.85%) (26264/26304) | Learning rate: (1e-06)
2022-06-06 22:37:33,780 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 420 |  Loss: (0.0046) | Acc: (99.84%) (26902/26944) | Learning rate: (1e-06)
2022-06-06 22:37:35,573 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 430 |  Loss: (0.0046) | Acc: (99.85%) (27542/27584) | Learning rate: (1e-06)
2022-06-06 22:37:37,368 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 440 |  Loss: (0.0047) | Acc: (99.84%) (28179/28224) | Learning rate: (1e-06)
2022-06-06 22:37:39,161 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 450 |  Loss: (0.0046) | Acc: (99.84%) (28819/28864) | Learning rate: (1e-06)
2022-06-06 22:37:40,959 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 460 |  Loss: (0.0047) | Acc: (99.84%) (29457/29504) | Learning rate: (1e-06)
2022-06-06 22:37:42,752 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 470 |  Loss: (0.0046) | Acc: (99.84%) (30096/30144) | Learning rate: (1e-06)
2022-06-06 22:37:44,546 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 480 |  Loss: (0.0046) | Acc: (99.84%) (30735/30784) | Learning rate: (1e-06)
2022-06-06 22:37:46,341 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 490 |  Loss: (0.0046) | Acc: (99.84%) (31375/31424) | Learning rate: (1e-06)
2022-06-06 22:37:48,136 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 500 |  Loss: (0.0047) | Acc: (99.84%) (32013/32064) | Learning rate: (1e-06)
2022-06-06 22:37:49,931 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 510 |  Loss: (0.0047) | Acc: (99.84%) (32651/32704) | Learning rate: (1e-06)
2022-06-06 22:37:51,725 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 520 |  Loss: (0.0047) | Acc: (99.84%) (33291/33344) | Learning rate: (1e-06)
2022-06-06 22:37:53,520 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 530 |  Loss: (0.0046) | Acc: (99.84%) (33931/33984) | Learning rate: (1e-06)
2022-06-06 22:37:55,316 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 540 |  Loss: (0.0046) | Acc: (99.85%) (34571/34624) | Learning rate: (1e-06)
2022-06-06 22:37:57,109 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 550 |  Loss: (0.0045) | Acc: (99.85%) (35211/35264) | Learning rate: (1e-06)
2022-06-06 22:37:58,904 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 560 |  Loss: (0.0045) | Acc: (99.85%) (35851/35904) | Learning rate: (1e-06)
2022-06-06 22:38:00,699 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 570 |  Loss: (0.0045) | Acc: (99.85%) (36490/36544) | Learning rate: (1e-06)
2022-06-06 22:38:02,495 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 580 |  Loss: (0.0046) | Acc: (99.85%) (37128/37184) | Learning rate: (1e-06)
2022-06-06 22:38:04,290 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 590 |  Loss: (0.0046) | Acc: (99.85%) (37767/37824) | Learning rate: (1e-06)
2022-06-06 22:38:06,083 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 600 |  Loss: (0.0046) | Acc: (99.85%) (38406/38464) | Learning rate: (1e-06)
2022-06-06 22:38:07,879 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 610 |  Loss: (0.0046) | Acc: (99.85%) (39046/39104) | Learning rate: (1e-06)
2022-06-06 22:38:09,674 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 620 |  Loss: (0.0046) | Acc: (99.85%) (39685/39744) | Learning rate: (1e-06)
2022-06-06 22:38:11,468 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 630 |  Loss: (0.0045) | Acc: (99.85%) (40325/40384) | Learning rate: (1e-06)
2022-06-06 22:38:13,262 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 640 |  Loss: (0.0046) | Acc: (99.85%) (40964/41024) | Learning rate: (1e-06)
2022-06-06 22:38:15,058 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 650 |  Loss: (0.0046) | Acc: (99.85%) (41603/41664) | Learning rate: (1e-06)
2022-06-06 22:38:16,854 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 660 |  Loss: (0.0046) | Acc: (99.86%) (42243/42304) | Learning rate: (1e-06)
2022-06-06 22:38:18,649 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 670 |  Loss: (0.0047) | Acc: (99.85%) (42881/42944) | Learning rate: (1e-06)
2022-06-06 22:38:20,442 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 680 |  Loss: (0.0047) | Acc: (99.86%) (43521/43584) | Learning rate: (1e-06)
2022-06-06 22:38:22,236 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 690 |  Loss: (0.0047) | Acc: (99.85%) (44159/44224) | Learning rate: (1e-06)
2022-06-06 22:38:24,032 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 700 |  Loss: (0.0047) | Acc: (99.85%) (44798/44864) | Learning rate: (1e-06)
2022-06-06 22:38:25,827 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 710 |  Loss: (0.0047) | Acc: (99.85%) (45438/45504) | Learning rate: (1e-06)
2022-06-06 22:38:27,621 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 720 |  Loss: (0.0047) | Acc: (99.85%) (46077/46144) | Learning rate: (1e-06)
2022-06-06 22:38:29,415 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 730 |  Loss: (0.0047) | Acc: (99.85%) (46715/46784) | Learning rate: (1e-06)
2022-06-06 22:38:31,211 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 740 |  Loss: (0.0047) | Acc: (99.85%) (47355/47424) | Learning rate: (1e-06)
2022-06-06 22:38:33,005 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 750 |  Loss: (0.0047) | Acc: (99.85%) (47994/48064) | Learning rate: (1e-06)
2022-06-06 22:38:34,800 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 760 |  Loss: (0.0046) | Acc: (99.86%) (48634/48704) | Learning rate: (1e-06)
2022-06-06 22:38:36,587 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 770 |  Loss: (0.0046) | Acc: (99.86%) (49273/49344) | Learning rate: (1e-06)
2022-06-06 22:38:38,375 - CIFAR10 Classifier - INFO - Epoch: 13 | Batch_idx: 780 |  Loss: (0.0046) | Acc: (99.86%) (49913/49984) | Learning rate: (1e-06)
2022-06-06 22:38:48,318 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0827) | Acc: (98.00%) (9800/10000)
2022-06-06 22:38:48,319 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:38:49,147 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:38:50,966 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 10 |  Loss: (0.0045) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:38:52,759 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 20 |  Loss: (0.0040) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:38:54,554 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 30 |  Loss: (0.0038) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 22:38:56,349 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 40 |  Loss: (0.0048) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 22:38:58,143 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 50 |  Loss: (0.0062) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-06)
2022-06-06 22:38:59,941 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 60 |  Loss: (0.0064) | Acc: (99.82%) (3897/3904) | Learning rate: (1e-06)
2022-06-06 22:39:01,736 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 70 |  Loss: (0.0061) | Acc: (99.82%) (4536/4544) | Learning rate: (1e-06)
2022-06-06 22:39:03,533 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 80 |  Loss: (0.0056) | Acc: (99.83%) (5175/5184) | Learning rate: (1e-06)
2022-06-06 22:39:05,328 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 90 |  Loss: (0.0054) | Acc: (99.83%) (5814/5824) | Learning rate: (1e-06)
2022-06-06 22:39:07,121 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 100 |  Loss: (0.0055) | Acc: (99.83%) (6453/6464) | Learning rate: (1e-06)
2022-06-06 22:39:08,918 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 110 |  Loss: (0.0053) | Acc: (99.85%) (7093/7104) | Learning rate: (1e-06)
2022-06-06 22:39:10,713 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.85%) (7732/7744) | Learning rate: (1e-06)
2022-06-06 22:39:12,509 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 130 |  Loss: (0.0060) | Acc: (99.84%) (8371/8384) | Learning rate: (1e-06)
2022-06-06 22:39:14,303 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 140 |  Loss: (0.0066) | Acc: (99.82%) (9008/9024) | Learning rate: (1e-06)
2022-06-06 22:39:16,098 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 150 |  Loss: (0.0065) | Acc: (99.81%) (9646/9664) | Learning rate: (1e-06)
2022-06-06 22:39:17,896 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 160 |  Loss: (0.0065) | Acc: (99.82%) (10285/10304) | Learning rate: (1e-06)
2022-06-06 22:39:19,694 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 170 |  Loss: (0.0065) | Acc: (99.82%) (10924/10944) | Learning rate: (1e-06)
2022-06-06 22:39:21,490 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 180 |  Loss: (0.0062) | Acc: (99.82%) (11563/11584) | Learning rate: (1e-06)
2022-06-06 22:39:23,286 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 190 |  Loss: (0.0062) | Acc: (99.82%) (12202/12224) | Learning rate: (1e-06)
2022-06-06 22:39:25,080 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 200 |  Loss: (0.0060) | Acc: (99.83%) (12842/12864) | Learning rate: (1e-06)
2022-06-06 22:39:26,875 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.84%) (13482/13504) | Learning rate: (1e-06)
2022-06-06 22:39:28,672 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.84%) (14122/14144) | Learning rate: (1e-06)
2022-06-06 22:39:30,468 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.85%) (14762/14784) | Learning rate: (1e-06)
2022-06-06 22:39:32,265 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.85%) (15401/15424) | Learning rate: (1e-06)
2022-06-06 22:39:34,061 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 250 |  Loss: (0.0053) | Acc: (99.85%) (16040/16064) | Learning rate: (1e-06)
2022-06-06 22:39:35,856 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.84%) (16678/16704) | Learning rate: (1e-06)
2022-06-06 22:39:37,651 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.84%) (17317/17344) | Learning rate: (1e-06)
2022-06-06 22:39:39,447 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 280 |  Loss: (0.0052) | Acc: (99.85%) (17957/17984) | Learning rate: (1e-06)
2022-06-06 22:39:41,245 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 290 |  Loss: (0.0051) | Acc: (99.86%) (18597/18624) | Learning rate: (1e-06)
2022-06-06 22:39:43,040 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 300 |  Loss: (0.0050) | Acc: (99.86%) (19237/19264) | Learning rate: (1e-06)
2022-06-06 22:39:44,835 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.86%) (19877/19904) | Learning rate: (1e-06)
2022-06-06 22:39:46,630 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 320 |  Loss: (0.0050) | Acc: (99.86%) (20515/20544) | Learning rate: (1e-06)
2022-06-06 22:39:48,425 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 330 |  Loss: (0.0049) | Acc: (99.86%) (21155/21184) | Learning rate: (1e-06)
2022-06-06 22:39:50,222 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 340 |  Loss: (0.0048) | Acc: (99.87%) (21795/21824) | Learning rate: (1e-06)
2022-06-06 22:39:52,016 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.87%) (22434/22464) | Learning rate: (1e-06)
2022-06-06 22:39:53,810 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 360 |  Loss: (0.0048) | Acc: (99.87%) (23074/23104) | Learning rate: (1e-06)
2022-06-06 22:39:55,604 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 370 |  Loss: (0.0048) | Acc: (99.87%) (23714/23744) | Learning rate: (1e-06)
2022-06-06 22:39:57,400 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 380 |  Loss: (0.0049) | Acc: (99.87%) (24352/24384) | Learning rate: (1e-06)
2022-06-06 22:39:59,196 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 390 |  Loss: (0.0049) | Acc: (99.87%) (24991/25024) | Learning rate: (1e-06)
2022-06-06 22:40:00,993 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 400 |  Loss: (0.0049) | Acc: (99.87%) (25630/25664) | Learning rate: (1e-06)
2022-06-06 22:40:02,787 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 410 |  Loss: (0.0051) | Acc: (99.86%) (26268/26304) | Learning rate: (1e-06)
2022-06-06 22:40:04,582 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 420 |  Loss: (0.0050) | Acc: (99.86%) (26907/26944) | Learning rate: (1e-06)
2022-06-06 22:40:06,377 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 430 |  Loss: (0.0052) | Acc: (99.85%) (27544/27584) | Learning rate: (1e-06)
2022-06-06 22:40:08,173 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 440 |  Loss: (0.0051) | Acc: (99.85%) (28183/28224) | Learning rate: (1e-06)
2022-06-06 22:40:09,968 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 450 |  Loss: (0.0051) | Acc: (99.86%) (28823/28864) | Learning rate: (1e-06)
2022-06-06 22:40:11,762 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 460 |  Loss: (0.0050) | Acc: (99.86%) (29462/29504) | Learning rate: (1e-06)
2022-06-06 22:40:13,557 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 470 |  Loss: (0.0050) | Acc: (99.86%) (30101/30144) | Learning rate: (1e-06)
2022-06-06 22:40:15,354 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 480 |  Loss: (0.0051) | Acc: (99.85%) (30737/30784) | Learning rate: (1e-06)
2022-06-06 22:40:17,151 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 490 |  Loss: (0.0052) | Acc: (99.84%) (31375/31424) | Learning rate: (1e-06)
2022-06-06 22:40:18,947 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 500 |  Loss: (0.0051) | Acc: (99.85%) (32015/32064) | Learning rate: (1e-06)
2022-06-06 22:40:20,742 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 510 |  Loss: (0.0051) | Acc: (99.85%) (32655/32704) | Learning rate: (1e-06)
2022-06-06 22:40:22,537 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 520 |  Loss: (0.0050) | Acc: (99.85%) (33295/33344) | Learning rate: (1e-06)
2022-06-06 22:40:24,333 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 530 |  Loss: (0.0050) | Acc: (99.85%) (33934/33984) | Learning rate: (1e-06)
2022-06-06 22:40:26,131 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 540 |  Loss: (0.0049) | Acc: (99.86%) (34574/34624) | Learning rate: (1e-06)
2022-06-06 22:40:27,928 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 550 |  Loss: (0.0049) | Acc: (99.86%) (35214/35264) | Learning rate: (1e-06)
2022-06-06 22:40:29,726 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 560 |  Loss: (0.0049) | Acc: (99.86%) (35853/35904) | Learning rate: (1e-06)
2022-06-06 22:40:31,524 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 570 |  Loss: (0.0049) | Acc: (99.85%) (36490/36544) | Learning rate: (1e-06)
2022-06-06 22:40:33,318 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 580 |  Loss: (0.0049) | Acc: (99.85%) (37130/37184) | Learning rate: (1e-06)
2022-06-06 22:40:35,113 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 590 |  Loss: (0.0049) | Acc: (99.85%) (37769/37824) | Learning rate: (1e-06)
2022-06-06 22:40:36,909 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 600 |  Loss: (0.0049) | Acc: (99.85%) (38408/38464) | Learning rate: (1e-06)
2022-06-06 22:40:38,706 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 610 |  Loss: (0.0048) | Acc: (99.85%) (39047/39104) | Learning rate: (1e-06)
2022-06-06 22:40:40,502 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 620 |  Loss: (0.0048) | Acc: (99.86%) (39687/39744) | Learning rate: (1e-06)
2022-06-06 22:40:42,298 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 630 |  Loss: (0.0048) | Acc: (99.86%) (40327/40384) | Learning rate: (1e-06)
2022-06-06 22:40:44,095 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 640 |  Loss: (0.0048) | Acc: (99.86%) (40967/41024) | Learning rate: (1e-06)
2022-06-06 22:40:45,891 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 650 |  Loss: (0.0048) | Acc: (99.86%) (41606/41664) | Learning rate: (1e-06)
2022-06-06 22:40:47,687 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 660 |  Loss: (0.0048) | Acc: (99.86%) (42243/42304) | Learning rate: (1e-06)
2022-06-06 22:40:49,485 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 670 |  Loss: (0.0048) | Acc: (99.86%) (42882/42944) | Learning rate: (1e-06)
2022-06-06 22:40:51,281 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 680 |  Loss: (0.0048) | Acc: (99.86%) (43522/43584) | Learning rate: (1e-06)
2022-06-06 22:40:53,077 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 690 |  Loss: (0.0048) | Acc: (99.86%) (44160/44224) | Learning rate: (1e-06)
2022-06-06 22:40:54,875 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 700 |  Loss: (0.0047) | Acc: (99.86%) (44800/44864) | Learning rate: (1e-06)
2022-06-06 22:40:56,670 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 710 |  Loss: (0.0047) | Acc: (99.86%) (45439/45504) | Learning rate: (1e-06)
2022-06-06 22:40:58,466 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 720 |  Loss: (0.0047) | Acc: (99.86%) (46079/46144) | Learning rate: (1e-06)
2022-06-06 22:41:00,262 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 730 |  Loss: (0.0047) | Acc: (99.86%) (46717/46784) | Learning rate: (1e-06)
2022-06-06 22:41:02,059 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 740 |  Loss: (0.0046) | Acc: (99.86%) (47357/47424) | Learning rate: (1e-06)
2022-06-06 22:41:03,857 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 750 |  Loss: (0.0047) | Acc: (99.86%) (47995/48064) | Learning rate: (1e-06)
2022-06-06 22:41:05,655 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 760 |  Loss: (0.0046) | Acc: (99.86%) (48635/48704) | Learning rate: (1e-06)
2022-06-06 22:41:07,445 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 770 |  Loss: (0.0046) | Acc: (99.86%) (49275/49344) | Learning rate: (1e-06)
2022-06-06 22:41:09,234 - CIFAR10 Classifier - INFO - Epoch: 14 | Batch_idx: 780 |  Loss: (0.0046) | Acc: (99.86%) (49915/49984) | Learning rate: (1e-06)
2022-06-06 22:41:19,181 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0841) | Acc: (97.98%) (9798/10000)
2022-06-06 22:41:19,182 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:41:19,989 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 0 |  Loss: (0.0014) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:41:21,812 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 10 |  Loss: (0.0029) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:41:23,605 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 20 |  Loss: (0.0025) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 22:41:25,399 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 22:41:27,194 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 40 |  Loss: (0.0034) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 22:41:28,989 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 50 |  Loss: (0.0053) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 22:41:30,786 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 60 |  Loss: (0.0050) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 22:41:32,583 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 70 |  Loss: (0.0045) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 22:41:34,379 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 22:41:36,174 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.88%) (5817/5824) | Learning rate: (1e-06)
2022-06-06 22:41:37,970 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 100 |  Loss: (0.0056) | Acc: (99.88%) (6456/6464) | Learning rate: (1e-06)
2022-06-06 22:41:39,768 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 110 |  Loss: (0.0059) | Acc: (99.86%) (7094/7104) | Learning rate: (1e-06)
2022-06-06 22:41:41,566 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.86%) (7733/7744) | Learning rate: (1e-06)
2022-06-06 22:41:43,360 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 130 |  Loss: (0.0057) | Acc: (99.86%) (8372/8384) | Learning rate: (1e-06)
2022-06-06 22:41:45,155 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 140 |  Loss: (0.0058) | Acc: (99.84%) (9010/9024) | Learning rate: (1e-06)
2022-06-06 22:41:46,948 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.83%) (9648/9664) | Learning rate: (1e-06)
2022-06-06 22:41:48,746 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 160 |  Loss: (0.0055) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 22:41:50,542 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.84%) (10927/10944) | Learning rate: (1e-06)
2022-06-06 22:41:52,338 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 180 |  Loss: (0.0057) | Acc: (99.84%) (11565/11584) | Learning rate: (1e-06)
2022-06-06 22:41:54,136 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 190 |  Loss: (0.0055) | Acc: (99.84%) (12204/12224) | Learning rate: (1e-06)
2022-06-06 22:41:55,930 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 200 |  Loss: (0.0057) | Acc: (99.83%) (12842/12864) | Learning rate: (1e-06)
2022-06-06 22:41:57,725 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.83%) (13481/13504) | Learning rate: (1e-06)
2022-06-06 22:41:59,520 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.83%) (14120/14144) | Learning rate: (1e-06)
2022-06-06 22:42:01,316 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.83%) (14759/14784) | Learning rate: (1e-06)
2022-06-06 22:42:03,113 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 240 |  Loss: (0.0057) | Acc: (99.83%) (15398/15424) | Learning rate: (1e-06)
2022-06-06 22:42:04,908 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 250 |  Loss: (0.0056) | Acc: (99.83%) (16037/16064) | Learning rate: (1e-06)
2022-06-06 22:42:06,702 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 260 |  Loss: (0.0057) | Acc: (99.83%) (16675/16704) | Learning rate: (1e-06)
2022-06-06 22:42:08,499 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 270 |  Loss: (0.0056) | Acc: (99.83%) (17314/17344) | Learning rate: (1e-06)
2022-06-06 22:42:10,297 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 280 |  Loss: (0.0056) | Acc: (99.83%) (17953/17984) | Learning rate: (1e-06)
2022-06-06 22:42:12,094 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 290 |  Loss: (0.0055) | Acc: (99.83%) (18593/18624) | Learning rate: (1e-06)
2022-06-06 22:42:13,890 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 300 |  Loss: (0.0054) | Acc: (99.83%) (19232/19264) | Learning rate: (1e-06)
2022-06-06 22:42:15,687 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.83%) (19871/19904) | Learning rate: (1e-06)
2022-06-06 22:42:17,485 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.84%) (20511/20544) | Learning rate: (1e-06)
2022-06-06 22:42:19,279 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 330 |  Loss: (0.0052) | Acc: (99.84%) (21150/21184) | Learning rate: (1e-06)
2022-06-06 22:42:21,075 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 340 |  Loss: (0.0051) | Acc: (99.84%) (21790/21824) | Learning rate: (1e-06)
2022-06-06 22:42:22,872 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.85%) (22430/22464) | Learning rate: (1e-06)
2022-06-06 22:42:24,669 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.85%) (23069/23104) | Learning rate: (1e-06)
2022-06-06 22:42:26,465 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 370 |  Loss: (0.0049) | Acc: (99.85%) (23709/23744) | Learning rate: (1e-06)
2022-06-06 22:42:28,259 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 380 |  Loss: (0.0048) | Acc: (99.85%) (24347/24384) | Learning rate: (1e-06)
2022-06-06 22:42:30,056 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 390 |  Loss: (0.0049) | Acc: (99.84%) (24985/25024) | Learning rate: (1e-06)
2022-06-06 22:42:31,851 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 400 |  Loss: (0.0050) | Acc: (99.84%) (25622/25664) | Learning rate: (1e-06)
2022-06-06 22:42:33,649 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 410 |  Loss: (0.0050) | Acc: (99.84%) (26261/26304) | Learning rate: (1e-06)
2022-06-06 22:42:35,447 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 420 |  Loss: (0.0049) | Acc: (99.84%) (26901/26944) | Learning rate: (1e-06)
2022-06-06 22:42:37,244 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 430 |  Loss: (0.0050) | Acc: (99.83%) (27538/27584) | Learning rate: (1e-06)
2022-06-06 22:42:39,042 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 440 |  Loss: (0.0049) | Acc: (99.84%) (28178/28224) | Learning rate: (1e-06)
2022-06-06 22:42:40,838 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 450 |  Loss: (0.0049) | Acc: (99.84%) (28817/28864) | Learning rate: (1e-06)
2022-06-06 22:42:42,634 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 460 |  Loss: (0.0050) | Acc: (99.84%) (29456/29504) | Learning rate: (1e-06)
2022-06-06 22:42:44,429 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 470 |  Loss: (0.0050) | Acc: (99.84%) (30096/30144) | Learning rate: (1e-06)
2022-06-06 22:42:46,226 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 480 |  Loss: (0.0049) | Acc: (99.84%) (30735/30784) | Learning rate: (1e-06)
2022-06-06 22:42:48,023 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 490 |  Loss: (0.0049) | Acc: (99.84%) (31375/31424) | Learning rate: (1e-06)
2022-06-06 22:42:49,818 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 500 |  Loss: (0.0049) | Acc: (99.84%) (32014/32064) | Learning rate: (1e-06)
2022-06-06 22:42:51,615 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 510 |  Loss: (0.0051) | Acc: (99.84%) (32651/32704) | Learning rate: (1e-06)
2022-06-06 22:42:53,412 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 520 |  Loss: (0.0050) | Acc: (99.84%) (33291/33344) | Learning rate: (1e-06)
2022-06-06 22:42:55,208 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 530 |  Loss: (0.0050) | Acc: (99.84%) (33931/33984) | Learning rate: (1e-06)
2022-06-06 22:42:57,004 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 540 |  Loss: (0.0049) | Acc: (99.85%) (34571/34624) | Learning rate: (1e-06)
2022-06-06 22:42:58,801 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 550 |  Loss: (0.0049) | Acc: (99.85%) (35210/35264) | Learning rate: (1e-06)
2022-06-06 22:43:00,598 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 560 |  Loss: (0.0049) | Acc: (99.85%) (35850/35904) | Learning rate: (1e-06)
2022-06-06 22:43:02,394 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 570 |  Loss: (0.0051) | Acc: (99.85%) (36488/36544) | Learning rate: (1e-06)
2022-06-06 22:43:04,191 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 580 |  Loss: (0.0051) | Acc: (99.85%) (37127/37184) | Learning rate: (1e-06)
2022-06-06 22:43:05,988 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 590 |  Loss: (0.0051) | Acc: (99.85%) (37767/37824) | Learning rate: (1e-06)
2022-06-06 22:43:07,784 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 600 |  Loss: (0.0051) | Acc: (99.85%) (38406/38464) | Learning rate: (1e-06)
2022-06-06 22:43:09,581 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 610 |  Loss: (0.0050) | Acc: (99.85%) (39046/39104) | Learning rate: (1e-06)
2022-06-06 22:43:11,377 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 620 |  Loss: (0.0051) | Acc: (99.85%) (39683/39744) | Learning rate: (1e-06)
2022-06-06 22:43:13,174 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 630 |  Loss: (0.0051) | Acc: (99.84%) (40321/40384) | Learning rate: (1e-06)
2022-06-06 22:43:14,971 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 640 |  Loss: (0.0051) | Acc: (99.85%) (40961/41024) | Learning rate: (1e-06)
2022-06-06 22:43:16,768 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 650 |  Loss: (0.0051) | Acc: (99.84%) (41599/41664) | Learning rate: (1e-06)
2022-06-06 22:43:18,565 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 660 |  Loss: (0.0050) | Acc: (99.85%) (42239/42304) | Learning rate: (1e-06)
2022-06-06 22:43:20,361 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 670 |  Loss: (0.0050) | Acc: (99.85%) (42878/42944) | Learning rate: (1e-06)
2022-06-06 22:43:22,156 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 680 |  Loss: (0.0051) | Acc: (99.84%) (43516/43584) | Learning rate: (1e-06)
2022-06-06 22:43:23,953 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 690 |  Loss: (0.0051) | Acc: (99.84%) (44155/44224) | Learning rate: (1e-06)
2022-06-06 22:43:25,751 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 700 |  Loss: (0.0051) | Acc: (99.84%) (44794/44864) | Learning rate: (1e-06)
2022-06-06 22:43:27,548 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 710 |  Loss: (0.0050) | Acc: (99.85%) (45434/45504) | Learning rate: (1e-06)
2022-06-06 22:43:29,346 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 720 |  Loss: (0.0050) | Acc: (99.85%) (46074/46144) | Learning rate: (1e-06)
2022-06-06 22:43:31,143 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 730 |  Loss: (0.0050) | Acc: (99.85%) (46713/46784) | Learning rate: (1e-06)
2022-06-06 22:43:32,938 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 740 |  Loss: (0.0050) | Acc: (99.85%) (47351/47424) | Learning rate: (1e-06)
2022-06-06 22:43:34,733 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 750 |  Loss: (0.0050) | Acc: (99.85%) (47990/48064) | Learning rate: (1e-06)
2022-06-06 22:43:36,530 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 760 |  Loss: (0.0050) | Acc: (99.85%) (48630/48704) | Learning rate: (1e-06)
2022-06-06 22:43:38,321 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 770 |  Loss: (0.0050) | Acc: (99.85%) (49269/49344) | Learning rate: (1e-06)
2022-06-06 22:43:40,109 - CIFAR10 Classifier - INFO - Epoch: 15 | Batch_idx: 780 |  Loss: (0.0050) | Acc: (99.85%) (49909/49984) | Learning rate: (1e-06)
2022-06-06 22:43:50,029 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0804) | Acc: (97.95%) (9795/10000)
2022-06-06 22:43:50,030 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:43:50,938 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 0 |  Loss: (0.0010) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:43:52,729 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 10 |  Loss: (0.0006) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:43:54,521 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 20 |  Loss: (0.0013) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 22:43:56,315 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 30 |  Loss: (0.0015) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 22:43:58,111 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 40 |  Loss: (0.0014) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-06)
2022-06-06 22:43:59,904 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 50 |  Loss: (0.0015) | Acc: (99.97%) (3263/3264) | Learning rate: (1e-06)
2022-06-06 22:44:01,701 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 60 |  Loss: (0.0016) | Acc: (99.97%) (3903/3904) | Learning rate: (1e-06)
2022-06-06 22:44:03,498 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 70 |  Loss: (0.0018) | Acc: (99.96%) (4542/4544) | Learning rate: (1e-06)
2022-06-06 22:44:05,295 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 80 |  Loss: (0.0019) | Acc: (99.96%) (5182/5184) | Learning rate: (1e-06)
2022-06-06 22:44:07,092 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 90 |  Loss: (0.0022) | Acc: (99.93%) (5820/5824) | Learning rate: (1e-06)
2022-06-06 22:44:08,886 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 100 |  Loss: (0.0022) | Acc: (99.94%) (6460/6464) | Learning rate: (1e-06)
2022-06-06 22:44:10,681 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 110 |  Loss: (0.0022) | Acc: (99.94%) (7100/7104) | Learning rate: (1e-06)
2022-06-06 22:44:12,478 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 120 |  Loss: (0.0023) | Acc: (99.95%) (7740/7744) | Learning rate: (1e-06)
2022-06-06 22:44:14,274 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 130 |  Loss: (0.0027) | Acc: (99.94%) (8379/8384) | Learning rate: (1e-06)
2022-06-06 22:44:16,071 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 140 |  Loss: (0.0027) | Acc: (99.93%) (9018/9024) | Learning rate: (1e-06)
2022-06-06 22:44:17,867 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 150 |  Loss: (0.0028) | Acc: (99.93%) (9657/9664) | Learning rate: (1e-06)
2022-06-06 22:44:19,663 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 160 |  Loss: (0.0027) | Acc: (99.93%) (10297/10304) | Learning rate: (1e-06)
2022-06-06 22:44:21,459 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 170 |  Loss: (0.0027) | Acc: (99.93%) (10936/10944) | Learning rate: (1e-06)
2022-06-06 22:44:23,255 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 180 |  Loss: (0.0027) | Acc: (99.93%) (11576/11584) | Learning rate: (1e-06)
2022-06-06 22:44:25,053 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 190 |  Loss: (0.0030) | Acc: (99.90%) (12212/12224) | Learning rate: (1e-06)
2022-06-06 22:44:26,849 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 200 |  Loss: (0.0031) | Acc: (99.90%) (12851/12864) | Learning rate: (1e-06)
2022-06-06 22:44:28,646 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 210 |  Loss: (0.0031) | Acc: (99.90%) (13491/13504) | Learning rate: (1e-06)
2022-06-06 22:44:30,443 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 220 |  Loss: (0.0033) | Acc: (99.90%) (14130/14144) | Learning rate: (1e-06)
2022-06-06 22:44:32,238 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 230 |  Loss: (0.0032) | Acc: (99.91%) (14770/14784) | Learning rate: (1e-06)
2022-06-06 22:44:34,034 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 240 |  Loss: (0.0033) | Acc: (99.90%) (15409/15424) | Learning rate: (1e-06)
2022-06-06 22:44:35,829 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 250 |  Loss: (0.0033) | Acc: (99.90%) (16048/16064) | Learning rate: (1e-06)
2022-06-06 22:44:37,625 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 260 |  Loss: (0.0033) | Acc: (99.90%) (16687/16704) | Learning rate: (1e-06)
2022-06-06 22:44:39,421 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 270 |  Loss: (0.0034) | Acc: (99.88%) (17324/17344) | Learning rate: (1e-06)
2022-06-06 22:44:41,220 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 280 |  Loss: (0.0034) | Acc: (99.88%) (17963/17984) | Learning rate: (1e-06)
2022-06-06 22:44:43,017 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 290 |  Loss: (0.0033) | Acc: (99.89%) (18603/18624) | Learning rate: (1e-06)
2022-06-06 22:44:44,812 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 300 |  Loss: (0.0032) | Acc: (99.89%) (19243/19264) | Learning rate: (1e-06)
2022-06-06 22:44:46,608 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 310 |  Loss: (0.0035) | Acc: (99.88%) (19880/19904) | Learning rate: (1e-06)
2022-06-06 22:44:48,406 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 320 |  Loss: (0.0034) | Acc: (99.88%) (20520/20544) | Learning rate: (1e-06)
2022-06-06 22:44:50,204 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 330 |  Loss: (0.0034) | Acc: (99.88%) (21159/21184) | Learning rate: (1e-06)
2022-06-06 22:44:52,001 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 340 |  Loss: (0.0035) | Acc: (99.88%) (21798/21824) | Learning rate: (1e-06)
2022-06-06 22:44:53,797 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 350 |  Loss: (0.0034) | Acc: (99.88%) (22438/22464) | Learning rate: (1e-06)
2022-06-06 22:44:55,593 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 360 |  Loss: (0.0034) | Acc: (99.88%) (23077/23104) | Learning rate: (1e-06)
2022-06-06 22:44:57,388 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 370 |  Loss: (0.0035) | Acc: (99.88%) (23716/23744) | Learning rate: (1e-06)
2022-06-06 22:44:59,185 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 380 |  Loss: (0.0035) | Acc: (99.89%) (24356/24384) | Learning rate: (1e-06)
2022-06-06 22:45:00,982 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 390 |  Loss: (0.0034) | Acc: (99.89%) (24996/25024) | Learning rate: (1e-06)
2022-06-06 22:45:02,780 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 400 |  Loss: (0.0034) | Acc: (99.89%) (25636/25664) | Learning rate: (1e-06)
2022-06-06 22:45:04,577 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 410 |  Loss: (0.0034) | Acc: (99.89%) (26275/26304) | Learning rate: (1e-06)
2022-06-06 22:45:06,373 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 420 |  Loss: (0.0034) | Acc: (99.89%) (26915/26944) | Learning rate: (1e-06)
2022-06-06 22:45:08,171 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 430 |  Loss: (0.0033) | Acc: (99.89%) (27555/27584) | Learning rate: (1e-06)
2022-06-06 22:45:09,967 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 440 |  Loss: (0.0034) | Acc: (99.89%) (28194/28224) | Learning rate: (1e-06)
2022-06-06 22:45:11,765 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 450 |  Loss: (0.0035) | Acc: (99.89%) (28831/28864) | Learning rate: (1e-06)
2022-06-06 22:45:13,561 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 460 |  Loss: (0.0035) | Acc: (99.88%) (29470/29504) | Learning rate: (1e-06)
2022-06-06 22:45:15,357 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 470 |  Loss: (0.0035) | Acc: (99.89%) (30110/30144) | Learning rate: (1e-06)
2022-06-06 22:45:17,155 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 480 |  Loss: (0.0035) | Acc: (99.89%) (30749/30784) | Learning rate: (1e-06)
2022-06-06 22:45:18,953 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 490 |  Loss: (0.0035) | Acc: (99.89%) (31389/31424) | Learning rate: (1e-06)
2022-06-06 22:45:20,749 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 500 |  Loss: (0.0036) | Acc: (99.89%) (32028/32064) | Learning rate: (1e-06)
2022-06-06 22:45:22,547 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 510 |  Loss: (0.0036) | Acc: (99.89%) (32667/32704) | Learning rate: (1e-06)
2022-06-06 22:45:24,345 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 520 |  Loss: (0.0037) | Acc: (99.88%) (33304/33344) | Learning rate: (1e-06)
2022-06-06 22:45:26,140 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 530 |  Loss: (0.0037) | Acc: (99.88%) (33943/33984) | Learning rate: (1e-06)
2022-06-06 22:45:27,936 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 540 |  Loss: (0.0037) | Acc: (99.88%) (34583/34624) | Learning rate: (1e-06)
2022-06-06 22:45:29,732 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 550 |  Loss: (0.0037) | Acc: (99.88%) (35223/35264) | Learning rate: (1e-06)
2022-06-06 22:45:31,531 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 560 |  Loss: (0.0038) | Acc: (99.87%) (35859/35904) | Learning rate: (1e-06)
2022-06-06 22:45:33,330 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 570 |  Loss: (0.0038) | Acc: (99.87%) (36498/36544) | Learning rate: (1e-06)
2022-06-06 22:45:35,128 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 580 |  Loss: (0.0038) | Acc: (99.87%) (37137/37184) | Learning rate: (1e-06)
2022-06-06 22:45:36,926 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 590 |  Loss: (0.0038) | Acc: (99.88%) (37777/37824) | Learning rate: (1e-06)
2022-06-06 22:45:38,722 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 600 |  Loss: (0.0038) | Acc: (99.88%) (38416/38464) | Learning rate: (1e-06)
2022-06-06 22:45:40,518 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 610 |  Loss: (0.0039) | Acc: (99.87%) (39055/39104) | Learning rate: (1e-06)
2022-06-06 22:45:42,313 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 620 |  Loss: (0.0039) | Acc: (99.87%) (39694/39744) | Learning rate: (1e-06)
2022-06-06 22:45:44,109 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 630 |  Loss: (0.0039) | Acc: (99.87%) (40333/40384) | Learning rate: (1e-06)
2022-06-06 22:45:45,907 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 640 |  Loss: (0.0041) | Acc: (99.87%) (40970/41024) | Learning rate: (1e-06)
2022-06-06 22:45:47,706 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 650 |  Loss: (0.0041) | Acc: (99.87%) (41610/41664) | Learning rate: (1e-06)
2022-06-06 22:45:49,504 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 660 |  Loss: (0.0041) | Acc: (99.87%) (42249/42304) | Learning rate: (1e-06)
2022-06-06 22:45:51,301 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 670 |  Loss: (0.0041) | Acc: (99.87%) (42888/42944) | Learning rate: (1e-06)
2022-06-06 22:45:53,099 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 680 |  Loss: (0.0041) | Acc: (99.87%) (43526/43584) | Learning rate: (1e-06)
2022-06-06 22:45:54,897 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 690 |  Loss: (0.0041) | Acc: (99.86%) (44164/44224) | Learning rate: (1e-06)
2022-06-06 22:45:56,694 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 700 |  Loss: (0.0041) | Acc: (99.87%) (44804/44864) | Learning rate: (1e-06)
2022-06-06 22:45:58,494 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 710 |  Loss: (0.0041) | Acc: (99.87%) (45443/45504) | Learning rate: (1e-06)
2022-06-06 22:46:00,290 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 720 |  Loss: (0.0041) | Acc: (99.86%) (46081/46144) | Learning rate: (1e-06)
2022-06-06 22:46:02,086 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 730 |  Loss: (0.0043) | Acc: (99.86%) (46719/46784) | Learning rate: (1e-06)
2022-06-06 22:46:03,883 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 740 |  Loss: (0.0043) | Acc: (99.86%) (47357/47424) | Learning rate: (1e-06)
2022-06-06 22:46:05,679 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 750 |  Loss: (0.0043) | Acc: (99.86%) (47997/48064) | Learning rate: (1e-06)
2022-06-06 22:46:07,479 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 760 |  Loss: (0.0042) | Acc: (99.86%) (48637/48704) | Learning rate: (1e-06)
2022-06-06 22:46:09,270 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 770 |  Loss: (0.0042) | Acc: (99.86%) (49276/49344) | Learning rate: (1e-06)
2022-06-06 22:46:11,058 - CIFAR10 Classifier - INFO - Epoch: 16 | Batch_idx: 780 |  Loss: (0.0043) | Acc: (99.86%) (49913/49984) | Learning rate: (1e-06)
2022-06-06 22:46:20,979 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0808) | Acc: (98.07%) (9807/10000)
2022-06-06 22:46:20,980 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:46:21,874 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 0 |  Loss: (0.0065) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:46:23,664 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 10 |  Loss: (0.0012) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:46:25,456 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 20 |  Loss: (0.0076) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:46:27,248 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 30 |  Loss: (0.0056) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 22:46:29,044 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 40 |  Loss: (0.0047) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 22:46:30,837 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 50 |  Loss: (0.0041) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-06)
2022-06-06 22:46:32,633 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 60 |  Loss: (0.0038) | Acc: (99.95%) (3902/3904) | Learning rate: (1e-06)
2022-06-06 22:46:34,427 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 70 |  Loss: (0.0036) | Acc: (99.96%) (4542/4544) | Learning rate: (1e-06)
2022-06-06 22:46:36,222 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 80 |  Loss: (0.0033) | Acc: (99.96%) (5182/5184) | Learning rate: (1e-06)
2022-06-06 22:46:38,018 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 90 |  Loss: (0.0035) | Acc: (99.95%) (5821/5824) | Learning rate: (1e-06)
2022-06-06 22:46:39,811 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 100 |  Loss: (0.0035) | Acc: (99.95%) (6461/6464) | Learning rate: (1e-06)
2022-06-06 22:46:41,607 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 110 |  Loss: (0.0035) | Acc: (99.93%) (7099/7104) | Learning rate: (1e-06)
2022-06-06 22:46:43,401 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 120 |  Loss: (0.0035) | Acc: (99.94%) (7739/7744) | Learning rate: (1e-06)
2022-06-06 22:46:45,197 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 130 |  Loss: (0.0036) | Acc: (99.93%) (8378/8384) | Learning rate: (1e-06)
2022-06-06 22:46:46,994 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 140 |  Loss: (0.0037) | Acc: (99.91%) (9016/9024) | Learning rate: (1e-06)
2022-06-06 22:46:48,788 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 150 |  Loss: (0.0036) | Acc: (99.92%) (9656/9664) | Learning rate: (1e-06)
2022-06-06 22:46:50,584 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 160 |  Loss: (0.0036) | Acc: (99.91%) (10295/10304) | Learning rate: (1e-06)
2022-06-06 22:46:52,379 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 170 |  Loss: (0.0037) | Acc: (99.91%) (10934/10944) | Learning rate: (1e-06)
2022-06-06 22:46:54,175 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 180 |  Loss: (0.0040) | Acc: (99.90%) (11572/11584) | Learning rate: (1e-06)
2022-06-06 22:46:55,968 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 190 |  Loss: (0.0038) | Acc: (99.90%) (12212/12224) | Learning rate: (1e-06)
2022-06-06 22:46:57,762 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 200 |  Loss: (0.0040) | Acc: (99.90%) (12851/12864) | Learning rate: (1e-06)
2022-06-06 22:46:59,559 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 210 |  Loss: (0.0039) | Acc: (99.90%) (13491/13504) | Learning rate: (1e-06)
2022-06-06 22:47:01,354 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 220 |  Loss: (0.0038) | Acc: (99.91%) (14131/14144) | Learning rate: (1e-06)
2022-06-06 22:47:03,150 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 230 |  Loss: (0.0037) | Acc: (99.91%) (14771/14784) | Learning rate: (1e-06)
2022-06-06 22:47:04,944 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 240 |  Loss: (0.0036) | Acc: (99.92%) (15411/15424) | Learning rate: (1e-06)
2022-06-06 22:47:06,739 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 250 |  Loss: (0.0035) | Acc: (99.92%) (16051/16064) | Learning rate: (1e-06)
2022-06-06 22:47:08,536 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 260 |  Loss: (0.0037) | Acc: (99.91%) (16689/16704) | Learning rate: (1e-06)
2022-06-06 22:47:10,331 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 270 |  Loss: (0.0037) | Acc: (99.91%) (17329/17344) | Learning rate: (1e-06)
2022-06-06 22:47:12,125 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 280 |  Loss: (0.0038) | Acc: (99.91%) (17967/17984) | Learning rate: (1e-06)
2022-06-06 22:47:13,920 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 290 |  Loss: (0.0038) | Acc: (99.91%) (18607/18624) | Learning rate: (1e-06)
2022-06-06 22:47:15,714 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 300 |  Loss: (0.0037) | Acc: (99.91%) (19246/19264) | Learning rate: (1e-06)
2022-06-06 22:47:17,510 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 310 |  Loss: (0.0037) | Acc: (99.91%) (19886/19904) | Learning rate: (1e-06)
2022-06-06 22:47:19,306 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 320 |  Loss: (0.0037) | Acc: (99.91%) (20525/20544) | Learning rate: (1e-06)
2022-06-06 22:47:21,101 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 330 |  Loss: (0.0037) | Acc: (99.91%) (21164/21184) | Learning rate: (1e-06)
2022-06-06 22:47:22,897 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 340 |  Loss: (0.0037) | Acc: (99.91%) (21804/21824) | Learning rate: (1e-06)
2022-06-06 22:47:24,691 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 350 |  Loss: (0.0037) | Acc: (99.91%) (22443/22464) | Learning rate: (1e-06)
2022-06-06 22:47:26,488 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 360 |  Loss: (0.0039) | Acc: (99.90%) (23081/23104) | Learning rate: (1e-06)
2022-06-06 22:47:28,282 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 370 |  Loss: (0.0039) | Acc: (99.90%) (23721/23744) | Learning rate: (1e-06)
2022-06-06 22:47:30,076 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 380 |  Loss: (0.0038) | Acc: (99.91%) (24361/24384) | Learning rate: (1e-06)
2022-06-06 22:47:31,871 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 390 |  Loss: (0.0039) | Acc: (99.90%) (24999/25024) | Learning rate: (1e-06)
2022-06-06 22:47:33,666 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 400 |  Loss: (0.0038) | Acc: (99.90%) (25639/25664) | Learning rate: (1e-06)
2022-06-06 22:47:35,463 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 410 |  Loss: (0.0038) | Acc: (99.90%) (26277/26304) | Learning rate: (1e-06)
2022-06-06 22:47:37,258 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 420 |  Loss: (0.0038) | Acc: (99.90%) (26917/26944) | Learning rate: (1e-06)
2022-06-06 22:47:39,053 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 430 |  Loss: (0.0037) | Acc: (99.90%) (27557/27584) | Learning rate: (1e-06)
2022-06-06 22:47:40,848 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 440 |  Loss: (0.0038) | Acc: (99.90%) (28195/28224) | Learning rate: (1e-06)
2022-06-06 22:47:42,644 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 450 |  Loss: (0.0038) | Acc: (99.90%) (28834/28864) | Learning rate: (1e-06)
2022-06-06 22:47:44,443 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 460 |  Loss: (0.0038) | Acc: (99.89%) (29473/29504) | Learning rate: (1e-06)
2022-06-06 22:47:46,238 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 470 |  Loss: (0.0038) | Acc: (99.89%) (30112/30144) | Learning rate: (1e-06)
2022-06-06 22:47:48,033 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 480 |  Loss: (0.0038) | Acc: (99.90%) (30752/30784) | Learning rate: (1e-06)
2022-06-06 22:47:49,829 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 490 |  Loss: (0.0037) | Acc: (99.90%) (31392/31424) | Learning rate: (1e-06)
2022-06-06 22:47:51,623 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 500 |  Loss: (0.0039) | Acc: (99.89%) (32029/32064) | Learning rate: (1e-06)
2022-06-06 22:47:53,422 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 510 |  Loss: (0.0039) | Acc: (99.89%) (32669/32704) | Learning rate: (1e-06)
2022-06-06 22:47:55,218 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 520 |  Loss: (0.0039) | Acc: (99.90%) (33309/33344) | Learning rate: (1e-06)
2022-06-06 22:47:57,014 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 530 |  Loss: (0.0038) | Acc: (99.90%) (33949/33984) | Learning rate: (1e-06)
2022-06-06 22:47:58,811 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 540 |  Loss: (0.0038) | Acc: (99.90%) (34589/34624) | Learning rate: (1e-06)
2022-06-06 22:48:00,606 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 550 |  Loss: (0.0038) | Acc: (99.90%) (35228/35264) | Learning rate: (1e-06)
2022-06-06 22:48:02,402 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 560 |  Loss: (0.0038) | Acc: (99.90%) (35867/35904) | Learning rate: (1e-06)
2022-06-06 22:48:04,198 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 570 |  Loss: (0.0038) | Acc: (99.90%) (36506/36544) | Learning rate: (1e-06)
2022-06-06 22:48:05,993 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 580 |  Loss: (0.0038) | Acc: (99.90%) (37146/37184) | Learning rate: (1e-06)
2022-06-06 22:48:07,790 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 590 |  Loss: (0.0037) | Acc: (99.90%) (37786/37824) | Learning rate: (1e-06)
2022-06-06 22:48:09,584 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 600 |  Loss: (0.0037) | Acc: (99.90%) (38425/38464) | Learning rate: (1e-06)
2022-06-06 22:48:11,379 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 610 |  Loss: (0.0037) | Acc: (99.90%) (39065/39104) | Learning rate: (1e-06)
2022-06-06 22:48:13,176 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 620 |  Loss: (0.0037) | Acc: (99.90%) (39704/39744) | Learning rate: (1e-06)
2022-06-06 22:48:14,971 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 630 |  Loss: (0.0037) | Acc: (99.90%) (40344/40384) | Learning rate: (1e-06)
2022-06-06 22:48:16,768 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 640 |  Loss: (0.0036) | Acc: (99.90%) (40984/41024) | Learning rate: (1e-06)
2022-06-06 22:48:18,563 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 650 |  Loss: (0.0036) | Acc: (99.90%) (41623/41664) | Learning rate: (1e-06)
2022-06-06 22:48:20,358 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 660 |  Loss: (0.0036) | Acc: (99.90%) (42262/42304) | Learning rate: (1e-06)
2022-06-06 22:48:22,154 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 670 |  Loss: (0.0036) | Acc: (99.90%) (42902/42944) | Learning rate: (1e-06)
2022-06-06 22:48:23,950 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 680 |  Loss: (0.0036) | Acc: (99.90%) (43542/43584) | Learning rate: (1e-06)
2022-06-06 22:48:25,747 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 690 |  Loss: (0.0036) | Acc: (99.91%) (44182/44224) | Learning rate: (1e-06)
2022-06-06 22:48:27,542 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 700 |  Loss: (0.0035) | Acc: (99.91%) (44822/44864) | Learning rate: (1e-06)
2022-06-06 22:48:29,337 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 710 |  Loss: (0.0035) | Acc: (99.91%) (45462/45504) | Learning rate: (1e-06)
2022-06-06 22:48:31,134 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 720 |  Loss: (0.0035) | Acc: (99.91%) (46102/46144) | Learning rate: (1e-06)
2022-06-06 22:48:32,931 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 730 |  Loss: (0.0035) | Acc: (99.91%) (46742/46784) | Learning rate: (1e-06)
2022-06-06 22:48:34,729 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 740 |  Loss: (0.0035) | Acc: (99.91%) (47381/47424) | Learning rate: (1e-06)
2022-06-06 22:48:36,525 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 750 |  Loss: (0.0035) | Acc: (99.91%) (48019/48064) | Learning rate: (1e-06)
2022-06-06 22:48:38,321 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 760 |  Loss: (0.0035) | Acc: (99.91%) (48658/48704) | Learning rate: (1e-06)
2022-06-06 22:48:40,110 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 770 |  Loss: (0.0035) | Acc: (99.90%) (49297/49344) | Learning rate: (1e-06)
2022-06-06 22:48:41,899 - CIFAR10 Classifier - INFO - Epoch: 17 | Batch_idx: 780 |  Loss: (0.0035) | Acc: (99.90%) (49936/49984) | Learning rate: (1e-06)
2022-06-06 22:48:51,841 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0841) | Acc: (97.89%) (9789/10000)
2022-06-06 22:48:51,841 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:48:52,739 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 0 |  Loss: (0.0003) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:48:54,527 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 10 |  Loss: (0.0053) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 22:48:56,317 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 20 |  Loss: (0.0065) | Acc: (99.78%) (1341/1344) | Learning rate: (1e-06)
2022-06-06 22:48:58,110 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 30 |  Loss: (0.0057) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-06)
2022-06-06 22:48:59,905 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 40 |  Loss: (0.0061) | Acc: (99.77%) (2618/2624) | Learning rate: (1e-06)
2022-06-06 22:49:01,700 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 50 |  Loss: (0.0059) | Acc: (99.79%) (3257/3264) | Learning rate: (1e-06)
2022-06-06 22:49:03,496 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 60 |  Loss: (0.0051) | Acc: (99.82%) (3897/3904) | Learning rate: (1e-06)
2022-06-06 22:49:05,290 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 70 |  Loss: (0.0047) | Acc: (99.85%) (4537/4544) | Learning rate: (1e-06)
2022-06-06 22:49:07,083 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 80 |  Loss: (0.0047) | Acc: (99.83%) (5175/5184) | Learning rate: (1e-06)
2022-06-06 22:49:08,878 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 90 |  Loss: (0.0046) | Acc: (99.85%) (5815/5824) | Learning rate: (1e-06)
2022-06-06 22:49:10,673 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 100 |  Loss: (0.0048) | Acc: (99.83%) (6453/6464) | Learning rate: (1e-06)
2022-06-06 22:49:12,468 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 110 |  Loss: (0.0070) | Acc: (99.80%) (7090/7104) | Learning rate: (1e-06)
2022-06-06 22:49:14,263 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 120 |  Loss: (0.0066) | Acc: (99.82%) (7730/7744) | Learning rate: (1e-06)
2022-06-06 22:49:16,057 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 130 |  Loss: (0.0064) | Acc: (99.82%) (8369/8384) | Learning rate: (1e-06)
2022-06-06 22:49:17,853 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 140 |  Loss: (0.0061) | Acc: (99.83%) (9009/9024) | Learning rate: (1e-06)
2022-06-06 22:49:19,649 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.84%) (9649/9664) | Learning rate: (1e-06)
2022-06-06 22:49:21,444 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 160 |  Loss: (0.0062) | Acc: (99.84%) (10287/10304) | Learning rate: (1e-06)
2022-06-06 22:49:23,237 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 170 |  Loss: (0.0059) | Acc: (99.84%) (10927/10944) | Learning rate: (1e-06)
2022-06-06 22:49:25,032 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 180 |  Loss: (0.0057) | Acc: (99.85%) (11567/11584) | Learning rate: (1e-06)
2022-06-06 22:49:26,828 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 190 |  Loss: (0.0055) | Acc: (99.85%) (12206/12224) | Learning rate: (1e-06)
2022-06-06 22:49:28,623 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.84%) (12844/12864) | Learning rate: (1e-06)
2022-06-06 22:49:30,417 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.83%) (13481/13504) | Learning rate: (1e-06)
2022-06-06 22:49:32,211 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 220 |  Loss: (0.0053) | Acc: (99.84%) (14121/14144) | Learning rate: (1e-06)
2022-06-06 22:49:34,008 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.84%) (14761/14784) | Learning rate: (1e-06)
2022-06-06 22:49:35,803 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.85%) (15401/15424) | Learning rate: (1e-06)
2022-06-06 22:49:37,596 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 250 |  Loss: (0.0052) | Acc: (99.84%) (16039/16064) | Learning rate: (1e-06)
2022-06-06 22:49:39,390 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 260 |  Loss: (0.0055) | Acc: (99.84%) (16677/16704) | Learning rate: (1e-06)
2022-06-06 22:49:41,185 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 270 |  Loss: (0.0054) | Acc: (99.84%) (17316/17344) | Learning rate: (1e-06)
2022-06-06 22:49:42,983 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.84%) (17956/17984) | Learning rate: (1e-06)
2022-06-06 22:49:44,778 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.84%) (18595/18624) | Learning rate: (1e-06)
2022-06-06 22:49:46,573 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.84%) (19234/19264) | Learning rate: (1e-06)
2022-06-06 22:49:48,369 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 310 |  Loss: (0.0056) | Acc: (99.84%) (19873/19904) | Learning rate: (1e-06)
2022-06-06 22:49:50,165 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 320 |  Loss: (0.0056) | Acc: (99.84%) (20512/20544) | Learning rate: (1e-06)
2022-06-06 22:49:51,962 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 330 |  Loss: (0.0056) | Acc: (99.85%) (21152/21184) | Learning rate: (1e-06)
2022-06-06 22:49:53,759 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 340 |  Loss: (0.0057) | Acc: (99.84%) (21789/21824) | Learning rate: (1e-06)
2022-06-06 22:49:55,555 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 350 |  Loss: (0.0056) | Acc: (99.84%) (22428/22464) | Learning rate: (1e-06)
2022-06-06 22:49:57,353 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.84%) (23068/23104) | Learning rate: (1e-06)
2022-06-06 22:49:59,147 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 370 |  Loss: (0.0054) | Acc: (99.85%) (23708/23744) | Learning rate: (1e-06)
2022-06-06 22:50:00,942 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.85%) (24348/24384) | Learning rate: (1e-06)
2022-06-06 22:50:02,739 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.86%) (24988/25024) | Learning rate: (1e-06)
2022-06-06 22:50:04,534 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 400 |  Loss: (0.0052) | Acc: (99.86%) (25628/25664) | Learning rate: (1e-06)
2022-06-06 22:50:06,331 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 410 |  Loss: (0.0051) | Acc: (99.86%) (26268/26304) | Learning rate: (1e-06)
2022-06-06 22:50:08,127 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 420 |  Loss: (0.0050) | Acc: (99.86%) (26907/26944) | Learning rate: (1e-06)
2022-06-06 22:50:09,921 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 430 |  Loss: (0.0049) | Acc: (99.87%) (27547/27584) | Learning rate: (1e-06)
2022-06-06 22:50:11,718 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 440 |  Loss: (0.0049) | Acc: (99.87%) (28186/28224) | Learning rate: (1e-06)
2022-06-06 22:50:13,515 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 450 |  Loss: (0.0049) | Acc: (99.86%) (28825/28864) | Learning rate: (1e-06)
2022-06-06 22:50:15,313 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 460 |  Loss: (0.0049) | Acc: (99.86%) (29463/29504) | Learning rate: (1e-06)
2022-06-06 22:50:17,110 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 470 |  Loss: (0.0049) | Acc: (99.86%) (30102/30144) | Learning rate: (1e-06)
2022-06-06 22:50:18,905 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 480 |  Loss: (0.0049) | Acc: (99.86%) (30741/30784) | Learning rate: (1e-06)
2022-06-06 22:50:20,699 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 490 |  Loss: (0.0048) | Acc: (99.86%) (31381/31424) | Learning rate: (1e-06)
2022-06-06 22:50:22,493 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 500 |  Loss: (0.0050) | Acc: (99.86%) (32020/32064) | Learning rate: (1e-06)
2022-06-06 22:50:24,294 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 510 |  Loss: (0.0050) | Acc: (99.86%) (32658/32704) | Learning rate: (1e-06)
2022-06-06 22:50:26,089 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 520 |  Loss: (0.0050) | Acc: (99.86%) (33298/33344) | Learning rate: (1e-06)
2022-06-06 22:50:27,885 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 530 |  Loss: (0.0049) | Acc: (99.86%) (33937/33984) | Learning rate: (1e-06)
2022-06-06 22:50:29,682 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 540 |  Loss: (0.0049) | Acc: (99.86%) (34577/34624) | Learning rate: (1e-06)
2022-06-06 22:50:31,475 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 550 |  Loss: (0.0049) | Acc: (99.86%) (35216/35264) | Learning rate: (1e-06)
2022-06-06 22:50:33,271 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 560 |  Loss: (0.0048) | Acc: (99.86%) (35855/35904) | Learning rate: (1e-06)
2022-06-06 22:50:35,068 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 570 |  Loss: (0.0047) | Acc: (99.87%) (36495/36544) | Learning rate: (1e-06)
2022-06-06 22:50:36,865 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 580 |  Loss: (0.0048) | Acc: (99.86%) (37133/37184) | Learning rate: (1e-06)
2022-06-06 22:50:38,663 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 590 |  Loss: (0.0047) | Acc: (99.87%) (37773/37824) | Learning rate: (1e-06)
2022-06-06 22:50:40,458 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 600 |  Loss: (0.0049) | Acc: (99.86%) (38410/38464) | Learning rate: (1e-06)
2022-06-06 22:50:42,253 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 610 |  Loss: (0.0048) | Acc: (99.86%) (39050/39104) | Learning rate: (1e-06)
2022-06-06 22:50:44,050 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 620 |  Loss: (0.0048) | Acc: (99.86%) (39690/39744) | Learning rate: (1e-06)
2022-06-06 22:50:45,846 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 630 |  Loss: (0.0048) | Acc: (99.87%) (40330/40384) | Learning rate: (1e-06)
2022-06-06 22:50:47,644 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 640 |  Loss: (0.0047) | Acc: (99.87%) (40969/41024) | Learning rate: (1e-06)
2022-06-06 22:50:49,440 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 650 |  Loss: (0.0047) | Acc: (99.87%) (41608/41664) | Learning rate: (1e-06)
2022-06-06 22:50:51,237 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 660 |  Loss: (0.0048) | Acc: (99.86%) (42246/42304) | Learning rate: (1e-06)
2022-06-06 22:50:53,034 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 670 |  Loss: (0.0048) | Acc: (99.86%) (42885/42944) | Learning rate: (1e-06)
2022-06-06 22:50:54,828 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 680 |  Loss: (0.0049) | Acc: (99.86%) (43523/43584) | Learning rate: (1e-06)
2022-06-06 22:50:56,623 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 690 |  Loss: (0.0048) | Acc: (99.86%) (44162/44224) | Learning rate: (1e-06)
2022-06-06 22:50:58,420 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 700 |  Loss: (0.0048) | Acc: (99.86%) (44801/44864) | Learning rate: (1e-06)
2022-06-06 22:51:00,217 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 710 |  Loss: (0.0048) | Acc: (99.86%) (45441/45504) | Learning rate: (1e-06)
2022-06-06 22:51:02,014 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 720 |  Loss: (0.0047) | Acc: (99.86%) (46081/46144) | Learning rate: (1e-06)
2022-06-06 22:51:03,812 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 730 |  Loss: (0.0047) | Acc: (99.87%) (46721/46784) | Learning rate: (1e-06)
2022-06-06 22:51:05,608 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 740 |  Loss: (0.0047) | Acc: (99.87%) (47360/47424) | Learning rate: (1e-06)
2022-06-06 22:51:07,403 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 750 |  Loss: (0.0046) | Acc: (99.87%) (48000/48064) | Learning rate: (1e-06)
2022-06-06 22:51:09,199 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 760 |  Loss: (0.0046) | Acc: (99.87%) (48640/48704) | Learning rate: (1e-06)
2022-06-06 22:51:10,989 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 770 |  Loss: (0.0046) | Acc: (99.87%) (49280/49344) | Learning rate: (1e-06)
2022-06-06 22:51:12,777 - CIFAR10 Classifier - INFO - Epoch: 18 | Batch_idx: 780 |  Loss: (0.0046) | Acc: (99.87%) (49919/49984) | Learning rate: (1e-06)
2022-06-06 22:51:22,684 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0821) | Acc: (98.06%) (9806/10000)
2022-06-06 22:51:22,685 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:51:23,585 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 0 |  Loss: (0.0725) | Acc: (98.44%) (63/64) | Learning rate: (1e-06)
2022-06-06 22:51:25,377 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 10 |  Loss: (0.0085) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 22:51:27,171 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 20 |  Loss: (0.0060) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:51:28,965 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 30 |  Loss: (0.0054) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-06)
2022-06-06 22:51:30,761 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 40 |  Loss: (0.0049) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-06)
2022-06-06 22:51:32,555 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 50 |  Loss: (0.0047) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 22:51:34,351 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 60 |  Loss: (0.0040) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 22:51:36,149 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 70 |  Loss: (0.0039) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 22:51:37,945 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 80 |  Loss: (0.0037) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-06)
2022-06-06 22:51:39,742 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 90 |  Loss: (0.0037) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 22:51:41,537 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 100 |  Loss: (0.0036) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-06)
2022-06-06 22:51:43,335 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 110 |  Loss: (0.0036) | Acc: (99.90%) (7097/7104) | Learning rate: (1e-06)
2022-06-06 22:51:45,129 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 120 |  Loss: (0.0036) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-06)
2022-06-06 22:51:46,926 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 130 |  Loss: (0.0035) | Acc: (99.92%) (8377/8384) | Learning rate: (1e-06)
2022-06-06 22:51:48,723 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 140 |  Loss: (0.0037) | Acc: (99.91%) (9016/9024) | Learning rate: (1e-06)
2022-06-06 22:51:50,519 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 150 |  Loss: (0.0035) | Acc: (99.92%) (9656/9664) | Learning rate: (1e-06)
2022-06-06 22:51:52,316 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 160 |  Loss: (0.0037) | Acc: (99.90%) (10294/10304) | Learning rate: (1e-06)
2022-06-06 22:51:54,111 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 170 |  Loss: (0.0037) | Acc: (99.91%) (10934/10944) | Learning rate: (1e-06)
2022-06-06 22:51:55,906 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.91%) (11573/11584) | Learning rate: (1e-06)
2022-06-06 22:51:57,703 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 190 |  Loss: (0.0037) | Acc: (99.90%) (12212/12224) | Learning rate: (1e-06)
2022-06-06 22:51:59,500 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 200 |  Loss: (0.0036) | Acc: (99.91%) (12852/12864) | Learning rate: (1e-06)
2022-06-06 22:52:01,298 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 210 |  Loss: (0.0038) | Acc: (99.90%) (13491/13504) | Learning rate: (1e-06)
2022-06-06 22:52:03,094 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 220 |  Loss: (0.0039) | Acc: (99.90%) (14130/14144) | Learning rate: (1e-06)
2022-06-06 22:52:04,894 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 230 |  Loss: (0.0039) | Acc: (99.90%) (14769/14784) | Learning rate: (1e-06)
2022-06-06 22:52:06,691 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 240 |  Loss: (0.0038) | Acc: (99.90%) (15409/15424) | Learning rate: (1e-06)
2022-06-06 22:52:08,487 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 250 |  Loss: (0.0039) | Acc: (99.90%) (16048/16064) | Learning rate: (1e-06)
2022-06-06 22:52:10,282 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 260 |  Loss: (0.0040) | Acc: (99.90%) (16687/16704) | Learning rate: (1e-06)
2022-06-06 22:52:12,079 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 270 |  Loss: (0.0039) | Acc: (99.90%) (17327/17344) | Learning rate: (1e-06)
2022-06-06 22:52:13,877 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 280 |  Loss: (0.0038) | Acc: (99.90%) (17966/17984) | Learning rate: (1e-06)
2022-06-06 22:52:15,675 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 290 |  Loss: (0.0038) | Acc: (99.90%) (18605/18624) | Learning rate: (1e-06)
2022-06-06 22:52:17,473 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 300 |  Loss: (0.0038) | Acc: (99.90%) (19245/19264) | Learning rate: (1e-06)
2022-06-06 22:52:19,270 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 310 |  Loss: (0.0038) | Acc: (99.90%) (19885/19904) | Learning rate: (1e-06)
2022-06-06 22:52:21,067 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 320 |  Loss: (0.0038) | Acc: (99.90%) (20524/20544) | Learning rate: (1e-06)
2022-06-06 22:52:22,864 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 330 |  Loss: (0.0038) | Acc: (99.91%) (21164/21184) | Learning rate: (1e-06)
2022-06-06 22:52:24,660 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 340 |  Loss: (0.0038) | Acc: (99.91%) (21804/21824) | Learning rate: (1e-06)
2022-06-06 22:52:26,455 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.91%) (22443/22464) | Learning rate: (1e-06)
2022-06-06 22:52:28,252 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 360 |  Loss: (0.0039) | Acc: (99.90%) (23081/23104) | Learning rate: (1e-06)
2022-06-06 22:52:30,049 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 370 |  Loss: (0.0040) | Acc: (99.90%) (23720/23744) | Learning rate: (1e-06)
2022-06-06 22:52:31,846 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 380 |  Loss: (0.0039) | Acc: (99.90%) (24360/24384) | Learning rate: (1e-06)
2022-06-06 22:52:33,643 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 390 |  Loss: (0.0041) | Acc: (99.89%) (24997/25024) | Learning rate: (1e-06)
2022-06-06 22:52:35,441 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 400 |  Loss: (0.0041) | Acc: (99.89%) (25636/25664) | Learning rate: (1e-06)
2022-06-06 22:52:37,238 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 410 |  Loss: (0.0041) | Acc: (99.89%) (26276/26304) | Learning rate: (1e-06)
2022-06-06 22:52:39,031 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 420 |  Loss: (0.0040) | Acc: (99.89%) (26915/26944) | Learning rate: (1e-06)
2022-06-06 22:52:40,828 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 430 |  Loss: (0.0041) | Acc: (99.89%) (27554/27584) | Learning rate: (1e-06)
2022-06-06 22:52:42,626 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 440 |  Loss: (0.0040) | Acc: (99.89%) (28194/28224) | Learning rate: (1e-06)
2022-06-06 22:52:44,423 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 450 |  Loss: (0.0040) | Acc: (99.90%) (28834/28864) | Learning rate: (1e-06)
2022-06-06 22:52:46,220 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 460 |  Loss: (0.0040) | Acc: (99.90%) (29474/29504) | Learning rate: (1e-06)
2022-06-06 22:52:48,015 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 470 |  Loss: (0.0040) | Acc: (99.90%) (30113/30144) | Learning rate: (1e-06)
2022-06-06 22:52:49,811 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 480 |  Loss: (0.0040) | Acc: (99.90%) (30752/30784) | Learning rate: (1e-06)
2022-06-06 22:52:51,605 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 490 |  Loss: (0.0039) | Acc: (99.90%) (31392/31424) | Learning rate: (1e-06)
2022-06-06 22:52:53,401 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 500 |  Loss: (0.0039) | Acc: (99.89%) (32030/32064) | Learning rate: (1e-06)
2022-06-06 22:52:55,197 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 510 |  Loss: (0.0040) | Acc: (99.89%) (32669/32704) | Learning rate: (1e-06)
2022-06-06 22:52:56,994 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 520 |  Loss: (0.0039) | Acc: (99.90%) (33309/33344) | Learning rate: (1e-06)
2022-06-06 22:52:58,787 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 530 |  Loss: (0.0039) | Acc: (99.90%) (33949/33984) | Learning rate: (1e-06)
2022-06-06 22:53:00,582 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 540 |  Loss: (0.0039) | Acc: (99.90%) (34588/34624) | Learning rate: (1e-06)
2022-06-06 22:53:02,380 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 550 |  Loss: (0.0039) | Acc: (99.90%) (35228/35264) | Learning rate: (1e-06)
2022-06-06 22:53:04,175 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 560 |  Loss: (0.0039) | Acc: (99.89%) (35866/35904) | Learning rate: (1e-06)
2022-06-06 22:53:05,972 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 570 |  Loss: (0.0038) | Acc: (99.90%) (36506/36544) | Learning rate: (1e-06)
2022-06-06 22:53:07,767 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 580 |  Loss: (0.0039) | Acc: (99.89%) (37144/37184) | Learning rate: (1e-06)
2022-06-06 22:53:09,560 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 590 |  Loss: (0.0039) | Acc: (99.89%) (37784/37824) | Learning rate: (1e-06)
2022-06-06 22:53:11,356 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 600 |  Loss: (0.0039) | Acc: (99.89%) (38423/38464) | Learning rate: (1e-06)
2022-06-06 22:53:13,152 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 610 |  Loss: (0.0039) | Acc: (99.90%) (39063/39104) | Learning rate: (1e-06)
2022-06-06 22:53:14,948 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 620 |  Loss: (0.0038) | Acc: (99.89%) (39702/39744) | Learning rate: (1e-06)
2022-06-06 22:53:16,743 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 630 |  Loss: (0.0039) | Acc: (99.89%) (40341/40384) | Learning rate: (1e-06)
2022-06-06 22:53:18,538 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 640 |  Loss: (0.0040) | Acc: (99.89%) (40979/41024) | Learning rate: (1e-06)
2022-06-06 22:53:20,333 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 650 |  Loss: (0.0041) | Acc: (99.89%) (41617/41664) | Learning rate: (1e-06)
2022-06-06 22:53:22,129 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 660 |  Loss: (0.0040) | Acc: (99.89%) (42257/42304) | Learning rate: (1e-06)
2022-06-06 22:53:23,925 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 670 |  Loss: (0.0040) | Acc: (99.89%) (42897/42944) | Learning rate: (1e-06)
2022-06-06 22:53:25,722 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 680 |  Loss: (0.0040) | Acc: (99.89%) (43537/43584) | Learning rate: (1e-06)
2022-06-06 22:53:27,516 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 690 |  Loss: (0.0040) | Acc: (99.89%) (44177/44224) | Learning rate: (1e-06)
2022-06-06 22:53:29,312 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 700 |  Loss: (0.0040) | Acc: (99.89%) (44816/44864) | Learning rate: (1e-06)
2022-06-06 22:53:31,109 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 710 |  Loss: (0.0040) | Acc: (99.89%) (45456/45504) | Learning rate: (1e-06)
2022-06-06 22:53:32,904 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 720 |  Loss: (0.0041) | Acc: (99.89%) (46093/46144) | Learning rate: (1e-06)
2022-06-06 22:53:34,700 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 730 |  Loss: (0.0041) | Acc: (99.89%) (46733/46784) | Learning rate: (1e-06)
2022-06-06 22:53:36,495 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 740 |  Loss: (0.0040) | Acc: (99.89%) (47372/47424) | Learning rate: (1e-06)
2022-06-06 22:53:38,290 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 750 |  Loss: (0.0041) | Acc: (99.89%) (48011/48064) | Learning rate: (1e-06)
2022-06-06 22:53:40,088 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 760 |  Loss: (0.0040) | Acc: (99.89%) (48651/48704) | Learning rate: (1e-06)
2022-06-06 22:53:41,875 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 770 |  Loss: (0.0041) | Acc: (99.89%) (49290/49344) | Learning rate: (1e-06)
2022-06-06 22:53:43,664 - CIFAR10 Classifier - INFO - Epoch: 19 | Batch_idx: 780 |  Loss: (0.0041) | Acc: (99.89%) (49928/49984) | Learning rate: (1e-06)
2022-06-06 22:53:53,569 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0804) | Acc: (97.98%) (9798/10000)
2022-06-06 22:53:53,570 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:53:54,378 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 0 |  Loss: (0.0006) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:53:56,187 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 10 |  Loss: (0.0043) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:53:57,981 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 20 |  Loss: (0.0054) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:53:59,773 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 30 |  Loss: (0.0058) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 22:54:01,565 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 40 |  Loss: (0.0065) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 22:54:03,359 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 22:54:05,153 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 22:54:06,946 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 70 |  Loss: (0.0056) | Acc: (99.85%) (4537/4544) | Learning rate: (1e-06)
2022-06-06 22:54:08,739 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 80 |  Loss: (0.0056) | Acc: (99.85%) (5176/5184) | Learning rate: (1e-06)
2022-06-06 22:54:10,533 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 90 |  Loss: (0.0053) | Acc: (99.85%) (5815/5824) | Learning rate: (1e-06)
2022-06-06 22:54:12,327 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 100 |  Loss: (0.0051) | Acc: (99.85%) (6454/6464) | Learning rate: (1e-06)
2022-06-06 22:54:14,120 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 110 |  Loss: (0.0051) | Acc: (99.85%) (7093/7104) | Learning rate: (1e-06)
2022-06-06 22:54:15,914 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.85%) (7732/7744) | Learning rate: (1e-06)
2022-06-06 22:54:17,710 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 130 |  Loss: (0.0047) | Acc: (99.86%) (8372/8384) | Learning rate: (1e-06)
2022-06-06 22:54:19,505 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 140 |  Loss: (0.0045) | Acc: (99.87%) (9012/9024) | Learning rate: (1e-06)
2022-06-06 22:54:21,299 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 150 |  Loss: (0.0043) | Acc: (99.88%) (9652/9664) | Learning rate: (1e-06)
2022-06-06 22:54:23,094 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 160 |  Loss: (0.0044) | Acc: (99.86%) (10290/10304) | Learning rate: (1e-06)
2022-06-06 22:54:24,890 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 170 |  Loss: (0.0043) | Acc: (99.87%) (10930/10944) | Learning rate: (1e-06)
2022-06-06 22:54:26,686 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 180 |  Loss: (0.0042) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-06)
2022-06-06 22:54:28,480 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 190 |  Loss: (0.0046) | Acc: (99.86%) (12207/12224) | Learning rate: (1e-06)
2022-06-06 22:54:30,273 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 200 |  Loss: (0.0044) | Acc: (99.87%) (12847/12864) | Learning rate: (1e-06)
2022-06-06 22:54:32,071 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 210 |  Loss: (0.0044) | Acc: (99.87%) (13486/13504) | Learning rate: (1e-06)
2022-06-06 22:54:33,866 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 220 |  Loss: (0.0047) | Acc: (99.86%) (14124/14144) | Learning rate: (1e-06)
2022-06-06 22:54:35,666 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 230 |  Loss: (0.0049) | Acc: (99.86%) (14763/14784) | Learning rate: (1e-06)
2022-06-06 22:54:37,462 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 240 |  Loss: (0.0050) | Acc: (99.86%) (15402/15424) | Learning rate: (1e-06)
2022-06-06 22:54:39,257 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 250 |  Loss: (0.0049) | Acc: (99.86%) (16041/16064) | Learning rate: (1e-06)
2022-06-06 22:54:41,053 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-06)
2022-06-06 22:54:42,847 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 270 |  Loss: (0.0049) | Acc: (99.86%) (17319/17344) | Learning rate: (1e-06)
2022-06-06 22:54:44,644 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 280 |  Loss: (0.0048) | Acc: (99.86%) (17959/17984) | Learning rate: (1e-06)
2022-06-06 22:54:46,440 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 290 |  Loss: (0.0047) | Acc: (99.87%) (18599/18624) | Learning rate: (1e-06)
2022-06-06 22:54:48,235 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 300 |  Loss: (0.0047) | Acc: (99.87%) (19238/19264) | Learning rate: (1e-06)
2022-06-06 22:54:50,030 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 310 |  Loss: (0.0047) | Acc: (99.86%) (19877/19904) | Learning rate: (1e-06)
2022-06-06 22:54:51,826 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 320 |  Loss: (0.0046) | Acc: (99.86%) (20516/20544) | Learning rate: (1e-06)
2022-06-06 22:54:53,622 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 330 |  Loss: (0.0045) | Acc: (99.87%) (21156/21184) | Learning rate: (1e-06)
2022-06-06 22:54:55,419 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.87%) (21796/21824) | Learning rate: (1e-06)
2022-06-06 22:54:57,217 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 350 |  Loss: (0.0043) | Acc: (99.88%) (22436/22464) | Learning rate: (1e-06)
2022-06-06 22:54:59,013 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 360 |  Loss: (0.0043) | Acc: (99.87%) (23075/23104) | Learning rate: (1e-06)
2022-06-06 22:55:00,808 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 370 |  Loss: (0.0043) | Acc: (99.87%) (23714/23744) | Learning rate: (1e-06)
2022-06-06 22:55:02,603 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 380 |  Loss: (0.0044) | Acc: (99.87%) (24353/24384) | Learning rate: (1e-06)
2022-06-06 22:55:04,400 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.88%) (24993/25024) | Learning rate: (1e-06)
2022-06-06 22:55:06,197 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 400 |  Loss: (0.0044) | Acc: (99.88%) (25632/25664) | Learning rate: (1e-06)
2022-06-06 22:55:07,993 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 410 |  Loss: (0.0043) | Acc: (99.88%) (26272/26304) | Learning rate: (1e-06)
2022-06-06 22:55:09,788 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 420 |  Loss: (0.0043) | Acc: (99.88%) (26911/26944) | Learning rate: (1e-06)
2022-06-06 22:55:11,582 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 430 |  Loss: (0.0043) | Acc: (99.88%) (27551/27584) | Learning rate: (1e-06)
2022-06-06 22:55:13,377 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 440 |  Loss: (0.0044) | Acc: (99.88%) (28190/28224) | Learning rate: (1e-06)
2022-06-06 22:55:15,172 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 450 |  Loss: (0.0046) | Acc: (99.88%) (28829/28864) | Learning rate: (1e-06)
2022-06-06 22:55:16,968 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 460 |  Loss: (0.0047) | Acc: (99.87%) (29466/29504) | Learning rate: (1e-06)
2022-06-06 22:55:18,763 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 470 |  Loss: (0.0047) | Acc: (99.87%) (30105/30144) | Learning rate: (1e-06)
2022-06-06 22:55:20,557 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 480 |  Loss: (0.0050) | Acc: (99.87%) (30743/30784) | Learning rate: (1e-06)
2022-06-06 22:55:22,352 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 490 |  Loss: (0.0050) | Acc: (99.87%) (31382/31424) | Learning rate: (1e-06)
2022-06-06 22:55:24,146 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 500 |  Loss: (0.0049) | Acc: (99.87%) (32021/32064) | Learning rate: (1e-06)
2022-06-06 22:55:25,944 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 510 |  Loss: (0.0050) | Acc: (99.86%) (32659/32704) | Learning rate: (1e-06)
2022-06-06 22:55:27,738 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 520 |  Loss: (0.0050) | Acc: (99.86%) (33298/33344) | Learning rate: (1e-06)
2022-06-06 22:55:29,534 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 530 |  Loss: (0.0049) | Acc: (99.86%) (33937/33984) | Learning rate: (1e-06)
2022-06-06 22:55:31,331 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 540 |  Loss: (0.0049) | Acc: (99.86%) (34576/34624) | Learning rate: (1e-06)
2022-06-06 22:55:33,128 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 550 |  Loss: (0.0049) | Acc: (99.86%) (35215/35264) | Learning rate: (1e-06)
2022-06-06 22:55:34,925 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 560 |  Loss: (0.0049) | Acc: (99.86%) (35854/35904) | Learning rate: (1e-06)
2022-06-06 22:55:36,722 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 570 |  Loss: (0.0049) | Acc: (99.86%) (36494/36544) | Learning rate: (1e-06)
2022-06-06 22:55:38,520 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 580 |  Loss: (0.0049) | Acc: (99.86%) (37133/37184) | Learning rate: (1e-06)
2022-06-06 22:55:40,316 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 590 |  Loss: (0.0049) | Acc: (99.87%) (37773/37824) | Learning rate: (1e-06)
2022-06-06 22:55:42,111 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 600 |  Loss: (0.0048) | Acc: (99.87%) (38413/38464) | Learning rate: (1e-06)
2022-06-06 22:55:43,907 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 610 |  Loss: (0.0048) | Acc: (99.87%) (39053/39104) | Learning rate: (1e-06)
2022-06-06 22:55:45,704 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 620 |  Loss: (0.0047) | Acc: (99.87%) (39693/39744) | Learning rate: (1e-06)
2022-06-06 22:55:47,501 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 630 |  Loss: (0.0047) | Acc: (99.87%) (40332/40384) | Learning rate: (1e-06)
2022-06-06 22:55:49,298 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 640 |  Loss: (0.0046) | Acc: (99.87%) (40972/41024) | Learning rate: (1e-06)
2022-06-06 22:55:51,096 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 650 |  Loss: (0.0046) | Acc: (99.88%) (41612/41664) | Learning rate: (1e-06)
2022-06-06 22:55:52,894 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 660 |  Loss: (0.0046) | Acc: (99.87%) (42250/42304) | Learning rate: (1e-06)
2022-06-06 22:55:54,689 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 670 |  Loss: (0.0047) | Acc: (99.87%) (42889/42944) | Learning rate: (1e-06)
2022-06-06 22:55:56,485 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 680 |  Loss: (0.0046) | Acc: (99.87%) (43528/43584) | Learning rate: (1e-06)
2022-06-06 22:55:58,282 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 690 |  Loss: (0.0047) | Acc: (99.87%) (44165/44224) | Learning rate: (1e-06)
2022-06-06 22:56:00,078 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 700 |  Loss: (0.0046) | Acc: (99.87%) (44805/44864) | Learning rate: (1e-06)
2022-06-06 22:56:01,876 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 710 |  Loss: (0.0046) | Acc: (99.87%) (45445/45504) | Learning rate: (1e-06)
2022-06-06 22:56:03,673 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 720 |  Loss: (0.0046) | Acc: (99.87%) (46083/46144) | Learning rate: (1e-06)
2022-06-06 22:56:05,471 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 730 |  Loss: (0.0047) | Acc: (99.87%) (46722/46784) | Learning rate: (1e-06)
2022-06-06 22:56:07,269 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 740 |  Loss: (0.0047) | Acc: (99.87%) (47361/47424) | Learning rate: (1e-06)
2022-06-06 22:56:09,066 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 750 |  Loss: (0.0047) | Acc: (99.87%) (48001/48064) | Learning rate: (1e-06)
2022-06-06 22:56:10,862 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 760 |  Loss: (0.0046) | Acc: (99.87%) (48641/48704) | Learning rate: (1e-06)
2022-06-06 22:56:12,652 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 770 |  Loss: (0.0046) | Acc: (99.87%) (49281/49344) | Learning rate: (1e-06)
2022-06-06 22:56:14,441 - CIFAR10 Classifier - INFO - Epoch: 20 | Batch_idx: 780 |  Loss: (0.0046) | Acc: (99.87%) (49920/49984) | Learning rate: (1e-06)
2022-06-06 22:56:24,353 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0802) | Acc: (98.05%) (9805/10000)
2022-06-06 22:56:24,354 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:56:25,252 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 0 |  Loss: (0.0003) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:56:27,045 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 10 |  Loss: (0.0016) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 22:56:28,835 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 20 |  Loss: (0.0020) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 22:56:30,629 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 30 |  Loss: (0.0030) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 22:56:32,426 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 40 |  Loss: (0.0037) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 22:56:34,221 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 50 |  Loss: (0.0050) | Acc: (99.88%) (3260/3264) | Learning rate: (1e-06)
2022-06-06 22:56:36,015 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 60 |  Loss: (0.0043) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 22:56:37,811 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 70 |  Loss: (0.0040) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-06)
2022-06-06 22:56:39,608 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 80 |  Loss: (0.0039) | Acc: (99.92%) (5180/5184) | Learning rate: (1e-06)
2022-06-06 22:56:41,404 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 90 |  Loss: (0.0040) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 22:56:43,199 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 100 |  Loss: (0.0040) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-06)
2022-06-06 22:56:44,996 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.89%) (7096/7104) | Learning rate: (1e-06)
2022-06-06 22:56:46,790 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 120 |  Loss: (0.0040) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 22:56:48,586 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 130 |  Loss: (0.0040) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-06)
2022-06-06 22:56:50,382 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 140 |  Loss: (0.0040) | Acc: (99.89%) (9014/9024) | Learning rate: (1e-06)
2022-06-06 22:56:52,178 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 150 |  Loss: (0.0038) | Acc: (99.90%) (9654/9664) | Learning rate: (1e-06)
2022-06-06 22:56:53,975 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 160 |  Loss: (0.0042) | Acc: (99.88%) (10292/10304) | Learning rate: (1e-06)
2022-06-06 22:56:55,771 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 170 |  Loss: (0.0042) | Acc: (99.88%) (10931/10944) | Learning rate: (1e-06)
2022-06-06 22:56:57,564 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 180 |  Loss: (0.0042) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-06)
2022-06-06 22:56:59,360 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 190 |  Loss: (0.0043) | Acc: (99.88%) (12209/12224) | Learning rate: (1e-06)
2022-06-06 22:57:01,155 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 200 |  Loss: (0.0043) | Acc: (99.87%) (12847/12864) | Learning rate: (1e-06)
2022-06-06 22:57:02,953 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 210 |  Loss: (0.0042) | Acc: (99.87%) (13487/13504) | Learning rate: (1e-06)
2022-06-06 22:57:04,748 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 220 |  Loss: (0.0043) | Acc: (99.87%) (14125/14144) | Learning rate: (1e-06)
2022-06-06 22:57:06,543 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 230 |  Loss: (0.0043) | Acc: (99.86%) (14764/14784) | Learning rate: (1e-06)
2022-06-06 22:57:08,340 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 240 |  Loss: (0.0042) | Acc: (99.87%) (15404/15424) | Learning rate: (1e-06)
2022-06-06 22:57:10,136 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 250 |  Loss: (0.0043) | Acc: (99.87%) (16043/16064) | Learning rate: (1e-06)
2022-06-06 22:57:11,932 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 260 |  Loss: (0.0042) | Acc: (99.87%) (16683/16704) | Learning rate: (1e-06)
2022-06-06 22:57:13,729 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 270 |  Loss: (0.0043) | Acc: (99.87%) (17321/17344) | Learning rate: (1e-06)
2022-06-06 22:57:15,525 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 280 |  Loss: (0.0043) | Acc: (99.87%) (17961/17984) | Learning rate: (1e-06)
2022-06-06 22:57:17,320 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 290 |  Loss: (0.0044) | Acc: (99.87%) (18600/18624) | Learning rate: (1e-06)
2022-06-06 22:57:19,114 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.88%) (19240/19264) | Learning rate: (1e-06)
2022-06-06 22:57:20,913 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 310 |  Loss: (0.0044) | Acc: (99.87%) (19879/19904) | Learning rate: (1e-06)
2022-06-06 22:57:22,712 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 320 |  Loss: (0.0045) | Acc: (99.87%) (20518/20544) | Learning rate: (1e-06)
2022-06-06 22:57:24,507 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 330 |  Loss: (0.0044) | Acc: (99.87%) (21157/21184) | Learning rate: (1e-06)
2022-06-06 22:57:26,305 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 340 |  Loss: (0.0045) | Acc: (99.87%) (21796/21824) | Learning rate: (1e-06)
2022-06-06 22:57:28,099 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 350 |  Loss: (0.0045) | Acc: (99.88%) (22436/22464) | Learning rate: (1e-06)
2022-06-06 22:57:29,895 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 360 |  Loss: (0.0044) | Acc: (99.87%) (23075/23104) | Learning rate: (1e-06)
2022-06-06 22:57:31,690 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 370 |  Loss: (0.0045) | Acc: (99.87%) (23714/23744) | Learning rate: (1e-06)
2022-06-06 22:57:33,484 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 380 |  Loss: (0.0044) | Acc: (99.88%) (24354/24384) | Learning rate: (1e-06)
2022-06-06 22:57:35,281 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.88%) (24994/25024) | Learning rate: (1e-06)
2022-06-06 22:57:37,077 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 400 |  Loss: (0.0043) | Acc: (99.88%) (25634/25664) | Learning rate: (1e-06)
2022-06-06 22:57:38,871 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 410 |  Loss: (0.0042) | Acc: (99.89%) (26274/26304) | Learning rate: (1e-06)
2022-06-06 22:57:40,666 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 420 |  Loss: (0.0042) | Acc: (99.89%) (26914/26944) | Learning rate: (1e-06)
2022-06-06 22:57:42,463 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 430 |  Loss: (0.0041) | Acc: (99.89%) (27554/27584) | Learning rate: (1e-06)
2022-06-06 22:57:44,259 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 440 |  Loss: (0.0041) | Acc: (99.89%) (28194/28224) | Learning rate: (1e-06)
2022-06-06 22:57:46,055 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 450 |  Loss: (0.0040) | Acc: (99.90%) (28834/28864) | Learning rate: (1e-06)
2022-06-06 22:57:47,850 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 460 |  Loss: (0.0039) | Acc: (99.90%) (29474/29504) | Learning rate: (1e-06)
2022-06-06 22:57:49,644 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 470 |  Loss: (0.0039) | Acc: (99.90%) (30114/30144) | Learning rate: (1e-06)
2022-06-06 22:57:51,443 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 480 |  Loss: (0.0039) | Acc: (99.90%) (30754/30784) | Learning rate: (1e-06)
2022-06-06 22:57:53,240 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 490 |  Loss: (0.0039) | Acc: (99.90%) (31393/31424) | Learning rate: (1e-06)
2022-06-06 22:57:55,035 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 500 |  Loss: (0.0038) | Acc: (99.90%) (32033/32064) | Learning rate: (1e-06)
2022-06-06 22:57:56,833 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 510 |  Loss: (0.0039) | Acc: (99.90%) (32672/32704) | Learning rate: (1e-06)
2022-06-06 22:57:58,629 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 520 |  Loss: (0.0040) | Acc: (99.90%) (33311/33344) | Learning rate: (1e-06)
2022-06-06 22:58:00,423 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 530 |  Loss: (0.0040) | Acc: (99.90%) (33950/33984) | Learning rate: (1e-06)
2022-06-06 22:58:02,220 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 540 |  Loss: (0.0039) | Acc: (99.90%) (34589/34624) | Learning rate: (1e-06)
2022-06-06 22:58:04,016 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 550 |  Loss: (0.0040) | Acc: (99.89%) (35226/35264) | Learning rate: (1e-06)
2022-06-06 22:58:05,813 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 560 |  Loss: (0.0040) | Acc: (99.89%) (35865/35904) | Learning rate: (1e-06)
2022-06-06 22:58:07,609 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 570 |  Loss: (0.0040) | Acc: (99.89%) (36505/36544) | Learning rate: (1e-06)
2022-06-06 22:58:09,403 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 580 |  Loss: (0.0039) | Acc: (99.90%) (37145/37184) | Learning rate: (1e-06)
2022-06-06 22:58:11,199 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 590 |  Loss: (0.0040) | Acc: (99.89%) (37784/37824) | Learning rate: (1e-06)
2022-06-06 22:58:12,997 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 600 |  Loss: (0.0040) | Acc: (99.89%) (38423/38464) | Learning rate: (1e-06)
2022-06-06 22:58:14,795 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 610 |  Loss: (0.0039) | Acc: (99.90%) (39063/39104) | Learning rate: (1e-06)
2022-06-06 22:58:16,591 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 620 |  Loss: (0.0039) | Acc: (99.89%) (39702/39744) | Learning rate: (1e-06)
2022-06-06 22:58:18,388 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 630 |  Loss: (0.0040) | Acc: (99.89%) (40341/40384) | Learning rate: (1e-06)
2022-06-06 22:58:20,185 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 640 |  Loss: (0.0039) | Acc: (99.90%) (40981/41024) | Learning rate: (1e-06)
2022-06-06 22:58:21,983 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 650 |  Loss: (0.0039) | Acc: (99.89%) (41620/41664) | Learning rate: (1e-06)
2022-06-06 22:58:23,779 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 660 |  Loss: (0.0039) | Acc: (99.89%) (42259/42304) | Learning rate: (1e-06)
2022-06-06 22:58:25,574 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 670 |  Loss: (0.0039) | Acc: (99.89%) (42897/42944) | Learning rate: (1e-06)
2022-06-06 22:58:27,372 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 680 |  Loss: (0.0040) | Acc: (99.89%) (43534/43584) | Learning rate: (1e-06)
2022-06-06 22:58:29,170 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 690 |  Loss: (0.0039) | Acc: (99.89%) (44174/44224) | Learning rate: (1e-06)
2022-06-06 22:58:30,966 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 700 |  Loss: (0.0039) | Acc: (99.89%) (44813/44864) | Learning rate: (1e-06)
2022-06-06 22:58:32,764 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 710 |  Loss: (0.0039) | Acc: (99.88%) (45451/45504) | Learning rate: (1e-06)
2022-06-06 22:58:34,561 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 720 |  Loss: (0.0039) | Acc: (99.89%) (46091/46144) | Learning rate: (1e-06)
2022-06-06 22:58:36,358 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 730 |  Loss: (0.0039) | Acc: (99.88%) (46730/46784) | Learning rate: (1e-06)
2022-06-06 22:58:38,154 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 740 |  Loss: (0.0040) | Acc: (99.88%) (47369/47424) | Learning rate: (1e-06)
2022-06-06 22:58:39,951 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 750 |  Loss: (0.0039) | Acc: (99.89%) (48009/48064) | Learning rate: (1e-06)
2022-06-06 22:58:41,749 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 760 |  Loss: (0.0040) | Acc: (99.88%) (48647/48704) | Learning rate: (1e-06)
2022-06-06 22:58:43,538 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 770 |  Loss: (0.0040) | Acc: (99.88%) (49286/49344) | Learning rate: (1e-06)
2022-06-06 22:58:45,325 - CIFAR10 Classifier - INFO - Epoch: 21 | Batch_idx: 780 |  Loss: (0.0041) | Acc: (99.88%) (49924/49984) | Learning rate: (1e-06)
2022-06-06 22:58:55,205 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0814) | Acc: (97.99%) (9799/10000)
2022-06-06 22:58:55,206 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 22:58:56,111 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 0 |  Loss: (0.0008) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 22:58:57,901 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 10 |  Loss: (0.0055) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 22:58:59,692 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 20 |  Loss: (0.0047) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 22:59:01,484 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 30 |  Loss: (0.0044) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 22:59:03,278 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 40 |  Loss: (0.0048) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 22:59:05,072 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 50 |  Loss: (0.0044) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 22:59:06,867 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 60 |  Loss: (0.0041) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-06)
2022-06-06 22:59:08,662 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 70 |  Loss: (0.0046) | Acc: (99.80%) (4535/4544) | Learning rate: (1e-06)
2022-06-06 22:59:10,457 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 80 |  Loss: (0.0047) | Acc: (99.81%) (5174/5184) | Learning rate: (1e-06)
2022-06-06 22:59:12,252 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 90 |  Loss: (0.0045) | Acc: (99.81%) (5813/5824) | Learning rate: (1e-06)
2022-06-06 22:59:14,045 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.81%) (6452/6464) | Learning rate: (1e-06)
2022-06-06 22:59:15,838 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.82%) (7091/7104) | Learning rate: (1e-06)
2022-06-06 22:59:17,633 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 120 |  Loss: (0.0041) | Acc: (99.83%) (7731/7744) | Learning rate: (1e-06)
2022-06-06 22:59:19,427 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 130 |  Loss: (0.0039) | Acc: (99.84%) (8371/8384) | Learning rate: (1e-06)
2022-06-06 22:59:21,225 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 140 |  Loss: (0.0037) | Acc: (99.86%) (9011/9024) | Learning rate: (1e-06)
2022-06-06 22:59:23,022 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 150 |  Loss: (0.0036) | Acc: (99.87%) (9651/9664) | Learning rate: (1e-06)
2022-06-06 22:59:24,821 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 160 |  Loss: (0.0035) | Acc: (99.87%) (10291/10304) | Learning rate: (1e-06)
2022-06-06 22:59:26,614 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 170 |  Loss: (0.0034) | Acc: (99.87%) (10930/10944) | Learning rate: (1e-06)
2022-06-06 22:59:28,411 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 180 |  Loss: (0.0034) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-06)
2022-06-06 22:59:30,208 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 190 |  Loss: (0.0034) | Acc: (99.88%) (12209/12224) | Learning rate: (1e-06)
2022-06-06 22:59:32,003 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 200 |  Loss: (0.0032) | Acc: (99.88%) (12849/12864) | Learning rate: (1e-06)
2022-06-06 22:59:33,799 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 210 |  Loss: (0.0032) | Acc: (99.88%) (13488/13504) | Learning rate: (1e-06)
2022-06-06 22:59:35,593 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 220 |  Loss: (0.0031) | Acc: (99.89%) (14128/14144) | Learning rate: (1e-06)
2022-06-06 22:59:37,388 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 230 |  Loss: (0.0031) | Acc: (99.89%) (14767/14784) | Learning rate: (1e-06)
2022-06-06 22:59:39,184 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 240 |  Loss: (0.0030) | Acc: (99.89%) (15407/15424) | Learning rate: (1e-06)
2022-06-06 22:59:40,979 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 250 |  Loss: (0.0029) | Acc: (99.89%) (16047/16064) | Learning rate: (1e-06)
2022-06-06 22:59:42,776 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 260 |  Loss: (0.0029) | Acc: (99.90%) (16687/16704) | Learning rate: (1e-06)
2022-06-06 22:59:44,570 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 270 |  Loss: (0.0032) | Acc: (99.89%) (17325/17344) | Learning rate: (1e-06)
2022-06-06 22:59:46,365 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 280 |  Loss: (0.0033) | Acc: (99.88%) (17963/17984) | Learning rate: (1e-06)
2022-06-06 22:59:48,163 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 290 |  Loss: (0.0032) | Acc: (99.89%) (18603/18624) | Learning rate: (1e-06)
2022-06-06 22:59:49,958 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 300 |  Loss: (0.0033) | Acc: (99.89%) (19242/19264) | Learning rate: (1e-06)
2022-06-06 22:59:51,757 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 310 |  Loss: (0.0033) | Acc: (99.89%) (19882/19904) | Learning rate: (1e-06)
2022-06-06 22:59:53,553 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 320 |  Loss: (0.0035) | Acc: (99.88%) (20519/20544) | Learning rate: (1e-06)
2022-06-06 22:59:55,347 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 330 |  Loss: (0.0035) | Acc: (99.88%) (21159/21184) | Learning rate: (1e-06)
2022-06-06 22:59:57,142 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 340 |  Loss: (0.0037) | Acc: (99.88%) (21797/21824) | Learning rate: (1e-06)
2022-06-06 22:59:58,940 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 350 |  Loss: (0.0037) | Acc: (99.88%) (22436/22464) | Learning rate: (1e-06)
2022-06-06 23:00:00,736 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 360 |  Loss: (0.0038) | Acc: (99.87%) (23075/23104) | Learning rate: (1e-06)
2022-06-06 23:00:02,532 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 370 |  Loss: (0.0037) | Acc: (99.88%) (23715/23744) | Learning rate: (1e-06)
2022-06-06 23:00:04,327 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 380 |  Loss: (0.0037) | Acc: (99.88%) (24354/24384) | Learning rate: (1e-06)
2022-06-06 23:00:06,122 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 390 |  Loss: (0.0037) | Acc: (99.88%) (24993/25024) | Learning rate: (1e-06)
2022-06-06 23:00:07,917 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 400 |  Loss: (0.0037) | Acc: (99.88%) (25633/25664) | Learning rate: (1e-06)
2022-06-06 23:00:09,715 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 410 |  Loss: (0.0037) | Acc: (99.88%) (26273/26304) | Learning rate: (1e-06)
2022-06-06 23:00:11,511 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 420 |  Loss: (0.0038) | Acc: (99.88%) (26911/26944) | Learning rate: (1e-06)
2022-06-06 23:00:13,308 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 430 |  Loss: (0.0037) | Acc: (99.88%) (27551/27584) | Learning rate: (1e-06)
2022-06-06 23:00:15,104 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 440 |  Loss: (0.0037) | Acc: (99.88%) (28191/28224) | Learning rate: (1e-06)
2022-06-06 23:00:16,898 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 450 |  Loss: (0.0037) | Acc: (99.89%) (28831/28864) | Learning rate: (1e-06)
2022-06-06 23:00:18,695 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 460 |  Loss: (0.0036) | Acc: (99.89%) (29471/29504) | Learning rate: (1e-06)
2022-06-06 23:00:20,493 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 470 |  Loss: (0.0036) | Acc: (99.89%) (30111/30144) | Learning rate: (1e-06)
2022-06-06 23:00:22,290 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 480 |  Loss: (0.0035) | Acc: (99.89%) (30751/30784) | Learning rate: (1e-06)
2022-06-06 23:00:24,087 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 490 |  Loss: (0.0036) | Acc: (99.89%) (31389/31424) | Learning rate: (1e-06)
2022-06-06 23:00:25,882 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 500 |  Loss: (0.0036) | Acc: (99.89%) (32028/32064) | Learning rate: (1e-06)
2022-06-06 23:00:27,678 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 510 |  Loss: (0.0036) | Acc: (99.89%) (32667/32704) | Learning rate: (1e-06)
2022-06-06 23:00:29,471 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 520 |  Loss: (0.0036) | Acc: (99.89%) (33307/33344) | Learning rate: (1e-06)
2022-06-06 23:00:31,268 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 530 |  Loss: (0.0035) | Acc: (99.89%) (33947/33984) | Learning rate: (1e-06)
2022-06-06 23:00:33,065 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 540 |  Loss: (0.0036) | Acc: (99.89%) (34586/34624) | Learning rate: (1e-06)
2022-06-06 23:00:34,863 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 550 |  Loss: (0.0036) | Acc: (99.89%) (35224/35264) | Learning rate: (1e-06)
2022-06-06 23:00:36,659 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 560 |  Loss: (0.0036) | Acc: (99.89%) (35863/35904) | Learning rate: (1e-06)
2022-06-06 23:00:38,453 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 570 |  Loss: (0.0035) | Acc: (99.89%) (36503/36544) | Learning rate: (1e-06)
2022-06-06 23:00:40,249 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 580 |  Loss: (0.0035) | Acc: (99.89%) (37143/37184) | Learning rate: (1e-06)
2022-06-06 23:00:42,045 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 590 |  Loss: (0.0035) | Acc: (99.89%) (37782/37824) | Learning rate: (1e-06)
2022-06-06 23:00:43,842 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 600 |  Loss: (0.0035) | Acc: (99.89%) (38422/38464) | Learning rate: (1e-06)
2022-06-06 23:00:45,639 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 610 |  Loss: (0.0035) | Acc: (99.89%) (39060/39104) | Learning rate: (1e-06)
2022-06-06 23:00:47,435 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 620 |  Loss: (0.0036) | Acc: (99.88%) (39698/39744) | Learning rate: (1e-06)
2022-06-06 23:00:49,231 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 630 |  Loss: (0.0036) | Acc: (99.88%) (40337/40384) | Learning rate: (1e-06)
2022-06-06 23:00:51,026 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 640 |  Loss: (0.0036) | Acc: (99.88%) (40976/41024) | Learning rate: (1e-06)
2022-06-06 23:00:52,822 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 650 |  Loss: (0.0037) | Acc: (99.88%) (41614/41664) | Learning rate: (1e-06)
2022-06-06 23:00:54,620 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 660 |  Loss: (0.0037) | Acc: (99.88%) (42254/42304) | Learning rate: (1e-06)
2022-06-06 23:00:56,416 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 670 |  Loss: (0.0037) | Acc: (99.88%) (42893/42944) | Learning rate: (1e-06)
2022-06-06 23:00:58,213 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 680 |  Loss: (0.0036) | Acc: (99.88%) (43533/43584) | Learning rate: (1e-06)
2022-06-06 23:01:00,010 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 690 |  Loss: (0.0036) | Acc: (99.88%) (44172/44224) | Learning rate: (1e-06)
2022-06-06 23:01:01,805 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 700 |  Loss: (0.0036) | Acc: (99.88%) (44812/44864) | Learning rate: (1e-06)
2022-06-06 23:01:03,602 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 710 |  Loss: (0.0036) | Acc: (99.89%) (45452/45504) | Learning rate: (1e-06)
2022-06-06 23:01:05,398 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 720 |  Loss: (0.0036) | Acc: (99.89%) (46091/46144) | Learning rate: (1e-06)
2022-06-06 23:01:07,194 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 730 |  Loss: (0.0036) | Acc: (99.88%) (46730/46784) | Learning rate: (1e-06)
2022-06-06 23:01:08,992 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 740 |  Loss: (0.0036) | Acc: (99.88%) (47369/47424) | Learning rate: (1e-06)
2022-06-06 23:01:10,788 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 750 |  Loss: (0.0036) | Acc: (99.88%) (48008/48064) | Learning rate: (1e-06)
2022-06-06 23:01:12,586 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 760 |  Loss: (0.0037) | Acc: (99.88%) (48647/48704) | Learning rate: (1e-06)
2022-06-06 23:01:14,373 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 770 |  Loss: (0.0036) | Acc: (99.88%) (49287/49344) | Learning rate: (1e-06)
2022-06-06 23:01:16,163 - CIFAR10 Classifier - INFO - Epoch: 22 | Batch_idx: 780 |  Loss: (0.0036) | Acc: (99.88%) (49926/49984) | Learning rate: (1e-06)
2022-06-06 23:01:26,110 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0809) | Acc: (97.98%) (9798/10000)
2022-06-06 23:01:26,111 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:01:27,033 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 0 |  Loss: (0.0002) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:01:28,823 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 10 |  Loss: (0.0018) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:01:30,614 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 20 |  Loss: (0.0047) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 23:01:32,407 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 23:01:34,202 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 40 |  Loss: (0.0034) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-06)
2022-06-06 23:01:35,995 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 50 |  Loss: (0.0041) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:01:37,790 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 60 |  Loss: (0.0049) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 23:01:39,585 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 70 |  Loss: (0.0047) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-06)
2022-06-06 23:01:41,380 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 23:01:43,176 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 90 |  Loss: (0.0042) | Acc: (99.90%) (5818/5824) | Learning rate: (1e-06)
2022-06-06 23:01:44,969 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 100 |  Loss: (0.0046) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-06)
2022-06-06 23:01:46,764 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 110 |  Loss: (0.0045) | Acc: (99.89%) (7096/7104) | Learning rate: (1e-06)
2022-06-06 23:01:48,560 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 120 |  Loss: (0.0042) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 23:01:50,355 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 130 |  Loss: (0.0041) | Acc: (99.90%) (8376/8384) | Learning rate: (1e-06)
2022-06-06 23:01:52,149 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 140 |  Loss: (0.0039) | Acc: (99.91%) (9016/9024) | Learning rate: (1e-06)
2022-06-06 23:01:53,943 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 150 |  Loss: (0.0039) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-06)
2022-06-06 23:01:55,738 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 160 |  Loss: (0.0041) | Acc: (99.90%) (10294/10304) | Learning rate: (1e-06)
2022-06-06 23:01:57,534 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 170 |  Loss: (0.0042) | Acc: (99.90%) (10933/10944) | Learning rate: (1e-06)
2022-06-06 23:01:59,327 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 180 |  Loss: (0.0040) | Acc: (99.91%) (11573/11584) | Learning rate: (1e-06)
2022-06-06 23:02:01,122 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 190 |  Loss: (0.0039) | Acc: (99.91%) (12213/12224) | Learning rate: (1e-06)
2022-06-06 23:02:02,917 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 200 |  Loss: (0.0043) | Acc: (99.89%) (12850/12864) | Learning rate: (1e-06)
2022-06-06 23:02:04,713 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 210 |  Loss: (0.0041) | Acc: (99.90%) (13490/13504) | Learning rate: (1e-06)
2022-06-06 23:02:06,508 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 220 |  Loss: (0.0040) | Acc: (99.90%) (14130/14144) | Learning rate: (1e-06)
2022-06-06 23:02:08,302 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 230 |  Loss: (0.0039) | Acc: (99.90%) (14769/14784) | Learning rate: (1e-06)
2022-06-06 23:02:10,096 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 240 |  Loss: (0.0040) | Acc: (99.90%) (15408/15424) | Learning rate: (1e-06)
2022-06-06 23:02:11,891 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 250 |  Loss: (0.0039) | Acc: (99.90%) (16048/16064) | Learning rate: (1e-06)
2022-06-06 23:02:13,690 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 260 |  Loss: (0.0039) | Acc: (99.90%) (16688/16704) | Learning rate: (1e-06)
2022-06-06 23:02:15,485 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 270 |  Loss: (0.0038) | Acc: (99.91%) (17328/17344) | Learning rate: (1e-06)
2022-06-06 23:02:17,280 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 280 |  Loss: (0.0037) | Acc: (99.91%) (17968/17984) | Learning rate: (1e-06)
2022-06-06 23:02:19,075 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 290 |  Loss: (0.0038) | Acc: (99.90%) (18605/18624) | Learning rate: (1e-06)
2022-06-06 23:02:20,870 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 300 |  Loss: (0.0038) | Acc: (99.90%) (19245/19264) | Learning rate: (1e-06)
2022-06-06 23:02:22,666 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 310 |  Loss: (0.0037) | Acc: (99.90%) (19885/19904) | Learning rate: (1e-06)
2022-06-06 23:02:24,460 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 320 |  Loss: (0.0037) | Acc: (99.91%) (20525/20544) | Learning rate: (1e-06)
2022-06-06 23:02:26,254 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 330 |  Loss: (0.0037) | Acc: (99.91%) (21165/21184) | Learning rate: (1e-06)
2022-06-06 23:02:28,051 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 340 |  Loss: (0.0037) | Acc: (99.91%) (21804/21824) | Learning rate: (1e-06)
2022-06-06 23:02:29,847 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 350 |  Loss: (0.0036) | Acc: (99.91%) (22444/22464) | Learning rate: (1e-06)
2022-06-06 23:02:31,642 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 360 |  Loss: (0.0039) | Acc: (99.90%) (23082/23104) | Learning rate: (1e-06)
2022-06-06 23:02:33,438 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 370 |  Loss: (0.0038) | Acc: (99.91%) (23722/23744) | Learning rate: (1e-06)
2022-06-06 23:02:35,234 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 380 |  Loss: (0.0038) | Acc: (99.90%) (24360/24384) | Learning rate: (1e-06)
2022-06-06 23:02:37,029 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 390 |  Loss: (0.0038) | Acc: (99.90%) (24999/25024) | Learning rate: (1e-06)
2022-06-06 23:02:38,826 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 400 |  Loss: (0.0038) | Acc: (99.90%) (25638/25664) | Learning rate: (1e-06)
2022-06-06 23:02:40,622 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 410 |  Loss: (0.0037) | Acc: (99.90%) (26278/26304) | Learning rate: (1e-06)
2022-06-06 23:02:42,419 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 420 |  Loss: (0.0037) | Acc: (99.90%) (26917/26944) | Learning rate: (1e-06)
2022-06-06 23:02:44,217 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 430 |  Loss: (0.0037) | Acc: (99.90%) (27557/27584) | Learning rate: (1e-06)
2022-06-06 23:02:46,011 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 440 |  Loss: (0.0037) | Acc: (99.90%) (28197/28224) | Learning rate: (1e-06)
2022-06-06 23:02:47,807 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 450 |  Loss: (0.0037) | Acc: (99.90%) (28836/28864) | Learning rate: (1e-06)
2022-06-06 23:02:49,604 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 460 |  Loss: (0.0037) | Acc: (99.91%) (29476/29504) | Learning rate: (1e-06)
2022-06-06 23:02:51,401 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 470 |  Loss: (0.0037) | Acc: (99.90%) (30115/30144) | Learning rate: (1e-06)
2022-06-06 23:02:53,199 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 480 |  Loss: (0.0037) | Acc: (99.91%) (30755/30784) | Learning rate: (1e-06)
2022-06-06 23:02:54,995 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 490 |  Loss: (0.0038) | Acc: (99.90%) (31393/31424) | Learning rate: (1e-06)
2022-06-06 23:02:56,791 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 500 |  Loss: (0.0038) | Acc: (99.90%) (32033/32064) | Learning rate: (1e-06)
2022-06-06 23:02:58,591 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 510 |  Loss: (0.0038) | Acc: (99.90%) (32672/32704) | Learning rate: (1e-06)
2022-06-06 23:03:00,388 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 520 |  Loss: (0.0038) | Acc: (99.90%) (33312/33344) | Learning rate: (1e-06)
2022-06-06 23:03:02,184 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 530 |  Loss: (0.0038) | Acc: (99.91%) (33952/33984) | Learning rate: (1e-06)
2022-06-06 23:03:03,981 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 540 |  Loss: (0.0037) | Acc: (99.91%) (34592/34624) | Learning rate: (1e-06)
2022-06-06 23:03:05,778 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 550 |  Loss: (0.0037) | Acc: (99.91%) (35232/35264) | Learning rate: (1e-06)
2022-06-06 23:03:07,578 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 560 |  Loss: (0.0037) | Acc: (99.91%) (35872/35904) | Learning rate: (1e-06)
2022-06-06 23:03:09,376 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 570 |  Loss: (0.0037) | Acc: (99.91%) (36511/36544) | Learning rate: (1e-06)
2022-06-06 23:03:11,174 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 580 |  Loss: (0.0037) | Acc: (99.91%) (37150/37184) | Learning rate: (1e-06)
2022-06-06 23:03:12,974 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 590 |  Loss: (0.0037) | Acc: (99.91%) (37790/37824) | Learning rate: (1e-06)
2022-06-06 23:03:14,772 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 600 |  Loss: (0.0037) | Acc: (99.91%) (38428/38464) | Learning rate: (1e-06)
2022-06-06 23:03:16,570 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 610 |  Loss: (0.0036) | Acc: (99.91%) (39068/39104) | Learning rate: (1e-06)
2022-06-06 23:03:18,368 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 620 |  Loss: (0.0037) | Acc: (99.91%) (39707/39744) | Learning rate: (1e-06)
2022-06-06 23:03:20,165 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 630 |  Loss: (0.0036) | Acc: (99.91%) (40347/40384) | Learning rate: (1e-06)
2022-06-06 23:03:21,960 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 640 |  Loss: (0.0036) | Acc: (99.91%) (40987/41024) | Learning rate: (1e-06)
2022-06-06 23:03:23,758 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 650 |  Loss: (0.0036) | Acc: (99.91%) (41627/41664) | Learning rate: (1e-06)
2022-06-06 23:03:25,555 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 660 |  Loss: (0.0036) | Acc: (99.91%) (42265/42304) | Learning rate: (1e-06)
2022-06-06 23:03:27,352 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 670 |  Loss: (0.0036) | Acc: (99.91%) (42904/42944) | Learning rate: (1e-06)
2022-06-06 23:03:29,149 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 680 |  Loss: (0.0036) | Acc: (99.91%) (43543/43584) | Learning rate: (1e-06)
2022-06-06 23:03:30,945 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 690 |  Loss: (0.0036) | Acc: (99.91%) (44183/44224) | Learning rate: (1e-06)
2022-06-06 23:03:32,742 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 700 |  Loss: (0.0036) | Acc: (99.91%) (44822/44864) | Learning rate: (1e-06)
2022-06-06 23:03:34,539 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 710 |  Loss: (0.0037) | Acc: (99.90%) (45460/45504) | Learning rate: (1e-06)
2022-06-06 23:03:36,333 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 720 |  Loss: (0.0037) | Acc: (99.90%) (46099/46144) | Learning rate: (1e-06)
2022-06-06 23:03:38,128 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 730 |  Loss: (0.0037) | Acc: (99.90%) (46738/46784) | Learning rate: (1e-06)
2022-06-06 23:03:39,926 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 740 |  Loss: (0.0037) | Acc: (99.90%) (47378/47424) | Learning rate: (1e-06)
2022-06-06 23:03:41,723 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 750 |  Loss: (0.0037) | Acc: (99.90%) (48017/48064) | Learning rate: (1e-06)
2022-06-06 23:03:43,520 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 760 |  Loss: (0.0037) | Acc: (99.90%) (48655/48704) | Learning rate: (1e-06)
2022-06-06 23:03:45,308 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 770 |  Loss: (0.0037) | Acc: (99.90%) (49295/49344) | Learning rate: (1e-06)
2022-06-06 23:03:47,098 - CIFAR10 Classifier - INFO - Epoch: 23 | Batch_idx: 780 |  Loss: (0.0036) | Acc: (99.90%) (49935/49984) | Learning rate: (1e-06)
2022-06-06 23:03:57,074 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0809) | Acc: (98.09%) (9809/10000)
2022-06-06 23:03:57,075 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:03:57,974 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:03:59,766 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 10 |  Loss: (0.0025) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 23:04:01,558 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 20 |  Loss: (0.0022) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 23:04:03,350 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 30 |  Loss: (0.0030) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 23:04:05,146 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 40 |  Loss: (0.0027) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 23:04:06,940 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 50 |  Loss: (0.0029) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:04:08,737 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 60 |  Loss: (0.0027) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 23:04:10,533 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 70 |  Loss: (0.0025) | Acc: (99.93%) (4541/4544) | Learning rate: (1e-06)
2022-06-06 23:04:12,329 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 80 |  Loss: (0.0023) | Acc: (99.94%) (5181/5184) | Learning rate: (1e-06)
2022-06-06 23:04:14,125 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 90 |  Loss: (0.0022) | Acc: (99.95%) (5821/5824) | Learning rate: (1e-06)
2022-06-06 23:04:15,918 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 100 |  Loss: (0.0025) | Acc: (99.92%) (6459/6464) | Learning rate: (1e-06)
2022-06-06 23:04:17,715 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 110 |  Loss: (0.0029) | Acc: (99.90%) (7097/7104) | Learning rate: (1e-06)
2022-06-06 23:04:19,512 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 120 |  Loss: (0.0035) | Acc: (99.88%) (7735/7744) | Learning rate: (1e-06)
2022-06-06 23:04:21,308 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 130 |  Loss: (0.0033) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-06)
2022-06-06 23:04:23,103 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 140 |  Loss: (0.0034) | Acc: (99.89%) (9014/9024) | Learning rate: (1e-06)
2022-06-06 23:04:24,898 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 150 |  Loss: (0.0033) | Acc: (99.90%) (9654/9664) | Learning rate: (1e-06)
2022-06-06 23:04:26,693 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 160 |  Loss: (0.0037) | Acc: (99.88%) (10292/10304) | Learning rate: (1e-06)
2022-06-06 23:04:28,490 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 170 |  Loss: (0.0037) | Acc: (99.88%) (10931/10944) | Learning rate: (1e-06)
2022-06-06 23:04:30,287 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.89%) (11571/11584) | Learning rate: (1e-06)
2022-06-06 23:04:32,082 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 190 |  Loss: (0.0040) | Acc: (99.87%) (12208/12224) | Learning rate: (1e-06)
2022-06-06 23:04:33,878 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 200 |  Loss: (0.0041) | Acc: (99.87%) (12847/12864) | Learning rate: (1e-06)
2022-06-06 23:04:35,674 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 210 |  Loss: (0.0039) | Acc: (99.87%) (13487/13504) | Learning rate: (1e-06)
2022-06-06 23:04:37,468 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 220 |  Loss: (0.0039) | Acc: (99.87%) (14126/14144) | Learning rate: (1e-06)
2022-06-06 23:04:39,265 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 230 |  Loss: (0.0038) | Acc: (99.88%) (14766/14784) | Learning rate: (1e-06)
2022-06-06 23:04:41,061 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 240 |  Loss: (0.0039) | Acc: (99.87%) (15404/15424) | Learning rate: (1e-06)
2022-06-06 23:04:42,858 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 250 |  Loss: (0.0038) | Acc: (99.88%) (16044/16064) | Learning rate: (1e-06)
2022-06-06 23:04:44,653 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 260 |  Loss: (0.0038) | Acc: (99.88%) (16684/16704) | Learning rate: (1e-06)
2022-06-06 23:04:46,447 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 270 |  Loss: (0.0038) | Acc: (99.87%) (17322/17344) | Learning rate: (1e-06)
2022-06-06 23:04:48,244 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 280 |  Loss: (0.0037) | Acc: (99.88%) (17962/17984) | Learning rate: (1e-06)
2022-06-06 23:04:50,041 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 290 |  Loss: (0.0036) | Acc: (99.88%) (18602/18624) | Learning rate: (1e-06)
2022-06-06 23:04:51,837 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 300 |  Loss: (0.0037) | Acc: (99.88%) (19241/19264) | Learning rate: (1e-06)
2022-06-06 23:04:53,634 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 310 |  Loss: (0.0036) | Acc: (99.88%) (19880/19904) | Learning rate: (1e-06)
2022-06-06 23:04:55,430 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 320 |  Loss: (0.0037) | Acc: (99.88%) (20519/20544) | Learning rate: (1e-06)
2022-06-06 23:04:57,226 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 330 |  Loss: (0.0037) | Acc: (99.88%) (21159/21184) | Learning rate: (1e-06)
2022-06-06 23:04:59,022 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 340 |  Loss: (0.0036) | Acc: (99.89%) (21799/21824) | Learning rate: (1e-06)
2022-06-06 23:05:00,819 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 350 |  Loss: (0.0036) | Acc: (99.88%) (22438/22464) | Learning rate: (1e-06)
2022-06-06 23:05:02,617 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 360 |  Loss: (0.0036) | Acc: (99.88%) (23077/23104) | Learning rate: (1e-06)
2022-06-06 23:05:04,413 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 370 |  Loss: (0.0035) | Acc: (99.89%) (23717/23744) | Learning rate: (1e-06)
2022-06-06 23:05:06,209 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 380 |  Loss: (0.0035) | Acc: (99.89%) (24357/24384) | Learning rate: (1e-06)
2022-06-06 23:05:08,006 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 390 |  Loss: (0.0036) | Acc: (99.88%) (24995/25024) | Learning rate: (1e-06)
2022-06-06 23:05:09,801 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 400 |  Loss: (0.0036) | Acc: (99.89%) (25635/25664) | Learning rate: (1e-06)
2022-06-06 23:05:11,598 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 410 |  Loss: (0.0036) | Acc: (99.89%) (26275/26304) | Learning rate: (1e-06)
2022-06-06 23:05:13,395 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 420 |  Loss: (0.0036) | Acc: (99.89%) (26915/26944) | Learning rate: (1e-06)
2022-06-06 23:05:15,192 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 430 |  Loss: (0.0037) | Acc: (99.89%) (27553/27584) | Learning rate: (1e-06)
2022-06-06 23:05:16,989 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 440 |  Loss: (0.0036) | Acc: (99.89%) (28193/28224) | Learning rate: (1e-06)
2022-06-06 23:05:18,786 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 450 |  Loss: (0.0036) | Acc: (99.89%) (28833/28864) | Learning rate: (1e-06)
2022-06-06 23:05:20,583 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 460 |  Loss: (0.0035) | Acc: (99.89%) (29473/29504) | Learning rate: (1e-06)
2022-06-06 23:05:22,378 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 470 |  Loss: (0.0036) | Acc: (99.89%) (30112/30144) | Learning rate: (1e-06)
2022-06-06 23:05:24,175 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 480 |  Loss: (0.0036) | Acc: (99.89%) (30751/30784) | Learning rate: (1e-06)
2022-06-06 23:05:25,971 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 490 |  Loss: (0.0036) | Acc: (99.89%) (31391/31424) | Learning rate: (1e-06)
2022-06-06 23:05:27,768 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 500 |  Loss: (0.0035) | Acc: (99.90%) (32031/32064) | Learning rate: (1e-06)
2022-06-06 23:05:29,565 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 510 |  Loss: (0.0036) | Acc: (99.90%) (32670/32704) | Learning rate: (1e-06)
2022-06-06 23:05:31,362 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 520 |  Loss: (0.0036) | Acc: (99.90%) (33310/33344) | Learning rate: (1e-06)
2022-06-06 23:05:33,159 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 530 |  Loss: (0.0036) | Acc: (99.90%) (33949/33984) | Learning rate: (1e-06)
2022-06-06 23:05:34,954 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 540 |  Loss: (0.0036) | Acc: (99.90%) (34589/34624) | Learning rate: (1e-06)
2022-06-06 23:05:36,750 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 550 |  Loss: (0.0036) | Acc: (99.90%) (35228/35264) | Learning rate: (1e-06)
2022-06-06 23:05:38,548 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 560 |  Loss: (0.0035) | Acc: (99.90%) (35868/35904) | Learning rate: (1e-06)
2022-06-06 23:05:40,345 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 570 |  Loss: (0.0036) | Acc: (99.90%) (36506/36544) | Learning rate: (1e-06)
2022-06-06 23:05:42,141 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 580 |  Loss: (0.0036) | Acc: (99.90%) (37146/37184) | Learning rate: (1e-06)
2022-06-06 23:05:43,939 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 590 |  Loss: (0.0036) | Acc: (99.90%) (37786/37824) | Learning rate: (1e-06)
2022-06-06 23:05:45,736 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 600 |  Loss: (0.0037) | Acc: (99.90%) (38424/38464) | Learning rate: (1e-06)
2022-06-06 23:05:47,534 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 610 |  Loss: (0.0037) | Acc: (99.90%) (39063/39104) | Learning rate: (1e-06)
2022-06-06 23:05:49,330 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 620 |  Loss: (0.0037) | Acc: (99.90%) (39703/39744) | Learning rate: (1e-06)
2022-06-06 23:05:51,126 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 630 |  Loss: (0.0037) | Acc: (99.90%) (40343/40384) | Learning rate: (1e-06)
2022-06-06 23:05:52,923 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 640 |  Loss: (0.0037) | Acc: (99.90%) (40982/41024) | Learning rate: (1e-06)
2022-06-06 23:05:54,721 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 650 |  Loss: (0.0037) | Acc: (99.89%) (41620/41664) | Learning rate: (1e-06)
2022-06-06 23:05:56,519 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 660 |  Loss: (0.0038) | Acc: (99.89%) (42258/42304) | Learning rate: (1e-06)
2022-06-06 23:05:58,316 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 670 |  Loss: (0.0038) | Acc: (99.89%) (42898/42944) | Learning rate: (1e-06)
2022-06-06 23:06:00,113 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 680 |  Loss: (0.0038) | Acc: (99.89%) (43537/43584) | Learning rate: (1e-06)
2022-06-06 23:06:01,911 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 690 |  Loss: (0.0039) | Acc: (99.89%) (44174/44224) | Learning rate: (1e-06)
2022-06-06 23:06:03,707 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 700 |  Loss: (0.0039) | Acc: (99.89%) (44813/44864) | Learning rate: (1e-06)
2022-06-06 23:06:05,503 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 710 |  Loss: (0.0039) | Acc: (99.89%) (45453/45504) | Learning rate: (1e-06)
2022-06-06 23:06:07,298 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 720 |  Loss: (0.0040) | Acc: (99.89%) (46091/46144) | Learning rate: (1e-06)
2022-06-06 23:06:09,096 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 730 |  Loss: (0.0040) | Acc: (99.89%) (46731/46784) | Learning rate: (1e-06)
2022-06-06 23:06:10,893 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 740 |  Loss: (0.0040) | Acc: (99.88%) (47369/47424) | Learning rate: (1e-06)
2022-06-06 23:06:12,688 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 750 |  Loss: (0.0040) | Acc: (99.89%) (48009/48064) | Learning rate: (1e-06)
2022-06-06 23:06:14,485 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 760 |  Loss: (0.0040) | Acc: (99.89%) (48648/48704) | Learning rate: (1e-06)
2022-06-06 23:06:16,274 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 770 |  Loss: (0.0040) | Acc: (99.88%) (49287/49344) | Learning rate: (1e-06)
2022-06-06 23:06:18,064 - CIFAR10 Classifier - INFO - Epoch: 24 | Batch_idx: 780 |  Loss: (0.0040) | Acc: (99.88%) (49926/49984) | Learning rate: (1e-06)
2022-06-06 23:06:27,962 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0810) | Acc: (98.09%) (9809/10000)
2022-06-06 23:06:27,963 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:06:28,840 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 0 |  Loss: (0.0006) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:06:30,633 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 10 |  Loss: (0.0006) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:06:32,424 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 20 |  Loss: (0.0037) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 23:06:34,216 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 23:06:36,011 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 40 |  Loss: (0.0033) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 23:06:37,806 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 50 |  Loss: (0.0031) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-06)
2022-06-06 23:06:39,602 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 60 |  Loss: (0.0028) | Acc: (99.95%) (3902/3904) | Learning rate: (1e-06)
2022-06-06 23:06:41,396 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 70 |  Loss: (0.0031) | Acc: (99.93%) (4541/4544) | Learning rate: (1e-06)
2022-06-06 23:06:43,190 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 80 |  Loss: (0.0029) | Acc: (99.94%) (5181/5184) | Learning rate: (1e-06)
2022-06-06 23:06:44,986 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 90 |  Loss: (0.0035) | Acc: (99.93%) (5820/5824) | Learning rate: (1e-06)
2022-06-06 23:06:46,784 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 100 |  Loss: (0.0032) | Acc: (99.94%) (6460/6464) | Learning rate: (1e-06)
2022-06-06 23:06:48,582 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 110 |  Loss: (0.0031) | Acc: (99.94%) (7100/7104) | Learning rate: (1e-06)
2022-06-06 23:06:50,379 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 120 |  Loss: (0.0032) | Acc: (99.94%) (7739/7744) | Learning rate: (1e-06)
2022-06-06 23:06:52,176 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 130 |  Loss: (0.0033) | Acc: (99.93%) (8378/8384) | Learning rate: (1e-06)
2022-06-06 23:06:53,972 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 140 |  Loss: (0.0036) | Acc: (99.92%) (9017/9024) | Learning rate: (1e-06)
2022-06-06 23:06:55,768 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 150 |  Loss: (0.0034) | Acc: (99.93%) (9657/9664) | Learning rate: (1e-06)
2022-06-06 23:06:57,564 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 160 |  Loss: (0.0032) | Acc: (99.93%) (10297/10304) | Learning rate: (1e-06)
2022-06-06 23:06:59,358 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 170 |  Loss: (0.0034) | Acc: (99.93%) (10936/10944) | Learning rate: (1e-06)
2022-06-06 23:07:01,155 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 180 |  Loss: (0.0038) | Acc: (99.92%) (11575/11584) | Learning rate: (1e-06)
2022-06-06 23:07:02,952 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 190 |  Loss: (0.0038) | Acc: (99.92%) (12214/12224) | Learning rate: (1e-06)
2022-06-06 23:07:04,748 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 200 |  Loss: (0.0038) | Acc: (99.91%) (12853/12864) | Learning rate: (1e-06)
2022-06-06 23:07:06,543 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 210 |  Loss: (0.0038) | Acc: (99.91%) (13492/13504) | Learning rate: (1e-06)
2022-06-06 23:07:08,337 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 220 |  Loss: (0.0037) | Acc: (99.92%) (14132/14144) | Learning rate: (1e-06)
2022-06-06 23:07:10,133 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 230 |  Loss: (0.0039) | Acc: (99.91%) (14771/14784) | Learning rate: (1e-06)
2022-06-06 23:07:11,930 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 240 |  Loss: (0.0038) | Acc: (99.92%) (15411/15424) | Learning rate: (1e-06)
2022-06-06 23:07:13,724 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 250 |  Loss: (0.0037) | Acc: (99.92%) (16051/16064) | Learning rate: (1e-06)
2022-06-06 23:07:15,520 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 260 |  Loss: (0.0037) | Acc: (99.92%) (16690/16704) | Learning rate: (1e-06)
2022-06-06 23:07:17,314 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 270 |  Loss: (0.0038) | Acc: (99.91%) (17329/17344) | Learning rate: (1e-06)
2022-06-06 23:07:19,111 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 280 |  Loss: (0.0037) | Acc: (99.91%) (17968/17984) | Learning rate: (1e-06)
2022-06-06 23:07:20,907 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 290 |  Loss: (0.0037) | Acc: (99.91%) (18608/18624) | Learning rate: (1e-06)
2022-06-06 23:07:22,701 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 300 |  Loss: (0.0036) | Acc: (99.92%) (19248/19264) | Learning rate: (1e-06)
2022-06-06 23:07:24,496 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 310 |  Loss: (0.0036) | Acc: (99.92%) (19888/19904) | Learning rate: (1e-06)
2022-06-06 23:07:26,292 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 320 |  Loss: (0.0036) | Acc: (99.91%) (20526/20544) | Learning rate: (1e-06)
2022-06-06 23:07:28,089 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 330 |  Loss: (0.0035) | Acc: (99.92%) (21166/21184) | Learning rate: (1e-06)
2022-06-06 23:07:29,884 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 340 |  Loss: (0.0037) | Acc: (99.91%) (21804/21824) | Learning rate: (1e-06)
2022-06-06 23:07:31,680 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 350 |  Loss: (0.0037) | Acc: (99.90%) (22441/22464) | Learning rate: (1e-06)
2022-06-06 23:07:33,474 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 360 |  Loss: (0.0037) | Acc: (99.90%) (23081/23104) | Learning rate: (1e-06)
2022-06-06 23:07:35,269 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 370 |  Loss: (0.0037) | Acc: (99.90%) (23720/23744) | Learning rate: (1e-06)
2022-06-06 23:07:37,066 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 380 |  Loss: (0.0037) | Acc: (99.90%) (24359/24384) | Learning rate: (1e-06)
2022-06-06 23:07:38,861 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 390 |  Loss: (0.0037) | Acc: (99.90%) (24999/25024) | Learning rate: (1e-06)
2022-06-06 23:07:40,658 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 400 |  Loss: (0.0037) | Acc: (99.90%) (25638/25664) | Learning rate: (1e-06)
2022-06-06 23:07:42,452 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 410 |  Loss: (0.0036) | Acc: (99.90%) (26278/26304) | Learning rate: (1e-06)
2022-06-06 23:07:44,247 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 420 |  Loss: (0.0036) | Acc: (99.90%) (26917/26944) | Learning rate: (1e-06)
2022-06-06 23:07:46,043 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 430 |  Loss: (0.0036) | Acc: (99.90%) (27557/27584) | Learning rate: (1e-06)
2022-06-06 23:07:47,841 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 440 |  Loss: (0.0036) | Acc: (99.90%) (28195/28224) | Learning rate: (1e-06)
2022-06-06 23:07:49,636 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 450 |  Loss: (0.0036) | Acc: (99.90%) (28834/28864) | Learning rate: (1e-06)
2022-06-06 23:07:51,434 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 460 |  Loss: (0.0036) | Acc: (99.90%) (29474/29504) | Learning rate: (1e-06)
2022-06-06 23:07:53,228 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 470 |  Loss: (0.0036) | Acc: (99.90%) (30113/30144) | Learning rate: (1e-06)
2022-06-06 23:07:55,024 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 480 |  Loss: (0.0036) | Acc: (99.89%) (30751/30784) | Learning rate: (1e-06)
2022-06-06 23:07:56,820 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 490 |  Loss: (0.0036) | Acc: (99.89%) (31391/31424) | Learning rate: (1e-06)
2022-06-06 23:07:58,615 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 500 |  Loss: (0.0037) | Acc: (99.89%) (32030/32064) | Learning rate: (1e-06)
2022-06-06 23:08:00,413 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 510 |  Loss: (0.0037) | Acc: (99.90%) (32670/32704) | Learning rate: (1e-06)
2022-06-06 23:08:02,207 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 520 |  Loss: (0.0037) | Acc: (99.90%) (33309/33344) | Learning rate: (1e-06)
2022-06-06 23:08:04,002 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 530 |  Loss: (0.0037) | Acc: (99.90%) (33949/33984) | Learning rate: (1e-06)
2022-06-06 23:08:05,799 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 540 |  Loss: (0.0037) | Acc: (99.90%) (34588/34624) | Learning rate: (1e-06)
2022-06-06 23:08:07,594 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 550 |  Loss: (0.0036) | Acc: (99.90%) (35228/35264) | Learning rate: (1e-06)
2022-06-06 23:08:09,392 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 560 |  Loss: (0.0036) | Acc: (99.90%) (35868/35904) | Learning rate: (1e-06)
2022-06-06 23:08:11,189 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 570 |  Loss: (0.0036) | Acc: (99.90%) (36507/36544) | Learning rate: (1e-06)
2022-06-06 23:08:12,985 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 580 |  Loss: (0.0037) | Acc: (99.90%) (37145/37184) | Learning rate: (1e-06)
2022-06-06 23:08:14,781 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 590 |  Loss: (0.0037) | Acc: (99.89%) (37784/37824) | Learning rate: (1e-06)
2022-06-06 23:08:16,576 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 600 |  Loss: (0.0038) | Acc: (99.89%) (38423/38464) | Learning rate: (1e-06)
2022-06-06 23:08:18,373 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 610 |  Loss: (0.0037) | Acc: (99.90%) (39063/39104) | Learning rate: (1e-06)
2022-06-06 23:08:20,172 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 620 |  Loss: (0.0037) | Acc: (99.90%) (39703/39744) | Learning rate: (1e-06)
2022-06-06 23:08:21,969 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 630 |  Loss: (0.0037) | Acc: (99.90%) (40343/40384) | Learning rate: (1e-06)
2022-06-06 23:08:23,767 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 640 |  Loss: (0.0037) | Acc: (99.90%) (40982/41024) | Learning rate: (1e-06)
2022-06-06 23:08:25,564 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 650 |  Loss: (0.0036) | Acc: (99.90%) (41622/41664) | Learning rate: (1e-06)
2022-06-06 23:08:27,359 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 660 |  Loss: (0.0036) | Acc: (99.90%) (42262/42304) | Learning rate: (1e-06)
2022-06-06 23:08:29,154 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 670 |  Loss: (0.0035) | Acc: (99.90%) (42902/42944) | Learning rate: (1e-06)
2022-06-06 23:08:30,951 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 680 |  Loss: (0.0036) | Acc: (99.90%) (43540/43584) | Learning rate: (1e-06)
2022-06-06 23:08:32,749 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 690 |  Loss: (0.0036) | Acc: (99.90%) (44179/44224) | Learning rate: (1e-06)
2022-06-06 23:08:34,545 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 700 |  Loss: (0.0036) | Acc: (99.89%) (44816/44864) | Learning rate: (1e-06)
2022-06-06 23:08:36,342 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 710 |  Loss: (0.0036) | Acc: (99.89%) (45456/45504) | Learning rate: (1e-06)
2022-06-06 23:08:38,139 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 720 |  Loss: (0.0036) | Acc: (99.90%) (46096/46144) | Learning rate: (1e-06)
2022-06-06 23:08:39,934 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 730 |  Loss: (0.0036) | Acc: (99.90%) (46736/46784) | Learning rate: (1e-06)
2022-06-06 23:08:41,730 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 740 |  Loss: (0.0036) | Acc: (99.90%) (47376/47424) | Learning rate: (1e-06)
2022-06-06 23:08:43,526 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 750 |  Loss: (0.0036) | Acc: (99.90%) (48014/48064) | Learning rate: (1e-06)
2022-06-06 23:08:45,325 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 760 |  Loss: (0.0036) | Acc: (99.90%) (48653/48704) | Learning rate: (1e-06)
2022-06-06 23:08:47,113 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 770 |  Loss: (0.0036) | Acc: (99.89%) (49291/49344) | Learning rate: (1e-06)
2022-06-06 23:08:48,904 - CIFAR10 Classifier - INFO - Epoch: 25 | Batch_idx: 780 |  Loss: (0.0036) | Acc: (99.89%) (49931/49984) | Learning rate: (1e-06)
2022-06-06 23:08:58,821 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0839) | Acc: (98.02%) (9802/10000)
2022-06-06 23:08:58,822 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:08:59,723 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 0 |  Loss: (0.0036) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:09:01,514 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 10 |  Loss: (0.0111) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 23:09:03,306 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 20 |  Loss: (0.0071) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 23:09:05,100 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 30 |  Loss: (0.0053) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 23:09:06,897 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 23:09:08,692 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 50 |  Loss: (0.0043) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:09:10,488 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 60 |  Loss: (0.0042) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 23:09:12,284 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 70 |  Loss: (0.0045) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-06)
2022-06-06 23:09:14,079 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 80 |  Loss: (0.0052) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-06)
2022-06-06 23:09:15,876 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 90 |  Loss: (0.0053) | Acc: (99.85%) (5815/5824) | Learning rate: (1e-06)
2022-06-06 23:09:17,671 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 100 |  Loss: (0.0054) | Acc: (99.83%) (6453/6464) | Learning rate: (1e-06)
2022-06-06 23:09:19,467 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 110 |  Loss: (0.0054) | Acc: (99.83%) (7092/7104) | Learning rate: (1e-06)
2022-06-06 23:09:21,263 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 120 |  Loss: (0.0053) | Acc: (99.83%) (7731/7744) | Learning rate: (1e-06)
2022-06-06 23:09:23,057 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 130 |  Loss: (0.0053) | Acc: (99.83%) (8370/8384) | Learning rate: (1e-06)
2022-06-06 23:09:24,852 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 140 |  Loss: (0.0052) | Acc: (99.84%) (9010/9024) | Learning rate: (1e-06)
2022-06-06 23:09:26,649 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 150 |  Loss: (0.0052) | Acc: (99.83%) (9648/9664) | Learning rate: (1e-06)
2022-06-06 23:09:28,446 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 23:09:30,242 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 170 |  Loss: (0.0050) | Acc: (99.84%) (10927/10944) | Learning rate: (1e-06)
2022-06-06 23:09:32,037 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 180 |  Loss: (0.0048) | Acc: (99.85%) (11567/11584) | Learning rate: (1e-06)
2022-06-06 23:09:33,832 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 190 |  Loss: (0.0046) | Acc: (99.85%) (12206/12224) | Learning rate: (1e-06)
2022-06-06 23:09:35,628 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 200 |  Loss: (0.0051) | Acc: (99.84%) (12844/12864) | Learning rate: (1e-06)
2022-06-06 23:09:37,424 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.84%) (13482/13504) | Learning rate: (1e-06)
2022-06-06 23:09:39,220 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 220 |  Loss: (0.0053) | Acc: (99.84%) (14122/14144) | Learning rate: (1e-06)
2022-06-06 23:09:41,015 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.85%) (14762/14784) | Learning rate: (1e-06)
2022-06-06 23:09:42,810 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.85%) (15401/15424) | Learning rate: (1e-06)
2022-06-06 23:09:44,605 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 250 |  Loss: (0.0050) | Acc: (99.86%) (16041/16064) | Learning rate: (1e-06)
2022-06-06 23:09:46,401 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 260 |  Loss: (0.0049) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-06)
2022-06-06 23:09:48,198 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 270 |  Loss: (0.0051) | Acc: (99.86%) (17320/17344) | Learning rate: (1e-06)
2022-06-06 23:09:49,994 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 280 |  Loss: (0.0050) | Acc: (99.87%) (17960/17984) | Learning rate: (1e-06)
2022-06-06 23:09:51,789 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.87%) (18600/18624) | Learning rate: (1e-06)
2022-06-06 23:09:53,585 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.87%) (19239/19264) | Learning rate: (1e-06)
2022-06-06 23:09:55,382 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 310 |  Loss: (0.0048) | Acc: (99.87%) (19878/19904) | Learning rate: (1e-06)
2022-06-06 23:09:57,179 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 320 |  Loss: (0.0047) | Acc: (99.87%) (20518/20544) | Learning rate: (1e-06)
2022-06-06 23:09:58,975 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 330 |  Loss: (0.0046) | Acc: (99.88%) (21158/21184) | Learning rate: (1e-06)
2022-06-06 23:10:00,773 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 340 |  Loss: (0.0045) | Acc: (99.88%) (21798/21824) | Learning rate: (1e-06)
2022-06-06 23:10:02,569 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 350 |  Loss: (0.0045) | Acc: (99.88%) (22437/22464) | Learning rate: (1e-06)
2022-06-06 23:10:04,367 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 360 |  Loss: (0.0045) | Acc: (99.88%) (23077/23104) | Learning rate: (1e-06)
2022-06-06 23:10:06,161 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 370 |  Loss: (0.0044) | Acc: (99.88%) (23716/23744) | Learning rate: (1e-06)
2022-06-06 23:10:07,958 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 380 |  Loss: (0.0045) | Acc: (99.88%) (24355/24384) | Learning rate: (1e-06)
2022-06-06 23:10:09,756 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.88%) (24995/25024) | Learning rate: (1e-06)
2022-06-06 23:10:11,552 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 400 |  Loss: (0.0043) | Acc: (99.89%) (25635/25664) | Learning rate: (1e-06)
2022-06-06 23:10:13,350 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 410 |  Loss: (0.0043) | Acc: (99.89%) (26275/26304) | Learning rate: (1e-06)
2022-06-06 23:10:15,147 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 420 |  Loss: (0.0044) | Acc: (99.88%) (26912/26944) | Learning rate: (1e-06)
2022-06-06 23:10:16,942 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 430 |  Loss: (0.0044) | Acc: (99.88%) (27552/27584) | Learning rate: (1e-06)
2022-06-06 23:10:18,739 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 440 |  Loss: (0.0044) | Acc: (99.88%) (28191/28224) | Learning rate: (1e-06)
2022-06-06 23:10:20,536 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 450 |  Loss: (0.0044) | Acc: (99.88%) (28829/28864) | Learning rate: (1e-06)
2022-06-06 23:10:22,334 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 460 |  Loss: (0.0044) | Acc: (99.88%) (29468/29504) | Learning rate: (1e-06)
2022-06-06 23:10:24,132 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 470 |  Loss: (0.0044) | Acc: (99.88%) (30108/30144) | Learning rate: (1e-06)
2022-06-06 23:10:25,928 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 480 |  Loss: (0.0043) | Acc: (99.88%) (30748/30784) | Learning rate: (1e-06)
2022-06-06 23:10:27,725 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 490 |  Loss: (0.0042) | Acc: (99.89%) (31388/31424) | Learning rate: (1e-06)
2022-06-06 23:10:29,520 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 500 |  Loss: (0.0042) | Acc: (99.88%) (32027/32064) | Learning rate: (1e-06)
2022-06-06 23:10:31,316 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 510 |  Loss: (0.0042) | Acc: (99.89%) (32667/32704) | Learning rate: (1e-06)
2022-06-06 23:10:33,113 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 520 |  Loss: (0.0042) | Acc: (99.88%) (33305/33344) | Learning rate: (1e-06)
2022-06-06 23:10:34,910 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 530 |  Loss: (0.0042) | Acc: (99.89%) (33945/33984) | Learning rate: (1e-06)
2022-06-06 23:10:36,708 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 540 |  Loss: (0.0041) | Acc: (99.88%) (34584/34624) | Learning rate: (1e-06)
2022-06-06 23:10:38,504 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 550 |  Loss: (0.0041) | Acc: (99.88%) (35223/35264) | Learning rate: (1e-06)
2022-06-06 23:10:40,303 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 560 |  Loss: (0.0042) | Acc: (99.88%) (35861/35904) | Learning rate: (1e-06)
2022-06-06 23:10:42,101 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 570 |  Loss: (0.0041) | Acc: (99.88%) (36500/36544) | Learning rate: (1e-06)
2022-06-06 23:10:43,898 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 580 |  Loss: (0.0041) | Acc: (99.88%) (37140/37184) | Learning rate: (1e-06)
2022-06-06 23:10:45,694 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 590 |  Loss: (0.0042) | Acc: (99.88%) (37778/37824) | Learning rate: (1e-06)
2022-06-06 23:10:47,490 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 600 |  Loss: (0.0042) | Acc: (99.88%) (38418/38464) | Learning rate: (1e-06)
2022-06-06 23:10:49,287 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 610 |  Loss: (0.0042) | Acc: (99.88%) (39057/39104) | Learning rate: (1e-06)
2022-06-06 23:10:51,085 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 620 |  Loss: (0.0041) | Acc: (99.88%) (39697/39744) | Learning rate: (1e-06)
2022-06-06 23:10:52,883 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 630 |  Loss: (0.0041) | Acc: (99.88%) (40337/40384) | Learning rate: (1e-06)
2022-06-06 23:10:54,680 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 640 |  Loss: (0.0040) | Acc: (99.89%) (40977/41024) | Learning rate: (1e-06)
2022-06-06 23:10:56,477 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 650 |  Loss: (0.0041) | Acc: (99.88%) (41615/41664) | Learning rate: (1e-06)
2022-06-06 23:10:58,275 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 660 |  Loss: (0.0041) | Acc: (99.88%) (42255/42304) | Learning rate: (1e-06)
2022-06-06 23:11:00,071 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 670 |  Loss: (0.0041) | Acc: (99.88%) (42894/42944) | Learning rate: (1e-06)
2022-06-06 23:11:01,867 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 680 |  Loss: (0.0041) | Acc: (99.89%) (43534/43584) | Learning rate: (1e-06)
2022-06-06 23:11:03,665 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 690 |  Loss: (0.0041) | Acc: (99.88%) (44173/44224) | Learning rate: (1e-06)
2022-06-06 23:11:05,461 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 700 |  Loss: (0.0041) | Acc: (99.89%) (44813/44864) | Learning rate: (1e-06)
2022-06-06 23:11:07,260 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 710 |  Loss: (0.0042) | Acc: (99.88%) (45450/45504) | Learning rate: (1e-06)
2022-06-06 23:11:09,057 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 720 |  Loss: (0.0042) | Acc: (99.88%) (46090/46144) | Learning rate: (1e-06)
2022-06-06 23:11:10,855 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 730 |  Loss: (0.0041) | Acc: (99.88%) (46730/46784) | Learning rate: (1e-06)
2022-06-06 23:11:12,652 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 740 |  Loss: (0.0041) | Acc: (99.89%) (47370/47424) | Learning rate: (1e-06)
2022-06-06 23:11:14,449 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 750 |  Loss: (0.0041) | Acc: (99.89%) (48009/48064) | Learning rate: (1e-06)
2022-06-06 23:11:16,246 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 760 |  Loss: (0.0041) | Acc: (99.88%) (48646/48704) | Learning rate: (1e-06)
2022-06-06 23:11:18,035 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 770 |  Loss: (0.0041) | Acc: (99.88%) (49284/49344) | Learning rate: (1e-06)
2022-06-06 23:11:19,825 - CIFAR10 Classifier - INFO - Epoch: 26 | Batch_idx: 780 |  Loss: (0.0041) | Acc: (99.88%) (49924/49984) | Learning rate: (1e-06)
2022-06-06 23:11:29,771 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0795) | Acc: (98.03%) (9803/10000)
2022-06-06 23:11:29,772 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:11:30,595 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 0 |  Loss: (0.0006) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:11:32,417 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 10 |  Loss: (0.0046) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 23:11:34,210 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 20 |  Loss: (0.0064) | Acc: (99.63%) (1339/1344) | Learning rate: (1e-06)
2022-06-06 23:11:36,003 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 30 |  Loss: (0.0046) | Acc: (99.75%) (1979/1984) | Learning rate: (1e-06)
2022-06-06 23:11:37,797 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 40 |  Loss: (0.0039) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-06)
2022-06-06 23:11:39,591 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 50 |  Loss: (0.0033) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 23:11:41,387 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 60 |  Loss: (0.0031) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-06)
2022-06-06 23:11:43,182 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 70 |  Loss: (0.0032) | Acc: (99.85%) (4537/4544) | Learning rate: (1e-06)
2022-06-06 23:11:44,976 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 80 |  Loss: (0.0030) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-06)
2022-06-06 23:11:46,771 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 90 |  Loss: (0.0035) | Acc: (99.85%) (5815/5824) | Learning rate: (1e-06)
2022-06-06 23:11:48,566 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 100 |  Loss: (0.0040) | Acc: (99.85%) (6454/6464) | Learning rate: (1e-06)
2022-06-06 23:11:50,362 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.82%) (7091/7104) | Learning rate: (1e-06)
2022-06-06 23:11:52,160 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 120 |  Loss: (0.0040) | Acc: (99.83%) (7731/7744) | Learning rate: (1e-06)
2022-06-06 23:11:53,955 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 130 |  Loss: (0.0042) | Acc: (99.83%) (8370/8384) | Learning rate: (1e-06)
2022-06-06 23:11:55,749 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 140 |  Loss: (0.0040) | Acc: (99.84%) (9010/9024) | Learning rate: (1e-06)
2022-06-06 23:11:57,544 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 150 |  Loss: (0.0039) | Acc: (99.86%) (9650/9664) | Learning rate: (1e-06)
2022-06-06 23:11:59,342 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 160 |  Loss: (0.0038) | Acc: (99.86%) (10290/10304) | Learning rate: (1e-06)
2022-06-06 23:12:01,138 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 170 |  Loss: (0.0041) | Acc: (99.85%) (10928/10944) | Learning rate: (1e-06)
2022-06-06 23:12:02,934 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 180 |  Loss: (0.0041) | Acc: (99.84%) (11566/11584) | Learning rate: (1e-06)
2022-06-06 23:12:04,730 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 190 |  Loss: (0.0039) | Acc: (99.85%) (12206/12224) | Learning rate: (1e-06)
2022-06-06 23:12:06,524 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 200 |  Loss: (0.0038) | Acc: (99.86%) (12846/12864) | Learning rate: (1e-06)
2022-06-06 23:12:08,320 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 210 |  Loss: (0.0042) | Acc: (99.84%) (13483/13504) | Learning rate: (1e-06)
2022-06-06 23:12:10,114 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 220 |  Loss: (0.0041) | Acc: (99.85%) (14123/14144) | Learning rate: (1e-06)
2022-06-06 23:12:11,910 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 230 |  Loss: (0.0040) | Acc: (99.86%) (14763/14784) | Learning rate: (1e-06)
2022-06-06 23:12:13,704 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 240 |  Loss: (0.0040) | Acc: (99.86%) (15403/15424) | Learning rate: (1e-06)
2022-06-06 23:12:15,497 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 250 |  Loss: (0.0041) | Acc: (99.86%) (16042/16064) | Learning rate: (1e-06)
2022-06-06 23:12:17,295 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 260 |  Loss: (0.0040) | Acc: (99.87%) (16682/16704) | Learning rate: (1e-06)
2022-06-06 23:12:19,090 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 270 |  Loss: (0.0040) | Acc: (99.87%) (17321/17344) | Learning rate: (1e-06)
2022-06-06 23:12:20,886 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 280 |  Loss: (0.0039) | Acc: (99.87%) (17961/17984) | Learning rate: (1e-06)
2022-06-06 23:12:22,680 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 290 |  Loss: (0.0038) | Acc: (99.88%) (18601/18624) | Learning rate: (1e-06)
2022-06-06 23:12:24,475 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 300 |  Loss: (0.0038) | Acc: (99.88%) (19241/19264) | Learning rate: (1e-06)
2022-06-06 23:12:26,271 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 310 |  Loss: (0.0038) | Acc: (99.88%) (19881/19904) | Learning rate: (1e-06)
2022-06-06 23:12:28,066 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 320 |  Loss: (0.0037) | Acc: (99.89%) (20521/20544) | Learning rate: (1e-06)
2022-06-06 23:12:29,861 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 330 |  Loss: (0.0038) | Acc: (99.88%) (21159/21184) | Learning rate: (1e-06)
2022-06-06 23:12:31,657 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 340 |  Loss: (0.0038) | Acc: (99.89%) (21799/21824) | Learning rate: (1e-06)
2022-06-06 23:12:33,452 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.88%) (22437/22464) | Learning rate: (1e-06)
2022-06-06 23:12:35,249 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 360 |  Loss: (0.0038) | Acc: (99.88%) (23076/23104) | Learning rate: (1e-06)
2022-06-06 23:12:37,047 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 370 |  Loss: (0.0037) | Acc: (99.88%) (23716/23744) | Learning rate: (1e-06)
2022-06-06 23:12:38,842 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 380 |  Loss: (0.0037) | Acc: (99.88%) (24355/24384) | Learning rate: (1e-06)
2022-06-06 23:12:40,640 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 390 |  Loss: (0.0037) | Acc: (99.88%) (24994/25024) | Learning rate: (1e-06)
2022-06-06 23:12:42,436 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 400 |  Loss: (0.0037) | Acc: (99.88%) (25633/25664) | Learning rate: (1e-06)
2022-06-06 23:12:44,233 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 410 |  Loss: (0.0037) | Acc: (99.88%) (26273/26304) | Learning rate: (1e-06)
2022-06-06 23:12:46,028 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 420 |  Loss: (0.0037) | Acc: (99.88%) (26912/26944) | Learning rate: (1e-06)
2022-06-06 23:12:47,825 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 430 |  Loss: (0.0036) | Acc: (99.88%) (27552/27584) | Learning rate: (1e-06)
2022-06-06 23:12:49,623 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 440 |  Loss: (0.0036) | Acc: (99.88%) (28191/28224) | Learning rate: (1e-06)
2022-06-06 23:12:51,420 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 450 |  Loss: (0.0036) | Acc: (99.89%) (28831/28864) | Learning rate: (1e-06)
2022-06-06 23:12:53,218 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 460 |  Loss: (0.0036) | Acc: (99.88%) (29470/29504) | Learning rate: (1e-06)
2022-06-06 23:12:55,016 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 470 |  Loss: (0.0036) | Acc: (99.89%) (30110/30144) | Learning rate: (1e-06)
2022-06-06 23:12:56,811 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 480 |  Loss: (0.0036) | Acc: (99.89%) (30749/30784) | Learning rate: (1e-06)
2022-06-06 23:12:58,608 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 490 |  Loss: (0.0036) | Acc: (99.89%) (31388/31424) | Learning rate: (1e-06)
2022-06-06 23:13:00,404 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 500 |  Loss: (0.0036) | Acc: (99.89%) (32028/32064) | Learning rate: (1e-06)
2022-06-06 23:13:02,203 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 510 |  Loss: (0.0035) | Acc: (99.89%) (32668/32704) | Learning rate: (1e-06)
2022-06-06 23:13:03,999 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 520 |  Loss: (0.0035) | Acc: (99.89%) (33308/33344) | Learning rate: (1e-06)
2022-06-06 23:13:05,795 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 530 |  Loss: (0.0035) | Acc: (99.89%) (33948/33984) | Learning rate: (1e-06)
2022-06-06 23:13:07,592 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 540 |  Loss: (0.0036) | Acc: (99.89%) (34585/34624) | Learning rate: (1e-06)
2022-06-06 23:13:09,387 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 550 |  Loss: (0.0036) | Acc: (99.89%) (35224/35264) | Learning rate: (1e-06)
2022-06-06 23:13:11,185 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 560 |  Loss: (0.0036) | Acc: (99.89%) (35864/35904) | Learning rate: (1e-06)
2022-06-06 23:13:12,980 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 570 |  Loss: (0.0036) | Acc: (99.89%) (36503/36544) | Learning rate: (1e-06)
2022-06-06 23:13:14,779 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 580 |  Loss: (0.0036) | Acc: (99.89%) (37142/37184) | Learning rate: (1e-06)
2022-06-06 23:13:16,576 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 590 |  Loss: (0.0036) | Acc: (99.89%) (37781/37824) | Learning rate: (1e-06)
2022-06-06 23:13:18,371 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 600 |  Loss: (0.0035) | Acc: (99.89%) (38421/38464) | Learning rate: (1e-06)
2022-06-06 23:13:20,169 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 610 |  Loss: (0.0035) | Acc: (99.89%) (39061/39104) | Learning rate: (1e-06)
2022-06-06 23:13:21,967 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 620 |  Loss: (0.0035) | Acc: (99.89%) (39700/39744) | Learning rate: (1e-06)
2022-06-06 23:13:23,765 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 630 |  Loss: (0.0035) | Acc: (99.89%) (40339/40384) | Learning rate: (1e-06)
2022-06-06 23:13:25,561 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 640 |  Loss: (0.0035) | Acc: (99.89%) (40979/41024) | Learning rate: (1e-06)
2022-06-06 23:13:27,357 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 650 |  Loss: (0.0035) | Acc: (99.89%) (41618/41664) | Learning rate: (1e-06)
2022-06-06 23:13:29,154 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 660 |  Loss: (0.0036) | Acc: (99.89%) (42257/42304) | Learning rate: (1e-06)
2022-06-06 23:13:30,954 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 670 |  Loss: (0.0036) | Acc: (99.89%) (42895/42944) | Learning rate: (1e-06)
2022-06-06 23:13:32,753 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 680 |  Loss: (0.0036) | Acc: (99.89%) (43535/43584) | Learning rate: (1e-06)
2022-06-06 23:13:34,550 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 690 |  Loss: (0.0037) | Acc: (99.88%) (44172/44224) | Learning rate: (1e-06)
2022-06-06 23:13:36,350 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 700 |  Loss: (0.0037) | Acc: (99.88%) (44809/44864) | Learning rate: (1e-06)
2022-06-06 23:13:38,147 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 710 |  Loss: (0.0039) | Acc: (99.87%) (45447/45504) | Learning rate: (1e-06)
2022-06-06 23:13:39,942 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 720 |  Loss: (0.0039) | Acc: (99.88%) (46087/46144) | Learning rate: (1e-06)
2022-06-06 23:13:41,738 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 730 |  Loss: (0.0039) | Acc: (99.88%) (46726/46784) | Learning rate: (1e-06)
2022-06-06 23:13:43,535 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 740 |  Loss: (0.0040) | Acc: (99.87%) (47363/47424) | Learning rate: (1e-06)
2022-06-06 23:13:45,331 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 750 |  Loss: (0.0040) | Acc: (99.87%) (48002/48064) | Learning rate: (1e-06)
2022-06-06 23:13:47,129 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 760 |  Loss: (0.0041) | Acc: (99.87%) (48640/48704) | Learning rate: (1e-06)
2022-06-06 23:13:48,922 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 770 |  Loss: (0.0040) | Acc: (99.87%) (49280/49344) | Learning rate: (1e-06)
2022-06-06 23:13:50,710 - CIFAR10 Classifier - INFO - Epoch: 27 | Batch_idx: 780 |  Loss: (0.0040) | Acc: (99.87%) (49919/49984) | Learning rate: (1e-06)
2022-06-06 23:14:00,665 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0817) | Acc: (98.07%) (9807/10000)
2022-06-06 23:14:00,666 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:14:01,590 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 0 |  Loss: (0.0014) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:14:03,383 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 10 |  Loss: (0.0014) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:14:05,175 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 20 |  Loss: (0.0024) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 23:14:06,966 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 30 |  Loss: (0.0028) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 23:14:08,763 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 40 |  Loss: (0.0023) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-06)
2022-06-06 23:14:10,556 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 50 |  Loss: (0.0029) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:14:12,353 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 60 |  Loss: (0.0027) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 23:14:14,147 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 70 |  Loss: (0.0026) | Acc: (99.93%) (4541/4544) | Learning rate: (1e-06)
2022-06-06 23:14:15,941 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 80 |  Loss: (0.0034) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 23:14:17,737 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 90 |  Loss: (0.0035) | Acc: (99.88%) (5817/5824) | Learning rate: (1e-06)
2022-06-06 23:14:19,531 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 100 |  Loss: (0.0032) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-06)
2022-06-06 23:14:21,325 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 110 |  Loss: (0.0030) | Acc: (99.90%) (7097/7104) | Learning rate: (1e-06)
2022-06-06 23:14:23,119 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 120 |  Loss: (0.0031) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-06)
2022-06-06 23:14:24,914 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 130 |  Loss: (0.0030) | Acc: (99.92%) (8377/8384) | Learning rate: (1e-06)
2022-06-06 23:14:26,711 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 140 |  Loss: (0.0030) | Acc: (99.92%) (9017/9024) | Learning rate: (1e-06)
2022-06-06 23:14:28,506 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 150 |  Loss: (0.0033) | Acc: (99.92%) (9656/9664) | Learning rate: (1e-06)
2022-06-06 23:14:30,301 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 160 |  Loss: (0.0034) | Acc: (99.91%) (10295/10304) | Learning rate: (1e-06)
2022-06-06 23:14:32,095 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 170 |  Loss: (0.0033) | Acc: (99.92%) (10935/10944) | Learning rate: (1e-06)
2022-06-06 23:14:33,891 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 180 |  Loss: (0.0032) | Acc: (99.91%) (11574/11584) | Learning rate: (1e-06)
2022-06-06 23:14:35,687 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 190 |  Loss: (0.0033) | Acc: (99.91%) (12213/12224) | Learning rate: (1e-06)
2022-06-06 23:14:37,483 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 200 |  Loss: (0.0032) | Acc: (99.91%) (12853/12864) | Learning rate: (1e-06)
2022-06-06 23:14:39,279 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 210 |  Loss: (0.0032) | Acc: (99.91%) (13492/13504) | Learning rate: (1e-06)
2022-06-06 23:14:41,074 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 220 |  Loss: (0.0032) | Acc: (99.92%) (14132/14144) | Learning rate: (1e-06)
2022-06-06 23:14:42,870 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 230 |  Loss: (0.0031) | Acc: (99.92%) (14772/14784) | Learning rate: (1e-06)
2022-06-06 23:14:44,666 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 240 |  Loss: (0.0031) | Acc: (99.92%) (15411/15424) | Learning rate: (1e-06)
2022-06-06 23:14:46,461 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 250 |  Loss: (0.0033) | Acc: (99.91%) (16049/16064) | Learning rate: (1e-06)
2022-06-06 23:14:48,256 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 260 |  Loss: (0.0033) | Acc: (99.90%) (16688/16704) | Learning rate: (1e-06)
2022-06-06 23:14:50,050 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 270 |  Loss: (0.0033) | Acc: (99.91%) (17328/17344) | Learning rate: (1e-06)
2022-06-06 23:14:51,846 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 280 |  Loss: (0.0034) | Acc: (99.91%) (17967/17984) | Learning rate: (1e-06)
2022-06-06 23:14:53,645 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 290 |  Loss: (0.0034) | Acc: (99.91%) (18607/18624) | Learning rate: (1e-06)
2022-06-06 23:14:55,439 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 300 |  Loss: (0.0034) | Acc: (99.91%) (19246/19264) | Learning rate: (1e-06)
2022-06-06 23:14:57,236 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 310 |  Loss: (0.0034) | Acc: (99.90%) (19885/19904) | Learning rate: (1e-06)
2022-06-06 23:14:59,030 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 320 |  Loss: (0.0037) | Acc: (99.90%) (20523/20544) | Learning rate: (1e-06)
2022-06-06 23:15:00,825 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 330 |  Loss: (0.0036) | Acc: (99.90%) (21163/21184) | Learning rate: (1e-06)
2022-06-06 23:15:02,622 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 340 |  Loss: (0.0037) | Acc: (99.90%) (21802/21824) | Learning rate: (1e-06)
2022-06-06 23:15:04,416 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 350 |  Loss: (0.0036) | Acc: (99.90%) (22442/22464) | Learning rate: (1e-06)
2022-06-06 23:15:06,213 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 360 |  Loss: (0.0035) | Acc: (99.90%) (23082/23104) | Learning rate: (1e-06)
2022-06-06 23:15:08,009 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 370 |  Loss: (0.0035) | Acc: (99.91%) (23722/23744) | Learning rate: (1e-06)
2022-06-06 23:15:09,804 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 380 |  Loss: (0.0034) | Acc: (99.91%) (24362/24384) | Learning rate: (1e-06)
2022-06-06 23:15:11,599 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 390 |  Loss: (0.0034) | Acc: (99.91%) (25001/25024) | Learning rate: (1e-06)
2022-06-06 23:15:13,396 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 400 |  Loss: (0.0034) | Acc: (99.91%) (25641/25664) | Learning rate: (1e-06)
2022-06-06 23:15:15,193 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 410 |  Loss: (0.0033) | Acc: (99.91%) (26281/26304) | Learning rate: (1e-06)
2022-06-06 23:15:16,988 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 420 |  Loss: (0.0033) | Acc: (99.91%) (26921/26944) | Learning rate: (1e-06)
2022-06-06 23:15:18,783 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 430 |  Loss: (0.0035) | Acc: (99.91%) (27559/27584) | Learning rate: (1e-06)
2022-06-06 23:15:20,578 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 440 |  Loss: (0.0035) | Acc: (99.91%) (28198/28224) | Learning rate: (1e-06)
2022-06-06 23:15:22,376 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 450 |  Loss: (0.0036) | Acc: (99.90%) (28835/28864) | Learning rate: (1e-06)
2022-06-06 23:15:24,173 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 460 |  Loss: (0.0035) | Acc: (99.90%) (29475/29504) | Learning rate: (1e-06)
2022-06-06 23:15:25,970 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 470 |  Loss: (0.0035) | Acc: (99.90%) (30115/30144) | Learning rate: (1e-06)
2022-06-06 23:15:27,769 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 480 |  Loss: (0.0035) | Acc: (99.90%) (30753/30784) | Learning rate: (1e-06)
2022-06-06 23:15:29,566 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 490 |  Loss: (0.0036) | Acc: (99.89%) (31391/31424) | Learning rate: (1e-06)
2022-06-06 23:15:31,365 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 500 |  Loss: (0.0035) | Acc: (99.90%) (32031/32064) | Learning rate: (1e-06)
2022-06-06 23:15:33,163 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 510 |  Loss: (0.0038) | Acc: (99.89%) (32669/32704) | Learning rate: (1e-06)
2022-06-06 23:15:34,958 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 520 |  Loss: (0.0037) | Acc: (99.90%) (33309/33344) | Learning rate: (1e-06)
2022-06-06 23:15:36,754 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 530 |  Loss: (0.0037) | Acc: (99.90%) (33949/33984) | Learning rate: (1e-06)
2022-06-06 23:15:38,551 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 540 |  Loss: (0.0037) | Acc: (99.90%) (34589/34624) | Learning rate: (1e-06)
2022-06-06 23:15:40,348 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 550 |  Loss: (0.0037) | Acc: (99.90%) (35229/35264) | Learning rate: (1e-06)
2022-06-06 23:15:42,147 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 560 |  Loss: (0.0036) | Acc: (99.90%) (35869/35904) | Learning rate: (1e-06)
2022-06-06 23:15:43,944 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 570 |  Loss: (0.0036) | Acc: (99.90%) (36509/36544) | Learning rate: (1e-06)
2022-06-06 23:15:45,742 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 580 |  Loss: (0.0035) | Acc: (99.91%) (37149/37184) | Learning rate: (1e-06)
2022-06-06 23:15:47,540 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 590 |  Loss: (0.0036) | Acc: (99.90%) (37788/37824) | Learning rate: (1e-06)
2022-06-06 23:15:49,337 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 600 |  Loss: (0.0035) | Acc: (99.91%) (38428/38464) | Learning rate: (1e-06)
2022-06-06 23:15:51,133 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 610 |  Loss: (0.0035) | Acc: (99.91%) (39068/39104) | Learning rate: (1e-06)
2022-06-06 23:15:52,930 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 620 |  Loss: (0.0037) | Acc: (99.90%) (39705/39744) | Learning rate: (1e-06)
2022-06-06 23:15:54,726 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 630 |  Loss: (0.0038) | Acc: (99.90%) (40343/40384) | Learning rate: (1e-06)
2022-06-06 23:15:56,524 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 640 |  Loss: (0.0038) | Acc: (99.90%) (40982/41024) | Learning rate: (1e-06)
2022-06-06 23:15:58,322 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 650 |  Loss: (0.0038) | Acc: (99.90%) (41621/41664) | Learning rate: (1e-06)
2022-06-06 23:16:00,118 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 660 |  Loss: (0.0038) | Acc: (99.90%) (42260/42304) | Learning rate: (1e-06)
2022-06-06 23:16:01,915 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 670 |  Loss: (0.0038) | Acc: (99.90%) (42899/42944) | Learning rate: (1e-06)
2022-06-06 23:16:03,712 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 680 |  Loss: (0.0038) | Acc: (99.89%) (43538/43584) | Learning rate: (1e-06)
2022-06-06 23:16:05,506 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 690 |  Loss: (0.0038) | Acc: (99.89%) (44177/44224) | Learning rate: (1e-06)
2022-06-06 23:16:07,302 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 700 |  Loss: (0.0041) | Acc: (99.88%) (44812/44864) | Learning rate: (1e-06)
2022-06-06 23:16:09,100 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 710 |  Loss: (0.0040) | Acc: (99.89%) (45452/45504) | Learning rate: (1e-06)
2022-06-06 23:16:10,896 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 720 |  Loss: (0.0040) | Acc: (99.89%) (46092/46144) | Learning rate: (1e-06)
2022-06-06 23:16:12,694 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 730 |  Loss: (0.0040) | Acc: (99.88%) (46730/46784) | Learning rate: (1e-06)
2022-06-06 23:16:14,492 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 740 |  Loss: (0.0040) | Acc: (99.89%) (47370/47424) | Learning rate: (1e-06)
2022-06-06 23:16:16,287 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 750 |  Loss: (0.0040) | Acc: (99.89%) (48009/48064) | Learning rate: (1e-06)
2022-06-06 23:16:18,083 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 760 |  Loss: (0.0040) | Acc: (99.89%) (48649/48704) | Learning rate: (1e-06)
2022-06-06 23:16:19,872 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 770 |  Loss: (0.0039) | Acc: (99.89%) (49289/49344) | Learning rate: (1e-06)
2022-06-06 23:16:21,662 - CIFAR10 Classifier - INFO - Epoch: 28 | Batch_idx: 780 |  Loss: (0.0039) | Acc: (99.89%) (49928/49984) | Learning rate: (1e-06)
2022-06-06 23:16:31,600 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0810) | Acc: (98.01%) (9801/10000)
2022-06-06 23:16:31,601 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:16:32,424 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 0 |  Loss: (0.0013) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:16:34,244 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 10 |  Loss: (0.0029) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 23:16:36,037 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 20 |  Loss: (0.0033) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 23:16:37,829 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 30 |  Loss: (0.0042) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-06)
2022-06-06 23:16:39,624 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 40 |  Loss: (0.0037) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 23:16:41,420 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 50 |  Loss: (0.0033) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:16:43,215 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 60 |  Loss: (0.0033) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 23:16:45,008 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 70 |  Loss: (0.0029) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-06)
2022-06-06 23:16:46,803 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 80 |  Loss: (0.0032) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-06)
2022-06-06 23:16:48,598 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 90 |  Loss: (0.0035) | Acc: (99.88%) (5817/5824) | Learning rate: (1e-06)
2022-06-06 23:16:50,394 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 100 |  Loss: (0.0034) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-06)
2022-06-06 23:16:52,189 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 110 |  Loss: (0.0040) | Acc: (99.87%) (7095/7104) | Learning rate: (1e-06)
2022-06-06 23:16:53,987 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 120 |  Loss: (0.0039) | Acc: (99.88%) (7735/7744) | Learning rate: (1e-06)
2022-06-06 23:16:55,783 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 130 |  Loss: (0.0039) | Acc: (99.88%) (8374/8384) | Learning rate: (1e-06)
2022-06-06 23:16:57,579 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 140 |  Loss: (0.0040) | Acc: (99.88%) (9013/9024) | Learning rate: (1e-06)
2022-06-06 23:16:59,375 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 150 |  Loss: (0.0038) | Acc: (99.89%) (9653/9664) | Learning rate: (1e-06)
2022-06-06 23:17:01,169 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 160 |  Loss: (0.0036) | Acc: (99.89%) (10293/10304) | Learning rate: (1e-06)
2022-06-06 23:17:02,965 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 170 |  Loss: (0.0036) | Acc: (99.89%) (10932/10944) | Learning rate: (1e-06)
2022-06-06 23:17:04,762 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 180 |  Loss: (0.0038) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-06)
2022-06-06 23:17:06,560 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 190 |  Loss: (0.0039) | Acc: (99.88%) (12209/12224) | Learning rate: (1e-06)
2022-06-06 23:17:08,354 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 200 |  Loss: (0.0041) | Acc: (99.88%) (12848/12864) | Learning rate: (1e-06)
2022-06-06 23:17:10,152 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 210 |  Loss: (0.0042) | Acc: (99.87%) (13486/13504) | Learning rate: (1e-06)
2022-06-06 23:17:11,947 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 220 |  Loss: (0.0040) | Acc: (99.87%) (14126/14144) | Learning rate: (1e-06)
2022-06-06 23:17:13,742 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 230 |  Loss: (0.0039) | Acc: (99.88%) (14766/14784) | Learning rate: (1e-06)
2022-06-06 23:17:15,538 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 240 |  Loss: (0.0038) | Acc: (99.88%) (15406/15424) | Learning rate: (1e-06)
2022-06-06 23:17:17,333 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 250 |  Loss: (0.0037) | Acc: (99.89%) (16046/16064) | Learning rate: (1e-06)
2022-06-06 23:17:19,131 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 260 |  Loss: (0.0037) | Acc: (99.89%) (16686/16704) | Learning rate: (1e-06)
2022-06-06 23:17:20,927 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 270 |  Loss: (0.0036) | Acc: (99.90%) (17326/17344) | Learning rate: (1e-06)
2022-06-06 23:17:22,723 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 280 |  Loss: (0.0035) | Acc: (99.90%) (17966/17984) | Learning rate: (1e-06)
2022-06-06 23:17:24,520 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 290 |  Loss: (0.0035) | Acc: (99.90%) (18605/18624) | Learning rate: (1e-06)
2022-06-06 23:17:26,316 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 300 |  Loss: (0.0035) | Acc: (99.90%) (19245/19264) | Learning rate: (1e-06)
2022-06-06 23:17:28,115 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 310 |  Loss: (0.0036) | Acc: (99.90%) (19884/19904) | Learning rate: (1e-06)
2022-06-06 23:17:29,912 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 320 |  Loss: (0.0035) | Acc: (99.90%) (20524/20544) | Learning rate: (1e-06)
2022-06-06 23:17:31,710 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 330 |  Loss: (0.0035) | Acc: (99.91%) (21164/21184) | Learning rate: (1e-06)
2022-06-06 23:17:33,508 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 340 |  Loss: (0.0035) | Acc: (99.90%) (21803/21824) | Learning rate: (1e-06)
2022-06-06 23:17:35,305 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 350 |  Loss: (0.0034) | Acc: (99.91%) (22443/22464) | Learning rate: (1e-06)
2022-06-06 23:17:37,102 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 360 |  Loss: (0.0034) | Acc: (99.91%) (23083/23104) | Learning rate: (1e-06)
2022-06-06 23:17:38,899 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 370 |  Loss: (0.0033) | Acc: (99.91%) (23723/23744) | Learning rate: (1e-06)
2022-06-06 23:17:40,695 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 380 |  Loss: (0.0034) | Acc: (99.91%) (24361/24384) | Learning rate: (1e-06)
2022-06-06 23:17:42,491 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 390 |  Loss: (0.0033) | Acc: (99.91%) (25001/25024) | Learning rate: (1e-06)
2022-06-06 23:17:44,289 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 400 |  Loss: (0.0033) | Acc: (99.91%) (25641/25664) | Learning rate: (1e-06)
2022-06-06 23:17:46,088 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 410 |  Loss: (0.0034) | Acc: (99.90%) (26279/26304) | Learning rate: (1e-06)
2022-06-06 23:17:47,885 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 420 |  Loss: (0.0033) | Acc: (99.91%) (26919/26944) | Learning rate: (1e-06)
2022-06-06 23:17:49,681 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 430 |  Loss: (0.0033) | Acc: (99.90%) (27557/27584) | Learning rate: (1e-06)
2022-06-06 23:17:51,477 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 440 |  Loss: (0.0033) | Acc: (99.90%) (28197/28224) | Learning rate: (1e-06)
2022-06-06 23:17:53,272 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 450 |  Loss: (0.0032) | Acc: (99.91%) (28837/28864) | Learning rate: (1e-06)
2022-06-06 23:17:55,069 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 460 |  Loss: (0.0033) | Acc: (99.91%) (29476/29504) | Learning rate: (1e-06)
2022-06-06 23:17:56,864 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 470 |  Loss: (0.0032) | Acc: (99.91%) (30116/30144) | Learning rate: (1e-06)
2022-06-06 23:17:58,661 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 480 |  Loss: (0.0032) | Acc: (99.91%) (30756/30784) | Learning rate: (1e-06)
2022-06-06 23:18:00,457 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 490 |  Loss: (0.0032) | Acc: (99.91%) (31395/31424) | Learning rate: (1e-06)
2022-06-06 23:18:02,251 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 500 |  Loss: (0.0033) | Acc: (99.91%) (32034/32064) | Learning rate: (1e-06)
2022-06-06 23:18:04,047 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 510 |  Loss: (0.0033) | Acc: (99.91%) (32674/32704) | Learning rate: (1e-06)
2022-06-06 23:18:05,843 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 520 |  Loss: (0.0033) | Acc: (99.91%) (33314/33344) | Learning rate: (1e-06)
2022-06-06 23:18:07,640 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 530 |  Loss: (0.0032) | Acc: (99.91%) (33954/33984) | Learning rate: (1e-06)
2022-06-06 23:18:09,438 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 540 |  Loss: (0.0032) | Acc: (99.91%) (34594/34624) | Learning rate: (1e-06)
2022-06-06 23:18:11,234 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 550 |  Loss: (0.0032) | Acc: (99.91%) (35233/35264) | Learning rate: (1e-06)
2022-06-06 23:18:13,031 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 560 |  Loss: (0.0032) | Acc: (99.91%) (35872/35904) | Learning rate: (1e-06)
2022-06-06 23:18:14,827 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 570 |  Loss: (0.0032) | Acc: (99.91%) (36512/36544) | Learning rate: (1e-06)
2022-06-06 23:18:16,622 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 580 |  Loss: (0.0032) | Acc: (99.91%) (37152/37184) | Learning rate: (1e-06)
2022-06-06 23:18:18,418 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 590 |  Loss: (0.0032) | Acc: (99.91%) (37791/37824) | Learning rate: (1e-06)
2022-06-06 23:18:20,214 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 600 |  Loss: (0.0032) | Acc: (99.91%) (38431/38464) | Learning rate: (1e-06)
2022-06-06 23:18:22,010 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 610 |  Loss: (0.0035) | Acc: (99.91%) (39067/39104) | Learning rate: (1e-06)
2022-06-06 23:18:23,810 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 620 |  Loss: (0.0035) | Acc: (99.90%) (39706/39744) | Learning rate: (1e-06)
2022-06-06 23:18:25,605 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 630 |  Loss: (0.0035) | Acc: (99.91%) (40346/40384) | Learning rate: (1e-06)
2022-06-06 23:18:27,401 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 640 |  Loss: (0.0035) | Acc: (99.91%) (40986/41024) | Learning rate: (1e-06)
2022-06-06 23:18:29,196 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 650 |  Loss: (0.0035) | Acc: (99.91%) (41625/41664) | Learning rate: (1e-06)
2022-06-06 23:18:30,993 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 660 |  Loss: (0.0034) | Acc: (99.91%) (42265/42304) | Learning rate: (1e-06)
2022-06-06 23:18:32,792 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 670 |  Loss: (0.0034) | Acc: (99.91%) (42905/42944) | Learning rate: (1e-06)
2022-06-06 23:18:34,588 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 680 |  Loss: (0.0034) | Acc: (99.91%) (43543/43584) | Learning rate: (1e-06)
2022-06-06 23:18:36,385 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 690 |  Loss: (0.0034) | Acc: (99.91%) (44183/44224) | Learning rate: (1e-06)
2022-06-06 23:18:38,180 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 700 |  Loss: (0.0035) | Acc: (99.90%) (44821/44864) | Learning rate: (1e-06)
2022-06-06 23:18:39,976 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 710 |  Loss: (0.0035) | Acc: (99.90%) (45460/45504) | Learning rate: (1e-06)
2022-06-06 23:18:41,772 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 720 |  Loss: (0.0035) | Acc: (99.90%) (46100/46144) | Learning rate: (1e-06)
2022-06-06 23:18:43,570 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 730 |  Loss: (0.0034) | Acc: (99.91%) (46740/46784) | Learning rate: (1e-06)
2022-06-06 23:18:45,369 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 740 |  Loss: (0.0034) | Acc: (99.91%) (47379/47424) | Learning rate: (1e-06)
2022-06-06 23:18:47,165 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 750 |  Loss: (0.0034) | Acc: (99.90%) (48017/48064) | Learning rate: (1e-06)
2022-06-06 23:18:48,964 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 760 |  Loss: (0.0034) | Acc: (99.90%) (48657/48704) | Learning rate: (1e-06)
2022-06-06 23:18:50,753 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 770 |  Loss: (0.0034) | Acc: (99.90%) (49297/49344) | Learning rate: (1e-06)
2022-06-06 23:18:52,542 - CIFAR10 Classifier - INFO - Epoch: 29 | Batch_idx: 780 |  Loss: (0.0034) | Acc: (99.90%) (49936/49984) | Learning rate: (1e-06)
2022-06-06 23:19:02,534 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0820) | Acc: (98.04%) (9804/10000)
2022-06-06 23:19:02,535 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:19:03,352 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 0 |  Loss: (0.0003) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:19:05,158 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 10 |  Loss: (0.0020) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:19:06,949 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 20 |  Loss: (0.0018) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 23:19:08,742 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 30 |  Loss: (0.0016) | Acc: (100.00%) (1984/1984) | Learning rate: (1e-06)
2022-06-06 23:19:10,536 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 40 |  Loss: (0.0016) | Acc: (100.00%) (2624/2624) | Learning rate: (1e-06)
2022-06-06 23:19:12,330 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 50 |  Loss: (0.0023) | Acc: (99.97%) (3263/3264) | Learning rate: (1e-06)
2022-06-06 23:19:14,125 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 60 |  Loss: (0.0039) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 23:19:15,919 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 70 |  Loss: (0.0036) | Acc: (99.93%) (4541/4544) | Learning rate: (1e-06)
2022-06-06 23:19:17,714 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 80 |  Loss: (0.0032) | Acc: (99.94%) (5181/5184) | Learning rate: (1e-06)
2022-06-06 23:19:19,509 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 90 |  Loss: (0.0031) | Acc: (99.95%) (5821/5824) | Learning rate: (1e-06)
2022-06-06 23:19:21,303 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 100 |  Loss: (0.0034) | Acc: (99.92%) (6459/6464) | Learning rate: (1e-06)
2022-06-06 23:19:23,098 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 110 |  Loss: (0.0032) | Acc: (99.93%) (7099/7104) | Learning rate: (1e-06)
2022-06-06 23:19:24,892 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 120 |  Loss: (0.0038) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 23:19:26,687 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 130 |  Loss: (0.0036) | Acc: (99.90%) (8376/8384) | Learning rate: (1e-06)
2022-06-06 23:19:28,482 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 140 |  Loss: (0.0035) | Acc: (99.91%) (9016/9024) | Learning rate: (1e-06)
2022-06-06 23:19:30,277 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 150 |  Loss: (0.0034) | Acc: (99.92%) (9656/9664) | Learning rate: (1e-06)
2022-06-06 23:19:32,073 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 160 |  Loss: (0.0033) | Acc: (99.92%) (10296/10304) | Learning rate: (1e-06)
2022-06-06 23:19:33,869 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 170 |  Loss: (0.0032) | Acc: (99.93%) (10936/10944) | Learning rate: (1e-06)
2022-06-06 23:19:35,665 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.91%) (11573/11584) | Learning rate: (1e-06)
2022-06-06 23:19:37,460 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 190 |  Loss: (0.0036) | Acc: (99.91%) (12213/12224) | Learning rate: (1e-06)
2022-06-06 23:19:39,254 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 200 |  Loss: (0.0038) | Acc: (99.89%) (12850/12864) | Learning rate: (1e-06)
2022-06-06 23:19:41,050 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 210 |  Loss: (0.0043) | Acc: (99.88%) (13488/13504) | Learning rate: (1e-06)
2022-06-06 23:19:42,848 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 220 |  Loss: (0.0043) | Acc: (99.88%) (14127/14144) | Learning rate: (1e-06)
2022-06-06 23:19:44,643 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 230 |  Loss: (0.0043) | Acc: (99.88%) (14766/14784) | Learning rate: (1e-06)
2022-06-06 23:19:46,438 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 240 |  Loss: (0.0044) | Acc: (99.87%) (15404/15424) | Learning rate: (1e-06)
2022-06-06 23:19:48,233 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 250 |  Loss: (0.0043) | Acc: (99.88%) (16044/16064) | Learning rate: (1e-06)
2022-06-06 23:19:50,029 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 260 |  Loss: (0.0043) | Acc: (99.87%) (16683/16704) | Learning rate: (1e-06)
2022-06-06 23:19:51,825 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 270 |  Loss: (0.0044) | Acc: (99.87%) (17322/17344) | Learning rate: (1e-06)
2022-06-06 23:19:53,620 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 280 |  Loss: (0.0044) | Acc: (99.87%) (17961/17984) | Learning rate: (1e-06)
2022-06-06 23:19:55,416 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 290 |  Loss: (0.0044) | Acc: (99.88%) (18601/18624) | Learning rate: (1e-06)
2022-06-06 23:19:57,209 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.88%) (19240/19264) | Learning rate: (1e-06)
2022-06-06 23:19:59,005 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 310 |  Loss: (0.0043) | Acc: (99.88%) (19880/19904) | Learning rate: (1e-06)
2022-06-06 23:20:00,799 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 320 |  Loss: (0.0042) | Acc: (99.88%) (20519/20544) | Learning rate: (1e-06)
2022-06-06 23:20:02,596 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 330 |  Loss: (0.0042) | Acc: (99.88%) (21159/21184) | Learning rate: (1e-06)
2022-06-06 23:20:04,391 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 340 |  Loss: (0.0041) | Acc: (99.89%) (21799/21824) | Learning rate: (1e-06)
2022-06-06 23:20:06,184 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 350 |  Loss: (0.0040) | Acc: (99.89%) (22439/22464) | Learning rate: (1e-06)
2022-06-06 23:20:07,981 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 360 |  Loss: (0.0042) | Acc: (99.88%) (23077/23104) | Learning rate: (1e-06)
2022-06-06 23:20:09,776 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 370 |  Loss: (0.0043) | Acc: (99.88%) (23715/23744) | Learning rate: (1e-06)
2022-06-06 23:20:11,572 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 380 |  Loss: (0.0045) | Acc: (99.87%) (24353/24384) | Learning rate: (1e-06)
2022-06-06 23:20:13,367 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.88%) (24993/25024) | Learning rate: (1e-06)
2022-06-06 23:20:15,162 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 400 |  Loss: (0.0046) | Acc: (99.87%) (25631/25664) | Learning rate: (1e-06)
2022-06-06 23:20:16,960 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 410 |  Loss: (0.0045) | Acc: (99.87%) (26271/26304) | Learning rate: (1e-06)
2022-06-06 23:20:18,758 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 420 |  Loss: (0.0045) | Acc: (99.88%) (26911/26944) | Learning rate: (1e-06)
2022-06-06 23:20:20,554 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 430 |  Loss: (0.0044) | Acc: (99.88%) (27551/27584) | Learning rate: (1e-06)
2022-06-06 23:20:22,350 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 440 |  Loss: (0.0044) | Acc: (99.88%) (28190/28224) | Learning rate: (1e-06)
2022-06-06 23:20:24,146 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 450 |  Loss: (0.0043) | Acc: (99.88%) (28830/28864) | Learning rate: (1e-06)
2022-06-06 23:20:25,942 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 460 |  Loss: (0.0043) | Acc: (99.88%) (29470/29504) | Learning rate: (1e-06)
2022-06-06 23:20:27,736 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 470 |  Loss: (0.0042) | Acc: (99.89%) (30110/30144) | Learning rate: (1e-06)
2022-06-06 23:20:29,532 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 480 |  Loss: (0.0043) | Acc: (99.89%) (30749/30784) | Learning rate: (1e-06)
2022-06-06 23:20:31,329 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 490 |  Loss: (0.0042) | Acc: (99.89%) (31388/31424) | Learning rate: (1e-06)
2022-06-06 23:20:33,124 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 500 |  Loss: (0.0043) | Acc: (99.88%) (32026/32064) | Learning rate: (1e-06)
2022-06-06 23:20:34,921 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 510 |  Loss: (0.0044) | Acc: (99.88%) (32664/32704) | Learning rate: (1e-06)
2022-06-06 23:20:36,715 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 520 |  Loss: (0.0043) | Acc: (99.88%) (33304/33344) | Learning rate: (1e-06)
2022-06-06 23:20:38,512 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 530 |  Loss: (0.0044) | Acc: (99.88%) (33943/33984) | Learning rate: (1e-06)
2022-06-06 23:20:40,309 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 540 |  Loss: (0.0043) | Acc: (99.88%) (34583/34624) | Learning rate: (1e-06)
2022-06-06 23:20:42,104 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 550 |  Loss: (0.0044) | Acc: (99.88%) (35222/35264) | Learning rate: (1e-06)
2022-06-06 23:20:43,903 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 560 |  Loss: (0.0044) | Acc: (99.88%) (35862/35904) | Learning rate: (1e-06)
2022-06-06 23:20:45,698 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 570 |  Loss: (0.0043) | Acc: (99.88%) (36501/36544) | Learning rate: (1e-06)
2022-06-06 23:20:47,492 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 580 |  Loss: (0.0043) | Acc: (99.88%) (37140/37184) | Learning rate: (1e-06)
2022-06-06 23:20:49,289 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 590 |  Loss: (0.0044) | Acc: (99.88%) (37778/37824) | Learning rate: (1e-06)
2022-06-06 23:20:51,086 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 600 |  Loss: (0.0043) | Acc: (99.88%) (38418/38464) | Learning rate: (1e-06)
2022-06-06 23:20:52,884 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 610 |  Loss: (0.0043) | Acc: (99.88%) (39058/39104) | Learning rate: (1e-06)
2022-06-06 23:20:54,679 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 620 |  Loss: (0.0042) | Acc: (99.88%) (39698/39744) | Learning rate: (1e-06)
2022-06-06 23:20:56,474 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 630 |  Loss: (0.0042) | Acc: (99.89%) (40338/40384) | Learning rate: (1e-06)
2022-06-06 23:20:58,269 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 640 |  Loss: (0.0042) | Acc: (99.89%) (40977/41024) | Learning rate: (1e-06)
2022-06-06 23:21:00,065 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 650 |  Loss: (0.0041) | Acc: (99.88%) (41616/41664) | Learning rate: (1e-06)
2022-06-06 23:21:01,862 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 660 |  Loss: (0.0041) | Acc: (99.89%) (42256/42304) | Learning rate: (1e-06)
2022-06-06 23:21:03,658 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 670 |  Loss: (0.0041) | Acc: (99.89%) (42895/42944) | Learning rate: (1e-06)
2022-06-06 23:21:05,457 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 680 |  Loss: (0.0041) | Acc: (99.88%) (43533/43584) | Learning rate: (1e-06)
2022-06-06 23:21:07,255 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 690 |  Loss: (0.0041) | Acc: (99.88%) (44173/44224) | Learning rate: (1e-06)
2022-06-06 23:21:09,051 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 700 |  Loss: (0.0041) | Acc: (99.88%) (44812/44864) | Learning rate: (1e-06)
2022-06-06 23:21:10,846 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 710 |  Loss: (0.0041) | Acc: (99.89%) (45452/45504) | Learning rate: (1e-06)
2022-06-06 23:21:12,641 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 720 |  Loss: (0.0042) | Acc: (99.89%) (46091/46144) | Learning rate: (1e-06)
2022-06-06 23:21:14,438 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 730 |  Loss: (0.0041) | Acc: (99.89%) (46731/46784) | Learning rate: (1e-06)
2022-06-06 23:21:16,236 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 740 |  Loss: (0.0041) | Acc: (99.89%) (47371/47424) | Learning rate: (1e-06)
2022-06-06 23:21:18,032 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 750 |  Loss: (0.0041) | Acc: (99.89%) (48009/48064) | Learning rate: (1e-06)
2022-06-06 23:21:19,829 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 760 |  Loss: (0.0041) | Acc: (99.89%) (48649/48704) | Learning rate: (1e-06)
2022-06-06 23:21:21,617 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 770 |  Loss: (0.0041) | Acc: (99.89%) (49289/49344) | Learning rate: (1e-06)
2022-06-06 23:21:23,407 - CIFAR10 Classifier - INFO - Epoch: 30 | Batch_idx: 780 |  Loss: (0.0040) | Acc: (99.89%) (49929/49984) | Learning rate: (1e-06)
2022-06-06 23:21:33,307 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0805) | Acc: (98.06%) (9806/10000)
2022-06-06 23:21:33,307 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:21:34,101 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:21:35,911 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 10 |  Loss: (0.0063) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 23:21:37,704 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 20 |  Loss: (0.0036) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 23:21:39,497 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 30 |  Loss: (0.0029) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 23:21:41,291 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 40 |  Loss: (0.0040) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-06)
2022-06-06 23:21:43,086 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 50 |  Loss: (0.0036) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:21:44,880 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 60 |  Loss: (0.0036) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 23:21:46,673 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 70 |  Loss: (0.0034) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-06)
2022-06-06 23:21:48,467 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 80 |  Loss: (0.0035) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-06)
2022-06-06 23:21:50,262 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 90 |  Loss: (0.0033) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 23:21:52,057 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 100 |  Loss: (0.0037) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-06)
2022-06-06 23:21:53,852 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 110 |  Loss: (0.0035) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-06)
2022-06-06 23:21:55,646 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 120 |  Loss: (0.0034) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-06)
2022-06-06 23:21:57,441 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 130 |  Loss: (0.0039) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-06)
2022-06-06 23:21:59,237 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 140 |  Loss: (0.0043) | Acc: (99.88%) (9013/9024) | Learning rate: (1e-06)
2022-06-06 23:22:01,029 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 150 |  Loss: (0.0041) | Acc: (99.89%) (9653/9664) | Learning rate: (1e-06)
2022-06-06 23:22:02,825 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 160 |  Loss: (0.0041) | Acc: (99.88%) (10292/10304) | Learning rate: (1e-06)
2022-06-06 23:22:04,620 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 170 |  Loss: (0.0039) | Acc: (99.89%) (10932/10944) | Learning rate: (1e-06)
2022-06-06 23:22:06,416 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.90%) (11572/11584) | Learning rate: (1e-06)
2022-06-06 23:22:08,213 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 190 |  Loss: (0.0039) | Acc: (99.89%) (12211/12224) | Learning rate: (1e-06)
2022-06-06 23:22:10,007 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 200 |  Loss: (0.0037) | Acc: (99.90%) (12851/12864) | Learning rate: (1e-06)
2022-06-06 23:22:11,801 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 210 |  Loss: (0.0036) | Acc: (99.90%) (13491/13504) | Learning rate: (1e-06)
2022-06-06 23:22:13,597 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 220 |  Loss: (0.0037) | Acc: (99.89%) (14129/14144) | Learning rate: (1e-06)
2022-06-06 23:22:15,394 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 230 |  Loss: (0.0037) | Acc: (99.89%) (14768/14784) | Learning rate: (1e-06)
2022-06-06 23:22:17,189 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 240 |  Loss: (0.0036) | Acc: (99.90%) (15408/15424) | Learning rate: (1e-06)
2022-06-06 23:22:18,984 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 250 |  Loss: (0.0035) | Acc: (99.90%) (16048/16064) | Learning rate: (1e-06)
2022-06-06 23:22:20,778 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 260 |  Loss: (0.0035) | Acc: (99.90%) (16688/16704) | Learning rate: (1e-06)
2022-06-06 23:22:22,575 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 270 |  Loss: (0.0035) | Acc: (99.90%) (17327/17344) | Learning rate: (1e-06)
2022-06-06 23:22:24,371 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 280 |  Loss: (0.0035) | Acc: (99.90%) (17966/17984) | Learning rate: (1e-06)
2022-06-06 23:22:26,167 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 290 |  Loss: (0.0035) | Acc: (99.90%) (18606/18624) | Learning rate: (1e-06)
2022-06-06 23:22:27,961 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 300 |  Loss: (0.0037) | Acc: (99.90%) (19245/19264) | Learning rate: (1e-06)
2022-06-06 23:22:29,756 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 310 |  Loss: (0.0036) | Acc: (99.90%) (19885/19904) | Learning rate: (1e-06)
2022-06-06 23:22:31,551 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 320 |  Loss: (0.0040) | Acc: (99.90%) (20524/20544) | Learning rate: (1e-06)
2022-06-06 23:22:33,346 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 330 |  Loss: (0.0040) | Acc: (99.90%) (21162/21184) | Learning rate: (1e-06)
2022-06-06 23:22:35,141 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 340 |  Loss: (0.0039) | Acc: (99.90%) (21802/21824) | Learning rate: (1e-06)
2022-06-06 23:22:36,935 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.90%) (22442/22464) | Learning rate: (1e-06)
2022-06-06 23:22:38,731 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 360 |  Loss: (0.0038) | Acc: (99.90%) (23081/23104) | Learning rate: (1e-06)
2022-06-06 23:22:40,527 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 370 |  Loss: (0.0037) | Acc: (99.90%) (23721/23744) | Learning rate: (1e-06)
2022-06-06 23:22:42,323 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 380 |  Loss: (0.0037) | Acc: (99.90%) (24360/24384) | Learning rate: (1e-06)
2022-06-06 23:22:44,120 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 390 |  Loss: (0.0036) | Acc: (99.90%) (25000/25024) | Learning rate: (1e-06)
2022-06-06 23:22:45,914 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 400 |  Loss: (0.0036) | Acc: (99.91%) (25640/25664) | Learning rate: (1e-06)
2022-06-06 23:22:47,710 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 410 |  Loss: (0.0036) | Acc: (99.90%) (26279/26304) | Learning rate: (1e-06)
2022-06-06 23:22:49,507 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 420 |  Loss: (0.0036) | Acc: (99.90%) (26918/26944) | Learning rate: (1e-06)
2022-06-06 23:22:51,305 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 430 |  Loss: (0.0036) | Acc: (99.91%) (27558/27584) | Learning rate: (1e-06)
2022-06-06 23:22:53,101 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 440 |  Loss: (0.0036) | Acc: (99.90%) (28197/28224) | Learning rate: (1e-06)
2022-06-06 23:22:54,897 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 450 |  Loss: (0.0036) | Acc: (99.91%) (28837/28864) | Learning rate: (1e-06)
2022-06-06 23:22:56,693 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 460 |  Loss: (0.0035) | Acc: (99.91%) (29477/29504) | Learning rate: (1e-06)
2022-06-06 23:22:58,488 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 470 |  Loss: (0.0036) | Acc: (99.91%) (30116/30144) | Learning rate: (1e-06)
2022-06-06 23:23:00,284 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 480 |  Loss: (0.0037) | Acc: (99.91%) (30755/30784) | Learning rate: (1e-06)
2022-06-06 23:23:02,080 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 490 |  Loss: (0.0037) | Acc: (99.90%) (31394/31424) | Learning rate: (1e-06)
2022-06-06 23:23:03,875 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 500 |  Loss: (0.0037) | Acc: (99.90%) (32033/32064) | Learning rate: (1e-06)
2022-06-06 23:23:05,671 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 510 |  Loss: (0.0037) | Acc: (99.91%) (32673/32704) | Learning rate: (1e-06)
2022-06-06 23:23:07,465 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 520 |  Loss: (0.0036) | Acc: (99.91%) (33313/33344) | Learning rate: (1e-06)
2022-06-06 23:23:09,261 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 530 |  Loss: (0.0036) | Acc: (99.91%) (33953/33984) | Learning rate: (1e-06)
2022-06-06 23:23:11,059 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 540 |  Loss: (0.0036) | Acc: (99.91%) (34592/34624) | Learning rate: (1e-06)
2022-06-06 23:23:12,855 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 550 |  Loss: (0.0035) | Acc: (99.91%) (35232/35264) | Learning rate: (1e-06)
2022-06-06 23:23:14,651 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 560 |  Loss: (0.0035) | Acc: (99.91%) (35871/35904) | Learning rate: (1e-06)
2022-06-06 23:23:16,446 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 570 |  Loss: (0.0035) | Acc: (99.91%) (36511/36544) | Learning rate: (1e-06)
2022-06-06 23:23:18,242 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 580 |  Loss: (0.0035) | Acc: (99.91%) (37151/37184) | Learning rate: (1e-06)
2022-06-06 23:23:20,038 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 590 |  Loss: (0.0035) | Acc: (99.91%) (37791/37824) | Learning rate: (1e-06)
2022-06-06 23:23:21,832 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 600 |  Loss: (0.0034) | Acc: (99.91%) (38431/38464) | Learning rate: (1e-06)
2022-06-06 23:23:23,627 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 610 |  Loss: (0.0034) | Acc: (99.92%) (39071/39104) | Learning rate: (1e-06)
2022-06-06 23:23:25,422 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 620 |  Loss: (0.0034) | Acc: (99.92%) (39711/39744) | Learning rate: (1e-06)
2022-06-06 23:23:27,216 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 630 |  Loss: (0.0033) | Acc: (99.92%) (40351/40384) | Learning rate: (1e-06)
2022-06-06 23:23:29,014 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 640 |  Loss: (0.0034) | Acc: (99.92%) (40990/41024) | Learning rate: (1e-06)
2022-06-06 23:23:30,809 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 650 |  Loss: (0.0034) | Acc: (99.92%) (41629/41664) | Learning rate: (1e-06)
2022-06-06 23:23:32,606 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 660 |  Loss: (0.0034) | Acc: (99.92%) (42269/42304) | Learning rate: (1e-06)
2022-06-06 23:23:34,401 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 670 |  Loss: (0.0034) | Acc: (99.92%) (42908/42944) | Learning rate: (1e-06)
2022-06-06 23:23:36,196 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 680 |  Loss: (0.0035) | Acc: (99.91%) (43545/43584) | Learning rate: (1e-06)
2022-06-06 23:23:37,992 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 690 |  Loss: (0.0034) | Acc: (99.91%) (44185/44224) | Learning rate: (1e-06)
2022-06-06 23:23:39,788 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 700 |  Loss: (0.0034) | Acc: (99.91%) (44825/44864) | Learning rate: (1e-06)
2022-06-06 23:23:41,584 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 710 |  Loss: (0.0034) | Acc: (99.91%) (45464/45504) | Learning rate: (1e-06)
2022-06-06 23:23:43,380 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 720 |  Loss: (0.0034) | Acc: (99.91%) (46104/46144) | Learning rate: (1e-06)
2022-06-06 23:23:45,174 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 730 |  Loss: (0.0034) | Acc: (99.91%) (46744/46784) | Learning rate: (1e-06)
2022-06-06 23:23:46,969 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 740 |  Loss: (0.0034) | Acc: (99.91%) (47383/47424) | Learning rate: (1e-06)
2022-06-06 23:23:48,765 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 750 |  Loss: (0.0035) | Acc: (99.91%) (48021/48064) | Learning rate: (1e-06)
2022-06-06 23:23:50,562 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 760 |  Loss: (0.0035) | Acc: (99.91%) (48660/48704) | Learning rate: (1e-06)
2022-06-06 23:23:52,349 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 770 |  Loss: (0.0035) | Acc: (99.91%) (49300/49344) | Learning rate: (1e-06)
2022-06-06 23:23:54,138 - CIFAR10 Classifier - INFO - Epoch: 31 | Batch_idx: 780 |  Loss: (0.0035) | Acc: (99.91%) (49940/49984) | Learning rate: (1e-06)
2022-06-06 23:24:04,009 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0810) | Acc: (98.00%) (9800/10000)
2022-06-06 23:24:04,009 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:24:04,916 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:24:06,705 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 10 |  Loss: (0.0041) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 23:24:08,496 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 20 |  Loss: (0.0033) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 23:24:10,289 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-06)
2022-06-06 23:24:12,084 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 40 |  Loss: (0.0039) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 23:24:13,879 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 50 |  Loss: (0.0048) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-06)
2022-06-06 23:24:15,676 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 60 |  Loss: (0.0050) | Acc: (99.80%) (3896/3904) | Learning rate: (1e-06)
2022-06-06 23:24:17,472 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 70 |  Loss: (0.0049) | Acc: (99.80%) (4535/4544) | Learning rate: (1e-06)
2022-06-06 23:24:19,268 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 80 |  Loss: (0.0049) | Acc: (99.79%) (5173/5184) | Learning rate: (1e-06)
2022-06-06 23:24:21,063 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.78%) (5811/5824) | Learning rate: (1e-06)
2022-06-06 23:24:22,858 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 100 |  Loss: (0.0048) | Acc: (99.78%) (6450/6464) | Learning rate: (1e-06)
2022-06-06 23:24:24,655 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 110 |  Loss: (0.0051) | Acc: (99.79%) (7089/7104) | Learning rate: (1e-06)
2022-06-06 23:24:26,452 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 120 |  Loss: (0.0048) | Acc: (99.81%) (7729/7744) | Learning rate: (1e-06)
2022-06-06 23:24:28,247 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 130 |  Loss: (0.0045) | Acc: (99.82%) (8369/8384) | Learning rate: (1e-06)
2022-06-06 23:24:30,039 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 140 |  Loss: (0.0043) | Acc: (99.83%) (9009/9024) | Learning rate: (1e-06)
2022-06-06 23:24:31,833 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 150 |  Loss: (0.0045) | Acc: (99.83%) (9648/9664) | Learning rate: (1e-06)
2022-06-06 23:24:33,629 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 160 |  Loss: (0.0043) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 23:24:35,424 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 170 |  Loss: (0.0041) | Acc: (99.85%) (10928/10944) | Learning rate: (1e-06)
2022-06-06 23:24:37,218 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 180 |  Loss: (0.0041) | Acc: (99.85%) (11567/11584) | Learning rate: (1e-06)
2022-06-06 23:24:39,013 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 190 |  Loss: (0.0040) | Acc: (99.85%) (12206/12224) | Learning rate: (1e-06)
2022-06-06 23:24:40,810 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 200 |  Loss: (0.0038) | Acc: (99.86%) (12846/12864) | Learning rate: (1e-06)
2022-06-06 23:24:42,605 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 210 |  Loss: (0.0045) | Acc: (99.84%) (13483/13504) | Learning rate: (1e-06)
2022-06-06 23:24:44,402 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 220 |  Loss: (0.0045) | Acc: (99.85%) (14123/14144) | Learning rate: (1e-06)
2022-06-06 23:24:46,197 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 230 |  Loss: (0.0044) | Acc: (99.85%) (14762/14784) | Learning rate: (1e-06)
2022-06-06 23:24:47,991 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 240 |  Loss: (0.0042) | Acc: (99.86%) (15402/15424) | Learning rate: (1e-06)
2022-06-06 23:24:49,787 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 250 |  Loss: (0.0045) | Acc: (99.85%) (16040/16064) | Learning rate: (1e-06)
2022-06-06 23:24:51,585 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 260 |  Loss: (0.0044) | Acc: (99.86%) (16680/16704) | Learning rate: (1e-06)
2022-06-06 23:24:53,381 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 270 |  Loss: (0.0042) | Acc: (99.86%) (17320/17344) | Learning rate: (1e-06)
2022-06-06 23:24:55,178 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 280 |  Loss: (0.0042) | Acc: (99.87%) (17960/17984) | Learning rate: (1e-06)
2022-06-06 23:24:56,972 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 290 |  Loss: (0.0041) | Acc: (99.87%) (18600/18624) | Learning rate: (1e-06)
2022-06-06 23:24:58,768 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 300 |  Loss: (0.0040) | Acc: (99.88%) (19240/19264) | Learning rate: (1e-06)
2022-06-06 23:25:00,566 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 310 |  Loss: (0.0040) | Acc: (99.87%) (19878/19904) | Learning rate: (1e-06)
2022-06-06 23:25:02,363 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 320 |  Loss: (0.0040) | Acc: (99.87%) (20517/20544) | Learning rate: (1e-06)
2022-06-06 23:25:04,159 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 330 |  Loss: (0.0039) | Acc: (99.87%) (21157/21184) | Learning rate: (1e-06)
2022-06-06 23:25:05,956 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 340 |  Loss: (0.0040) | Acc: (99.87%) (21796/21824) | Learning rate: (1e-06)
2022-06-06 23:25:07,752 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 350 |  Loss: (0.0040) | Acc: (99.87%) (22435/22464) | Learning rate: (1e-06)
2022-06-06 23:25:09,547 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 360 |  Loss: (0.0040) | Acc: (99.87%) (23074/23104) | Learning rate: (1e-06)
2022-06-06 23:25:11,343 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 370 |  Loss: (0.0039) | Acc: (99.87%) (23714/23744) | Learning rate: (1e-06)
2022-06-06 23:25:13,140 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 380 |  Loss: (0.0038) | Acc: (99.88%) (24354/24384) | Learning rate: (1e-06)
2022-06-06 23:25:14,936 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 390 |  Loss: (0.0042) | Acc: (99.88%) (24993/25024) | Learning rate: (1e-06)
2022-06-06 23:25:16,733 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 400 |  Loss: (0.0041) | Acc: (99.88%) (25633/25664) | Learning rate: (1e-06)
2022-06-06 23:25:18,529 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 410 |  Loss: (0.0042) | Acc: (99.88%) (26272/26304) | Learning rate: (1e-06)
2022-06-06 23:25:20,324 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 420 |  Loss: (0.0042) | Acc: (99.87%) (26910/26944) | Learning rate: (1e-06)
2022-06-06 23:25:22,120 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 430 |  Loss: (0.0041) | Acc: (99.88%) (27550/27584) | Learning rate: (1e-06)
2022-06-06 23:25:23,917 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 440 |  Loss: (0.0041) | Acc: (99.88%) (28189/28224) | Learning rate: (1e-06)
2022-06-06 23:25:25,713 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 450 |  Loss: (0.0041) | Acc: (99.88%) (28828/28864) | Learning rate: (1e-06)
2022-06-06 23:25:27,510 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 460 |  Loss: (0.0041) | Acc: (99.88%) (29468/29504) | Learning rate: (1e-06)
2022-06-06 23:25:29,309 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 470 |  Loss: (0.0040) | Acc: (99.88%) (30108/30144) | Learning rate: (1e-06)
2022-06-06 23:25:31,107 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 480 |  Loss: (0.0041) | Acc: (99.88%) (30746/30784) | Learning rate: (1e-06)
2022-06-06 23:25:32,904 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 490 |  Loss: (0.0042) | Acc: (99.88%) (31385/31424) | Learning rate: (1e-06)
2022-06-06 23:25:34,698 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 500 |  Loss: (0.0042) | Acc: (99.88%) (32024/32064) | Learning rate: (1e-06)
2022-06-06 23:25:36,494 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 510 |  Loss: (0.0041) | Acc: (99.88%) (32664/32704) | Learning rate: (1e-06)
2022-06-06 23:25:38,290 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 520 |  Loss: (0.0041) | Acc: (99.88%) (33304/33344) | Learning rate: (1e-06)
2022-06-06 23:25:40,086 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 530 |  Loss: (0.0041) | Acc: (99.88%) (33943/33984) | Learning rate: (1e-06)
2022-06-06 23:25:41,884 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 540 |  Loss: (0.0041) | Acc: (99.88%) (34583/34624) | Learning rate: (1e-06)
2022-06-06 23:25:43,679 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 550 |  Loss: (0.0040) | Acc: (99.88%) (35223/35264) | Learning rate: (1e-06)
2022-06-06 23:25:45,476 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 560 |  Loss: (0.0040) | Acc: (99.88%) (35862/35904) | Learning rate: (1e-06)
2022-06-06 23:25:47,271 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 570 |  Loss: (0.0040) | Acc: (99.88%) (36501/36544) | Learning rate: (1e-06)
2022-06-06 23:25:49,068 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 580 |  Loss: (0.0040) | Acc: (99.88%) (37140/37184) | Learning rate: (1e-06)
2022-06-06 23:25:50,866 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 590 |  Loss: (0.0039) | Acc: (99.88%) (37780/37824) | Learning rate: (1e-06)
2022-06-06 23:25:52,667 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 600 |  Loss: (0.0039) | Acc: (99.88%) (38418/38464) | Learning rate: (1e-06)
2022-06-06 23:25:54,467 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 610 |  Loss: (0.0039) | Acc: (99.88%) (39058/39104) | Learning rate: (1e-06)
2022-06-06 23:25:56,266 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 620 |  Loss: (0.0039) | Acc: (99.88%) (39698/39744) | Learning rate: (1e-06)
2022-06-06 23:25:58,063 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 630 |  Loss: (0.0039) | Acc: (99.88%) (40337/40384) | Learning rate: (1e-06)
2022-06-06 23:25:59,862 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 640 |  Loss: (0.0039) | Acc: (99.88%) (40975/41024) | Learning rate: (1e-06)
2022-06-06 23:26:01,661 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 650 |  Loss: (0.0039) | Acc: (99.88%) (41614/41664) | Learning rate: (1e-06)
2022-06-06 23:26:03,460 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 660 |  Loss: (0.0039) | Acc: (99.88%) (42253/42304) | Learning rate: (1e-06)
2022-06-06 23:26:05,258 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 670 |  Loss: (0.0039) | Acc: (99.88%) (42892/42944) | Learning rate: (1e-06)
2022-06-06 23:26:07,058 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 680 |  Loss: (0.0040) | Acc: (99.88%) (43530/43584) | Learning rate: (1e-06)
2022-06-06 23:26:08,854 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 690 |  Loss: (0.0039) | Acc: (99.88%) (44169/44224) | Learning rate: (1e-06)
2022-06-06 23:26:10,654 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 700 |  Loss: (0.0039) | Acc: (99.88%) (44809/44864) | Learning rate: (1e-06)
2022-06-06 23:26:12,453 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 710 |  Loss: (0.0039) | Acc: (99.88%) (45448/45504) | Learning rate: (1e-06)
2022-06-06 23:26:14,252 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 720 |  Loss: (0.0038) | Acc: (99.88%) (46087/46144) | Learning rate: (1e-06)
2022-06-06 23:26:16,052 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 730 |  Loss: (0.0038) | Acc: (99.88%) (46727/46784) | Learning rate: (1e-06)
2022-06-06 23:26:17,854 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 740 |  Loss: (0.0039) | Acc: (99.88%) (47366/47424) | Learning rate: (1e-06)
2022-06-06 23:26:19,650 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 750 |  Loss: (0.0039) | Acc: (99.88%) (48004/48064) | Learning rate: (1e-06)
2022-06-06 23:26:21,451 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 760 |  Loss: (0.0039) | Acc: (99.87%) (48643/48704) | Learning rate: (1e-06)
2022-06-06 23:26:23,240 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 770 |  Loss: (0.0038) | Acc: (99.88%) (49283/49344) | Learning rate: (1e-06)
2022-06-06 23:26:25,029 - CIFAR10 Classifier - INFO - Epoch: 32 | Batch_idx: 780 |  Loss: (0.0038) | Acc: (99.88%) (49923/49984) | Learning rate: (1e-06)
2022-06-06 23:26:34,942 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0828) | Acc: (98.08%) (9808/10000)
2022-06-06 23:26:34,943 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:26:35,763 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 0 |  Loss: (0.0002) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:26:37,584 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 10 |  Loss: (0.0011) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:26:39,377 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 20 |  Loss: (0.0008) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 23:26:41,173 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 30 |  Loss: (0.0017) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 23:26:42,970 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 40 |  Loss: (0.0015) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-06)
2022-06-06 23:26:44,768 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 50 |  Loss: (0.0019) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-06)
2022-06-06 23:26:46,564 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 60 |  Loss: (0.0020) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 23:26:48,359 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 70 |  Loss: (0.0023) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 23:26:50,154 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 80 |  Loss: (0.0021) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-06)
2022-06-06 23:26:51,950 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 90 |  Loss: (0.0020) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 23:26:53,745 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 100 |  Loss: (0.0021) | Acc: (99.92%) (6459/6464) | Learning rate: (1e-06)
2022-06-06 23:26:55,544 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 110 |  Loss: (0.0023) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-06)
2022-06-06 23:26:57,340 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 120 |  Loss: (0.0028) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-06)
2022-06-06 23:26:59,139 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 130 |  Loss: (0.0028) | Acc: (99.92%) (8377/8384) | Learning rate: (1e-06)
2022-06-06 23:27:00,937 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 140 |  Loss: (0.0034) | Acc: (99.89%) (9014/9024) | Learning rate: (1e-06)
2022-06-06 23:27:02,734 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 150 |  Loss: (0.0033) | Acc: (99.90%) (9654/9664) | Learning rate: (1e-06)
2022-06-06 23:27:04,530 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 160 |  Loss: (0.0032) | Acc: (99.90%) (10294/10304) | Learning rate: (1e-06)
2022-06-06 23:27:06,326 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 170 |  Loss: (0.0032) | Acc: (99.89%) (10932/10944) | Learning rate: (1e-06)
2022-06-06 23:27:08,123 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 180 |  Loss: (0.0032) | Acc: (99.89%) (11571/11584) | Learning rate: (1e-06)
2022-06-06 23:27:09,920 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 190 |  Loss: (0.0033) | Acc: (99.89%) (12210/12224) | Learning rate: (1e-06)
2022-06-06 23:27:11,717 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 200 |  Loss: (0.0035) | Acc: (99.88%) (12848/12864) | Learning rate: (1e-06)
2022-06-06 23:27:13,513 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 210 |  Loss: (0.0034) | Acc: (99.88%) (13488/13504) | Learning rate: (1e-06)
2022-06-06 23:27:15,308 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 220 |  Loss: (0.0033) | Acc: (99.89%) (14128/14144) | Learning rate: (1e-06)
2022-06-06 23:27:17,102 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 230 |  Loss: (0.0033) | Acc: (99.89%) (14768/14784) | Learning rate: (1e-06)
2022-06-06 23:27:18,897 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 240 |  Loss: (0.0032) | Acc: (99.90%) (15408/15424) | Learning rate: (1e-06)
2022-06-06 23:27:20,693 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 250 |  Loss: (0.0032) | Acc: (99.90%) (16048/16064) | Learning rate: (1e-06)
2022-06-06 23:27:22,489 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 260 |  Loss: (0.0031) | Acc: (99.90%) (16688/16704) | Learning rate: (1e-06)
2022-06-06 23:27:24,284 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 270 |  Loss: (0.0030) | Acc: (99.91%) (17328/17344) | Learning rate: (1e-06)
2022-06-06 23:27:26,079 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 280 |  Loss: (0.0030) | Acc: (99.91%) (17967/17984) | Learning rate: (1e-06)
2022-06-06 23:27:27,877 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 290 |  Loss: (0.0030) | Acc: (99.91%) (18607/18624) | Learning rate: (1e-06)
2022-06-06 23:27:29,673 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 300 |  Loss: (0.0030) | Acc: (99.91%) (19247/19264) | Learning rate: (1e-06)
2022-06-06 23:27:31,469 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 310 |  Loss: (0.0030) | Acc: (99.91%) (19886/19904) | Learning rate: (1e-06)
2022-06-06 23:27:33,264 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 320 |  Loss: (0.0030) | Acc: (99.91%) (20525/20544) | Learning rate: (1e-06)
2022-06-06 23:27:35,058 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 330 |  Loss: (0.0031) | Acc: (99.91%) (21165/21184) | Learning rate: (1e-06)
2022-06-06 23:27:36,855 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 340 |  Loss: (0.0030) | Acc: (99.91%) (21804/21824) | Learning rate: (1e-06)
2022-06-06 23:27:38,651 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 350 |  Loss: (0.0030) | Acc: (99.91%) (22444/22464) | Learning rate: (1e-06)
2022-06-06 23:27:40,449 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 360 |  Loss: (0.0031) | Acc: (99.91%) (23083/23104) | Learning rate: (1e-06)
2022-06-06 23:27:42,245 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 370 |  Loss: (0.0034) | Acc: (99.91%) (23722/23744) | Learning rate: (1e-06)
2022-06-06 23:27:44,042 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 380 |  Loss: (0.0033) | Acc: (99.91%) (24361/24384) | Learning rate: (1e-06)
2022-06-06 23:27:45,837 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 390 |  Loss: (0.0033) | Acc: (99.91%) (25001/25024) | Learning rate: (1e-06)
2022-06-06 23:27:47,633 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 400 |  Loss: (0.0033) | Acc: (99.91%) (25641/25664) | Learning rate: (1e-06)
2022-06-06 23:27:49,429 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 410 |  Loss: (0.0034) | Acc: (99.90%) (26279/26304) | Learning rate: (1e-06)
2022-06-06 23:27:51,226 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 420 |  Loss: (0.0034) | Acc: (99.90%) (26918/26944) | Learning rate: (1e-06)
2022-06-06 23:27:53,022 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 430 |  Loss: (0.0034) | Acc: (99.91%) (27558/27584) | Learning rate: (1e-06)
2022-06-06 23:27:54,819 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 440 |  Loss: (0.0033) | Acc: (99.91%) (28198/28224) | Learning rate: (1e-06)
2022-06-06 23:27:56,614 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 450 |  Loss: (0.0034) | Acc: (99.90%) (28836/28864) | Learning rate: (1e-06)
2022-06-06 23:27:58,411 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 460 |  Loss: (0.0033) | Acc: (99.91%) (29476/29504) | Learning rate: (1e-06)
2022-06-06 23:28:00,207 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 470 |  Loss: (0.0034) | Acc: (99.90%) (30114/30144) | Learning rate: (1e-06)
2022-06-06 23:28:02,005 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 480 |  Loss: (0.0034) | Acc: (99.90%) (30753/30784) | Learning rate: (1e-06)
2022-06-06 23:28:03,802 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 490 |  Loss: (0.0035) | Acc: (99.90%) (31392/31424) | Learning rate: (1e-06)
2022-06-06 23:28:05,597 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 500 |  Loss: (0.0035) | Acc: (99.90%) (32032/32064) | Learning rate: (1e-06)
2022-06-06 23:28:07,396 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 510 |  Loss: (0.0035) | Acc: (99.90%) (32671/32704) | Learning rate: (1e-06)
2022-06-06 23:28:09,192 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 520 |  Loss: (0.0035) | Acc: (99.90%) (33310/33344) | Learning rate: (1e-06)
2022-06-06 23:28:10,987 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 530 |  Loss: (0.0035) | Acc: (99.90%) (33950/33984) | Learning rate: (1e-06)
2022-06-06 23:28:12,784 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 540 |  Loss: (0.0035) | Acc: (99.90%) (34590/34624) | Learning rate: (1e-06)
2022-06-06 23:28:14,580 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 550 |  Loss: (0.0035) | Acc: (99.90%) (35229/35264) | Learning rate: (1e-06)
2022-06-06 23:28:16,379 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 560 |  Loss: (0.0035) | Acc: (99.90%) (35868/35904) | Learning rate: (1e-06)
2022-06-06 23:28:18,177 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 570 |  Loss: (0.0034) | Acc: (99.90%) (36508/36544) | Learning rate: (1e-06)
2022-06-06 23:28:19,973 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 580 |  Loss: (0.0034) | Acc: (99.90%) (37147/37184) | Learning rate: (1e-06)
2022-06-06 23:28:21,770 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 590 |  Loss: (0.0035) | Acc: (99.90%) (37785/37824) | Learning rate: (1e-06)
2022-06-06 23:28:23,567 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 600 |  Loss: (0.0034) | Acc: (99.90%) (38425/38464) | Learning rate: (1e-06)
2022-06-06 23:28:25,363 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 610 |  Loss: (0.0034) | Acc: (99.90%) (39064/39104) | Learning rate: (1e-06)
2022-06-06 23:28:27,159 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 620 |  Loss: (0.0035) | Acc: (99.89%) (39702/39744) | Learning rate: (1e-06)
2022-06-06 23:28:28,956 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 630 |  Loss: (0.0035) | Acc: (99.89%) (40340/40384) | Learning rate: (1e-06)
2022-06-06 23:28:30,755 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 640 |  Loss: (0.0035) | Acc: (99.89%) (40978/41024) | Learning rate: (1e-06)
2022-06-06 23:28:32,552 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 650 |  Loss: (0.0035) | Acc: (99.89%) (41617/41664) | Learning rate: (1e-06)
2022-06-06 23:28:34,349 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 660 |  Loss: (0.0035) | Acc: (99.89%) (42257/42304) | Learning rate: (1e-06)
2022-06-06 23:28:36,145 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 670 |  Loss: (0.0035) | Acc: (99.89%) (42895/42944) | Learning rate: (1e-06)
2022-06-06 23:28:37,941 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 680 |  Loss: (0.0035) | Acc: (99.89%) (43534/43584) | Learning rate: (1e-06)
2022-06-06 23:28:39,737 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 690 |  Loss: (0.0035) | Acc: (99.89%) (44174/44224) | Learning rate: (1e-06)
2022-06-06 23:28:41,531 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 700 |  Loss: (0.0035) | Acc: (99.88%) (44811/44864) | Learning rate: (1e-06)
2022-06-06 23:28:43,330 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 710 |  Loss: (0.0035) | Acc: (99.88%) (45450/45504) | Learning rate: (1e-06)
2022-06-06 23:28:45,127 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 720 |  Loss: (0.0036) | Acc: (99.88%) (46089/46144) | Learning rate: (1e-06)
2022-06-06 23:28:46,924 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 730 |  Loss: (0.0036) | Acc: (99.88%) (46728/46784) | Learning rate: (1e-06)
2022-06-06 23:28:48,721 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 740 |  Loss: (0.0035) | Acc: (99.88%) (47368/47424) | Learning rate: (1e-06)
2022-06-06 23:28:50,519 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 750 |  Loss: (0.0035) | Acc: (99.88%) (48008/48064) | Learning rate: (1e-06)
2022-06-06 23:28:52,317 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 760 |  Loss: (0.0035) | Acc: (99.89%) (48648/48704) | Learning rate: (1e-06)
2022-06-06 23:28:54,107 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 770 |  Loss: (0.0035) | Acc: (99.89%) (49288/49344) | Learning rate: (1e-06)
2022-06-06 23:28:55,897 - CIFAR10 Classifier - INFO - Epoch: 33 | Batch_idx: 780 |  Loss: (0.0034) | Acc: (99.89%) (49928/49984) | Learning rate: (1e-06)
2022-06-06 23:29:05,836 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0798) | Acc: (98.14%) (9814/10000)
2022-06-06 23:29:05,837 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:29:06,747 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 0 |  Loss: (0.0027) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:29:08,539 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 10 |  Loss: (0.0062) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 23:29:10,329 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 20 |  Loss: (0.0046) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 23:29:12,125 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 30 |  Loss: (0.0037) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 23:29:13,919 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-06)
2022-06-06 23:29:15,718 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 50 |  Loss: (0.0042) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-06)
2022-06-06 23:29:17,516 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 60 |  Loss: (0.0037) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 23:29:19,314 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 70 |  Loss: (0.0033) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 23:29:21,109 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 80 |  Loss: (0.0033) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-06)
2022-06-06 23:29:22,903 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 90 |  Loss: (0.0036) | Acc: (99.86%) (5816/5824) | Learning rate: (1e-06)
2022-06-06 23:29:24,697 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 100 |  Loss: (0.0034) | Acc: (99.88%) (6456/6464) | Learning rate: (1e-06)
2022-06-06 23:29:26,493 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 110 |  Loss: (0.0033) | Acc: (99.89%) (7096/7104) | Learning rate: (1e-06)
2022-06-06 23:29:28,289 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 120 |  Loss: (0.0032) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 23:29:30,085 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 130 |  Loss: (0.0032) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-06)
2022-06-06 23:29:31,878 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 140 |  Loss: (0.0033) | Acc: (99.89%) (9014/9024) | Learning rate: (1e-06)
2022-06-06 23:29:33,673 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 150 |  Loss: (0.0031) | Acc: (99.90%) (9654/9664) | Learning rate: (1e-06)
2022-06-06 23:29:35,468 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 160 |  Loss: (0.0032) | Acc: (99.89%) (10293/10304) | Learning rate: (1e-06)
2022-06-06 23:29:37,262 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 170 |  Loss: (0.0033) | Acc: (99.90%) (10933/10944) | Learning rate: (1e-06)
2022-06-06 23:29:39,056 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 180 |  Loss: (0.0033) | Acc: (99.90%) (11572/11584) | Learning rate: (1e-06)
2022-06-06 23:29:40,851 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 190 |  Loss: (0.0033) | Acc: (99.89%) (12211/12224) | Learning rate: (1e-06)
2022-06-06 23:29:42,647 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 200 |  Loss: (0.0033) | Acc: (99.90%) (12851/12864) | Learning rate: (1e-06)
2022-06-06 23:29:44,443 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 210 |  Loss: (0.0033) | Acc: (99.90%) (13491/13504) | Learning rate: (1e-06)
2022-06-06 23:29:46,238 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 220 |  Loss: (0.0035) | Acc: (99.89%) (14129/14144) | Learning rate: (1e-06)
2022-06-06 23:29:48,033 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 230 |  Loss: (0.0034) | Acc: (99.90%) (14769/14784) | Learning rate: (1e-06)
2022-06-06 23:29:49,828 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 240 |  Loss: (0.0035) | Acc: (99.88%) (15406/15424) | Learning rate: (1e-06)
2022-06-06 23:29:51,622 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 250 |  Loss: (0.0035) | Acc: (99.89%) (16046/16064) | Learning rate: (1e-06)
2022-06-06 23:29:53,419 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 260 |  Loss: (0.0038) | Acc: (99.88%) (16684/16704) | Learning rate: (1e-06)
2022-06-06 23:29:55,213 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 270 |  Loss: (0.0037) | Acc: (99.88%) (17324/17344) | Learning rate: (1e-06)
2022-06-06 23:29:57,008 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 280 |  Loss: (0.0036) | Acc: (99.89%) (17964/17984) | Learning rate: (1e-06)
2022-06-06 23:29:58,805 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 290 |  Loss: (0.0040) | Acc: (99.89%) (18603/18624) | Learning rate: (1e-06)
2022-06-06 23:30:00,600 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 300 |  Loss: (0.0040) | Acc: (99.89%) (19243/19264) | Learning rate: (1e-06)
2022-06-06 23:30:02,397 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 310 |  Loss: (0.0042) | Acc: (99.88%) (19880/19904) | Learning rate: (1e-06)
2022-06-06 23:30:04,192 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 320 |  Loss: (0.0043) | Acc: (99.88%) (20519/20544) | Learning rate: (1e-06)
2022-06-06 23:30:05,987 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 330 |  Loss: (0.0042) | Acc: (99.88%) (21159/21184) | Learning rate: (1e-06)
2022-06-06 23:30:07,782 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.87%) (21796/21824) | Learning rate: (1e-06)
2022-06-06 23:30:09,579 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 350 |  Loss: (0.0044) | Acc: (99.87%) (22435/22464) | Learning rate: (1e-06)
2022-06-06 23:30:11,375 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 360 |  Loss: (0.0043) | Acc: (99.87%) (23075/23104) | Learning rate: (1e-06)
2022-06-06 23:30:13,172 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 370 |  Loss: (0.0042) | Acc: (99.88%) (23715/23744) | Learning rate: (1e-06)
2022-06-06 23:30:14,967 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 380 |  Loss: (0.0042) | Acc: (99.88%) (24355/24384) | Learning rate: (1e-06)
2022-06-06 23:30:16,761 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 390 |  Loss: (0.0042) | Acc: (99.88%) (24994/25024) | Learning rate: (1e-06)
2022-06-06 23:30:18,558 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 400 |  Loss: (0.0042) | Acc: (99.88%) (25634/25664) | Learning rate: (1e-06)
2022-06-06 23:30:20,354 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 410 |  Loss: (0.0042) | Acc: (99.88%) (26273/26304) | Learning rate: (1e-06)
2022-06-06 23:30:22,150 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 420 |  Loss: (0.0042) | Acc: (99.88%) (26912/26944) | Learning rate: (1e-06)
2022-06-06 23:30:23,945 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 430 |  Loss: (0.0041) | Acc: (99.88%) (27551/27584) | Learning rate: (1e-06)
2022-06-06 23:30:25,740 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 440 |  Loss: (0.0041) | Acc: (99.88%) (28190/28224) | Learning rate: (1e-06)
2022-06-06 23:30:27,536 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 450 |  Loss: (0.0041) | Acc: (99.88%) (28830/28864) | Learning rate: (1e-06)
2022-06-06 23:30:29,333 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 460 |  Loss: (0.0041) | Acc: (99.88%) (29468/29504) | Learning rate: (1e-06)
2022-06-06 23:30:31,129 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 470 |  Loss: (0.0040) | Acc: (99.88%) (30108/30144) | Learning rate: (1e-06)
2022-06-06 23:30:32,926 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 480 |  Loss: (0.0041) | Acc: (99.88%) (30746/30784) | Learning rate: (1e-06)
2022-06-06 23:30:34,723 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 490 |  Loss: (0.0041) | Acc: (99.88%) (31385/31424) | Learning rate: (1e-06)
2022-06-06 23:30:36,517 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 500 |  Loss: (0.0041) | Acc: (99.88%) (32025/32064) | Learning rate: (1e-06)
2022-06-06 23:30:38,314 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 510 |  Loss: (0.0040) | Acc: (99.88%) (32665/32704) | Learning rate: (1e-06)
2022-06-06 23:30:40,111 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 520 |  Loss: (0.0040) | Acc: (99.88%) (33304/33344) | Learning rate: (1e-06)
2022-06-06 23:30:41,908 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 530 |  Loss: (0.0040) | Acc: (99.88%) (33943/33984) | Learning rate: (1e-06)
2022-06-06 23:30:43,704 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 540 |  Loss: (0.0040) | Acc: (99.88%) (34583/34624) | Learning rate: (1e-06)
2022-06-06 23:30:45,500 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 550 |  Loss: (0.0040) | Acc: (99.88%) (35222/35264) | Learning rate: (1e-06)
2022-06-06 23:30:47,295 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 560 |  Loss: (0.0040) | Acc: (99.87%) (35859/35904) | Learning rate: (1e-06)
2022-06-06 23:30:49,091 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 570 |  Loss: (0.0040) | Acc: (99.88%) (36499/36544) | Learning rate: (1e-06)
2022-06-06 23:30:50,887 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 580 |  Loss: (0.0039) | Acc: (99.88%) (37139/37184) | Learning rate: (1e-06)
2022-06-06 23:30:52,685 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 590 |  Loss: (0.0039) | Acc: (99.88%) (37778/37824) | Learning rate: (1e-06)
2022-06-06 23:30:54,483 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 600 |  Loss: (0.0040) | Acc: (99.87%) (38415/38464) | Learning rate: (1e-06)
2022-06-06 23:30:56,280 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 610 |  Loss: (0.0040) | Acc: (99.87%) (39054/39104) | Learning rate: (1e-06)
2022-06-06 23:30:58,076 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 620 |  Loss: (0.0040) | Acc: (99.87%) (39693/39744) | Learning rate: (1e-06)
2022-06-06 23:30:59,872 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 630 |  Loss: (0.0040) | Acc: (99.87%) (40332/40384) | Learning rate: (1e-06)
2022-06-06 23:31:01,667 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 640 |  Loss: (0.0039) | Acc: (99.87%) (40972/41024) | Learning rate: (1e-06)
2022-06-06 23:31:03,465 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 650 |  Loss: (0.0039) | Acc: (99.88%) (41612/41664) | Learning rate: (1e-06)
2022-06-06 23:31:05,263 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 660 |  Loss: (0.0041) | Acc: (99.87%) (42250/42304) | Learning rate: (1e-06)
2022-06-06 23:31:07,060 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 670 |  Loss: (0.0041) | Acc: (99.87%) (42890/42944) | Learning rate: (1e-06)
2022-06-06 23:31:08,857 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 680 |  Loss: (0.0041) | Acc: (99.87%) (43529/43584) | Learning rate: (1e-06)
2022-06-06 23:31:10,655 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 690 |  Loss: (0.0041) | Acc: (99.88%) (44169/44224) | Learning rate: (1e-06)
2022-06-06 23:31:12,450 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 700 |  Loss: (0.0041) | Acc: (99.88%) (44809/44864) | Learning rate: (1e-06)
2022-06-06 23:31:14,246 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 710 |  Loss: (0.0041) | Acc: (99.88%) (45448/45504) | Learning rate: (1e-06)
2022-06-06 23:31:16,042 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 720 |  Loss: (0.0041) | Acc: (99.88%) (46087/46144) | Learning rate: (1e-06)
2022-06-06 23:31:17,840 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 730 |  Loss: (0.0040) | Acc: (99.88%) (46727/46784) | Learning rate: (1e-06)
2022-06-06 23:31:19,638 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 740 |  Loss: (0.0040) | Acc: (99.88%) (47367/47424) | Learning rate: (1e-06)
2022-06-06 23:31:21,434 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 750 |  Loss: (0.0042) | Acc: (99.88%) (48004/48064) | Learning rate: (1e-06)
2022-06-06 23:31:23,231 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 760 |  Loss: (0.0043) | Acc: (99.87%) (48643/48704) | Learning rate: (1e-06)
2022-06-06 23:31:25,020 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 770 |  Loss: (0.0042) | Acc: (99.88%) (49283/49344) | Learning rate: (1e-06)
2022-06-06 23:31:26,810 - CIFAR10 Classifier - INFO - Epoch: 34 | Batch_idx: 780 |  Loss: (0.0042) | Acc: (99.88%) (49922/49984) | Learning rate: (1e-06)
2022-06-06 23:31:36,717 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0815) | Acc: (98.06%) (9806/10000)
2022-06-06 23:31:36,719 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:31:37,597 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 0 |  Loss: (0.0012) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:31:39,389 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 10 |  Loss: (0.0019) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 23:31:41,182 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 20 |  Loss: (0.0032) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 23:31:42,974 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 30 |  Loss: (0.0025) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 23:31:44,769 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 40 |  Loss: (0.0028) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 23:31:46,564 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 50 |  Loss: (0.0024) | Acc: (99.88%) (3260/3264) | Learning rate: (1e-06)
2022-06-06 23:31:48,360 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 60 |  Loss: (0.0026) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 23:31:50,153 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 70 |  Loss: (0.0023) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 23:31:51,949 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 80 |  Loss: (0.0021) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-06)
2022-06-06 23:31:53,746 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 90 |  Loss: (0.0021) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 23:31:55,543 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 100 |  Loss: (0.0020) | Acc: (99.92%) (6459/6464) | Learning rate: (1e-06)
2022-06-06 23:31:57,339 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 110 |  Loss: (0.0019) | Acc: (99.93%) (7099/7104) | Learning rate: (1e-06)
2022-06-06 23:31:59,133 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 120 |  Loss: (0.0019) | Acc: (99.94%) (7739/7744) | Learning rate: (1e-06)
2022-06-06 23:32:00,928 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 130 |  Loss: (0.0020) | Acc: (99.94%) (8379/8384) | Learning rate: (1e-06)
2022-06-06 23:32:02,724 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 140 |  Loss: (0.0019) | Acc: (99.94%) (9019/9024) | Learning rate: (1e-06)
2022-06-06 23:32:04,519 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 150 |  Loss: (0.0021) | Acc: (99.94%) (9658/9664) | Learning rate: (1e-06)
2022-06-06 23:32:06,318 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 160 |  Loss: (0.0023) | Acc: (99.93%) (10297/10304) | Learning rate: (1e-06)
2022-06-06 23:32:08,114 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 170 |  Loss: (0.0023) | Acc: (99.93%) (10936/10944) | Learning rate: (1e-06)
2022-06-06 23:32:09,909 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 180 |  Loss: (0.0022) | Acc: (99.93%) (11576/11584) | Learning rate: (1e-06)
2022-06-06 23:32:11,704 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 190 |  Loss: (0.0023) | Acc: (99.93%) (12215/12224) | Learning rate: (1e-06)
2022-06-06 23:32:13,501 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 200 |  Loss: (0.0023) | Acc: (99.92%) (12854/12864) | Learning rate: (1e-06)
2022-06-06 23:32:15,297 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 210 |  Loss: (0.0024) | Acc: (99.92%) (13493/13504) | Learning rate: (1e-06)
2022-06-06 23:32:17,091 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 220 |  Loss: (0.0024) | Acc: (99.92%) (14133/14144) | Learning rate: (1e-06)
2022-06-06 23:32:18,887 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 230 |  Loss: (0.0024) | Acc: (99.92%) (14772/14784) | Learning rate: (1e-06)
2022-06-06 23:32:20,684 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 240 |  Loss: (0.0025) | Acc: (99.91%) (15410/15424) | Learning rate: (1e-06)
2022-06-06 23:32:22,479 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 250 |  Loss: (0.0025) | Acc: (99.91%) (16049/16064) | Learning rate: (1e-06)
2022-06-06 23:32:24,279 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 260 |  Loss: (0.0025) | Acc: (99.90%) (16688/16704) | Learning rate: (1e-06)
2022-06-06 23:32:26,075 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 270 |  Loss: (0.0026) | Acc: (99.90%) (17326/17344) | Learning rate: (1e-06)
2022-06-06 23:32:27,872 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 280 |  Loss: (0.0026) | Acc: (99.90%) (17966/17984) | Learning rate: (1e-06)
2022-06-06 23:32:29,669 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 290 |  Loss: (0.0025) | Acc: (99.90%) (18606/18624) | Learning rate: (1e-06)
2022-06-06 23:32:31,464 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 300 |  Loss: (0.0025) | Acc: (99.91%) (19246/19264) | Learning rate: (1e-06)
2022-06-06 23:32:33,261 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 310 |  Loss: (0.0025) | Acc: (99.91%) (19886/19904) | Learning rate: (1e-06)
2022-06-06 23:32:35,056 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 320 |  Loss: (0.0025) | Acc: (99.91%) (20526/20544) | Learning rate: (1e-06)
2022-06-06 23:32:36,852 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 330 |  Loss: (0.0026) | Acc: (99.91%) (21165/21184) | Learning rate: (1e-06)
2022-06-06 23:32:38,647 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 340 |  Loss: (0.0025) | Acc: (99.91%) (21805/21824) | Learning rate: (1e-06)
2022-06-06 23:32:40,442 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 350 |  Loss: (0.0025) | Acc: (99.91%) (22444/22464) | Learning rate: (1e-06)
2022-06-06 23:32:42,237 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 360 |  Loss: (0.0027) | Acc: (99.90%) (23082/23104) | Learning rate: (1e-06)
2022-06-06 23:32:44,030 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 370 |  Loss: (0.0027) | Acc: (99.91%) (23722/23744) | Learning rate: (1e-06)
2022-06-06 23:32:45,825 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 380 |  Loss: (0.0027) | Acc: (99.90%) (24360/24384) | Learning rate: (1e-06)
2022-06-06 23:32:47,621 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 390 |  Loss: (0.0027) | Acc: (99.90%) (25000/25024) | Learning rate: (1e-06)
2022-06-06 23:32:49,414 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 400 |  Loss: (0.0027) | Acc: (99.90%) (25639/25664) | Learning rate: (1e-06)
2022-06-06 23:32:51,209 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 410 |  Loss: (0.0027) | Acc: (99.90%) (26279/26304) | Learning rate: (1e-06)
2022-06-06 23:32:53,004 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 420 |  Loss: (0.0027) | Acc: (99.91%) (26919/26944) | Learning rate: (1e-06)
2022-06-06 23:32:54,800 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 430 |  Loss: (0.0027) | Acc: (99.91%) (27559/27584) | Learning rate: (1e-06)
2022-06-06 23:32:56,596 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 440 |  Loss: (0.0027) | Acc: (99.91%) (28199/28224) | Learning rate: (1e-06)
2022-06-06 23:32:58,388 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 450 |  Loss: (0.0026) | Acc: (99.91%) (28839/28864) | Learning rate: (1e-06)
2022-06-06 23:33:00,185 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 460 |  Loss: (0.0026) | Acc: (99.92%) (29479/29504) | Learning rate: (1e-06)
2022-06-06 23:33:01,980 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 470 |  Loss: (0.0026) | Acc: (99.92%) (30119/30144) | Learning rate: (1e-06)
2022-06-06 23:33:03,776 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 480 |  Loss: (0.0026) | Acc: (99.92%) (30758/30784) | Learning rate: (1e-06)
2022-06-06 23:33:05,569 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 490 |  Loss: (0.0026) | Acc: (99.92%) (31398/31424) | Learning rate: (1e-06)
2022-06-06 23:33:07,363 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 500 |  Loss: (0.0026) | Acc: (99.92%) (32038/32064) | Learning rate: (1e-06)
2022-06-06 23:33:09,160 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 510 |  Loss: (0.0027) | Acc: (99.91%) (32676/32704) | Learning rate: (1e-06)
2022-06-06 23:33:10,957 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 520 |  Loss: (0.0026) | Acc: (99.92%) (33316/33344) | Learning rate: (1e-06)
2022-06-06 23:33:12,753 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 530 |  Loss: (0.0027) | Acc: (99.91%) (33954/33984) | Learning rate: (1e-06)
2022-06-06 23:33:14,549 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 540 |  Loss: (0.0027) | Acc: (99.91%) (34593/34624) | Learning rate: (1e-06)
2022-06-06 23:33:16,343 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 550 |  Loss: (0.0028) | Acc: (99.91%) (35232/35264) | Learning rate: (1e-06)
2022-06-06 23:33:18,139 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 560 |  Loss: (0.0029) | Acc: (99.91%) (35871/35904) | Learning rate: (1e-06)
2022-06-06 23:33:19,933 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 570 |  Loss: (0.0029) | Acc: (99.91%) (36510/36544) | Learning rate: (1e-06)
2022-06-06 23:33:21,728 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 580 |  Loss: (0.0029) | Acc: (99.91%) (37150/37184) | Learning rate: (1e-06)
2022-06-06 23:33:23,524 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 590 |  Loss: (0.0028) | Acc: (99.91%) (37790/37824) | Learning rate: (1e-06)
2022-06-06 23:33:25,318 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 600 |  Loss: (0.0028) | Acc: (99.91%) (38430/38464) | Learning rate: (1e-06)
2022-06-06 23:33:27,116 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 610 |  Loss: (0.0028) | Acc: (99.91%) (39070/39104) | Learning rate: (1e-06)
2022-06-06 23:33:28,915 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 620 |  Loss: (0.0028) | Acc: (99.91%) (39710/39744) | Learning rate: (1e-06)
2022-06-06 23:33:30,716 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 630 |  Loss: (0.0028) | Acc: (99.92%) (40350/40384) | Learning rate: (1e-06)
2022-06-06 23:33:32,516 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 640 |  Loss: (0.0028) | Acc: (99.91%) (40988/41024) | Learning rate: (1e-06)
2022-06-06 23:33:34,314 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 650 |  Loss: (0.0028) | Acc: (99.91%) (41627/41664) | Learning rate: (1e-06)
2022-06-06 23:33:36,114 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 660 |  Loss: (0.0028) | Acc: (99.91%) (42267/42304) | Learning rate: (1e-06)
2022-06-06 23:33:37,913 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 670 |  Loss: (0.0028) | Acc: (99.91%) (42907/42944) | Learning rate: (1e-06)
2022-06-06 23:33:39,713 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 680 |  Loss: (0.0028) | Acc: (99.91%) (43545/43584) | Learning rate: (1e-06)
2022-06-06 23:33:41,512 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 690 |  Loss: (0.0028) | Acc: (99.91%) (44185/44224) | Learning rate: (1e-06)
2022-06-06 23:33:43,311 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 700 |  Loss: (0.0028) | Acc: (99.91%) (44825/44864) | Learning rate: (1e-06)
2022-06-06 23:33:45,111 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 710 |  Loss: (0.0028) | Acc: (99.91%) (45465/45504) | Learning rate: (1e-06)
2022-06-06 23:33:46,911 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 720 |  Loss: (0.0028) | Acc: (99.92%) (46105/46144) | Learning rate: (1e-06)
2022-06-06 23:33:48,710 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 730 |  Loss: (0.0028) | Acc: (99.91%) (46744/46784) | Learning rate: (1e-06)
2022-06-06 23:33:50,508 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 740 |  Loss: (0.0028) | Acc: (99.92%) (47384/47424) | Learning rate: (1e-06)
2022-06-06 23:33:52,307 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 750 |  Loss: (0.0028) | Acc: (99.92%) (48024/48064) | Learning rate: (1e-06)
2022-06-06 23:33:54,108 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 760 |  Loss: (0.0027) | Acc: (99.92%) (48664/48704) | Learning rate: (1e-06)
2022-06-06 23:33:55,897 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 770 |  Loss: (0.0029) | Acc: (99.92%) (49303/49344) | Learning rate: (1e-06)
2022-06-06 23:33:57,686 - CIFAR10 Classifier - INFO - Epoch: 35 | Batch_idx: 780 |  Loss: (0.0029) | Acc: (99.92%) (49942/49984) | Learning rate: (1e-06)
2022-06-06 23:34:07,591 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0815) | Acc: (98.00%) (9800/10000)
2022-06-06 23:34:07,592 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:34:08,396 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 0 |  Loss: (0.0029) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:34:10,211 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 10 |  Loss: (0.0024) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:34:12,002 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 20 |  Loss: (0.0016) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 23:34:13,794 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 30 |  Loss: (0.0030) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 23:34:15,587 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 40 |  Loss: (0.0033) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 23:34:17,380 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 50 |  Loss: (0.0030) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:34:19,176 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 60 |  Loss: (0.0032) | Acc: (99.90%) (3900/3904) | Learning rate: (1e-06)
2022-06-06 23:34:20,970 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 70 |  Loss: (0.0029) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-06)
2022-06-06 23:34:22,763 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 80 |  Loss: (0.0027) | Acc: (99.92%) (5180/5184) | Learning rate: (1e-06)
2022-06-06 23:34:24,557 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 90 |  Loss: (0.0029) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 23:34:26,350 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 100 |  Loss: (0.0031) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-06)
2022-06-06 23:34:28,144 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 110 |  Loss: (0.0029) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-06)
2022-06-06 23:34:29,937 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 120 |  Loss: (0.0032) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 23:34:31,732 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 130 |  Loss: (0.0032) | Acc: (99.90%) (8376/8384) | Learning rate: (1e-06)
2022-06-06 23:34:33,526 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 140 |  Loss: (0.0032) | Acc: (99.90%) (9015/9024) | Learning rate: (1e-06)
2022-06-06 23:34:35,321 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 150 |  Loss: (0.0031) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-06)
2022-06-06 23:34:37,114 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 160 |  Loss: (0.0030) | Acc: (99.91%) (10295/10304) | Learning rate: (1e-06)
2022-06-06 23:34:38,908 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 170 |  Loss: (0.0029) | Acc: (99.92%) (10935/10944) | Learning rate: (1e-06)
2022-06-06 23:34:40,707 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 180 |  Loss: (0.0030) | Acc: (99.91%) (11574/11584) | Learning rate: (1e-06)
2022-06-06 23:34:42,505 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 190 |  Loss: (0.0029) | Acc: (99.92%) (12214/12224) | Learning rate: (1e-06)
2022-06-06 23:34:44,301 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 200 |  Loss: (0.0028) | Acc: (99.92%) (12854/12864) | Learning rate: (1e-06)
2022-06-06 23:34:46,097 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 210 |  Loss: (0.0028) | Acc: (99.92%) (13493/13504) | Learning rate: (1e-06)
2022-06-06 23:34:47,895 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 220 |  Loss: (0.0028) | Acc: (99.92%) (14133/14144) | Learning rate: (1e-06)
2022-06-06 23:34:49,691 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 230 |  Loss: (0.0028) | Acc: (99.92%) (14772/14784) | Learning rate: (1e-06)
2022-06-06 23:34:51,488 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 240 |  Loss: (0.0027) | Acc: (99.92%) (15412/15424) | Learning rate: (1e-06)
2022-06-06 23:34:53,284 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 250 |  Loss: (0.0027) | Acc: (99.93%) (16052/16064) | Learning rate: (1e-06)
2022-06-06 23:34:55,082 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 260 |  Loss: (0.0030) | Acc: (99.92%) (16691/16704) | Learning rate: (1e-06)
2022-06-06 23:34:56,878 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 270 |  Loss: (0.0030) | Acc: (99.92%) (17330/17344) | Learning rate: (1e-06)
2022-06-06 23:34:58,675 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 280 |  Loss: (0.0030) | Acc: (99.92%) (17970/17984) | Learning rate: (1e-06)
2022-06-06 23:35:00,470 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 290 |  Loss: (0.0030) | Acc: (99.92%) (18610/18624) | Learning rate: (1e-06)
2022-06-06 23:35:02,267 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 300 |  Loss: (0.0029) | Acc: (99.93%) (19250/19264) | Learning rate: (1e-06)
2022-06-06 23:35:04,064 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 310 |  Loss: (0.0032) | Acc: (99.92%) (19888/19904) | Learning rate: (1e-06)
2022-06-06 23:35:05,862 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 320 |  Loss: (0.0032) | Acc: (99.92%) (20528/20544) | Learning rate: (1e-06)
2022-06-06 23:35:07,659 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 330 |  Loss: (0.0031) | Acc: (99.92%) (21168/21184) | Learning rate: (1e-06)
2022-06-06 23:35:09,457 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 340 |  Loss: (0.0031) | Acc: (99.92%) (21807/21824) | Learning rate: (1e-06)
2022-06-06 23:35:11,255 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 350 |  Loss: (0.0031) | Acc: (99.92%) (22447/22464) | Learning rate: (1e-06)
2022-06-06 23:35:13,052 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 360 |  Loss: (0.0031) | Acc: (99.92%) (23086/23104) | Learning rate: (1e-06)
2022-06-06 23:35:14,849 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 370 |  Loss: (0.0030) | Acc: (99.92%) (23726/23744) | Learning rate: (1e-06)
2022-06-06 23:35:16,645 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 380 |  Loss: (0.0033) | Acc: (99.92%) (24364/24384) | Learning rate: (1e-06)
2022-06-06 23:35:18,441 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 390 |  Loss: (0.0032) | Acc: (99.92%) (25004/25024) | Learning rate: (1e-06)
2022-06-06 23:35:20,239 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 400 |  Loss: (0.0032) | Acc: (99.92%) (25643/25664) | Learning rate: (1e-06)
2022-06-06 23:35:22,038 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 410 |  Loss: (0.0032) | Acc: (99.92%) (26282/26304) | Learning rate: (1e-06)
2022-06-06 23:35:23,839 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 420 |  Loss: (0.0032) | Acc: (99.91%) (26921/26944) | Learning rate: (1e-06)
2022-06-06 23:35:25,637 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 430 |  Loss: (0.0032) | Acc: (99.92%) (27561/27584) | Learning rate: (1e-06)
2022-06-06 23:35:27,434 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 440 |  Loss: (0.0033) | Acc: (99.91%) (28198/28224) | Learning rate: (1e-06)
2022-06-06 23:35:29,232 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 450 |  Loss: (0.0034) | Acc: (99.91%) (28837/28864) | Learning rate: (1e-06)
2022-06-06 23:35:31,032 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 460 |  Loss: (0.0035) | Acc: (99.91%) (29476/29504) | Learning rate: (1e-06)
2022-06-06 23:35:32,829 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 470 |  Loss: (0.0034) | Acc: (99.91%) (30116/30144) | Learning rate: (1e-06)
2022-06-06 23:35:34,626 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 480 |  Loss: (0.0034) | Acc: (99.91%) (30756/30784) | Learning rate: (1e-06)
2022-06-06 23:35:36,423 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 490 |  Loss: (0.0034) | Acc: (99.91%) (31396/31424) | Learning rate: (1e-06)
2022-06-06 23:35:38,219 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 500 |  Loss: (0.0033) | Acc: (99.91%) (32036/32064) | Learning rate: (1e-06)
2022-06-06 23:35:40,015 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 510 |  Loss: (0.0035) | Acc: (99.91%) (32675/32704) | Learning rate: (1e-06)
2022-06-06 23:35:41,811 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 520 |  Loss: (0.0034) | Acc: (99.91%) (33315/33344) | Learning rate: (1e-06)
2022-06-06 23:35:43,609 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 530 |  Loss: (0.0034) | Acc: (99.91%) (33955/33984) | Learning rate: (1e-06)
2022-06-06 23:35:45,406 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 540 |  Loss: (0.0034) | Acc: (99.91%) (34594/34624) | Learning rate: (1e-06)
2022-06-06 23:35:47,203 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 550 |  Loss: (0.0034) | Acc: (99.91%) (35234/35264) | Learning rate: (1e-06)
2022-06-06 23:35:49,001 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 560 |  Loss: (0.0034) | Acc: (99.92%) (35874/35904) | Learning rate: (1e-06)
2022-06-06 23:35:50,799 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 570 |  Loss: (0.0034) | Acc: (99.92%) (36513/36544) | Learning rate: (1e-06)
2022-06-06 23:35:52,597 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 580 |  Loss: (0.0033) | Acc: (99.92%) (37153/37184) | Learning rate: (1e-06)
2022-06-06 23:35:54,393 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 590 |  Loss: (0.0033) | Acc: (99.92%) (37792/37824) | Learning rate: (1e-06)
2022-06-06 23:35:56,188 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 600 |  Loss: (0.0035) | Acc: (99.91%) (38430/38464) | Learning rate: (1e-06)
2022-06-06 23:35:57,986 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 610 |  Loss: (0.0035) | Acc: (99.91%) (39070/39104) | Learning rate: (1e-06)
2022-06-06 23:35:59,785 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 620 |  Loss: (0.0035) | Acc: (99.91%) (39710/39744) | Learning rate: (1e-06)
2022-06-06 23:36:01,583 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 630 |  Loss: (0.0034) | Acc: (99.92%) (40350/40384) | Learning rate: (1e-06)
2022-06-06 23:36:03,380 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 640 |  Loss: (0.0035) | Acc: (99.91%) (40989/41024) | Learning rate: (1e-06)
2022-06-06 23:36:05,176 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 650 |  Loss: (0.0035) | Acc: (99.92%) (41629/41664) | Learning rate: (1e-06)
2022-06-06 23:36:06,973 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 660 |  Loss: (0.0035) | Acc: (99.91%) (42268/42304) | Learning rate: (1e-06)
2022-06-06 23:36:08,768 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 670 |  Loss: (0.0035) | Acc: (99.92%) (42908/42944) | Learning rate: (1e-06)
2022-06-06 23:36:10,564 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 680 |  Loss: (0.0035) | Acc: (99.92%) (43548/43584) | Learning rate: (1e-06)
2022-06-06 23:36:12,361 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 690 |  Loss: (0.0035) | Acc: (99.92%) (44187/44224) | Learning rate: (1e-06)
2022-06-06 23:36:14,157 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 700 |  Loss: (0.0035) | Acc: (99.92%) (44827/44864) | Learning rate: (1e-06)
2022-06-06 23:36:15,954 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 710 |  Loss: (0.0035) | Acc: (99.92%) (45467/45504) | Learning rate: (1e-06)
2022-06-06 23:36:17,750 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 720 |  Loss: (0.0034) | Acc: (99.92%) (46107/46144) | Learning rate: (1e-06)
2022-06-06 23:36:19,544 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 730 |  Loss: (0.0034) | Acc: (99.92%) (46747/46784) | Learning rate: (1e-06)
2022-06-06 23:36:21,341 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 740 |  Loss: (0.0034) | Acc: (99.92%) (47387/47424) | Learning rate: (1e-06)
2022-06-06 23:36:23,138 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 750 |  Loss: (0.0035) | Acc: (99.92%) (48025/48064) | Learning rate: (1e-06)
2022-06-06 23:36:24,936 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 760 |  Loss: (0.0034) | Acc: (99.92%) (48665/48704) | Learning rate: (1e-06)
2022-06-06 23:36:26,725 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 770 |  Loss: (0.0034) | Acc: (99.92%) (49304/49344) | Learning rate: (1e-06)
2022-06-06 23:36:28,514 - CIFAR10 Classifier - INFO - Epoch: 36 | Batch_idx: 780 |  Loss: (0.0035) | Acc: (99.91%) (49941/49984) | Learning rate: (1e-06)
2022-06-06 23:36:38,478 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0816) | Acc: (98.02%) (9802/10000)
2022-06-06 23:36:38,479 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:36:39,376 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 0 |  Loss: (0.0007) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:36:41,167 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 10 |  Loss: (0.0014) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:36:42,959 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 20 |  Loss: (0.0026) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 23:36:44,752 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 30 |  Loss: (0.0024) | Acc: (100.00%) (1984/1984) | Learning rate: (1e-06)
2022-06-06 23:36:46,548 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 40 |  Loss: (0.0031) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 23:36:48,343 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 50 |  Loss: (0.0031) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-06)
2022-06-06 23:36:50,139 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 60 |  Loss: (0.0028) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-06)
2022-06-06 23:36:51,934 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 70 |  Loss: (0.0040) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 23:36:53,729 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 80 |  Loss: (0.0046) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-06)
2022-06-06 23:36:55,525 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 90 |  Loss: (0.0053) | Acc: (99.83%) (5814/5824) | Learning rate: (1e-06)
2022-06-06 23:36:57,321 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 100 |  Loss: (0.0049) | Acc: (99.85%) (6454/6464) | Learning rate: (1e-06)
2022-06-06 23:36:59,117 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 110 |  Loss: (0.0054) | Acc: (99.82%) (7091/7104) | Learning rate: (1e-06)
2022-06-06 23:37:00,912 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 120 |  Loss: (0.0052) | Acc: (99.82%) (7730/7744) | Learning rate: (1e-06)
2022-06-06 23:37:02,706 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.83%) (8370/8384) | Learning rate: (1e-06)
2022-06-06 23:37:04,502 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 140 |  Loss: (0.0046) | Acc: (99.84%) (9010/9024) | Learning rate: (1e-06)
2022-06-06 23:37:06,298 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 150 |  Loss: (0.0045) | Acc: (99.84%) (9649/9664) | Learning rate: (1e-06)
2022-06-06 23:37:08,094 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 160 |  Loss: (0.0043) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-06)
2022-06-06 23:37:09,887 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 170 |  Loss: (0.0042) | Acc: (99.85%) (10928/10944) | Learning rate: (1e-06)
2022-06-06 23:37:11,683 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 180 |  Loss: (0.0045) | Acc: (99.84%) (11566/11584) | Learning rate: (1e-06)
2022-06-06 23:37:13,480 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 190 |  Loss: (0.0046) | Acc: (99.84%) (12205/12224) | Learning rate: (1e-06)
2022-06-06 23:37:15,276 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 200 |  Loss: (0.0044) | Acc: (99.85%) (12845/12864) | Learning rate: (1e-06)
2022-06-06 23:37:17,072 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 210 |  Loss: (0.0043) | Acc: (99.86%) (13485/13504) | Learning rate: (1e-06)
2022-06-06 23:37:18,867 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 220 |  Loss: (0.0042) | Acc: (99.87%) (14125/14144) | Learning rate: (1e-06)
2022-06-06 23:37:20,661 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 230 |  Loss: (0.0041) | Acc: (99.86%) (14764/14784) | Learning rate: (1e-06)
2022-06-06 23:37:22,458 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 240 |  Loss: (0.0041) | Acc: (99.86%) (15403/15424) | Learning rate: (1e-06)
2022-06-06 23:37:24,254 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 250 |  Loss: (0.0044) | Acc: (99.86%) (16041/16064) | Learning rate: (1e-06)
2022-06-06 23:37:26,051 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 260 |  Loss: (0.0042) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-06)
2022-06-06 23:37:27,848 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 270 |  Loss: (0.0042) | Acc: (99.86%) (17320/17344) | Learning rate: (1e-06)
2022-06-06 23:37:29,642 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 280 |  Loss: (0.0041) | Acc: (99.87%) (17960/17984) | Learning rate: (1e-06)
2022-06-06 23:37:31,438 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 290 |  Loss: (0.0040) | Acc: (99.87%) (18600/18624) | Learning rate: (1e-06)
2022-06-06 23:37:33,233 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 300 |  Loss: (0.0041) | Acc: (99.87%) (19238/19264) | Learning rate: (1e-06)
2022-06-06 23:37:35,031 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 310 |  Loss: (0.0041) | Acc: (99.86%) (19877/19904) | Learning rate: (1e-06)
2022-06-06 23:37:36,828 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 320 |  Loss: (0.0040) | Acc: (99.87%) (20517/20544) | Learning rate: (1e-06)
2022-06-06 23:37:38,625 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 330 |  Loss: (0.0040) | Acc: (99.87%) (21157/21184) | Learning rate: (1e-06)
2022-06-06 23:37:40,420 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 340 |  Loss: (0.0039) | Acc: (99.88%) (21797/21824) | Learning rate: (1e-06)
2022-06-06 23:37:42,215 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.88%) (22437/22464) | Learning rate: (1e-06)
2022-06-06 23:37:44,012 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 360 |  Loss: (0.0039) | Acc: (99.87%) (23075/23104) | Learning rate: (1e-06)
2022-06-06 23:37:45,808 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 370 |  Loss: (0.0039) | Acc: (99.87%) (23714/23744) | Learning rate: (1e-06)
2022-06-06 23:37:47,604 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 380 |  Loss: (0.0039) | Acc: (99.88%) (24354/24384) | Learning rate: (1e-06)
2022-06-06 23:37:49,401 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 390 |  Loss: (0.0039) | Acc: (99.88%) (24994/25024) | Learning rate: (1e-06)
2022-06-06 23:37:51,197 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 400 |  Loss: (0.0038) | Acc: (99.88%) (25633/25664) | Learning rate: (1e-06)
2022-06-06 23:37:52,993 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 410 |  Loss: (0.0038) | Acc: (99.88%) (26273/26304) | Learning rate: (1e-06)
2022-06-06 23:37:54,788 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 420 |  Loss: (0.0038) | Acc: (99.88%) (26912/26944) | Learning rate: (1e-06)
2022-06-06 23:37:56,587 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 430 |  Loss: (0.0037) | Acc: (99.88%) (27552/27584) | Learning rate: (1e-06)
2022-06-06 23:37:58,384 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 440 |  Loss: (0.0037) | Acc: (99.89%) (28192/28224) | Learning rate: (1e-06)
2022-06-06 23:38:00,180 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 450 |  Loss: (0.0036) | Acc: (99.89%) (28832/28864) | Learning rate: (1e-06)
2022-06-06 23:38:01,975 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 460 |  Loss: (0.0036) | Acc: (99.89%) (29472/29504) | Learning rate: (1e-06)
2022-06-06 23:38:03,770 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 470 |  Loss: (0.0036) | Acc: (99.89%) (30112/30144) | Learning rate: (1e-06)
2022-06-06 23:38:05,567 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 480 |  Loss: (0.0035) | Acc: (99.90%) (30752/30784) | Learning rate: (1e-06)
2022-06-06 23:38:07,362 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 490 |  Loss: (0.0035) | Acc: (99.90%) (31392/31424) | Learning rate: (1e-06)
2022-06-06 23:38:09,158 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 500 |  Loss: (0.0038) | Acc: (99.89%) (32030/32064) | Learning rate: (1e-06)
2022-06-06 23:38:10,954 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 510 |  Loss: (0.0038) | Acc: (99.89%) (32669/32704) | Learning rate: (1e-06)
2022-06-06 23:38:12,749 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 520 |  Loss: (0.0038) | Acc: (99.89%) (33308/33344) | Learning rate: (1e-06)
2022-06-06 23:38:14,543 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 530 |  Loss: (0.0038) | Acc: (99.89%) (33947/33984) | Learning rate: (1e-06)
2022-06-06 23:38:16,339 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 540 |  Loss: (0.0038) | Acc: (99.89%) (34587/34624) | Learning rate: (1e-06)
2022-06-06 23:38:18,136 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 550 |  Loss: (0.0038) | Acc: (99.90%) (35227/35264) | Learning rate: (1e-06)
2022-06-06 23:38:19,932 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 560 |  Loss: (0.0037) | Acc: (99.89%) (35866/35904) | Learning rate: (1e-06)
2022-06-06 23:38:21,726 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 570 |  Loss: (0.0037) | Acc: (99.90%) (36506/36544) | Learning rate: (1e-06)
2022-06-06 23:38:23,520 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 580 |  Loss: (0.0037) | Acc: (99.90%) (37146/37184) | Learning rate: (1e-06)
2022-06-06 23:38:25,317 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 590 |  Loss: (0.0037) | Acc: (99.90%) (37785/37824) | Learning rate: (1e-06)
2022-06-06 23:38:27,114 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 600 |  Loss: (0.0036) | Acc: (99.90%) (38425/38464) | Learning rate: (1e-06)
2022-06-06 23:38:28,910 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 610 |  Loss: (0.0036) | Acc: (99.90%) (39065/39104) | Learning rate: (1e-06)
2022-06-06 23:38:30,706 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 620 |  Loss: (0.0037) | Acc: (99.90%) (39703/39744) | Learning rate: (1e-06)
2022-06-06 23:38:32,502 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 630 |  Loss: (0.0036) | Acc: (99.90%) (40343/40384) | Learning rate: (1e-06)
2022-06-06 23:38:34,297 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 640 |  Loss: (0.0036) | Acc: (99.90%) (40983/41024) | Learning rate: (1e-06)
2022-06-06 23:38:36,092 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 650 |  Loss: (0.0036) | Acc: (99.90%) (41622/41664) | Learning rate: (1e-06)
2022-06-06 23:38:37,890 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 660 |  Loss: (0.0036) | Acc: (99.90%) (42262/42304) | Learning rate: (1e-06)
2022-06-06 23:38:39,686 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 670 |  Loss: (0.0035) | Acc: (99.90%) (42902/42944) | Learning rate: (1e-06)
2022-06-06 23:38:41,483 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 680 |  Loss: (0.0035) | Acc: (99.90%) (43542/43584) | Learning rate: (1e-06)
2022-06-06 23:38:43,277 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 690 |  Loss: (0.0035) | Acc: (99.91%) (44182/44224) | Learning rate: (1e-06)
2022-06-06 23:38:45,073 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 700 |  Loss: (0.0035) | Acc: (99.90%) (44821/44864) | Learning rate: (1e-06)
2022-06-06 23:38:46,870 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 710 |  Loss: (0.0035) | Acc: (99.90%) (45460/45504) | Learning rate: (1e-06)
2022-06-06 23:38:48,668 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 720 |  Loss: (0.0035) | Acc: (99.90%) (46100/46144) | Learning rate: (1e-06)
2022-06-06 23:38:50,465 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 730 |  Loss: (0.0035) | Acc: (99.90%) (46739/46784) | Learning rate: (1e-06)
2022-06-06 23:38:52,261 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 740 |  Loss: (0.0035) | Acc: (99.91%) (47379/47424) | Learning rate: (1e-06)
2022-06-06 23:38:54,058 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 750 |  Loss: (0.0035) | Acc: (99.91%) (48019/48064) | Learning rate: (1e-06)
2022-06-06 23:38:55,857 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 760 |  Loss: (0.0034) | Acc: (99.91%) (48659/48704) | Learning rate: (1e-06)
2022-06-06 23:38:57,644 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 770 |  Loss: (0.0035) | Acc: (99.90%) (49297/49344) | Learning rate: (1e-06)
2022-06-06 23:38:59,433 - CIFAR10 Classifier - INFO - Epoch: 37 | Batch_idx: 780 |  Loss: (0.0035) | Acc: (99.90%) (49936/49984) | Learning rate: (1e-06)
2022-06-06 23:39:09,378 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0806) | Acc: (98.03%) (9803/10000)
2022-06-06 23:39:09,379 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:39:10,177 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 0 |  Loss: (0.0030) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:39:11,991 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 10 |  Loss: (0.0033) | Acc: (99.86%) (703/704) | Learning rate: (1e-06)
2022-06-06 23:39:13,784 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 20 |  Loss: (0.0032) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 23:39:15,577 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 30 |  Loss: (0.0029) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 23:39:17,373 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 40 |  Loss: (0.0035) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 23:39:19,168 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 50 |  Loss: (0.0038) | Acc: (99.88%) (3260/3264) | Learning rate: (1e-06)
2022-06-06 23:39:20,963 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 60 |  Loss: (0.0051) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-06)
2022-06-06 23:39:22,760 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 70 |  Loss: (0.0046) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-06)
2022-06-06 23:39:24,556 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 80 |  Loss: (0.0047) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-06)
2022-06-06 23:39:26,353 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 90 |  Loss: (0.0044) | Acc: (99.88%) (5817/5824) | Learning rate: (1e-06)
2022-06-06 23:39:28,148 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 100 |  Loss: (0.0041) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-06)
2022-06-06 23:39:29,946 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 110 |  Loss: (0.0039) | Acc: (99.90%) (7097/7104) | Learning rate: (1e-06)
2022-06-06 23:39:31,741 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 120 |  Loss: (0.0041) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 23:39:33,536 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 130 |  Loss: (0.0043) | Acc: (99.88%) (8374/8384) | Learning rate: (1e-06)
2022-06-06 23:39:35,334 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 140 |  Loss: (0.0045) | Acc: (99.88%) (9013/9024) | Learning rate: (1e-06)
2022-06-06 23:39:37,131 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 150 |  Loss: (0.0044) | Acc: (99.87%) (9651/9664) | Learning rate: (1e-06)
2022-06-06 23:39:38,927 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 160 |  Loss: (0.0043) | Acc: (99.87%) (10291/10304) | Learning rate: (1e-06)
2022-06-06 23:39:40,723 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 170 |  Loss: (0.0041) | Acc: (99.88%) (10931/10944) | Learning rate: (1e-06)
2022-06-06 23:39:42,518 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 180 |  Loss: (0.0040) | Acc: (99.89%) (11571/11584) | Learning rate: (1e-06)
2022-06-06 23:39:44,315 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 190 |  Loss: (0.0039) | Acc: (99.89%) (12211/12224) | Learning rate: (1e-06)
2022-06-06 23:39:46,111 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 200 |  Loss: (0.0038) | Acc: (99.90%) (12851/12864) | Learning rate: (1e-06)
2022-06-06 23:39:47,911 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 210 |  Loss: (0.0038) | Acc: (99.90%) (13490/13504) | Learning rate: (1e-06)
2022-06-06 23:39:49,706 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 220 |  Loss: (0.0037) | Acc: (99.90%) (14130/14144) | Learning rate: (1e-06)
2022-06-06 23:39:51,506 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 230 |  Loss: (0.0036) | Acc: (99.91%) (14770/14784) | Learning rate: (1e-06)
2022-06-06 23:39:53,303 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 240 |  Loss: (0.0035) | Acc: (99.91%) (15410/15424) | Learning rate: (1e-06)
2022-06-06 23:39:55,099 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 250 |  Loss: (0.0034) | Acc: (99.91%) (16050/16064) | Learning rate: (1e-06)
2022-06-06 23:39:56,897 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 260 |  Loss: (0.0034) | Acc: (99.91%) (16689/16704) | Learning rate: (1e-06)
2022-06-06 23:39:58,693 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 270 |  Loss: (0.0033) | Acc: (99.91%) (17329/17344) | Learning rate: (1e-06)
2022-06-06 23:40:00,488 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 280 |  Loss: (0.0034) | Acc: (99.91%) (17968/17984) | Learning rate: (1e-06)
2022-06-06 23:40:02,284 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 290 |  Loss: (0.0033) | Acc: (99.91%) (18608/18624) | Learning rate: (1e-06)
2022-06-06 23:40:04,082 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 300 |  Loss: (0.0032) | Acc: (99.92%) (19248/19264) | Learning rate: (1e-06)
2022-06-06 23:40:05,879 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 310 |  Loss: (0.0032) | Acc: (99.92%) (19888/19904) | Learning rate: (1e-06)
2022-06-06 23:40:07,675 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 320 |  Loss: (0.0032) | Acc: (99.92%) (20527/20544) | Learning rate: (1e-06)
2022-06-06 23:40:09,471 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 330 |  Loss: (0.0032) | Acc: (99.92%) (21166/21184) | Learning rate: (1e-06)
2022-06-06 23:40:11,265 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 340 |  Loss: (0.0033) | Acc: (99.91%) (21805/21824) | Learning rate: (1e-06)
2022-06-06 23:40:13,062 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 350 |  Loss: (0.0032) | Acc: (99.92%) (22445/22464) | Learning rate: (1e-06)
2022-06-06 23:40:14,860 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 360 |  Loss: (0.0032) | Acc: (99.91%) (23084/23104) | Learning rate: (1e-06)
2022-06-06 23:40:16,657 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 370 |  Loss: (0.0032) | Acc: (99.92%) (23724/23744) | Learning rate: (1e-06)
2022-06-06 23:40:18,453 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 380 |  Loss: (0.0032) | Acc: (99.91%) (24363/24384) | Learning rate: (1e-06)
2022-06-06 23:40:20,251 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 390 |  Loss: (0.0032) | Acc: (99.91%) (25002/25024) | Learning rate: (1e-06)
2022-06-06 23:40:22,047 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 400 |  Loss: (0.0033) | Acc: (99.91%) (25640/25664) | Learning rate: (1e-06)
2022-06-06 23:40:23,842 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 410 |  Loss: (0.0033) | Acc: (99.90%) (26279/26304) | Learning rate: (1e-06)
2022-06-06 23:40:25,638 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 420 |  Loss: (0.0033) | Acc: (99.90%) (26918/26944) | Learning rate: (1e-06)
2022-06-06 23:40:27,435 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 430 |  Loss: (0.0033) | Acc: (99.90%) (27557/27584) | Learning rate: (1e-06)
2022-06-06 23:40:29,234 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 440 |  Loss: (0.0033) | Acc: (99.90%) (28197/28224) | Learning rate: (1e-06)
2022-06-06 23:40:31,030 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 450 |  Loss: (0.0032) | Acc: (99.91%) (28837/28864) | Learning rate: (1e-06)
2022-06-06 23:40:32,827 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 460 |  Loss: (0.0032) | Acc: (99.91%) (29477/29504) | Learning rate: (1e-06)
2022-06-06 23:40:34,624 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 470 |  Loss: (0.0032) | Acc: (99.91%) (30117/30144) | Learning rate: (1e-06)
2022-06-06 23:40:36,420 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 480 |  Loss: (0.0031) | Acc: (99.91%) (30757/30784) | Learning rate: (1e-06)
2022-06-06 23:40:38,215 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 490 |  Loss: (0.0031) | Acc: (99.91%) (31397/31424) | Learning rate: (1e-06)
2022-06-06 23:40:40,012 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 500 |  Loss: (0.0030) | Acc: (99.92%) (32037/32064) | Learning rate: (1e-06)
2022-06-06 23:40:41,809 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 510 |  Loss: (0.0031) | Acc: (99.91%) (32675/32704) | Learning rate: (1e-06)
2022-06-06 23:40:43,609 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 520 |  Loss: (0.0032) | Acc: (99.91%) (33314/33344) | Learning rate: (1e-06)
2022-06-06 23:40:45,406 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 530 |  Loss: (0.0032) | Acc: (99.91%) (33954/33984) | Learning rate: (1e-06)
2022-06-06 23:40:47,204 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 540 |  Loss: (0.0031) | Acc: (99.91%) (34594/34624) | Learning rate: (1e-06)
2022-06-06 23:40:49,001 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 550 |  Loss: (0.0031) | Acc: (99.91%) (35234/35264) | Learning rate: (1e-06)
2022-06-06 23:40:50,799 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 560 |  Loss: (0.0030) | Acc: (99.92%) (35874/35904) | Learning rate: (1e-06)
2022-06-06 23:40:52,594 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 570 |  Loss: (0.0031) | Acc: (99.92%) (36513/36544) | Learning rate: (1e-06)
2022-06-06 23:40:54,390 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 580 |  Loss: (0.0031) | Acc: (99.91%) (37152/37184) | Learning rate: (1e-06)
2022-06-06 23:40:56,187 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 590 |  Loss: (0.0030) | Acc: (99.92%) (37792/37824) | Learning rate: (1e-06)
2022-06-06 23:40:57,985 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 600 |  Loss: (0.0031) | Acc: (99.91%) (38430/38464) | Learning rate: (1e-06)
2022-06-06 23:40:59,781 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 610 |  Loss: (0.0031) | Acc: (99.91%) (39070/39104) | Learning rate: (1e-06)
2022-06-06 23:41:01,579 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 620 |  Loss: (0.0030) | Acc: (99.91%) (39710/39744) | Learning rate: (1e-06)
2022-06-06 23:41:03,376 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 630 |  Loss: (0.0030) | Acc: (99.92%) (40350/40384) | Learning rate: (1e-06)
2022-06-06 23:41:05,174 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 640 |  Loss: (0.0031) | Acc: (99.91%) (40989/41024) | Learning rate: (1e-06)
2022-06-06 23:41:06,970 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 650 |  Loss: (0.0031) | Acc: (99.91%) (41628/41664) | Learning rate: (1e-06)
2022-06-06 23:41:08,765 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 660 |  Loss: (0.0030) | Acc: (99.91%) (42268/42304) | Learning rate: (1e-06)
2022-06-06 23:41:10,563 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 670 |  Loss: (0.0030) | Acc: (99.91%) (42906/42944) | Learning rate: (1e-06)
2022-06-06 23:41:12,360 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 680 |  Loss: (0.0030) | Acc: (99.91%) (43546/43584) | Learning rate: (1e-06)
2022-06-06 23:41:14,158 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 690 |  Loss: (0.0030) | Acc: (99.91%) (44185/44224) | Learning rate: (1e-06)
2022-06-06 23:41:15,955 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 700 |  Loss: (0.0030) | Acc: (99.91%) (44824/44864) | Learning rate: (1e-06)
2022-06-06 23:41:17,753 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 710 |  Loss: (0.0031) | Acc: (99.91%) (45463/45504) | Learning rate: (1e-06)
2022-06-06 23:41:19,550 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 720 |  Loss: (0.0031) | Acc: (99.91%) (46102/46144) | Learning rate: (1e-06)
2022-06-06 23:41:21,346 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 730 |  Loss: (0.0031) | Acc: (99.91%) (46742/46784) | Learning rate: (1e-06)
2022-06-06 23:41:23,143 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 740 |  Loss: (0.0030) | Acc: (99.91%) (47382/47424) | Learning rate: (1e-06)
2022-06-06 23:41:24,942 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 750 |  Loss: (0.0030) | Acc: (99.91%) (48022/48064) | Learning rate: (1e-06)
2022-06-06 23:41:26,744 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 760 |  Loss: (0.0030) | Acc: (99.91%) (48662/48704) | Learning rate: (1e-06)
2022-06-06 23:41:28,533 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 770 |  Loss: (0.0030) | Acc: (99.91%) (49302/49344) | Learning rate: (1e-06)
2022-06-06 23:41:30,322 - CIFAR10 Classifier - INFO - Epoch: 38 | Batch_idx: 780 |  Loss: (0.0029) | Acc: (99.92%) (49942/49984) | Learning rate: (1e-06)
2022-06-06 23:41:40,236 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0825) | Acc: (98.00%) (9800/10000)
2022-06-06 23:41:40,237 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:41:41,056 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:41:42,863 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 10 |  Loss: (0.0008) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:41:44,655 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 20 |  Loss: (0.0035) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 23:41:46,450 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 30 |  Loss: (0.0027) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 23:41:48,246 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 40 |  Loss: (0.0023) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-06)
2022-06-06 23:41:50,041 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 50 |  Loss: (0.0022) | Acc: (99.97%) (3263/3264) | Learning rate: (1e-06)
2022-06-06 23:41:51,837 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 60 |  Loss: (0.0022) | Acc: (99.97%) (3903/3904) | Learning rate: (1e-06)
2022-06-06 23:41:53,631 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 70 |  Loss: (0.0023) | Acc: (99.98%) (4543/4544) | Learning rate: (1e-06)
2022-06-06 23:41:55,427 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 80 |  Loss: (0.0024) | Acc: (99.96%) (5182/5184) | Learning rate: (1e-06)
2022-06-06 23:41:57,223 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 90 |  Loss: (0.0022) | Acc: (99.97%) (5822/5824) | Learning rate: (1e-06)
2022-06-06 23:41:59,018 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 100 |  Loss: (0.0025) | Acc: (99.95%) (6461/6464) | Learning rate: (1e-06)
2022-06-06 23:42:00,814 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 110 |  Loss: (0.0029) | Acc: (99.93%) (7099/7104) | Learning rate: (1e-06)
2022-06-06 23:42:02,608 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 120 |  Loss: (0.0028) | Acc: (99.94%) (7739/7744) | Learning rate: (1e-06)
2022-06-06 23:42:04,404 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 130 |  Loss: (0.0029) | Acc: (99.93%) (8378/8384) | Learning rate: (1e-06)
2022-06-06 23:42:06,201 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 140 |  Loss: (0.0027) | Acc: (99.93%) (9018/9024) | Learning rate: (1e-06)
2022-06-06 23:42:07,997 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 150 |  Loss: (0.0030) | Acc: (99.93%) (9657/9664) | Learning rate: (1e-06)
2022-06-06 23:42:09,792 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 160 |  Loss: (0.0030) | Acc: (99.93%) (10297/10304) | Learning rate: (1e-06)
2022-06-06 23:42:11,588 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 170 |  Loss: (0.0029) | Acc: (99.94%) (10937/10944) | Learning rate: (1e-06)
2022-06-06 23:42:13,383 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 180 |  Loss: (0.0029) | Acc: (99.94%) (11577/11584) | Learning rate: (1e-06)
2022-06-06 23:42:15,180 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 190 |  Loss: (0.0030) | Acc: (99.93%) (12215/12224) | Learning rate: (1e-06)
2022-06-06 23:42:16,976 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 200 |  Loss: (0.0030) | Acc: (99.93%) (12855/12864) | Learning rate: (1e-06)
2022-06-06 23:42:18,773 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 210 |  Loss: (0.0029) | Acc: (99.93%) (13495/13504) | Learning rate: (1e-06)
2022-06-06 23:42:20,569 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 220 |  Loss: (0.0029) | Acc: (99.93%) (14134/14144) | Learning rate: (1e-06)
2022-06-06 23:42:22,364 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 230 |  Loss: (0.0029) | Acc: (99.93%) (14773/14784) | Learning rate: (1e-06)
2022-06-06 23:42:24,160 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 240 |  Loss: (0.0031) | Acc: (99.92%) (15411/15424) | Learning rate: (1e-06)
2022-06-06 23:42:25,956 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 250 |  Loss: (0.0030) | Acc: (99.92%) (16051/16064) | Learning rate: (1e-06)
2022-06-06 23:42:27,755 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 260 |  Loss: (0.0030) | Acc: (99.92%) (16690/16704) | Learning rate: (1e-06)
2022-06-06 23:42:29,551 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 270 |  Loss: (0.0031) | Acc: (99.91%) (17329/17344) | Learning rate: (1e-06)
2022-06-06 23:42:31,348 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 280 |  Loss: (0.0032) | Acc: (99.91%) (17967/17984) | Learning rate: (1e-06)
2022-06-06 23:42:33,145 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 290 |  Loss: (0.0031) | Acc: (99.91%) (18607/18624) | Learning rate: (1e-06)
2022-06-06 23:42:34,940 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 300 |  Loss: (0.0031) | Acc: (99.91%) (19247/19264) | Learning rate: (1e-06)
2022-06-06 23:42:36,737 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 310 |  Loss: (0.0030) | Acc: (99.91%) (19887/19904) | Learning rate: (1e-06)
2022-06-06 23:42:38,533 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 320 |  Loss: (0.0030) | Acc: (99.91%) (20526/20544) | Learning rate: (1e-06)
2022-06-06 23:42:40,330 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 330 |  Loss: (0.0030) | Acc: (99.91%) (21165/21184) | Learning rate: (1e-06)
2022-06-06 23:42:42,128 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 340 |  Loss: (0.0030) | Acc: (99.91%) (21805/21824) | Learning rate: (1e-06)
2022-06-06 23:42:43,924 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 350 |  Loss: (0.0029) | Acc: (99.92%) (22445/22464) | Learning rate: (1e-06)
2022-06-06 23:42:45,721 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 360 |  Loss: (0.0030) | Acc: (99.91%) (23084/23104) | Learning rate: (1e-06)
2022-06-06 23:42:47,517 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 370 |  Loss: (0.0029) | Acc: (99.92%) (23724/23744) | Learning rate: (1e-06)
2022-06-06 23:42:49,313 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 380 |  Loss: (0.0030) | Acc: (99.91%) (24363/24384) | Learning rate: (1e-06)
2022-06-06 23:42:51,109 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 390 |  Loss: (0.0030) | Acc: (99.91%) (25002/25024) | Learning rate: (1e-06)
2022-06-06 23:42:52,906 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 400 |  Loss: (0.0029) | Acc: (99.91%) (25642/25664) | Learning rate: (1e-06)
2022-06-06 23:42:54,703 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 410 |  Loss: (0.0029) | Acc: (99.92%) (26282/26304) | Learning rate: (1e-06)
2022-06-06 23:42:56,500 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 420 |  Loss: (0.0030) | Acc: (99.91%) (26921/26944) | Learning rate: (1e-06)
2022-06-06 23:42:58,295 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 430 |  Loss: (0.0029) | Acc: (99.92%) (27561/27584) | Learning rate: (1e-06)
2022-06-06 23:43:00,090 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 440 |  Loss: (0.0029) | Acc: (99.91%) (28200/28224) | Learning rate: (1e-06)
2022-06-06 23:43:01,886 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 450 |  Loss: (0.0029) | Acc: (99.92%) (28840/28864) | Learning rate: (1e-06)
2022-06-06 23:43:03,683 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 460 |  Loss: (0.0030) | Acc: (99.92%) (29479/29504) | Learning rate: (1e-06)
2022-06-06 23:43:05,482 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 470 |  Loss: (0.0030) | Acc: (99.92%) (30119/30144) | Learning rate: (1e-06)
2022-06-06 23:43:07,278 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 480 |  Loss: (0.0030) | Acc: (99.92%) (30759/30784) | Learning rate: (1e-06)
2022-06-06 23:43:09,074 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 490 |  Loss: (0.0030) | Acc: (99.92%) (31399/31424) | Learning rate: (1e-06)
2022-06-06 23:43:10,870 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 500 |  Loss: (0.0029) | Acc: (99.92%) (32039/32064) | Learning rate: (1e-06)
2022-06-06 23:43:12,665 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 510 |  Loss: (0.0029) | Acc: (99.92%) (32679/32704) | Learning rate: (1e-06)
2022-06-06 23:43:14,461 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 520 |  Loss: (0.0030) | Acc: (99.92%) (33318/33344) | Learning rate: (1e-06)
2022-06-06 23:43:16,259 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 530 |  Loss: (0.0029) | Acc: (99.92%) (33957/33984) | Learning rate: (1e-06)
2022-06-06 23:43:18,058 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 540 |  Loss: (0.0030) | Acc: (99.92%) (34596/34624) | Learning rate: (1e-06)
2022-06-06 23:43:19,854 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 550 |  Loss: (0.0030) | Acc: (99.92%) (35235/35264) | Learning rate: (1e-06)
2022-06-06 23:43:21,652 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 560 |  Loss: (0.0030) | Acc: (99.92%) (35874/35904) | Learning rate: (1e-06)
2022-06-06 23:43:23,449 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 570 |  Loss: (0.0031) | Acc: (99.91%) (36512/36544) | Learning rate: (1e-06)
2022-06-06 23:43:25,245 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 580 |  Loss: (0.0030) | Acc: (99.91%) (37152/37184) | Learning rate: (1e-06)
2022-06-06 23:43:27,042 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 590 |  Loss: (0.0030) | Acc: (99.92%) (37792/37824) | Learning rate: (1e-06)
2022-06-06 23:43:28,838 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 600 |  Loss: (0.0030) | Acc: (99.91%) (38430/38464) | Learning rate: (1e-06)
2022-06-06 23:43:30,635 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 610 |  Loss: (0.0031) | Acc: (99.91%) (39069/39104) | Learning rate: (1e-06)
2022-06-06 23:43:32,434 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 620 |  Loss: (0.0032) | Acc: (99.90%) (39706/39744) | Learning rate: (1e-06)
2022-06-06 23:43:34,232 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 630 |  Loss: (0.0032) | Acc: (99.91%) (40346/40384) | Learning rate: (1e-06)
2022-06-06 23:43:36,029 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 640 |  Loss: (0.0032) | Acc: (99.90%) (40985/41024) | Learning rate: (1e-06)
2022-06-06 23:43:37,826 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 650 |  Loss: (0.0031) | Acc: (99.91%) (41625/41664) | Learning rate: (1e-06)
2022-06-06 23:43:39,623 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 660 |  Loss: (0.0031) | Acc: (99.91%) (42265/42304) | Learning rate: (1e-06)
2022-06-06 23:43:41,422 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 670 |  Loss: (0.0032) | Acc: (99.91%) (42905/42944) | Learning rate: (1e-06)
2022-06-06 23:43:43,218 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 680 |  Loss: (0.0031) | Acc: (99.91%) (43544/43584) | Learning rate: (1e-06)
2022-06-06 23:43:45,014 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 690 |  Loss: (0.0031) | Acc: (99.91%) (44184/44224) | Learning rate: (1e-06)
2022-06-06 23:43:46,810 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 700 |  Loss: (0.0031) | Acc: (99.91%) (44824/44864) | Learning rate: (1e-06)
2022-06-06 23:43:48,610 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 710 |  Loss: (0.0031) | Acc: (99.91%) (45464/45504) | Learning rate: (1e-06)
2022-06-06 23:43:50,407 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 720 |  Loss: (0.0030) | Acc: (99.91%) (46104/46144) | Learning rate: (1e-06)
2022-06-06 23:43:52,205 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 730 |  Loss: (0.0030) | Acc: (99.91%) (46744/46784) | Learning rate: (1e-06)
2022-06-06 23:43:54,003 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 740 |  Loss: (0.0030) | Acc: (99.91%) (47383/47424) | Learning rate: (1e-06)
2022-06-06 23:43:55,801 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 750 |  Loss: (0.0031) | Acc: (99.91%) (48022/48064) | Learning rate: (1e-06)
2022-06-06 23:43:57,597 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 760 |  Loss: (0.0030) | Acc: (99.91%) (48662/48704) | Learning rate: (1e-06)
2022-06-06 23:43:59,388 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 770 |  Loss: (0.0030) | Acc: (99.91%) (49302/49344) | Learning rate: (1e-06)
2022-06-06 23:44:01,178 - CIFAR10 Classifier - INFO - Epoch: 39 | Batch_idx: 780 |  Loss: (0.0030) | Acc: (99.92%) (49942/49984) | Learning rate: (1e-06)
2022-06-06 23:44:11,106 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0813) | Acc: (98.01%) (9801/10000)
2022-06-06 23:44:11,107 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:44:11,930 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 0 |  Loss: (0.0017) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:44:13,750 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 10 |  Loss: (0.0107) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 23:44:15,541 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 20 |  Loss: (0.0066) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-06)
2022-06-06 23:44:17,335 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 30 |  Loss: (0.0046) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-06)
2022-06-06 23:44:19,131 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 40 |  Loss: (0.0039) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-06)
2022-06-06 23:44:20,926 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 50 |  Loss: (0.0033) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-06)
2022-06-06 23:44:22,721 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 60 |  Loss: (0.0035) | Acc: (99.95%) (3902/3904) | Learning rate: (1e-06)
2022-06-06 23:44:24,517 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 70 |  Loss: (0.0032) | Acc: (99.96%) (4542/4544) | Learning rate: (1e-06)
2022-06-06 23:44:26,312 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 80 |  Loss: (0.0030) | Acc: (99.96%) (5182/5184) | Learning rate: (1e-06)
2022-06-06 23:44:28,109 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 90 |  Loss: (0.0036) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-06)
2022-06-06 23:44:29,904 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 100 |  Loss: (0.0039) | Acc: (99.88%) (6456/6464) | Learning rate: (1e-06)
2022-06-06 23:44:31,699 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 110 |  Loss: (0.0036) | Acc: (99.89%) (7096/7104) | Learning rate: (1e-06)
2022-06-06 23:44:33,495 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 120 |  Loss: (0.0035) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-06)
2022-06-06 23:44:35,291 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 130 |  Loss: (0.0036) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-06)
2022-06-06 23:44:37,088 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 140 |  Loss: (0.0034) | Acc: (99.90%) (9015/9024) | Learning rate: (1e-06)
2022-06-06 23:44:38,884 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 150 |  Loss: (0.0032) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-06)
2022-06-06 23:44:40,680 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 160 |  Loss: (0.0031) | Acc: (99.91%) (10295/10304) | Learning rate: (1e-06)
2022-06-06 23:44:42,475 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 170 |  Loss: (0.0030) | Acc: (99.92%) (10935/10944) | Learning rate: (1e-06)
2022-06-06 23:44:44,271 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 180 |  Loss: (0.0029) | Acc: (99.92%) (11575/11584) | Learning rate: (1e-06)
2022-06-06 23:44:46,068 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 190 |  Loss: (0.0029) | Acc: (99.93%) (12215/12224) | Learning rate: (1e-06)
2022-06-06 23:44:47,862 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 200 |  Loss: (0.0030) | Acc: (99.92%) (12854/12864) | Learning rate: (1e-06)
2022-06-06 23:44:49,658 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 210 |  Loss: (0.0029) | Acc: (99.93%) (13494/13504) | Learning rate: (1e-06)
2022-06-06 23:44:51,453 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 220 |  Loss: (0.0029) | Acc: (99.92%) (14133/14144) | Learning rate: (1e-06)
2022-06-06 23:44:53,249 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 230 |  Loss: (0.0028) | Acc: (99.93%) (14773/14784) | Learning rate: (1e-06)
2022-06-06 23:44:55,044 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 240 |  Loss: (0.0028) | Acc: (99.93%) (15413/15424) | Learning rate: (1e-06)
2022-06-06 23:44:56,840 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 250 |  Loss: (0.0027) | Acc: (99.93%) (16052/16064) | Learning rate: (1e-06)
2022-06-06 23:44:58,638 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 260 |  Loss: (0.0027) | Acc: (99.93%) (16692/16704) | Learning rate: (1e-06)
2022-06-06 23:45:00,434 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 270 |  Loss: (0.0027) | Acc: (99.93%) (17331/17344) | Learning rate: (1e-06)
2022-06-06 23:45:02,229 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 280 |  Loss: (0.0027) | Acc: (99.93%) (17971/17984) | Learning rate: (1e-06)
2022-06-06 23:45:04,024 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 290 |  Loss: (0.0028) | Acc: (99.92%) (18610/18624) | Learning rate: (1e-06)
2022-06-06 23:45:05,822 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 300 |  Loss: (0.0029) | Acc: (99.92%) (19249/19264) | Learning rate: (1e-06)
2022-06-06 23:45:07,619 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 310 |  Loss: (0.0028) | Acc: (99.92%) (19889/19904) | Learning rate: (1e-06)
2022-06-06 23:45:09,414 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 320 |  Loss: (0.0030) | Acc: (99.92%) (20528/20544) | Learning rate: (1e-06)
2022-06-06 23:45:11,210 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 330 |  Loss: (0.0030) | Acc: (99.92%) (21167/21184) | Learning rate: (1e-06)
2022-06-06 23:45:13,006 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 340 |  Loss: (0.0031) | Acc: (99.92%) (21806/21824) | Learning rate: (1e-06)
2022-06-06 23:45:14,802 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 350 |  Loss: (0.0032) | Acc: (99.91%) (22444/22464) | Learning rate: (1e-06)
2022-06-06 23:45:16,599 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 360 |  Loss: (0.0033) | Acc: (99.91%) (23083/23104) | Learning rate: (1e-06)
2022-06-06 23:45:18,396 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 370 |  Loss: (0.0034) | Acc: (99.91%) (23722/23744) | Learning rate: (1e-06)
2022-06-06 23:45:20,192 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 380 |  Loss: (0.0036) | Acc: (99.90%) (24360/24384) | Learning rate: (1e-06)
2022-06-06 23:45:21,989 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 390 |  Loss: (0.0038) | Acc: (99.90%) (24998/25024) | Learning rate: (1e-06)
2022-06-06 23:45:23,785 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 400 |  Loss: (0.0037) | Acc: (99.90%) (25638/25664) | Learning rate: (1e-06)
2022-06-06 23:45:25,580 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 410 |  Loss: (0.0039) | Acc: (99.89%) (26276/26304) | Learning rate: (1e-06)
2022-06-06 23:45:27,376 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 420 |  Loss: (0.0038) | Acc: (99.90%) (26916/26944) | Learning rate: (1e-06)
2022-06-06 23:45:29,174 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 430 |  Loss: (0.0038) | Acc: (99.89%) (27555/27584) | Learning rate: (1e-06)
2022-06-06 23:45:30,972 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 440 |  Loss: (0.0038) | Acc: (99.89%) (28194/28224) | Learning rate: (1e-06)
2022-06-06 23:45:32,768 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 450 |  Loss: (0.0038) | Acc: (99.90%) (28834/28864) | Learning rate: (1e-06)
2022-06-06 23:45:34,567 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 460 |  Loss: (0.0037) | Acc: (99.90%) (29474/29504) | Learning rate: (1e-06)
2022-06-06 23:45:36,362 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 470 |  Loss: (0.0037) | Acc: (99.90%) (30114/30144) | Learning rate: (1e-06)
2022-06-06 23:45:38,158 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 480 |  Loss: (0.0037) | Acc: (99.90%) (30754/30784) | Learning rate: (1e-06)
2022-06-06 23:45:39,954 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 490 |  Loss: (0.0036) | Acc: (99.90%) (31394/31424) | Learning rate: (1e-06)
2022-06-06 23:45:41,751 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 500 |  Loss: (0.0036) | Acc: (99.90%) (32033/32064) | Learning rate: (1e-06)
2022-06-06 23:45:43,551 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 510 |  Loss: (0.0035) | Acc: (99.91%) (32673/32704) | Learning rate: (1e-06)
2022-06-06 23:45:45,348 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 520 |  Loss: (0.0035) | Acc: (99.91%) (33313/33344) | Learning rate: (1e-06)
2022-06-06 23:45:47,146 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 530 |  Loss: (0.0035) | Acc: (99.91%) (33953/33984) | Learning rate: (1e-06)
2022-06-06 23:45:48,944 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 540 |  Loss: (0.0035) | Acc: (99.91%) (34592/34624) | Learning rate: (1e-06)
2022-06-06 23:45:50,741 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 550 |  Loss: (0.0034) | Acc: (99.91%) (35232/35264) | Learning rate: (1e-06)
2022-06-06 23:45:52,539 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 560 |  Loss: (0.0034) | Acc: (99.91%) (35872/35904) | Learning rate: (1e-06)
2022-06-06 23:45:54,337 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 570 |  Loss: (0.0034) | Acc: (99.91%) (36512/36544) | Learning rate: (1e-06)
2022-06-06 23:45:56,132 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 580 |  Loss: (0.0034) | Acc: (99.91%) (37150/37184) | Learning rate: (1e-06)
2022-06-06 23:45:57,928 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 590 |  Loss: (0.0034) | Acc: (99.91%) (37790/37824) | Learning rate: (1e-06)
2022-06-06 23:45:59,725 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 600 |  Loss: (0.0034) | Acc: (99.91%) (38428/38464) | Learning rate: (1e-06)
2022-06-06 23:46:01,524 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 610 |  Loss: (0.0034) | Acc: (99.91%) (39068/39104) | Learning rate: (1e-06)
2022-06-06 23:46:03,323 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 620 |  Loss: (0.0033) | Acc: (99.91%) (39708/39744) | Learning rate: (1e-06)
2022-06-06 23:46:05,120 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 630 |  Loss: (0.0033) | Acc: (99.91%) (40348/40384) | Learning rate: (1e-06)
2022-06-06 23:46:06,918 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 640 |  Loss: (0.0033) | Acc: (99.91%) (40988/41024) | Learning rate: (1e-06)
2022-06-06 23:46:08,714 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 650 |  Loss: (0.0032) | Acc: (99.91%) (41628/41664) | Learning rate: (1e-06)
2022-06-06 23:46:10,512 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 660 |  Loss: (0.0033) | Acc: (99.91%) (42267/42304) | Learning rate: (1e-06)
2022-06-06 23:46:12,310 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 670 |  Loss: (0.0033) | Acc: (99.91%) (42906/42944) | Learning rate: (1e-06)
2022-06-06 23:46:14,105 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 680 |  Loss: (0.0033) | Acc: (99.91%) (43544/43584) | Learning rate: (1e-06)
2022-06-06 23:46:15,901 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 690 |  Loss: (0.0033) | Acc: (99.91%) (44184/44224) | Learning rate: (1e-06)
2022-06-06 23:46:17,698 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 700 |  Loss: (0.0033) | Acc: (99.91%) (44824/44864) | Learning rate: (1e-06)
2022-06-06 23:46:19,495 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 710 |  Loss: (0.0033) | Acc: (99.91%) (45464/45504) | Learning rate: (1e-06)
2022-06-06 23:46:21,292 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 720 |  Loss: (0.0034) | Acc: (99.91%) (46101/46144) | Learning rate: (1e-06)
2022-06-06 23:46:23,091 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 730 |  Loss: (0.0034) | Acc: (99.91%) (46740/46784) | Learning rate: (1e-06)
2022-06-06 23:46:24,890 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 740 |  Loss: (0.0034) | Acc: (99.90%) (47378/47424) | Learning rate: (1e-06)
2022-06-06 23:46:26,688 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 750 |  Loss: (0.0034) | Acc: (99.90%) (48018/48064) | Learning rate: (1e-06)
2022-06-06 23:46:28,487 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 760 |  Loss: (0.0033) | Acc: (99.91%) (48658/48704) | Learning rate: (1e-06)
2022-06-06 23:46:30,275 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 770 |  Loss: (0.0033) | Acc: (99.90%) (49297/49344) | Learning rate: (1e-06)
2022-06-06 23:46:32,066 - CIFAR10 Classifier - INFO - Epoch: 40 | Batch_idx: 780 |  Loss: (0.0033) | Acc: (99.91%) (49937/49984) | Learning rate: (1e-06)
2022-06-06 23:46:42,021 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0803) | Acc: (98.08%) (9808/10000)
2022-06-06 23:46:42,022 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:46:42,933 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 0 |  Loss: (0.0002) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:46:44,726 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 10 |  Loss: (0.0017) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:46:46,517 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 20 |  Loss: (0.0013) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-06)
2022-06-06 23:46:48,310 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 30 |  Loss: (0.0011) | Acc: (100.00%) (1984/1984) | Learning rate: (1e-06)
2022-06-06 23:46:50,106 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 40 |  Loss: (0.0019) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-06)
2022-06-06 23:46:51,902 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 50 |  Loss: (0.0016) | Acc: (99.97%) (3263/3264) | Learning rate: (1e-06)
2022-06-06 23:46:53,697 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 60 |  Loss: (0.0022) | Acc: (99.95%) (3902/3904) | Learning rate: (1e-06)
2022-06-06 23:46:55,491 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 70 |  Loss: (0.0021) | Acc: (99.96%) (4542/4544) | Learning rate: (1e-06)
2022-06-06 23:46:57,287 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 80 |  Loss: (0.0019) | Acc: (99.96%) (5182/5184) | Learning rate: (1e-06)
2022-06-06 23:46:59,083 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 90 |  Loss: (0.0019) | Acc: (99.97%) (5822/5824) | Learning rate: (1e-06)
2022-06-06 23:47:00,878 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 100 |  Loss: (0.0019) | Acc: (99.97%) (6462/6464) | Learning rate: (1e-06)
2022-06-06 23:47:02,674 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 110 |  Loss: (0.0021) | Acc: (99.96%) (7101/7104) | Learning rate: (1e-06)
2022-06-06 23:47:04,472 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 120 |  Loss: (0.0021) | Acc: (99.96%) (7741/7744) | Learning rate: (1e-06)
2022-06-06 23:47:06,265 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 130 |  Loss: (0.0020) | Acc: (99.96%) (8381/8384) | Learning rate: (1e-06)
2022-06-06 23:47:08,063 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 140 |  Loss: (0.0019) | Acc: (99.97%) (9021/9024) | Learning rate: (1e-06)
2022-06-06 23:47:09,858 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 150 |  Loss: (0.0024) | Acc: (99.95%) (9659/9664) | Learning rate: (1e-06)
2022-06-06 23:47:11,654 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 160 |  Loss: (0.0027) | Acc: (99.93%) (10297/10304) | Learning rate: (1e-06)
2022-06-06 23:47:13,450 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 170 |  Loss: (0.0032) | Acc: (99.92%) (10935/10944) | Learning rate: (1e-06)
2022-06-06 23:47:15,245 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 180 |  Loss: (0.0031) | Acc: (99.92%) (11575/11584) | Learning rate: (1e-06)
2022-06-06 23:47:17,040 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 190 |  Loss: (0.0030) | Acc: (99.93%) (12215/12224) | Learning rate: (1e-06)
2022-06-06 23:47:18,837 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 200 |  Loss: (0.0029) | Acc: (99.93%) (12855/12864) | Learning rate: (1e-06)
2022-06-06 23:47:20,633 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 210 |  Loss: (0.0028) | Acc: (99.93%) (13495/13504) | Learning rate: (1e-06)
2022-06-06 23:47:22,427 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 220 |  Loss: (0.0027) | Acc: (99.94%) (14135/14144) | Learning rate: (1e-06)
2022-06-06 23:47:24,221 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 230 |  Loss: (0.0029) | Acc: (99.93%) (14774/14784) | Learning rate: (1e-06)
2022-06-06 23:47:26,019 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 240 |  Loss: (0.0029) | Acc: (99.94%) (15414/15424) | Learning rate: (1e-06)
2022-06-06 23:47:27,816 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 250 |  Loss: (0.0029) | Acc: (99.94%) (16054/16064) | Learning rate: (1e-06)
2022-06-06 23:47:29,615 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 260 |  Loss: (0.0033) | Acc: (99.93%) (16692/16704) | Learning rate: (1e-06)
2022-06-06 23:47:31,412 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 270 |  Loss: (0.0032) | Acc: (99.93%) (17331/17344) | Learning rate: (1e-06)
2022-06-06 23:47:33,208 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 280 |  Loss: (0.0032) | Acc: (99.92%) (17970/17984) | Learning rate: (1e-06)
2022-06-06 23:47:35,003 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 290 |  Loss: (0.0031) | Acc: (99.92%) (18610/18624) | Learning rate: (1e-06)
2022-06-06 23:47:36,798 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 300 |  Loss: (0.0030) | Acc: (99.93%) (19250/19264) | Learning rate: (1e-06)
2022-06-06 23:47:38,592 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 310 |  Loss: (0.0030) | Acc: (99.92%) (19889/19904) | Learning rate: (1e-06)
2022-06-06 23:47:40,390 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 320 |  Loss: (0.0031) | Acc: (99.92%) (20528/20544) | Learning rate: (1e-06)
2022-06-06 23:47:42,188 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 330 |  Loss: (0.0030) | Acc: (99.92%) (21168/21184) | Learning rate: (1e-06)
2022-06-06 23:47:43,984 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 340 |  Loss: (0.0030) | Acc: (99.92%) (21807/21824) | Learning rate: (1e-06)
2022-06-06 23:47:45,779 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 350 |  Loss: (0.0029) | Acc: (99.92%) (22447/22464) | Learning rate: (1e-06)
2022-06-06 23:47:47,575 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 360 |  Loss: (0.0030) | Acc: (99.92%) (23086/23104) | Learning rate: (1e-06)
2022-06-06 23:47:49,370 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 370 |  Loss: (0.0030) | Acc: (99.92%) (23726/23744) | Learning rate: (1e-06)
2022-06-06 23:47:51,168 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 380 |  Loss: (0.0030) | Acc: (99.93%) (24366/24384) | Learning rate: (1e-06)
2022-06-06 23:47:52,966 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 390 |  Loss: (0.0029) | Acc: (99.93%) (25006/25024) | Learning rate: (1e-06)
2022-06-06 23:47:54,767 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 400 |  Loss: (0.0029) | Acc: (99.93%) (25646/25664) | Learning rate: (1e-06)
2022-06-06 23:47:56,564 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 410 |  Loss: (0.0028) | Acc: (99.93%) (26286/26304) | Learning rate: (1e-06)
2022-06-06 23:47:58,361 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 420 |  Loss: (0.0030) | Acc: (99.93%) (26924/26944) | Learning rate: (1e-06)
2022-06-06 23:48:00,155 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 430 |  Loss: (0.0029) | Acc: (99.93%) (27564/27584) | Learning rate: (1e-06)
2022-06-06 23:48:01,948 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 440 |  Loss: (0.0030) | Acc: (99.92%) (28202/28224) | Learning rate: (1e-06)
2022-06-06 23:48:03,742 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 450 |  Loss: (0.0030) | Acc: (99.92%) (28842/28864) | Learning rate: (1e-06)
2022-06-06 23:48:05,536 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 460 |  Loss: (0.0029) | Acc: (99.93%) (29482/29504) | Learning rate: (1e-06)
2022-06-06 23:48:07,329 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 470 |  Loss: (0.0029) | Acc: (99.93%) (30122/30144) | Learning rate: (1e-06)
2022-06-06 23:48:09,123 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 480 |  Loss: (0.0030) | Acc: (99.93%) (30761/30784) | Learning rate: (1e-06)
2022-06-06 23:48:10,916 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 490 |  Loss: (0.0029) | Acc: (99.93%) (31401/31424) | Learning rate: (1e-06)
2022-06-06 23:48:12,709 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 500 |  Loss: (0.0029) | Acc: (99.93%) (32041/32064) | Learning rate: (1e-06)
2022-06-06 23:48:14,502 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 510 |  Loss: (0.0029) | Acc: (99.93%) (32680/32704) | Learning rate: (1e-06)
2022-06-06 23:48:16,296 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 520 |  Loss: (0.0028) | Acc: (99.93%) (33320/33344) | Learning rate: (1e-06)
2022-06-06 23:48:18,090 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 530 |  Loss: (0.0029) | Acc: (99.92%) (33958/33984) | Learning rate: (1e-06)
2022-06-06 23:48:19,883 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 540 |  Loss: (0.0029) | Acc: (99.92%) (34598/34624) | Learning rate: (1e-06)
2022-06-06 23:48:21,675 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 550 |  Loss: (0.0029) | Acc: (99.93%) (35238/35264) | Learning rate: (1e-06)
2022-06-06 23:48:23,469 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 560 |  Loss: (0.0028) | Acc: (99.93%) (35878/35904) | Learning rate: (1e-06)
2022-06-06 23:48:25,262 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 570 |  Loss: (0.0028) | Acc: (99.93%) (36518/36544) | Learning rate: (1e-06)
2022-06-06 23:48:27,055 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 580 |  Loss: (0.0028) | Acc: (99.93%) (37158/37184) | Learning rate: (1e-06)
2022-06-06 23:48:28,850 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 590 |  Loss: (0.0028) | Acc: (99.93%) (37797/37824) | Learning rate: (1e-06)
2022-06-06 23:48:30,643 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 600 |  Loss: (0.0028) | Acc: (99.93%) (38436/38464) | Learning rate: (1e-06)
2022-06-06 23:48:32,437 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 610 |  Loss: (0.0028) | Acc: (99.93%) (39076/39104) | Learning rate: (1e-06)
2022-06-06 23:48:34,231 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 620 |  Loss: (0.0028) | Acc: (99.93%) (39716/39744) | Learning rate: (1e-06)
2022-06-06 23:48:36,025 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 630 |  Loss: (0.0028) | Acc: (99.93%) (40356/40384) | Learning rate: (1e-06)
2022-06-06 23:48:37,819 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 640 |  Loss: (0.0028) | Acc: (99.93%) (40995/41024) | Learning rate: (1e-06)
2022-06-06 23:48:39,612 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 650 |  Loss: (0.0028) | Acc: (99.93%) (41635/41664) | Learning rate: (1e-06)
2022-06-06 23:48:41,405 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 660 |  Loss: (0.0028) | Acc: (99.93%) (42274/42304) | Learning rate: (1e-06)
2022-06-06 23:48:43,200 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 670 |  Loss: (0.0028) | Acc: (99.93%) (42914/42944) | Learning rate: (1e-06)
2022-06-06 23:48:44,993 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 680 |  Loss: (0.0028) | Acc: (99.93%) (43554/43584) | Learning rate: (1e-06)
2022-06-06 23:48:46,787 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 690 |  Loss: (0.0028) | Acc: (99.93%) (44194/44224) | Learning rate: (1e-06)
2022-06-06 23:48:48,583 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 700 |  Loss: (0.0028) | Acc: (99.93%) (44833/44864) | Learning rate: (1e-06)
2022-06-06 23:48:50,376 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 710 |  Loss: (0.0028) | Acc: (99.93%) (45473/45504) | Learning rate: (1e-06)
2022-06-06 23:48:52,169 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 720 |  Loss: (0.0027) | Acc: (99.93%) (46112/46144) | Learning rate: (1e-06)
2022-06-06 23:48:53,963 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 730 |  Loss: (0.0027) | Acc: (99.93%) (46752/46784) | Learning rate: (1e-06)
2022-06-06 23:48:55,758 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 740 |  Loss: (0.0027) | Acc: (99.93%) (47391/47424) | Learning rate: (1e-06)
2022-06-06 23:48:57,553 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 750 |  Loss: (0.0028) | Acc: (99.93%) (48030/48064) | Learning rate: (1e-06)
2022-06-06 23:48:59,349 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 760 |  Loss: (0.0027) | Acc: (99.93%) (48670/48704) | Learning rate: (1e-06)
2022-06-06 23:49:01,136 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 770 |  Loss: (0.0028) | Acc: (99.93%) (49309/49344) | Learning rate: (1e-06)
2022-06-06 23:49:02,924 - CIFAR10 Classifier - INFO - Epoch: 41 | Batch_idx: 780 |  Loss: (0.0028) | Acc: (99.93%) (49948/49984) | Learning rate: (1e-06)
2022-06-06 23:49:12,837 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0826) | Acc: (98.04%) (9804/10000)
2022-06-06 23:49:12,838 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:49:13,743 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 0 |  Loss: (0.0123) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:49:15,534 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 10 |  Loss: (0.0036) | Acc: (100.00%) (704/704) | Learning rate: (1e-06)
2022-06-06 23:49:17,325 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 20 |  Loss: (0.0029) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-06)
2022-06-06 23:49:19,116 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 30 |  Loss: (0.0021) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-06)
2022-06-06 23:49:20,910 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 40 |  Loss: (0.0021) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-06)
2022-06-06 23:49:22,704 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 50 |  Loss: (0.0021) | Acc: (99.97%) (3263/3264) | Learning rate: (1e-06)
2022-06-06 23:49:24,499 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 60 |  Loss: (0.0024) | Acc: (99.95%) (3902/3904) | Learning rate: (1e-06)
2022-06-06 23:49:26,296 - CIFAR10 Classifier - INFO - Epoch: 42 | Batch_idx: 70 |  Loss: (0.0022) | Acc: (99.96%) (4542/4544) | Learning rate: (1e-06)
2022-06-06 23:49:43,026 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0800) | Acc: (98.08%) (9808/10000)
2022-06-06 23:49:43,027 - CIFAR10 Classifier - INFO - Epoch time : 0:00:30
2022-06-06 23:49:43,900 - CIFAR10 Classifier - INFO - Epoch: 43 | Batch_idx: 0 |  Loss: (0.0001) | Acc: (100.00%) (64/64) | Learning rate: (1e-06)
2022-06-06 23:49:45,687 - CIFAR10 Classifier - INFO - Epoch: 43 | Batch_idx: 10 |  Loss: (0.0075) | Acc: (99.72%) (702/704) | Learning rate: (1e-06)
2022-06-06 23:49:47,475 - CIFAR10 Classifier - INFO - Epoch: 43 | Batch_idx: 20 |  Loss: (0.0050) | Acc: (99.78%) (1341/1344) | Learning rate: (1e-06)
2022-06-06 23:49:49,264 - CIFAR10 Classifier - INFO - Epoch: 43 | Batch_idx: 30 |  Loss: (0.0048) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-06)
2022-06-06 23:49:51,056 - CIFAR10 Classifier - INFO - Epoch: 43 | Batch_idx: 40 |  Loss: (0.0042) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-06)
2022-06-06 23:50:05,662 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0806) | Acc: (98.09%) (9809/10000)
2022-06-06 23:50:05,663 - CIFAR10 Classifier - INFO - Epoch time : 0:00:22
2022-06-06 23:50:06,477 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 0 |  Loss: (0.0696) | Acc: (96.88%) (62/64) | Learning rate: (1e-07)
2022-06-06 23:50:08,283 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 10 |  Loss: (0.0078) | Acc: (99.72%) (702/704) | Learning rate: (1e-07)
2022-06-06 23:50:10,073 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 20 |  Loss: (0.0056) | Acc: (99.78%) (1341/1344) | Learning rate: (1e-07)
2022-06-06 23:50:11,860 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 30 |  Loss: (0.0061) | Acc: (99.75%) (1979/1984) | Learning rate: (1e-07)
2022-06-06 23:50:13,651 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-07)
2022-06-06 23:50:15,440 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 50 |  Loss: (0.0041) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-07)
2022-06-06 23:50:17,232 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 60 |  Loss: (0.0038) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-07)
2022-06-06 23:50:19,022 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 70 |  Loss: (0.0034) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-07)
2022-06-06 23:50:20,813 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 80 |  Loss: (0.0035) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-07)
2022-06-06 23:50:22,607 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 90 |  Loss: (0.0034) | Acc: (99.90%) (5818/5824) | Learning rate: (1e-07)
2022-06-06 23:50:24,399 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 100 |  Loss: (0.0032) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-07)
2022-06-06 23:50:26,193 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 110 |  Loss: (0.0032) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-07)
2022-06-06 23:50:27,987 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 120 |  Loss: (0.0036) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-07)
2022-06-06 23:50:29,780 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 130 |  Loss: (0.0033) | Acc: (99.90%) (8376/8384) | Learning rate: (1e-07)
2022-06-06 23:50:31,574 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 140 |  Loss: (0.0036) | Acc: (99.90%) (9015/9024) | Learning rate: (1e-07)
2022-06-06 23:50:33,368 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 150 |  Loss: (0.0034) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-07)
2022-06-06 23:50:35,162 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 160 |  Loss: (0.0034) | Acc: (99.90%) (10294/10304) | Learning rate: (1e-07)
2022-06-06 23:50:36,955 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 170 |  Loss: (0.0033) | Acc: (99.91%) (10934/10944) | Learning rate: (1e-07)
2022-06-06 23:50:38,749 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 180 |  Loss: (0.0032) | Acc: (99.91%) (11574/11584) | Learning rate: (1e-07)
2022-06-06 23:50:40,542 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 190 |  Loss: (0.0031) | Acc: (99.92%) (12214/12224) | Learning rate: (1e-07)
2022-06-06 23:50:42,334 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 200 |  Loss: (0.0031) | Acc: (99.91%) (12853/12864) | Learning rate: (1e-07)
2022-06-06 23:50:44,129 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 210 |  Loss: (0.0031) | Acc: (99.92%) (13493/13504) | Learning rate: (1e-07)
2022-06-06 23:50:45,922 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 220 |  Loss: (0.0031) | Acc: (99.92%) (14133/14144) | Learning rate: (1e-07)
2022-06-06 23:50:47,716 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 230 |  Loss: (0.0030) | Acc: (99.93%) (14773/14784) | Learning rate: (1e-07)
2022-06-06 23:50:49,508 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 240 |  Loss: (0.0029) | Acc: (99.93%) (15413/15424) | Learning rate: (1e-07)
2022-06-06 23:50:51,303 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 250 |  Loss: (0.0030) | Acc: (99.92%) (16051/16064) | Learning rate: (1e-07)
2022-06-06 23:50:53,100 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 260 |  Loss: (0.0029) | Acc: (99.92%) (16691/16704) | Learning rate: (1e-07)
2022-06-06 23:50:54,896 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 270 |  Loss: (0.0029) | Acc: (99.92%) (17330/17344) | Learning rate: (1e-07)
2022-06-06 23:50:56,691 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 280 |  Loss: (0.0029) | Acc: (99.92%) (17970/17984) | Learning rate: (1e-07)
2022-06-06 23:50:58,487 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 290 |  Loss: (0.0030) | Acc: (99.91%) (18608/18624) | Learning rate: (1e-07)
2022-06-06 23:51:00,284 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 300 |  Loss: (0.0029) | Acc: (99.92%) (19248/19264) | Learning rate: (1e-07)
2022-06-06 23:51:02,081 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 310 |  Loss: (0.0029) | Acc: (99.92%) (19888/19904) | Learning rate: (1e-07)
2022-06-06 23:51:03,877 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 320 |  Loss: (0.0029) | Acc: (99.92%) (20527/20544) | Learning rate: (1e-07)
2022-06-06 23:51:05,674 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 330 |  Loss: (0.0028) | Acc: (99.92%) (21167/21184) | Learning rate: (1e-07)
2022-06-06 23:51:07,470 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 340 |  Loss: (0.0030) | Acc: (99.91%) (21805/21824) | Learning rate: (1e-07)
2022-06-06 23:51:09,264 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 350 |  Loss: (0.0030) | Acc: (99.92%) (22445/22464) | Learning rate: (1e-07)
2022-06-06 23:51:11,061 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 360 |  Loss: (0.0030) | Acc: (99.91%) (23083/23104) | Learning rate: (1e-07)
2022-06-06 23:51:12,857 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 370 |  Loss: (0.0031) | Acc: (99.91%) (23722/23744) | Learning rate: (1e-07)
2022-06-06 23:51:14,654 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 380 |  Loss: (0.0030) | Acc: (99.91%) (24362/24384) | Learning rate: (1e-07)
2022-06-06 23:51:16,451 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 390 |  Loss: (0.0030) | Acc: (99.91%) (25001/25024) | Learning rate: (1e-07)
2022-06-06 23:51:18,248 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 400 |  Loss: (0.0030) | Acc: (99.91%) (25641/25664) | Learning rate: (1e-07)
2022-06-06 23:51:20,046 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 410 |  Loss: (0.0030) | Acc: (99.91%) (26280/26304) | Learning rate: (1e-07)
2022-06-06 23:51:21,843 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 420 |  Loss: (0.0030) | Acc: (99.90%) (26918/26944) | Learning rate: (1e-07)
2022-06-06 23:51:23,639 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 430 |  Loss: (0.0030) | Acc: (99.90%) (27557/27584) | Learning rate: (1e-07)
2022-06-06 23:51:25,437 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 440 |  Loss: (0.0030) | Acc: (99.90%) (28197/28224) | Learning rate: (1e-07)
2022-06-06 23:51:27,235 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 450 |  Loss: (0.0030) | Acc: (99.91%) (28837/28864) | Learning rate: (1e-07)
2022-06-06 23:51:29,034 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 460 |  Loss: (0.0030) | Acc: (99.91%) (29476/29504) | Learning rate: (1e-07)
2022-06-06 23:51:30,831 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 470 |  Loss: (0.0030) | Acc: (99.91%) (30116/30144) | Learning rate: (1e-07)
2022-06-06 23:51:32,629 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 480 |  Loss: (0.0029) | Acc: (99.91%) (30756/30784) | Learning rate: (1e-07)
2022-06-06 23:51:34,427 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 490 |  Loss: (0.0029) | Acc: (99.91%) (31396/31424) | Learning rate: (1e-07)
2022-06-06 23:51:36,223 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 500 |  Loss: (0.0029) | Acc: (99.91%) (32036/32064) | Learning rate: (1e-07)
2022-06-06 23:51:38,021 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 510 |  Loss: (0.0030) | Acc: (99.91%) (32675/32704) | Learning rate: (1e-07)
2022-06-06 23:51:39,818 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 520 |  Loss: (0.0029) | Acc: (99.91%) (33315/33344) | Learning rate: (1e-07)
2022-06-06 23:51:41,617 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 530 |  Loss: (0.0029) | Acc: (99.91%) (33955/33984) | Learning rate: (1e-07)
2022-06-06 23:51:43,414 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 540 |  Loss: (0.0029) | Acc: (99.92%) (34595/34624) | Learning rate: (1e-07)
2022-06-06 23:51:45,210 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 550 |  Loss: (0.0029) | Acc: (99.92%) (35235/35264) | Learning rate: (1e-07)
2022-06-06 23:51:47,010 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 560 |  Loss: (0.0029) | Acc: (99.92%) (35875/35904) | Learning rate: (1e-07)
2022-06-06 23:51:48,809 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 570 |  Loss: (0.0028) | Acc: (99.92%) (36515/36544) | Learning rate: (1e-07)
2022-06-06 23:51:50,607 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 580 |  Loss: (0.0028) | Acc: (99.92%) (37155/37184) | Learning rate: (1e-07)
2022-06-06 23:51:52,406 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 590 |  Loss: (0.0028) | Acc: (99.92%) (37794/37824) | Learning rate: (1e-07)
2022-06-06 23:51:54,205 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 600 |  Loss: (0.0028) | Acc: (99.92%) (38433/38464) | Learning rate: (1e-07)
2022-06-06 23:51:56,003 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 610 |  Loss: (0.0028) | Acc: (99.92%) (39073/39104) | Learning rate: (1e-07)
2022-06-06 23:51:57,801 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 620 |  Loss: (0.0028) | Acc: (99.92%) (39712/39744) | Learning rate: (1e-07)
2022-06-06 23:51:59,598 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 630 |  Loss: (0.0028) | Acc: (99.92%) (40352/40384) | Learning rate: (1e-07)
2022-06-06 23:52:01,397 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 640 |  Loss: (0.0028) | Acc: (99.92%) (40992/41024) | Learning rate: (1e-07)
2022-06-06 23:52:03,196 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 650 |  Loss: (0.0028) | Acc: (99.92%) (41631/41664) | Learning rate: (1e-07)
2022-06-06 23:52:04,993 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 660 |  Loss: (0.0028) | Acc: (99.92%) (42270/42304) | Learning rate: (1e-07)
2022-06-06 23:52:06,790 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 670 |  Loss: (0.0029) | Acc: (99.92%) (42908/42944) | Learning rate: (1e-07)
2022-06-06 23:52:08,588 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 680 |  Loss: (0.0029) | Acc: (99.92%) (43547/43584) | Learning rate: (1e-07)
2022-06-06 23:52:10,386 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 690 |  Loss: (0.0029) | Acc: (99.92%) (44187/44224) | Learning rate: (1e-07)
2022-06-06 23:52:12,184 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 700 |  Loss: (0.0028) | Acc: (99.92%) (44827/44864) | Learning rate: (1e-07)
2022-06-06 23:52:13,982 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 710 |  Loss: (0.0029) | Acc: (99.91%) (45465/45504) | Learning rate: (1e-07)
2022-06-06 23:52:15,780 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 720 |  Loss: (0.0029) | Acc: (99.92%) (46105/46144) | Learning rate: (1e-07)
2022-06-06 23:52:17,580 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 730 |  Loss: (0.0029) | Acc: (99.91%) (46744/46784) | Learning rate: (1e-07)
2022-06-06 23:52:19,379 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 740 |  Loss: (0.0031) | Acc: (99.91%) (47382/47424) | Learning rate: (1e-07)
2022-06-06 23:52:21,177 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 750 |  Loss: (0.0031) | Acc: (99.91%) (48020/48064) | Learning rate: (1e-07)
2022-06-06 23:52:22,978 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 760 |  Loss: (0.0031) | Acc: (99.91%) (48660/48704) | Learning rate: (1e-07)
2022-06-06 23:52:24,770 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 770 |  Loss: (0.0030) | Acc: (99.91%) (49300/49344) | Learning rate: (1e-07)
2022-06-06 23:52:26,561 - CIFAR10 Classifier - INFO - Epoch: 44 | Batch_idx: 780 |  Loss: (0.0030) | Acc: (99.91%) (49940/49984) | Learning rate: (1e-07)
2022-06-06 23:52:36,531 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0795) | Acc: (98.03%) (9803/10000)
2022-06-06 23:52:36,532 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:52:37,461 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 0 |  Loss: (0.0004) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-06 23:52:39,250 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 10 |  Loss: (0.0142) | Acc: (99.43%) (700/704) | Learning rate: (1e-07)
2022-06-06 23:52:41,044 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 20 |  Loss: (0.0080) | Acc: (99.70%) (1340/1344) | Learning rate: (1e-07)
2022-06-06 23:52:42,838 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 30 |  Loss: (0.0061) | Acc: (99.80%) (1980/1984) | Learning rate: (1e-07)
2022-06-06 23:52:44,634 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.81%) (2619/2624) | Learning rate: (1e-07)
2022-06-06 23:52:46,430 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 50 |  Loss: (0.0048) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-07)
2022-06-06 23:52:48,226 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 60 |  Loss: (0.0049) | Acc: (99.82%) (3897/3904) | Learning rate: (1e-07)
2022-06-06 23:52:50,023 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 70 |  Loss: (0.0046) | Acc: (99.82%) (4536/4544) | Learning rate: (1e-07)
2022-06-06 23:52:51,820 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 80 |  Loss: (0.0043) | Acc: (99.85%) (5176/5184) | Learning rate: (1e-07)
2022-06-06 23:52:53,617 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 90 |  Loss: (0.0042) | Acc: (99.85%) (5815/5824) | Learning rate: (1e-07)
2022-06-06 23:52:55,413 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.83%) (6453/6464) | Learning rate: (1e-07)
2022-06-06 23:52:57,208 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.85%) (7093/7104) | Learning rate: (1e-07)
2022-06-06 23:52:59,004 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 120 |  Loss: (0.0042) | Acc: (99.86%) (7733/7744) | Learning rate: (1e-07)
2022-06-06 23:53:00,801 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 130 |  Loss: (0.0042) | Acc: (99.84%) (8371/8384) | Learning rate: (1e-07)
2022-06-06 23:53:02,598 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 140 |  Loss: (0.0041) | Acc: (99.86%) (9011/9024) | Learning rate: (1e-07)
2022-06-06 23:53:04,397 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 150 |  Loss: (0.0039) | Acc: (99.87%) (9651/9664) | Learning rate: (1e-07)
2022-06-06 23:53:06,194 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 160 |  Loss: (0.0038) | Acc: (99.87%) (10291/10304) | Learning rate: (1e-07)
2022-06-06 23:53:07,991 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 170 |  Loss: (0.0036) | Acc: (99.88%) (10931/10944) | Learning rate: (1e-07)
2022-06-06 23:53:09,787 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.87%) (11569/11584) | Learning rate: (1e-07)
2022-06-06 23:53:11,584 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 190 |  Loss: (0.0035) | Acc: (99.88%) (12209/12224) | Learning rate: (1e-07)
2022-06-06 23:53:13,380 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 200 |  Loss: (0.0034) | Acc: (99.88%) (12849/12864) | Learning rate: (1e-07)
2022-06-06 23:53:15,179 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 210 |  Loss: (0.0033) | Acc: (99.89%) (13489/13504) | Learning rate: (1e-07)
2022-06-06 23:53:16,976 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 220 |  Loss: (0.0032) | Acc: (99.89%) (14129/14144) | Learning rate: (1e-07)
2022-06-06 23:53:18,774 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 230 |  Loss: (0.0033) | Acc: (99.89%) (14768/14784) | Learning rate: (1e-07)
2022-06-06 23:53:20,571 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 240 |  Loss: (0.0033) | Acc: (99.89%) (15407/15424) | Learning rate: (1e-07)
2022-06-06 23:53:22,368 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 250 |  Loss: (0.0033) | Acc: (99.89%) (16047/16064) | Learning rate: (1e-07)
2022-06-06 23:53:24,167 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 260 |  Loss: (0.0032) | Acc: (99.89%) (16686/16704) | Learning rate: (1e-07)
2022-06-06 23:53:25,963 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 270 |  Loss: (0.0032) | Acc: (99.90%) (17326/17344) | Learning rate: (1e-07)
2022-06-06 23:53:27,761 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 280 |  Loss: (0.0033) | Acc: (99.89%) (17964/17984) | Learning rate: (1e-07)
2022-06-06 23:53:29,558 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 290 |  Loss: (0.0032) | Acc: (99.89%) (18604/18624) | Learning rate: (1e-07)
2022-06-06 23:53:31,354 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 300 |  Loss: (0.0032) | Acc: (99.90%) (19244/19264) | Learning rate: (1e-07)
2022-06-06 23:53:33,152 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 310 |  Loss: (0.0032) | Acc: (99.89%) (19883/19904) | Learning rate: (1e-07)
2022-06-06 23:53:34,949 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 320 |  Loss: (0.0032) | Acc: (99.90%) (20523/20544) | Learning rate: (1e-07)
2022-06-06 23:53:36,746 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 330 |  Loss: (0.0032) | Acc: (99.90%) (21162/21184) | Learning rate: (1e-07)
2022-06-06 23:53:38,544 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 340 |  Loss: (0.0032) | Acc: (99.89%) (21801/21824) | Learning rate: (1e-07)
2022-06-06 23:53:40,343 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 350 |  Loss: (0.0031) | Acc: (99.90%) (22441/22464) | Learning rate: (1e-07)
2022-06-06 23:53:42,140 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 360 |  Loss: (0.0031) | Acc: (99.90%) (23081/23104) | Learning rate: (1e-07)
2022-06-06 23:53:43,936 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 370 |  Loss: (0.0031) | Acc: (99.90%) (23720/23744) | Learning rate: (1e-07)
2022-06-06 23:53:45,734 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 380 |  Loss: (0.0031) | Acc: (99.90%) (24360/24384) | Learning rate: (1e-07)
2022-06-06 23:53:47,530 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 390 |  Loss: (0.0031) | Acc: (99.90%) (24999/25024) | Learning rate: (1e-07)
2022-06-06 23:53:49,327 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 400 |  Loss: (0.0031) | Acc: (99.90%) (25638/25664) | Learning rate: (1e-07)
2022-06-06 23:53:51,126 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 410 |  Loss: (0.0031) | Acc: (99.90%) (26277/26304) | Learning rate: (1e-07)
2022-06-06 23:53:52,924 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 420 |  Loss: (0.0030) | Acc: (99.90%) (26917/26944) | Learning rate: (1e-07)
2022-06-06 23:53:54,723 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 430 |  Loss: (0.0031) | Acc: (99.89%) (27555/27584) | Learning rate: (1e-07)
2022-06-06 23:53:56,520 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 440 |  Loss: (0.0033) | Acc: (99.89%) (28194/28224) | Learning rate: (1e-07)
2022-06-06 23:53:58,317 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 450 |  Loss: (0.0032) | Acc: (99.90%) (28834/28864) | Learning rate: (1e-07)
2022-06-06 23:54:00,115 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 460 |  Loss: (0.0032) | Acc: (99.89%) (29473/29504) | Learning rate: (1e-07)
2022-06-06 23:54:01,912 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 470 |  Loss: (0.0032) | Acc: (99.90%) (30113/30144) | Learning rate: (1e-07)
2022-06-06 23:54:03,710 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 480 |  Loss: (0.0032) | Acc: (99.90%) (30753/30784) | Learning rate: (1e-07)
2022-06-06 23:54:05,506 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 490 |  Loss: (0.0033) | Acc: (99.89%) (31391/31424) | Learning rate: (1e-07)
2022-06-06 23:54:07,303 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 500 |  Loss: (0.0032) | Acc: (99.90%) (32031/32064) | Learning rate: (1e-07)
2022-06-06 23:54:09,103 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 510 |  Loss: (0.0032) | Acc: (99.90%) (32670/32704) | Learning rate: (1e-07)
2022-06-06 23:54:10,902 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 520 |  Loss: (0.0032) | Acc: (99.90%) (33310/33344) | Learning rate: (1e-07)
2022-06-06 23:54:12,699 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 530 |  Loss: (0.0031) | Acc: (99.90%) (33950/33984) | Learning rate: (1e-07)
2022-06-06 23:54:14,497 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 540 |  Loss: (0.0031) | Acc: (99.90%) (34589/34624) | Learning rate: (1e-07)
2022-06-06 23:54:16,294 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 550 |  Loss: (0.0032) | Acc: (99.90%) (35228/35264) | Learning rate: (1e-07)
2022-06-06 23:54:18,095 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 560 |  Loss: (0.0033) | Acc: (99.90%) (35867/35904) | Learning rate: (1e-07)
2022-06-06 23:54:19,893 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 570 |  Loss: (0.0033) | Acc: (99.90%) (36506/36544) | Learning rate: (1e-07)
2022-06-06 23:54:21,691 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 580 |  Loss: (0.0033) | Acc: (99.90%) (37146/37184) | Learning rate: (1e-07)
2022-06-06 23:54:23,490 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 590 |  Loss: (0.0033) | Acc: (99.90%) (37785/37824) | Learning rate: (1e-07)
2022-06-06 23:54:25,287 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 600 |  Loss: (0.0033) | Acc: (99.89%) (38423/38464) | Learning rate: (1e-07)
2022-06-06 23:54:27,086 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 610 |  Loss: (0.0033) | Acc: (99.90%) (39063/39104) | Learning rate: (1e-07)
2022-06-06 23:54:28,883 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 620 |  Loss: (0.0033) | Acc: (99.90%) (39703/39744) | Learning rate: (1e-07)
2022-06-06 23:54:30,680 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 630 |  Loss: (0.0032) | Acc: (99.90%) (40343/40384) | Learning rate: (1e-07)
2022-06-06 23:54:32,477 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 640 |  Loss: (0.0032) | Acc: (99.90%) (40983/41024) | Learning rate: (1e-07)
2022-06-06 23:54:34,277 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 650 |  Loss: (0.0032) | Acc: (99.90%) (41622/41664) | Learning rate: (1e-07)
2022-06-06 23:54:36,074 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 660 |  Loss: (0.0032) | Acc: (99.90%) (42261/42304) | Learning rate: (1e-07)
2022-06-06 23:54:37,871 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 670 |  Loss: (0.0032) | Acc: (99.90%) (42899/42944) | Learning rate: (1e-07)
2022-06-06 23:54:39,670 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 680 |  Loss: (0.0032) | Acc: (99.90%) (43539/43584) | Learning rate: (1e-07)
2022-06-06 23:54:41,469 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 690 |  Loss: (0.0032) | Acc: (99.90%) (44179/44224) | Learning rate: (1e-07)
2022-06-06 23:54:43,269 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 700 |  Loss: (0.0032) | Acc: (99.90%) (44819/44864) | Learning rate: (1e-07)
2022-06-06 23:54:45,067 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 710 |  Loss: (0.0032) | Acc: (99.90%) (45457/45504) | Learning rate: (1e-07)
2022-06-06 23:54:46,864 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 720 |  Loss: (0.0032) | Acc: (99.90%) (46097/46144) | Learning rate: (1e-07)
2022-06-06 23:54:48,663 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 730 |  Loss: (0.0031) | Acc: (99.90%) (46736/46784) | Learning rate: (1e-07)
2022-06-06 23:54:50,461 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 740 |  Loss: (0.0032) | Acc: (99.90%) (47376/47424) | Learning rate: (1e-07)
2022-06-06 23:54:52,259 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 750 |  Loss: (0.0031) | Acc: (99.90%) (48016/48064) | Learning rate: (1e-07)
2022-06-06 23:54:54,059 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 760 |  Loss: (0.0031) | Acc: (99.90%) (48656/48704) | Learning rate: (1e-07)
2022-06-06 23:54:55,851 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 770 |  Loss: (0.0031) | Acc: (99.90%) (49296/49344) | Learning rate: (1e-07)
2022-06-06 23:54:57,641 - CIFAR10 Classifier - INFO - Epoch: 45 | Batch_idx: 780 |  Loss: (0.0031) | Acc: (99.90%) (49936/49984) | Learning rate: (1e-07)
2022-06-06 23:55:07,600 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0812) | Acc: (98.07%) (9807/10000)
2022-06-06 23:55:07,601 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:55:08,479 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 0 |  Loss: (0.0006) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-06 23:55:10,273 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 10 |  Loss: (0.0031) | Acc: (99.86%) (703/704) | Learning rate: (1e-07)
2022-06-06 23:55:12,065 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 20 |  Loss: (0.0037) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-07)
2022-06-06 23:55:13,859 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 30 |  Loss: (0.0026) | Acc: (99.90%) (1982/1984) | Learning rate: (1e-07)
2022-06-06 23:55:15,655 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 40 |  Loss: (0.0023) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-07)
2022-06-06 23:55:17,451 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 50 |  Loss: (0.0023) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-07)
2022-06-06 23:55:19,247 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 60 |  Loss: (0.0022) | Acc: (99.95%) (3902/3904) | Learning rate: (1e-07)
2022-06-06 23:55:21,042 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 70 |  Loss: (0.0020) | Acc: (99.96%) (4542/4544) | Learning rate: (1e-07)
2022-06-06 23:55:22,838 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 80 |  Loss: (0.0024) | Acc: (99.92%) (5180/5184) | Learning rate: (1e-07)
2022-06-06 23:55:24,635 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 90 |  Loss: (0.0022) | Acc: (99.93%) (5820/5824) | Learning rate: (1e-07)
2022-06-06 23:55:26,432 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 100 |  Loss: (0.0023) | Acc: (99.92%) (6459/6464) | Learning rate: (1e-07)
2022-06-06 23:55:28,228 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 110 |  Loss: (0.0022) | Acc: (99.93%) (7099/7104) | Learning rate: (1e-07)
2022-06-06 23:55:30,024 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 120 |  Loss: (0.0023) | Acc: (99.94%) (7739/7744) | Learning rate: (1e-07)
2022-06-06 23:55:31,820 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 130 |  Loss: (0.0024) | Acc: (99.93%) (8378/8384) | Learning rate: (1e-07)
2022-06-06 23:55:33,615 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 140 |  Loss: (0.0024) | Acc: (99.93%) (9018/9024) | Learning rate: (1e-07)
2022-06-06 23:55:35,412 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 150 |  Loss: (0.0023) | Acc: (99.94%) (9658/9664) | Learning rate: (1e-07)
2022-06-06 23:55:37,208 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 160 |  Loss: (0.0022) | Acc: (99.94%) (10298/10304) | Learning rate: (1e-07)
2022-06-06 23:55:39,004 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 170 |  Loss: (0.0023) | Acc: (99.95%) (10938/10944) | Learning rate: (1e-07)
2022-06-06 23:55:40,800 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 180 |  Loss: (0.0022) | Acc: (99.95%) (11578/11584) | Learning rate: (1e-07)
2022-06-06 23:55:42,595 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 190 |  Loss: (0.0022) | Acc: (99.95%) (12218/12224) | Learning rate: (1e-07)
2022-06-06 23:55:44,391 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 200 |  Loss: (0.0021) | Acc: (99.95%) (12858/12864) | Learning rate: (1e-07)
2022-06-06 23:55:46,188 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 210 |  Loss: (0.0022) | Acc: (99.96%) (13498/13504) | Learning rate: (1e-07)
2022-06-06 23:55:47,985 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 220 |  Loss: (0.0024) | Acc: (99.95%) (14137/14144) | Learning rate: (1e-07)
2022-06-06 23:55:49,782 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 230 |  Loss: (0.0023) | Acc: (99.95%) (14777/14784) | Learning rate: (1e-07)
2022-06-06 23:55:51,578 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 240 |  Loss: (0.0024) | Acc: (99.95%) (15416/15424) | Learning rate: (1e-07)
2022-06-06 23:55:53,374 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 250 |  Loss: (0.0023) | Acc: (99.95%) (16056/16064) | Learning rate: (1e-07)
2022-06-06 23:55:55,171 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 260 |  Loss: (0.0023) | Acc: (99.95%) (16696/16704) | Learning rate: (1e-07)
2022-06-06 23:55:56,966 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 270 |  Loss: (0.0024) | Acc: (99.95%) (17335/17344) | Learning rate: (1e-07)
2022-06-06 23:55:58,763 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 280 |  Loss: (0.0026) | Acc: (99.94%) (17973/17984) | Learning rate: (1e-07)
2022-06-06 23:56:00,561 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 290 |  Loss: (0.0026) | Acc: (99.94%) (18613/18624) | Learning rate: (1e-07)
2022-06-06 23:56:02,359 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 300 |  Loss: (0.0025) | Acc: (99.94%) (19253/19264) | Learning rate: (1e-07)
2022-06-06 23:56:04,157 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 310 |  Loss: (0.0029) | Acc: (99.93%) (19890/19904) | Learning rate: (1e-07)
2022-06-06 23:56:05,954 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 320 |  Loss: (0.0030) | Acc: (99.92%) (20528/20544) | Learning rate: (1e-07)
2022-06-06 23:56:07,750 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 330 |  Loss: (0.0030) | Acc: (99.92%) (21167/21184) | Learning rate: (1e-07)
2022-06-06 23:56:09,546 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 340 |  Loss: (0.0029) | Acc: (99.92%) (21807/21824) | Learning rate: (1e-07)
2022-06-06 23:56:11,343 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 350 |  Loss: (0.0030) | Acc: (99.92%) (22446/22464) | Learning rate: (1e-07)
2022-06-06 23:56:13,140 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 360 |  Loss: (0.0030) | Acc: (99.92%) (23085/23104) | Learning rate: (1e-07)
2022-06-06 23:56:14,939 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 370 |  Loss: (0.0029) | Acc: (99.92%) (23725/23744) | Learning rate: (1e-07)
2022-06-06 23:56:16,736 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 380 |  Loss: (0.0029) | Acc: (99.92%) (24365/24384) | Learning rate: (1e-07)
2022-06-06 23:56:18,534 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 390 |  Loss: (0.0031) | Acc: (99.92%) (25003/25024) | Learning rate: (1e-07)
2022-06-06 23:56:20,330 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 400 |  Loss: (0.0032) | Acc: (99.91%) (25642/25664) | Learning rate: (1e-07)
2022-06-06 23:56:22,126 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 410 |  Loss: (0.0031) | Acc: (99.92%) (26282/26304) | Learning rate: (1e-07)
2022-06-06 23:56:23,922 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 420 |  Loss: (0.0031) | Acc: (99.92%) (26922/26944) | Learning rate: (1e-07)
2022-06-06 23:56:25,721 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 430 |  Loss: (0.0031) | Acc: (99.92%) (27562/27584) | Learning rate: (1e-07)
2022-06-06 23:56:27,516 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 440 |  Loss: (0.0031) | Acc: (99.92%) (28201/28224) | Learning rate: (1e-07)
2022-06-06 23:56:29,313 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 450 |  Loss: (0.0031) | Acc: (99.92%) (28840/28864) | Learning rate: (1e-07)
2022-06-06 23:56:31,111 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 460 |  Loss: (0.0031) | Acc: (99.92%) (29480/29504) | Learning rate: (1e-07)
2022-06-06 23:56:32,909 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 470 |  Loss: (0.0031) | Acc: (99.92%) (30120/30144) | Learning rate: (1e-07)
2022-06-06 23:56:34,707 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 480 |  Loss: (0.0032) | Acc: (99.92%) (30758/30784) | Learning rate: (1e-07)
2022-06-06 23:56:36,503 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 490 |  Loss: (0.0031) | Acc: (99.92%) (31398/31424) | Learning rate: (1e-07)
2022-06-06 23:56:38,299 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 500 |  Loss: (0.0031) | Acc: (99.92%) (32038/32064) | Learning rate: (1e-07)
2022-06-06 23:56:40,096 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 510 |  Loss: (0.0031) | Acc: (99.92%) (32678/32704) | Learning rate: (1e-07)
2022-06-06 23:56:41,891 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 520 |  Loss: (0.0031) | Acc: (99.92%) (33317/33344) | Learning rate: (1e-07)
2022-06-06 23:56:43,690 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 530 |  Loss: (0.0030) | Acc: (99.92%) (33957/33984) | Learning rate: (1e-07)
2022-06-06 23:56:45,488 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 540 |  Loss: (0.0032) | Acc: (99.91%) (34594/34624) | Learning rate: (1e-07)
2022-06-06 23:56:47,287 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 550 |  Loss: (0.0032) | Acc: (99.91%) (35234/35264) | Learning rate: (1e-07)
2022-06-06 23:56:49,085 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 560 |  Loss: (0.0031) | Acc: (99.92%) (35874/35904) | Learning rate: (1e-07)
2022-06-06 23:56:50,883 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 570 |  Loss: (0.0031) | Acc: (99.92%) (36514/36544) | Learning rate: (1e-07)
2022-06-06 23:56:52,680 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 580 |  Loss: (0.0030) | Acc: (99.92%) (37154/37184) | Learning rate: (1e-07)
2022-06-06 23:56:54,476 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 590 |  Loss: (0.0030) | Acc: (99.92%) (37794/37824) | Learning rate: (1e-07)
2022-06-06 23:56:56,272 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 600 |  Loss: (0.0030) | Acc: (99.92%) (38432/38464) | Learning rate: (1e-07)
2022-06-06 23:56:58,069 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 610 |  Loss: (0.0031) | Acc: (99.92%) (39071/39104) | Learning rate: (1e-07)
2022-06-06 23:56:59,867 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 620 |  Loss: (0.0031) | Acc: (99.91%) (39709/39744) | Learning rate: (1e-07)
2022-06-06 23:57:01,664 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 630 |  Loss: (0.0031) | Acc: (99.91%) (40349/40384) | Learning rate: (1e-07)
2022-06-06 23:57:03,463 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 640 |  Loss: (0.0031) | Acc: (99.91%) (40988/41024) | Learning rate: (1e-07)
2022-06-06 23:57:05,261 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 650 |  Loss: (0.0031) | Acc: (99.91%) (41628/41664) | Learning rate: (1e-07)
2022-06-06 23:57:07,060 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 660 |  Loss: (0.0032) | Acc: (99.91%) (42267/42304) | Learning rate: (1e-07)
2022-06-06 23:57:08,859 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 670 |  Loss: (0.0031) | Acc: (99.91%) (42907/42944) | Learning rate: (1e-07)
2022-06-06 23:57:10,659 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 680 |  Loss: (0.0031) | Acc: (99.92%) (43547/43584) | Learning rate: (1e-07)
2022-06-06 23:57:12,458 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 690 |  Loss: (0.0031) | Acc: (99.91%) (44186/44224) | Learning rate: (1e-07)
2022-06-06 23:57:14,256 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 700 |  Loss: (0.0032) | Acc: (99.91%) (44824/44864) | Learning rate: (1e-07)
2022-06-06 23:57:16,055 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 710 |  Loss: (0.0032) | Acc: (99.91%) (45464/45504) | Learning rate: (1e-07)
2022-06-06 23:57:17,853 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 720 |  Loss: (0.0032) | Acc: (99.91%) (46104/46144) | Learning rate: (1e-07)
2022-06-06 23:57:19,652 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 730 |  Loss: (0.0032) | Acc: (99.91%) (46742/46784) | Learning rate: (1e-07)
2022-06-06 23:57:21,451 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 740 |  Loss: (0.0032) | Acc: (99.91%) (47382/47424) | Learning rate: (1e-07)
2022-06-06 23:57:23,249 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 750 |  Loss: (0.0031) | Acc: (99.91%) (48022/48064) | Learning rate: (1e-07)
2022-06-06 23:57:25,047 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 760 |  Loss: (0.0031) | Acc: (99.91%) (48662/48704) | Learning rate: (1e-07)
2022-06-06 23:57:26,836 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 770 |  Loss: (0.0031) | Acc: (99.91%) (49302/49344) | Learning rate: (1e-07)
2022-06-06 23:57:28,629 - CIFAR10 Classifier - INFO - Epoch: 46 | Batch_idx: 780 |  Loss: (0.0031) | Acc: (99.91%) (49941/49984) | Learning rate: (1e-07)
2022-06-06 23:57:38,556 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0817) | Acc: (97.95%) (9795/10000)
2022-06-06 23:57:38,557 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-06 23:57:39,457 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 0 |  Loss: (0.0061) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-06 23:57:41,248 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 10 |  Loss: (0.0042) | Acc: (99.86%) (703/704) | Learning rate: (1e-07)
2022-06-06 23:57:43,041 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 20 |  Loss: (0.0026) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-07)
2022-06-06 23:57:44,837 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 30 |  Loss: (0.0022) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-07)
2022-06-06 23:57:46,633 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 40 |  Loss: (0.0019) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-07)
2022-06-06 23:57:48,429 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 50 |  Loss: (0.0022) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-07)
2022-06-06 23:57:50,226 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 60 |  Loss: (0.0020) | Acc: (99.95%) (3902/3904) | Learning rate: (1e-07)
2022-06-06 23:57:52,023 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 70 |  Loss: (0.0022) | Acc: (99.93%) (4541/4544) | Learning rate: (1e-07)
2022-06-06 23:57:53,820 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 80 |  Loss: (0.0022) | Acc: (99.94%) (5181/5184) | Learning rate: (1e-07)
2022-06-06 23:57:55,616 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 90 |  Loss: (0.0020) | Acc: (99.95%) (5821/5824) | Learning rate: (1e-07)
2022-06-06 23:57:57,410 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 100 |  Loss: (0.0021) | Acc: (99.95%) (6461/6464) | Learning rate: (1e-07)
2022-06-06 23:57:59,205 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 110 |  Loss: (0.0022) | Acc: (99.94%) (7100/7104) | Learning rate: (1e-07)
2022-06-06 23:58:01,004 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 120 |  Loss: (0.0022) | Acc: (99.95%) (7740/7744) | Learning rate: (1e-07)
2022-06-06 23:58:02,800 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 130 |  Loss: (0.0026) | Acc: (99.94%) (8379/8384) | Learning rate: (1e-07)
2022-06-06 23:58:04,598 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 140 |  Loss: (0.0027) | Acc: (99.94%) (9019/9024) | Learning rate: (1e-07)
2022-06-06 23:58:06,394 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 150 |  Loss: (0.0027) | Acc: (99.94%) (9658/9664) | Learning rate: (1e-07)
2022-06-06 23:58:08,191 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 160 |  Loss: (0.0025) | Acc: (99.94%) (10298/10304) | Learning rate: (1e-07)
2022-06-06 23:58:09,986 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 170 |  Loss: (0.0024) | Acc: (99.95%) (10938/10944) | Learning rate: (1e-07)
2022-06-06 23:58:11,782 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 180 |  Loss: (0.0024) | Acc: (99.95%) (11578/11584) | Learning rate: (1e-07)
2022-06-06 23:58:13,578 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 190 |  Loss: (0.0027) | Acc: (99.94%) (12217/12224) | Learning rate: (1e-07)
2022-06-06 23:58:15,376 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 200 |  Loss: (0.0026) | Acc: (99.95%) (12857/12864) | Learning rate: (1e-07)
2022-06-06 23:58:17,172 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 210 |  Loss: (0.0029) | Acc: (99.93%) (13495/13504) | Learning rate: (1e-07)
2022-06-06 23:58:18,969 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 220 |  Loss: (0.0029) | Acc: (99.94%) (14135/14144) | Learning rate: (1e-07)
2022-06-06 23:58:20,766 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 230 |  Loss: (0.0030) | Acc: (99.93%) (14774/14784) | Learning rate: (1e-07)
2022-06-06 23:58:22,563 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 240 |  Loss: (0.0031) | Acc: (99.92%) (15412/15424) | Learning rate: (1e-07)
2022-06-06 23:58:24,359 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 250 |  Loss: (0.0031) | Acc: (99.93%) (16052/16064) | Learning rate: (1e-07)
2022-06-06 23:58:26,156 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 260 |  Loss: (0.0032) | Acc: (99.92%) (16691/16704) | Learning rate: (1e-07)
2022-06-06 23:58:27,954 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 270 |  Loss: (0.0031) | Acc: (99.93%) (17331/17344) | Learning rate: (1e-07)
2022-06-06 23:58:29,752 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 280 |  Loss: (0.0031) | Acc: (99.93%) (17971/17984) | Learning rate: (1e-07)
2022-06-06 23:58:31,550 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 290 |  Loss: (0.0030) | Acc: (99.93%) (18611/18624) | Learning rate: (1e-07)
2022-06-06 23:58:33,347 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 300 |  Loss: (0.0030) | Acc: (99.92%) (19249/19264) | Learning rate: (1e-07)
2022-06-06 23:58:35,145 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 310 |  Loss: (0.0029) | Acc: (99.92%) (19889/19904) | Learning rate: (1e-07)
2022-06-06 23:58:36,943 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 320 |  Loss: (0.0029) | Acc: (99.93%) (20529/20544) | Learning rate: (1e-07)
2022-06-06 23:58:38,739 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 330 |  Loss: (0.0030) | Acc: (99.92%) (21168/21184) | Learning rate: (1e-07)
2022-06-06 23:58:40,535 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 340 |  Loss: (0.0029) | Acc: (99.93%) (21808/21824) | Learning rate: (1e-07)
2022-06-06 23:58:42,333 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 350 |  Loss: (0.0030) | Acc: (99.92%) (22447/22464) | Learning rate: (1e-07)
2022-06-06 23:58:44,130 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 360 |  Loss: (0.0030) | Acc: (99.93%) (23087/23104) | Learning rate: (1e-07)
2022-06-06 23:58:45,928 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 370 |  Loss: (0.0029) | Acc: (99.93%) (23727/23744) | Learning rate: (1e-07)
2022-06-06 23:58:47,725 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 380 |  Loss: (0.0029) | Acc: (99.93%) (24367/24384) | Learning rate: (1e-07)
2022-06-06 23:58:49,521 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 390 |  Loss: (0.0029) | Acc: (99.93%) (25007/25024) | Learning rate: (1e-07)
2022-06-06 23:58:51,318 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 400 |  Loss: (0.0029) | Acc: (99.93%) (25647/25664) | Learning rate: (1e-07)
2022-06-06 23:58:53,114 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 410 |  Loss: (0.0029) | Acc: (99.94%) (26287/26304) | Learning rate: (1e-07)
2022-06-06 23:58:54,910 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 420 |  Loss: (0.0028) | Acc: (99.94%) (26927/26944) | Learning rate: (1e-07)
2022-06-06 23:58:56,707 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 430 |  Loss: (0.0028) | Acc: (99.93%) (27566/27584) | Learning rate: (1e-07)
2022-06-06 23:58:58,505 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 440 |  Loss: (0.0028) | Acc: (99.94%) (28206/28224) | Learning rate: (1e-07)
2022-06-06 23:59:00,301 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 450 |  Loss: (0.0028) | Acc: (99.94%) (28846/28864) | Learning rate: (1e-07)
2022-06-06 23:59:02,097 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 460 |  Loss: (0.0027) | Acc: (99.94%) (29486/29504) | Learning rate: (1e-07)
2022-06-06 23:59:03,895 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 470 |  Loss: (0.0027) | Acc: (99.94%) (30126/30144) | Learning rate: (1e-07)
2022-06-06 23:59:05,692 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 480 |  Loss: (0.0027) | Acc: (99.94%) (30765/30784) | Learning rate: (1e-07)
2022-06-06 23:59:07,487 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 490 |  Loss: (0.0028) | Acc: (99.94%) (31404/31424) | Learning rate: (1e-07)
2022-06-06 23:59:09,283 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 500 |  Loss: (0.0028) | Acc: (99.94%) (32044/32064) | Learning rate: (1e-07)
2022-06-06 23:59:11,081 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 510 |  Loss: (0.0028) | Acc: (99.94%) (32684/32704) | Learning rate: (1e-07)
2022-06-06 23:59:12,878 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 520 |  Loss: (0.0027) | Acc: (99.94%) (33324/33344) | Learning rate: (1e-07)
2022-06-06 23:59:14,676 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 530 |  Loss: (0.0028) | Acc: (99.94%) (33963/33984) | Learning rate: (1e-07)
2022-06-06 23:59:16,473 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 540 |  Loss: (0.0028) | Acc: (99.94%) (34603/34624) | Learning rate: (1e-07)
2022-06-06 23:59:18,270 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 550 |  Loss: (0.0028) | Acc: (99.94%) (35243/35264) | Learning rate: (1e-07)
2022-06-06 23:59:20,068 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 560 |  Loss: (0.0027) | Acc: (99.94%) (35883/35904) | Learning rate: (1e-07)
2022-06-06 23:59:21,864 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 570 |  Loss: (0.0027) | Acc: (99.94%) (36523/36544) | Learning rate: (1e-07)
2022-06-06 23:59:23,662 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 580 |  Loss: (0.0027) | Acc: (99.94%) (37163/37184) | Learning rate: (1e-07)
2022-06-06 23:59:25,459 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 590 |  Loss: (0.0027) | Acc: (99.94%) (37803/37824) | Learning rate: (1e-07)
2022-06-06 23:59:27,255 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 600 |  Loss: (0.0027) | Acc: (99.94%) (38442/38464) | Learning rate: (1e-07)
2022-06-06 23:59:29,055 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 610 |  Loss: (0.0027) | Acc: (99.94%) (39081/39104) | Learning rate: (1e-07)
2022-06-06 23:59:30,853 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 620 |  Loss: (0.0027) | Acc: (99.94%) (39721/39744) | Learning rate: (1e-07)
2022-06-06 23:59:32,652 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 630 |  Loss: (0.0027) | Acc: (99.94%) (40359/40384) | Learning rate: (1e-07)
2022-06-06 23:59:34,450 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 640 |  Loss: (0.0027) | Acc: (99.94%) (40999/41024) | Learning rate: (1e-07)
2022-06-06 23:59:36,249 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 650 |  Loss: (0.0027) | Acc: (99.94%) (41639/41664) | Learning rate: (1e-07)
2022-06-06 23:59:38,047 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 660 |  Loss: (0.0027) | Acc: (99.94%) (42278/42304) | Learning rate: (1e-07)
2022-06-06 23:59:39,845 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 670 |  Loss: (0.0026) | Acc: (99.94%) (42918/42944) | Learning rate: (1e-07)
2022-06-06 23:59:41,642 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 680 |  Loss: (0.0026) | Acc: (99.94%) (43558/43584) | Learning rate: (1e-07)
2022-06-06 23:59:43,440 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 690 |  Loss: (0.0026) | Acc: (99.94%) (44197/44224) | Learning rate: (1e-07)
2022-06-06 23:59:45,236 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 700 |  Loss: (0.0028) | Acc: (99.94%) (44835/44864) | Learning rate: (1e-07)
2022-06-06 23:59:47,032 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 710 |  Loss: (0.0028) | Acc: (99.94%) (45475/45504) | Learning rate: (1e-07)
2022-06-06 23:59:48,829 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 720 |  Loss: (0.0027) | Acc: (99.94%) (46115/46144) | Learning rate: (1e-07)
2022-06-06 23:59:50,627 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 730 |  Loss: (0.0028) | Acc: (99.94%) (46754/46784) | Learning rate: (1e-07)
2022-06-06 23:59:52,426 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 740 |  Loss: (0.0027) | Acc: (99.94%) (47394/47424) | Learning rate: (1e-07)
2022-06-06 23:59:54,224 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 750 |  Loss: (0.0028) | Acc: (99.94%) (48033/48064) | Learning rate: (1e-07)
2022-06-06 23:59:56,023 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 760 |  Loss: (0.0027) | Acc: (99.94%) (48673/48704) | Learning rate: (1e-07)
2022-06-06 23:59:57,815 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 770 |  Loss: (0.0027) | Acc: (99.94%) (49313/49344) | Learning rate: (1e-07)
2022-06-06 23:59:59,606 - CIFAR10 Classifier - INFO - Epoch: 47 | Batch_idx: 780 |  Loss: (0.0027) | Acc: (99.94%) (49953/49984) | Learning rate: (1e-07)
2022-06-07 00:00:09,563 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0843) | Acc: (98.02%) (9802/10000)
2022-06-07 00:00:09,563 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-07 00:00:10,420 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 0 |  Loss: (0.0002) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-07 00:00:12,228 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 10 |  Loss: (0.0010) | Acc: (100.00%) (704/704) | Learning rate: (1e-07)
2022-06-07 00:00:14,024 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 20 |  Loss: (0.0008) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-07)
2022-06-07 00:00:15,816 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 30 |  Loss: (0.0018) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-07)
2022-06-07 00:00:17,614 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 40 |  Loss: (0.0028) | Acc: (99.92%) (2622/2624) | Learning rate: (1e-07)
2022-06-07 00:00:19,410 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 50 |  Loss: (0.0026) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-07)
2022-06-07 00:00:21,205 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 60 |  Loss: (0.0039) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-07)
2022-06-07 00:00:23,000 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 70 |  Loss: (0.0036) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-07)
2022-06-07 00:00:24,796 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 80 |  Loss: (0.0042) | Acc: (99.86%) (5177/5184) | Learning rate: (1e-07)
2022-06-07 00:00:26,594 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 90 |  Loss: (0.0041) | Acc: (99.86%) (5816/5824) | Learning rate: (1e-07)
2022-06-07 00:00:28,392 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 100 |  Loss: (0.0041) | Acc: (99.88%) (6456/6464) | Learning rate: (1e-07)
2022-06-07 00:00:30,190 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 110 |  Loss: (0.0039) | Acc: (99.89%) (7096/7104) | Learning rate: (1e-07)
2022-06-07 00:00:31,986 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 120 |  Loss: (0.0039) | Acc: (99.88%) (7735/7744) | Learning rate: (1e-07)
2022-06-07 00:00:33,782 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 130 |  Loss: (0.0037) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-07)
2022-06-07 00:00:35,579 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 140 |  Loss: (0.0038) | Acc: (99.89%) (9014/9024) | Learning rate: (1e-07)
2022-06-07 00:00:37,375 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 150 |  Loss: (0.0038) | Acc: (99.90%) (9654/9664) | Learning rate: (1e-07)
2022-06-07 00:00:39,173 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 160 |  Loss: (0.0040) | Acc: (99.88%) (10292/10304) | Learning rate: (1e-07)
2022-06-07 00:00:40,969 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 170 |  Loss: (0.0039) | Acc: (99.89%) (10932/10944) | Learning rate: (1e-07)
2022-06-07 00:00:42,766 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 180 |  Loss: (0.0039) | Acc: (99.89%) (11571/11584) | Learning rate: (1e-07)
2022-06-07 00:00:44,561 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 190 |  Loss: (0.0037) | Acc: (99.89%) (12211/12224) | Learning rate: (1e-07)
2022-06-07 00:00:46,355 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 200 |  Loss: (0.0036) | Acc: (99.90%) (12851/12864) | Learning rate: (1e-07)
2022-06-07 00:00:48,150 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 210 |  Loss: (0.0039) | Acc: (99.89%) (13489/13504) | Learning rate: (1e-07)
2022-06-07 00:00:49,947 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 220 |  Loss: (0.0038) | Acc: (99.89%) (14129/14144) | Learning rate: (1e-07)
2022-06-07 00:00:51,743 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 230 |  Loss: (0.0038) | Acc: (99.90%) (14769/14784) | Learning rate: (1e-07)
2022-06-07 00:00:53,539 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 240 |  Loss: (0.0039) | Acc: (99.90%) (15408/15424) | Learning rate: (1e-07)
2022-06-07 00:00:55,334 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 250 |  Loss: (0.0039) | Acc: (99.89%) (16046/16064) | Learning rate: (1e-07)
2022-06-07 00:00:57,131 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 260 |  Loss: (0.0038) | Acc: (99.89%) (16686/16704) | Learning rate: (1e-07)
2022-06-07 00:00:58,926 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 270 |  Loss: (0.0037) | Acc: (99.90%) (17326/17344) | Learning rate: (1e-07)
2022-06-07 00:01:00,722 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 280 |  Loss: (0.0037) | Acc: (99.89%) (17965/17984) | Learning rate: (1e-07)
2022-06-07 00:01:02,518 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 290 |  Loss: (0.0038) | Acc: (99.89%) (18603/18624) | Learning rate: (1e-07)
2022-06-07 00:01:04,314 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 300 |  Loss: (0.0039) | Acc: (99.89%) (19242/19264) | Learning rate: (1e-07)
2022-06-07 00:01:06,110 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 310 |  Loss: (0.0039) | Acc: (99.88%) (19881/19904) | Learning rate: (1e-07)
2022-06-07 00:01:07,905 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 320 |  Loss: (0.0040) | Acc: (99.88%) (20520/20544) | Learning rate: (1e-07)
2022-06-07 00:01:09,700 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 330 |  Loss: (0.0039) | Acc: (99.89%) (21160/21184) | Learning rate: (1e-07)
2022-06-07 00:01:11,496 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 340 |  Loss: (0.0038) | Acc: (99.89%) (21800/21824) | Learning rate: (1e-07)
2022-06-07 00:01:13,292 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.89%) (22439/22464) | Learning rate: (1e-07)
2022-06-07 00:01:15,088 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 360 |  Loss: (0.0037) | Acc: (99.89%) (23079/23104) | Learning rate: (1e-07)
2022-06-07 00:01:16,883 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 370 |  Loss: (0.0038) | Acc: (99.89%) (23717/23744) | Learning rate: (1e-07)
2022-06-07 00:01:18,679 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 380 |  Loss: (0.0037) | Acc: (99.89%) (24357/24384) | Learning rate: (1e-07)
2022-06-07 00:01:20,476 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 390 |  Loss: (0.0039) | Acc: (99.88%) (24995/25024) | Learning rate: (1e-07)
2022-06-07 00:01:22,271 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 400 |  Loss: (0.0038) | Acc: (99.89%) (25635/25664) | Learning rate: (1e-07)
2022-06-07 00:01:24,068 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 410 |  Loss: (0.0038) | Acc: (99.89%) (26274/26304) | Learning rate: (1e-07)
2022-06-07 00:01:25,864 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 420 |  Loss: (0.0040) | Acc: (99.88%) (26913/26944) | Learning rate: (1e-07)
2022-06-07 00:01:27,662 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 430 |  Loss: (0.0039) | Acc: (99.89%) (27553/27584) | Learning rate: (1e-07)
2022-06-07 00:01:29,459 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 440 |  Loss: (0.0039) | Acc: (99.89%) (28192/28224) | Learning rate: (1e-07)
2022-06-07 00:01:31,256 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 450 |  Loss: (0.0038) | Acc: (99.89%) (28832/28864) | Learning rate: (1e-07)
2022-06-07 00:01:33,055 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 460 |  Loss: (0.0038) | Acc: (99.89%) (29471/29504) | Learning rate: (1e-07)
2022-06-07 00:01:34,852 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 470 |  Loss: (0.0037) | Acc: (99.89%) (30111/30144) | Learning rate: (1e-07)
2022-06-07 00:01:36,650 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 480 |  Loss: (0.0036) | Acc: (99.89%) (30751/30784) | Learning rate: (1e-07)
2022-06-07 00:01:38,447 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 490 |  Loss: (0.0038) | Acc: (99.88%) (31387/31424) | Learning rate: (1e-07)
2022-06-07 00:01:40,244 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 500 |  Loss: (0.0038) | Acc: (99.88%) (32027/32064) | Learning rate: (1e-07)
2022-06-07 00:01:42,043 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 510 |  Loss: (0.0037) | Acc: (99.89%) (32667/32704) | Learning rate: (1e-07)
2022-06-07 00:01:43,842 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 520 |  Loss: (0.0037) | Acc: (99.89%) (33306/33344) | Learning rate: (1e-07)
2022-06-07 00:01:45,638 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 530 |  Loss: (0.0037) | Acc: (99.89%) (33946/33984) | Learning rate: (1e-07)
2022-06-07 00:01:47,436 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 540 |  Loss: (0.0036) | Acc: (99.89%) (34586/34624) | Learning rate: (1e-07)
2022-06-07 00:01:49,234 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 550 |  Loss: (0.0036) | Acc: (99.89%) (35226/35264) | Learning rate: (1e-07)
2022-06-07 00:01:51,030 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 560 |  Loss: (0.0037) | Acc: (99.89%) (35864/35904) | Learning rate: (1e-07)
2022-06-07 00:01:52,827 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 570 |  Loss: (0.0039) | Acc: (99.88%) (36501/36544) | Learning rate: (1e-07)
2022-06-07 00:01:54,625 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 580 |  Loss: (0.0039) | Acc: (99.88%) (37140/37184) | Learning rate: (1e-07)
2022-06-07 00:01:56,426 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 590 |  Loss: (0.0039) | Acc: (99.88%) (37779/37824) | Learning rate: (1e-07)
2022-06-07 00:01:58,223 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 600 |  Loss: (0.0040) | Acc: (99.88%) (38417/38464) | Learning rate: (1e-07)
2022-06-07 00:02:00,022 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 610 |  Loss: (0.0039) | Acc: (99.88%) (39057/39104) | Learning rate: (1e-07)
2022-06-07 00:02:01,822 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 620 |  Loss: (0.0039) | Acc: (99.88%) (39696/39744) | Learning rate: (1e-07)
2022-06-07 00:02:03,620 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 630 |  Loss: (0.0039) | Acc: (99.88%) (40336/40384) | Learning rate: (1e-07)
2022-06-07 00:02:05,419 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 640 |  Loss: (0.0039) | Acc: (99.88%) (40975/41024) | Learning rate: (1e-07)
2022-06-07 00:02:07,217 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 650 |  Loss: (0.0038) | Acc: (99.88%) (41615/41664) | Learning rate: (1e-07)
2022-06-07 00:02:09,017 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 660 |  Loss: (0.0039) | Acc: (99.88%) (42254/42304) | Learning rate: (1e-07)
2022-06-07 00:02:10,815 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 670 |  Loss: (0.0038) | Acc: (99.88%) (42894/42944) | Learning rate: (1e-07)
2022-06-07 00:02:12,613 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 680 |  Loss: (0.0038) | Acc: (99.89%) (43534/43584) | Learning rate: (1e-07)
2022-06-07 00:02:14,413 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 690 |  Loss: (0.0038) | Acc: (99.88%) (44173/44224) | Learning rate: (1e-07)
2022-06-07 00:02:16,211 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 700 |  Loss: (0.0038) | Acc: (99.88%) (44812/44864) | Learning rate: (1e-07)
2022-06-07 00:02:18,009 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 710 |  Loss: (0.0037) | Acc: (99.89%) (45452/45504) | Learning rate: (1e-07)
2022-06-07 00:02:19,807 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 720 |  Loss: (0.0037) | Acc: (99.89%) (46092/46144) | Learning rate: (1e-07)
2022-06-07 00:02:21,603 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 730 |  Loss: (0.0037) | Acc: (99.89%) (46732/46784) | Learning rate: (1e-07)
2022-06-07 00:02:23,400 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 740 |  Loss: (0.0037) | Acc: (99.89%) (47372/47424) | Learning rate: (1e-07)
2022-06-07 00:02:25,198 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 750 |  Loss: (0.0037) | Acc: (99.89%) (48011/48064) | Learning rate: (1e-07)
2022-06-07 00:02:26,995 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 760 |  Loss: (0.0036) | Acc: (99.89%) (48651/48704) | Learning rate: (1e-07)
2022-06-07 00:02:28,787 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 770 |  Loss: (0.0037) | Acc: (99.89%) (49289/49344) | Learning rate: (1e-07)
2022-06-07 00:02:30,576 - CIFAR10 Classifier - INFO - Epoch: 48 | Batch_idx: 780 |  Loss: (0.0037) | Acc: (99.89%) (49927/49984) | Learning rate: (1e-07)
2022-06-07 00:02:40,501 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0832) | Acc: (97.95%) (9795/10000)
2022-06-07 00:02:40,502 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-07 00:02:41,356 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 0 |  Loss: (0.0004) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-07 00:02:43,158 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 10 |  Loss: (0.0053) | Acc: (99.86%) (703/704) | Learning rate: (1e-07)
2022-06-07 00:02:44,951 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 20 |  Loss: (0.0034) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-07)
2022-06-07 00:02:46,745 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 30 |  Loss: (0.0025) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-07)
2022-06-07 00:02:48,543 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 40 |  Loss: (0.0042) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-07)
2022-06-07 00:02:50,339 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 50 |  Loss: (0.0049) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-07)
2022-06-07 00:02:52,138 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 60 |  Loss: (0.0044) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-07)
2022-06-07 00:02:53,935 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 70 |  Loss: (0.0039) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-07)
2022-06-07 00:02:55,731 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 80 |  Loss: (0.0035) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-07)
2022-06-07 00:02:57,528 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 90 |  Loss: (0.0035) | Acc: (99.90%) (5818/5824) | Learning rate: (1e-07)
2022-06-07 00:02:59,325 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 100 |  Loss: (0.0037) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-07)
2022-06-07 00:03:01,123 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 110 |  Loss: (0.0036) | Acc: (99.89%) (7096/7104) | Learning rate: (1e-07)
2022-06-07 00:03:02,921 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 120 |  Loss: (0.0034) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-07)
2022-06-07 00:03:04,718 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 130 |  Loss: (0.0033) | Acc: (99.90%) (8376/8384) | Learning rate: (1e-07)
2022-06-07 00:03:06,516 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 140 |  Loss: (0.0032) | Acc: (99.91%) (9016/9024) | Learning rate: (1e-07)
2022-06-07 00:03:08,313 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 150 |  Loss: (0.0032) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-07)
2022-06-07 00:03:10,112 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 160 |  Loss: (0.0033) | Acc: (99.90%) (10294/10304) | Learning rate: (1e-07)
2022-06-07 00:03:11,907 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 170 |  Loss: (0.0032) | Acc: (99.91%) (10934/10944) | Learning rate: (1e-07)
2022-06-07 00:03:13,704 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 180 |  Loss: (0.0030) | Acc: (99.91%) (11574/11584) | Learning rate: (1e-07)
2022-06-07 00:03:15,502 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 190 |  Loss: (0.0030) | Acc: (99.92%) (12214/12224) | Learning rate: (1e-07)
2022-06-07 00:03:17,299 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 200 |  Loss: (0.0030) | Acc: (99.92%) (12854/12864) | Learning rate: (1e-07)
2022-06-07 00:03:19,098 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 210 |  Loss: (0.0029) | Acc: (99.93%) (13494/13504) | Learning rate: (1e-07)
2022-06-07 00:03:20,896 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 220 |  Loss: (0.0029) | Acc: (99.93%) (14134/14144) | Learning rate: (1e-07)
2022-06-07 00:03:22,695 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 230 |  Loss: (0.0030) | Acc: (99.93%) (14773/14784) | Learning rate: (1e-07)
2022-06-07 00:03:24,493 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 240 |  Loss: (0.0030) | Acc: (99.92%) (15412/15424) | Learning rate: (1e-07)
2022-06-07 00:03:26,290 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 250 |  Loss: (0.0029) | Acc: (99.93%) (16052/16064) | Learning rate: (1e-07)
2022-06-07 00:03:28,089 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 260 |  Loss: (0.0028) | Acc: (99.92%) (16691/16704) | Learning rate: (1e-07)
2022-06-07 00:03:29,886 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 270 |  Loss: (0.0028) | Acc: (99.93%) (17331/17344) | Learning rate: (1e-07)
2022-06-07 00:03:31,684 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 280 |  Loss: (0.0028) | Acc: (99.92%) (17970/17984) | Learning rate: (1e-07)
2022-06-07 00:03:33,480 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 290 |  Loss: (0.0028) | Acc: (99.92%) (18610/18624) | Learning rate: (1e-07)
2022-06-07 00:03:35,276 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 300 |  Loss: (0.0028) | Acc: (99.92%) (19249/19264) | Learning rate: (1e-07)
2022-06-07 00:03:37,073 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 310 |  Loss: (0.0028) | Acc: (99.92%) (19889/19904) | Learning rate: (1e-07)
2022-06-07 00:03:38,870 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 320 |  Loss: (0.0028) | Acc: (99.92%) (20528/20544) | Learning rate: (1e-07)
2022-06-07 00:03:40,666 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 330 |  Loss: (0.0030) | Acc: (99.92%) (21167/21184) | Learning rate: (1e-07)
2022-06-07 00:03:42,463 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 340 |  Loss: (0.0029) | Acc: (99.92%) (21807/21824) | Learning rate: (1e-07)
2022-06-07 00:03:44,260 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 350 |  Loss: (0.0029) | Acc: (99.92%) (22446/22464) | Learning rate: (1e-07)
2022-06-07 00:03:46,055 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 360 |  Loss: (0.0028) | Acc: (99.92%) (23086/23104) | Learning rate: (1e-07)
2022-06-07 00:03:47,852 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 370 |  Loss: (0.0028) | Acc: (99.92%) (23725/23744) | Learning rate: (1e-07)
2022-06-07 00:03:49,648 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 380 |  Loss: (0.0028) | Acc: (99.92%) (24365/24384) | Learning rate: (1e-07)
2022-06-07 00:03:51,446 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 390 |  Loss: (0.0028) | Acc: (99.92%) (25005/25024) | Learning rate: (1e-07)
2022-06-07 00:03:53,244 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 400 |  Loss: (0.0029) | Acc: (99.92%) (25643/25664) | Learning rate: (1e-07)
2022-06-07 00:03:55,042 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 410 |  Loss: (0.0029) | Acc: (99.92%) (26282/26304) | Learning rate: (1e-07)
2022-06-07 00:03:56,839 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 420 |  Loss: (0.0030) | Acc: (99.91%) (26920/26944) | Learning rate: (1e-07)
2022-06-07 00:03:58,637 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 430 |  Loss: (0.0029) | Acc: (99.91%) (27560/27584) | Learning rate: (1e-07)
2022-06-07 00:04:00,435 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 440 |  Loss: (0.0030) | Acc: (99.91%) (28199/28224) | Learning rate: (1e-07)
2022-06-07 00:04:02,232 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 450 |  Loss: (0.0030) | Acc: (99.91%) (28839/28864) | Learning rate: (1e-07)
2022-06-07 00:04:04,029 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 460 |  Loss: (0.0032) | Acc: (99.91%) (29477/29504) | Learning rate: (1e-07)
2022-06-07 00:04:05,825 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 470 |  Loss: (0.0032) | Acc: (99.91%) (30116/30144) | Learning rate: (1e-07)
2022-06-07 00:04:07,623 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 480 |  Loss: (0.0032) | Acc: (99.91%) (30755/30784) | Learning rate: (1e-07)
2022-06-07 00:04:09,421 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 490 |  Loss: (0.0032) | Acc: (99.90%) (31394/31424) | Learning rate: (1e-07)
2022-06-07 00:04:11,221 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 500 |  Loss: (0.0032) | Acc: (99.90%) (32033/32064) | Learning rate: (1e-07)
2022-06-07 00:04:13,020 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 510 |  Loss: (0.0032) | Acc: (99.90%) (32672/32704) | Learning rate: (1e-07)
2022-06-07 00:04:14,818 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 520 |  Loss: (0.0032) | Acc: (99.90%) (33312/33344) | Learning rate: (1e-07)
2022-06-07 00:04:16,617 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 530 |  Loss: (0.0032) | Acc: (99.91%) (33952/33984) | Learning rate: (1e-07)
2022-06-07 00:04:18,414 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 540 |  Loss: (0.0032) | Acc: (99.90%) (34591/34624) | Learning rate: (1e-07)
2022-06-07 00:04:20,213 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 550 |  Loss: (0.0033) | Acc: (99.90%) (35229/35264) | Learning rate: (1e-07)
2022-06-07 00:04:22,013 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 560 |  Loss: (0.0034) | Acc: (99.90%) (35867/35904) | Learning rate: (1e-07)
2022-06-07 00:04:23,810 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 570 |  Loss: (0.0034) | Acc: (99.90%) (36506/36544) | Learning rate: (1e-07)
2022-06-07 00:04:25,609 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 580 |  Loss: (0.0034) | Acc: (99.90%) (37145/37184) | Learning rate: (1e-07)
2022-06-07 00:04:27,409 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 590 |  Loss: (0.0033) | Acc: (99.90%) (37785/37824) | Learning rate: (1e-07)
2022-06-07 00:04:29,208 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 600 |  Loss: (0.0033) | Acc: (99.90%) (38424/38464) | Learning rate: (1e-07)
2022-06-07 00:04:31,007 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 610 |  Loss: (0.0034) | Acc: (99.90%) (39063/39104) | Learning rate: (1e-07)
2022-06-07 00:04:32,805 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 620 |  Loss: (0.0034) | Acc: (99.89%) (39702/39744) | Learning rate: (1e-07)
2022-06-07 00:04:34,602 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 630 |  Loss: (0.0034) | Acc: (99.90%) (40342/40384) | Learning rate: (1e-07)
2022-06-07 00:04:36,400 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 640 |  Loss: (0.0034) | Acc: (99.90%) (40981/41024) | Learning rate: (1e-07)
2022-06-07 00:04:38,197 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 650 |  Loss: (0.0034) | Acc: (99.90%) (41621/41664) | Learning rate: (1e-07)
2022-06-07 00:04:39,994 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 660 |  Loss: (0.0033) | Acc: (99.90%) (42261/42304) | Learning rate: (1e-07)
2022-06-07 00:04:41,792 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 670 |  Loss: (0.0033) | Acc: (99.90%) (42901/42944) | Learning rate: (1e-07)
2022-06-07 00:04:43,591 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 680 |  Loss: (0.0033) | Acc: (99.90%) (43541/43584) | Learning rate: (1e-07)
2022-06-07 00:04:45,389 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 690 |  Loss: (0.0033) | Acc: (99.90%) (44180/44224) | Learning rate: (1e-07)
2022-06-07 00:04:47,188 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 700 |  Loss: (0.0034) | Acc: (99.90%) (44817/44864) | Learning rate: (1e-07)
2022-06-07 00:04:48,988 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 710 |  Loss: (0.0034) | Acc: (99.89%) (45456/45504) | Learning rate: (1e-07)
2022-06-07 00:04:50,787 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 720 |  Loss: (0.0034) | Acc: (99.89%) (46095/46144) | Learning rate: (1e-07)
2022-06-07 00:04:52,587 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 730 |  Loss: (0.0034) | Acc: (99.89%) (46734/46784) | Learning rate: (1e-07)
2022-06-07 00:04:54,387 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 740 |  Loss: (0.0034) | Acc: (99.89%) (47374/47424) | Learning rate: (1e-07)
2022-06-07 00:04:56,185 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 750 |  Loss: (0.0033) | Acc: (99.90%) (48014/48064) | Learning rate: (1e-07)
2022-06-07 00:04:57,985 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 760 |  Loss: (0.0033) | Acc: (99.90%) (48654/48704) | Learning rate: (1e-07)
2022-06-07 00:04:59,777 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 770 |  Loss: (0.0033) | Acc: (99.90%) (49293/49344) | Learning rate: (1e-07)
2022-06-07 00:05:01,567 - CIFAR10 Classifier - INFO - Epoch: 49 | Batch_idx: 780 |  Loss: (0.0033) | Acc: (99.90%) (49933/49984) | Learning rate: (1e-07)
2022-06-07 00:05:11,506 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0827) | Acc: (98.05%) (9805/10000)
2022-06-07 00:05:11,507 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-07 00:05:12,392 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-07 00:05:14,185 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 10 |  Loss: (0.0034) | Acc: (99.86%) (703/704) | Learning rate: (1e-07)
2022-06-07 00:05:15,976 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 20 |  Loss: (0.0025) | Acc: (99.93%) (1343/1344) | Learning rate: (1e-07)
2022-06-07 00:05:17,772 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-07)
2022-06-07 00:05:19,569 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 40 |  Loss: (0.0042) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-07)
2022-06-07 00:05:21,364 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 50 |  Loss: (0.0042) | Acc: (99.85%) (3259/3264) | Learning rate: (1e-07)
2022-06-07 00:05:23,161 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 60 |  Loss: (0.0047) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-07)
2022-06-07 00:05:24,958 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 70 |  Loss: (0.0041) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-07)
2022-06-07 00:05:26,756 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 80 |  Loss: (0.0037) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-07)
2022-06-07 00:05:28,555 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 90 |  Loss: (0.0037) | Acc: (99.88%) (5817/5824) | Learning rate: (1e-07)
2022-06-07 00:05:30,352 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 100 |  Loss: (0.0034) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-07)
2022-06-07 00:05:32,149 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 110 |  Loss: (0.0032) | Acc: (99.90%) (7097/7104) | Learning rate: (1e-07)
2022-06-07 00:05:33,945 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 120 |  Loss: (0.0031) | Acc: (99.91%) (7737/7744) | Learning rate: (1e-07)
2022-06-07 00:05:35,742 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 130 |  Loss: (0.0030) | Acc: (99.92%) (8377/8384) | Learning rate: (1e-07)
2022-06-07 00:05:37,537 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 140 |  Loss: (0.0029) | Acc: (99.92%) (9017/9024) | Learning rate: (1e-07)
2022-06-07 00:05:39,333 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 150 |  Loss: (0.0029) | Acc: (99.93%) (9657/9664) | Learning rate: (1e-07)
2022-06-07 00:05:41,129 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 160 |  Loss: (0.0028) | Acc: (99.93%) (10297/10304) | Learning rate: (1e-07)
2022-06-07 00:05:42,927 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 170 |  Loss: (0.0027) | Acc: (99.94%) (10937/10944) | Learning rate: (1e-07)
2022-06-07 00:05:44,724 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 180 |  Loss: (0.0027) | Acc: (99.93%) (11576/11584) | Learning rate: (1e-07)
2022-06-07 00:05:46,520 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 190 |  Loss: (0.0026) | Acc: (99.93%) (12216/12224) | Learning rate: (1e-07)
2022-06-07 00:05:48,317 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 200 |  Loss: (0.0026) | Acc: (99.94%) (12856/12864) | Learning rate: (1e-07)
2022-06-07 00:05:50,114 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 210 |  Loss: (0.0025) | Acc: (99.94%) (13496/13504) | Learning rate: (1e-07)
2022-06-07 00:05:51,910 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 220 |  Loss: (0.0026) | Acc: (99.94%) (14135/14144) | Learning rate: (1e-07)
2022-06-07 00:05:53,707 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 230 |  Loss: (0.0026) | Acc: (99.94%) (14775/14784) | Learning rate: (1e-07)
2022-06-07 00:05:55,505 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 240 |  Loss: (0.0026) | Acc: (99.94%) (15414/15424) | Learning rate: (1e-07)
2022-06-07 00:05:57,302 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 250 |  Loss: (0.0026) | Acc: (99.93%) (16053/16064) | Learning rate: (1e-07)
2022-06-07 00:05:59,101 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 260 |  Loss: (0.0025) | Acc: (99.93%) (16693/16704) | Learning rate: (1e-07)
2022-06-07 00:06:00,897 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 270 |  Loss: (0.0025) | Acc: (99.93%) (17332/17344) | Learning rate: (1e-07)
2022-06-07 00:06:02,694 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 280 |  Loss: (0.0026) | Acc: (99.92%) (17969/17984) | Learning rate: (1e-07)
2022-06-07 00:06:04,491 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 290 |  Loss: (0.0026) | Acc: (99.92%) (18609/18624) | Learning rate: (1e-07)
2022-06-07 00:06:06,286 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 300 |  Loss: (0.0025) | Acc: (99.92%) (19249/19264) | Learning rate: (1e-07)
2022-06-07 00:06:08,082 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 310 |  Loss: (0.0025) | Acc: (99.92%) (19889/19904) | Learning rate: (1e-07)
2022-06-07 00:06:09,880 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 320 |  Loss: (0.0026) | Acc: (99.92%) (20528/20544) | Learning rate: (1e-07)
2022-06-07 00:06:11,677 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 330 |  Loss: (0.0026) | Acc: (99.92%) (21168/21184) | Learning rate: (1e-07)
2022-06-07 00:06:13,476 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 340 |  Loss: (0.0026) | Acc: (99.92%) (21807/21824) | Learning rate: (1e-07)
2022-06-07 00:06:15,272 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 350 |  Loss: (0.0026) | Acc: (99.92%) (22447/22464) | Learning rate: (1e-07)
2022-06-07 00:06:17,069 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 360 |  Loss: (0.0028) | Acc: (99.92%) (23086/23104) | Learning rate: (1e-07)
2022-06-07 00:06:18,865 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 370 |  Loss: (0.0028) | Acc: (99.92%) (23725/23744) | Learning rate: (1e-07)
2022-06-07 00:06:20,661 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 380 |  Loss: (0.0029) | Acc: (99.92%) (24364/24384) | Learning rate: (1e-07)
2022-06-07 00:06:22,457 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 390 |  Loss: (0.0030) | Acc: (99.92%) (25003/25024) | Learning rate: (1e-07)
2022-06-07 00:06:24,256 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 400 |  Loss: (0.0030) | Acc: (99.92%) (25643/25664) | Learning rate: (1e-07)
2022-06-07 00:06:26,053 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 410 |  Loss: (0.0029) | Acc: (99.92%) (26283/26304) | Learning rate: (1e-07)
2022-06-07 00:06:27,851 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 420 |  Loss: (0.0029) | Acc: (99.92%) (26923/26944) | Learning rate: (1e-07)
2022-06-07 00:06:29,647 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 430 |  Loss: (0.0029) | Acc: (99.92%) (27562/27584) | Learning rate: (1e-07)
2022-06-07 00:06:31,445 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 440 |  Loss: (0.0029) | Acc: (99.92%) (28202/28224) | Learning rate: (1e-07)
2022-06-07 00:06:33,242 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 450 |  Loss: (0.0031) | Acc: (99.91%) (28839/28864) | Learning rate: (1e-07)
2022-06-07 00:06:35,039 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 460 |  Loss: (0.0030) | Acc: (99.92%) (29479/29504) | Learning rate: (1e-07)
2022-06-07 00:06:36,836 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 470 |  Loss: (0.0030) | Acc: (99.92%) (30119/30144) | Learning rate: (1e-07)
2022-06-07 00:06:38,632 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 480 |  Loss: (0.0030) | Acc: (99.92%) (30758/30784) | Learning rate: (1e-07)
2022-06-07 00:06:40,430 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 490 |  Loss: (0.0030) | Acc: (99.92%) (31398/31424) | Learning rate: (1e-07)
2022-06-07 00:06:42,229 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 500 |  Loss: (0.0029) | Acc: (99.92%) (32038/32064) | Learning rate: (1e-07)
2022-06-07 00:06:44,027 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 510 |  Loss: (0.0029) | Acc: (99.92%) (32678/32704) | Learning rate: (1e-07)
2022-06-07 00:06:45,824 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 520 |  Loss: (0.0029) | Acc: (99.92%) (33318/33344) | Learning rate: (1e-07)
2022-06-07 00:06:47,622 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 530 |  Loss: (0.0028) | Acc: (99.92%) (33958/33984) | Learning rate: (1e-07)
2022-06-07 00:06:49,420 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 540 |  Loss: (0.0028) | Acc: (99.92%) (34598/34624) | Learning rate: (1e-07)
2022-06-07 00:06:51,216 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 550 |  Loss: (0.0028) | Acc: (99.93%) (35238/35264) | Learning rate: (1e-07)
2022-06-07 00:06:53,012 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 560 |  Loss: (0.0028) | Acc: (99.93%) (35878/35904) | Learning rate: (1e-07)
2022-06-07 00:06:54,809 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 570 |  Loss: (0.0027) | Acc: (99.93%) (36518/36544) | Learning rate: (1e-07)
2022-06-07 00:06:56,605 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 580 |  Loss: (0.0028) | Acc: (99.93%) (37157/37184) | Learning rate: (1e-07)
2022-06-07 00:06:58,405 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 590 |  Loss: (0.0028) | Acc: (99.93%) (37797/37824) | Learning rate: (1e-07)
2022-06-07 00:07:00,202 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 600 |  Loss: (0.0029) | Acc: (99.92%) (38435/38464) | Learning rate: (1e-07)
2022-06-07 00:07:02,000 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 610 |  Loss: (0.0029) | Acc: (99.93%) (39075/39104) | Learning rate: (1e-07)
2022-06-07 00:07:03,798 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 620 |  Loss: (0.0029) | Acc: (99.93%) (39715/39744) | Learning rate: (1e-07)
2022-06-07 00:07:05,595 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 630 |  Loss: (0.0029) | Acc: (99.93%) (40355/40384) | Learning rate: (1e-07)
2022-06-07 00:07:07,393 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 640 |  Loss: (0.0029) | Acc: (99.93%) (40994/41024) | Learning rate: (1e-07)
2022-06-07 00:07:09,189 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 650 |  Loss: (0.0029) | Acc: (99.93%) (41633/41664) | Learning rate: (1e-07)
2022-06-07 00:07:10,986 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 660 |  Loss: (0.0028) | Acc: (99.93%) (42273/42304) | Learning rate: (1e-07)
2022-06-07 00:07:12,783 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 670 |  Loss: (0.0028) | Acc: (99.93%) (42913/42944) | Learning rate: (1e-07)
2022-06-07 00:07:14,580 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 680 |  Loss: (0.0028) | Acc: (99.93%) (43553/43584) | Learning rate: (1e-07)
2022-06-07 00:07:16,378 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 690 |  Loss: (0.0028) | Acc: (99.93%) (44191/44224) | Learning rate: (1e-07)
2022-06-07 00:07:18,176 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 700 |  Loss: (0.0028) | Acc: (99.92%) (44830/44864) | Learning rate: (1e-07)
2022-06-07 00:07:19,978 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 710 |  Loss: (0.0028) | Acc: (99.93%) (45470/45504) | Learning rate: (1e-07)
2022-06-07 00:07:21,776 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 720 |  Loss: (0.0028) | Acc: (99.92%) (46109/46144) | Learning rate: (1e-07)
2022-06-07 00:07:23,575 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 730 |  Loss: (0.0029) | Acc: (99.92%) (46747/46784) | Learning rate: (1e-07)
2022-06-07 00:07:25,372 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 740 |  Loss: (0.0029) | Acc: (99.92%) (47385/47424) | Learning rate: (1e-07)
2022-06-07 00:07:27,170 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 750 |  Loss: (0.0029) | Acc: (99.92%) (48024/48064) | Learning rate: (1e-07)
2022-06-07 00:07:28,967 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 760 |  Loss: (0.0029) | Acc: (99.91%) (48662/48704) | Learning rate: (1e-07)
2022-06-07 00:07:30,756 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 770 |  Loss: (0.0031) | Acc: (99.91%) (49299/49344) | Learning rate: (1e-07)
2022-06-07 00:07:32,546 - CIFAR10 Classifier - INFO - Epoch: 50 | Batch_idx: 780 |  Loss: (0.0032) | Acc: (99.90%) (49936/49984) | Learning rate: (1e-07)
2022-06-07 00:07:42,521 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0843) | Acc: (98.06%) (9806/10000)
2022-06-07 00:07:42,522 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-07 00:07:43,417 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 0 |  Loss: (0.0030) | Acc: (100.00%) (64/64) | Learning rate: (1e-07)
2022-06-07 00:07:45,208 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 10 |  Loss: (0.0009) | Acc: (100.00%) (704/704) | Learning rate: (1e-07)
2022-06-07 00:07:47,001 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 20 |  Loss: (0.0011) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-07)
2022-06-07 00:07:48,794 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 30 |  Loss: (0.0018) | Acc: (99.95%) (1983/1984) | Learning rate: (1e-07)
2022-06-07 00:07:50,590 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 40 |  Loss: (0.0027) | Acc: (99.89%) (2621/2624) | Learning rate: (1e-07)
2022-06-07 00:07:52,385 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 50 |  Loss: (0.0026) | Acc: (99.91%) (3261/3264) | Learning rate: (1e-07)
2022-06-07 00:07:54,180 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 60 |  Loss: (0.0024) | Acc: (99.92%) (3901/3904) | Learning rate: (1e-07)
2022-06-07 00:07:55,978 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 70 |  Loss: (0.0030) | Acc: (99.91%) (4540/4544) | Learning rate: (1e-07)
2022-06-07 00:07:57,773 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 80 |  Loss: (0.0028) | Acc: (99.92%) (5180/5184) | Learning rate: (1e-07)
2022-06-07 00:07:59,567 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 90 |  Loss: (0.0029) | Acc: (99.91%) (5819/5824) | Learning rate: (1e-07)
2022-06-07 00:08:01,361 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 100 |  Loss: (0.0028) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-07)
2022-06-07 00:08:03,158 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 110 |  Loss: (0.0027) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-07)
2022-06-07 00:08:04,955 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 120 |  Loss: (0.0033) | Acc: (99.90%) (7736/7744) | Learning rate: (1e-07)
2022-06-07 00:08:06,750 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 130 |  Loss: (0.0032) | Acc: (99.89%) (8375/8384) | Learning rate: (1e-07)
2022-06-07 00:08:08,544 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 140 |  Loss: (0.0031) | Acc: (99.90%) (9015/9024) | Learning rate: (1e-07)
2022-06-07 00:08:10,339 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 150 |  Loss: (0.0030) | Acc: (99.91%) (9655/9664) | Learning rate: (1e-07)
2022-06-07 00:08:12,137 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 160 |  Loss: (0.0031) | Acc: (99.89%) (10293/10304) | Learning rate: (1e-07)
2022-06-07 00:08:13,932 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 170 |  Loss: (0.0036) | Acc: (99.87%) (10930/10944) | Learning rate: (1e-07)
2022-06-07 00:08:15,727 - CIFAR10 Classifier - INFO - Epoch: 51 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.86%) (11568/11584) | Learning rate: (1e-07)
2022-06-07 00:08:31,717 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0832) | Acc: (98.01%) (9801/10000)
2022-06-07 00:08:31,718 - CIFAR10 Classifier - INFO - Epoch time : 0:00:49
2022-06-07 00:08:32,613 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 0 |  Loss: (0.0031) | Acc: (100.00%) (64/64) | Learning rate: (1e-08)
2022-06-07 00:08:34,398 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 10 |  Loss: (0.0016) | Acc: (100.00%) (704/704) | Learning rate: (1e-08)
2022-06-07 00:08:36,187 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 20 |  Loss: (0.0017) | Acc: (100.00%) (1344/1344) | Learning rate: (1e-08)
2022-06-07 00:08:37,978 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 30 |  Loss: (0.0015) | Acc: (100.00%) (1984/1984) | Learning rate: (1e-08)
2022-06-07 00:08:39,770 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 40 |  Loss: (0.0020) | Acc: (99.96%) (2623/2624) | Learning rate: (1e-08)
2022-06-07 00:08:41,562 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 50 |  Loss: (0.0024) | Acc: (99.94%) (3262/3264) | Learning rate: (1e-08)
2022-06-07 00:08:43,354 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 60 |  Loss: (0.0032) | Acc: (99.87%) (3899/3904) | Learning rate: (1e-08)
2022-06-07 00:08:45,146 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 70 |  Loss: (0.0029) | Acc: (99.89%) (4539/4544) | Learning rate: (1e-08)
2022-06-07 00:08:46,939 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 80 |  Loss: (0.0028) | Acc: (99.90%) (5179/5184) | Learning rate: (1e-08)
2022-06-07 00:08:48,734 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 90 |  Loss: (0.0030) | Acc: (99.90%) (5818/5824) | Learning rate: (1e-08)
2022-06-07 00:08:50,530 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 100 |  Loss: (0.0033) | Acc: (99.89%) (6457/6464) | Learning rate: (1e-08)
2022-06-07 00:08:52,327 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 110 |  Loss: (0.0032) | Acc: (99.89%) (7096/7104) | Learning rate: (1e-08)
2022-06-07 00:08:54,124 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 120 |  Loss: (0.0042) | Acc: (99.87%) (7734/7744) | Learning rate: (1e-08)
2022-06-07 00:08:55,919 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.86%) (8372/8384) | Learning rate: (1e-08)
2022-06-07 00:08:57,717 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 140 |  Loss: (0.0050) | Acc: (99.86%) (9011/9024) | Learning rate: (1e-08)
2022-06-07 00:08:59,514 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 150 |  Loss: (0.0049) | Acc: (99.86%) (9650/9664) | Learning rate: (1e-08)
2022-06-07 00:09:01,310 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 160 |  Loss: (0.0051) | Acc: (99.84%) (10288/10304) | Learning rate: (1e-08)
2022-06-07 00:09:03,106 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.84%) (10927/10944) | Learning rate: (1e-08)
2022-06-07 00:09:04,904 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.84%) (11565/11584) | Learning rate: (1e-08)
2022-06-07 00:09:06,701 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.84%) (12204/12224) | Learning rate: (1e-08)
2022-06-07 00:09:08,499 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 200 |  Loss: (0.0052) | Acc: (99.84%) (12844/12864) | Learning rate: (1e-08)
2022-06-07 00:09:10,297 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.84%) (13483/13504) | Learning rate: (1e-08)
2022-06-07 00:09:12,094 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 220 |  Loss: (0.0049) | Acc: (99.85%) (14123/14144) | Learning rate: (1e-08)
2022-06-07 00:09:13,893 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 230 |  Loss: (0.0047) | Acc: (99.86%) (14763/14784) | Learning rate: (1e-08)
2022-06-07 00:09:15,691 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 240 |  Loss: (0.0046) | Acc: (99.86%) (15403/15424) | Learning rate: (1e-08)
2022-06-07 00:09:17,488 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 250 |  Loss: (0.0046) | Acc: (99.86%) (16041/16064) | Learning rate: (1e-08)
2022-06-07 00:09:19,286 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 260 |  Loss: (0.0045) | Acc: (99.86%) (16681/16704) | Learning rate: (1e-08)
2022-06-07 00:09:21,082 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 270 |  Loss: (0.0044) | Acc: (99.86%) (17320/17344) | Learning rate: (1e-08)
2022-06-07 00:09:22,879 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 280 |  Loss: (0.0043) | Acc: (99.87%) (17960/17984) | Learning rate: (1e-08)
2022-06-07 00:09:24,676 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 290 |  Loss: (0.0044) | Acc: (99.86%) (18598/18624) | Learning rate: (1e-08)
2022-06-07 00:09:26,474 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.86%) (19237/19264) | Learning rate: (1e-08)
2022-06-07 00:09:28,275 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 310 |  Loss: (0.0043) | Acc: (99.86%) (19877/19904) | Learning rate: (1e-08)
2022-06-07 00:09:30,074 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 320 |  Loss: (0.0043) | Acc: (99.86%) (20515/20544) | Learning rate: (1e-08)
2022-06-07 00:09:31,874 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 330 |  Loss: (0.0042) | Acc: (99.86%) (21155/21184) | Learning rate: (1e-08)
2022-06-07 00:09:33,673 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 340 |  Loss: (0.0042) | Acc: (99.86%) (21794/21824) | Learning rate: (1e-08)
2022-06-07 00:09:35,473 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 350 |  Loss: (0.0042) | Acc: (99.86%) (22433/22464) | Learning rate: (1e-08)
2022-06-07 00:09:37,271 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 360 |  Loss: (0.0042) | Acc: (99.86%) (23072/23104) | Learning rate: (1e-08)
2022-06-07 00:09:39,071 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 370 |  Loss: (0.0041) | Acc: (99.87%) (23712/23744) | Learning rate: (1e-08)
2022-06-07 00:09:40,869 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 380 |  Loss: (0.0041) | Acc: (99.87%) (24352/24384) | Learning rate: (1e-08)
2022-06-07 00:09:42,670 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 390 |  Loss: (0.0040) | Acc: (99.87%) (24992/25024) | Learning rate: (1e-08)
2022-06-07 00:09:44,469 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 400 |  Loss: (0.0040) | Acc: (99.88%) (25632/25664) | Learning rate: (1e-08)
2022-06-07 00:09:46,269 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 410 |  Loss: (0.0039) | Acc: (99.88%) (26272/26304) | Learning rate: (1e-08)
2022-06-07 00:09:48,068 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 420 |  Loss: (0.0039) | Acc: (99.88%) (26912/26944) | Learning rate: (1e-08)
2022-06-07 00:09:49,868 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 430 |  Loss: (0.0039) | Acc: (99.88%) (27551/27584) | Learning rate: (1e-08)
2022-06-07 00:09:51,667 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 440 |  Loss: (0.0039) | Acc: (99.88%) (28191/28224) | Learning rate: (1e-08)
2022-06-07 00:09:53,466 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 450 |  Loss: (0.0038) | Acc: (99.89%) (28831/28864) | Learning rate: (1e-08)
2022-06-07 00:09:55,266 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 460 |  Loss: (0.0038) | Acc: (99.89%) (29471/29504) | Learning rate: (1e-08)
2022-06-07 00:09:57,065 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 470 |  Loss: (0.0038) | Acc: (99.89%) (30110/30144) | Learning rate: (1e-08)
2022-06-07 00:09:58,865 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 480 |  Loss: (0.0037) | Acc: (99.89%) (30750/30784) | Learning rate: (1e-08)
2022-06-07 00:10:00,664 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 490 |  Loss: (0.0037) | Acc: (99.89%) (31390/31424) | Learning rate: (1e-08)
2022-06-07 00:10:02,463 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 500 |  Loss: (0.0036) | Acc: (99.89%) (32030/32064) | Learning rate: (1e-08)
2022-06-07 00:10:04,263 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 510 |  Loss: (0.0037) | Acc: (99.89%) (32668/32704) | Learning rate: (1e-08)
2022-06-07 00:10:06,062 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 520 |  Loss: (0.0037) | Acc: (99.89%) (33308/33344) | Learning rate: (1e-08)
2022-06-07 00:10:07,862 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 530 |  Loss: (0.0038) | Acc: (99.89%) (33946/33984) | Learning rate: (1e-08)
2022-06-07 00:10:09,661 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 540 |  Loss: (0.0037) | Acc: (99.89%) (34586/34624) | Learning rate: (1e-08)
2022-06-07 00:10:11,459 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 550 |  Loss: (0.0037) | Acc: (99.89%) (35225/35264) | Learning rate: (1e-08)
2022-06-07 00:10:13,260 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 560 |  Loss: (0.0037) | Acc: (99.89%) (35864/35904) | Learning rate: (1e-08)
2022-06-07 00:10:15,059 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 570 |  Loss: (0.0037) | Acc: (99.89%) (36504/36544) | Learning rate: (1e-08)
2022-06-07 00:10:16,858 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 580 |  Loss: (0.0037) | Acc: (99.89%) (37144/37184) | Learning rate: (1e-08)
2022-06-07 00:10:18,658 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 590 |  Loss: (0.0036) | Acc: (99.89%) (37784/37824) | Learning rate: (1e-08)
2022-06-07 00:10:20,457 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 600 |  Loss: (0.0036) | Acc: (99.89%) (38423/38464) | Learning rate: (1e-08)
2022-06-07 00:10:22,258 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 610 |  Loss: (0.0036) | Acc: (99.90%) (39063/39104) | Learning rate: (1e-08)
2022-06-07 00:10:24,057 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 620 |  Loss: (0.0036) | Acc: (99.89%) (39702/39744) | Learning rate: (1e-08)
2022-06-07 00:10:25,856 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 630 |  Loss: (0.0036) | Acc: (99.90%) (40342/40384) | Learning rate: (1e-08)
2022-06-07 00:10:27,656 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 640 |  Loss: (0.0035) | Acc: (99.90%) (40982/41024) | Learning rate: (1e-08)
2022-06-07 00:10:29,455 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 650 |  Loss: (0.0036) | Acc: (99.89%) (41620/41664) | Learning rate: (1e-08)
2022-06-07 00:10:31,255 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 660 |  Loss: (0.0036) | Acc: (99.90%) (42260/42304) | Learning rate: (1e-08)
2022-06-07 00:10:33,054 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 670 |  Loss: (0.0036) | Acc: (99.90%) (42900/42944) | Learning rate: (1e-08)
2022-06-07 00:10:34,853 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 680 |  Loss: (0.0035) | Acc: (99.90%) (43540/43584) | Learning rate: (1e-08)
2022-06-07 00:10:36,653 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 690 |  Loss: (0.0035) | Acc: (99.90%) (44179/44224) | Learning rate: (1e-08)
2022-06-07 00:10:38,452 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 700 |  Loss: (0.0036) | Acc: (99.90%) (44818/44864) | Learning rate: (1e-08)
2022-06-07 00:10:40,252 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 710 |  Loss: (0.0036) | Acc: (99.90%) (45457/45504) | Learning rate: (1e-08)
2022-06-07 00:10:42,050 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 720 |  Loss: (0.0036) | Acc: (99.90%) (46096/46144) | Learning rate: (1e-08)
2022-06-07 00:10:43,851 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 730 |  Loss: (0.0036) | Acc: (99.89%) (46734/46784) | Learning rate: (1e-08)
2022-06-07 00:10:45,650 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 740 |  Loss: (0.0036) | Acc: (99.89%) (47373/47424) | Learning rate: (1e-08)
2022-06-07 00:10:47,449 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 750 |  Loss: (0.0037) | Acc: (99.89%) (48012/48064) | Learning rate: (1e-08)
2022-06-07 00:10:49,249 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 760 |  Loss: (0.0037) | Acc: (99.89%) (48652/48704) | Learning rate: (1e-08)
2022-06-07 00:10:51,041 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 770 |  Loss: (0.0036) | Acc: (99.89%) (49292/49344) | Learning rate: (1e-08)
2022-06-07 00:10:52,834 - CIFAR10 Classifier - INFO - Epoch: 52 | Batch_idx: 780 |  Loss: (0.0036) | Acc: (99.89%) (49931/49984) | Learning rate: (1e-08)
2022-06-07 00:11:02,763 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0810) | Acc: (98.07%) (9807/10000)
2022-06-07 00:11:02,764 - CIFAR10 Classifier - INFO - Epoch time : 0:02:30
2022-06-07 00:11:03,569 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 0 |  Loss: (0.0004) | Acc: (100.00%) (64/64) | Learning rate: (1e-08)
2022-06-07 00:11:05,383 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 10 |  Loss: (0.0040) | Acc: (99.86%) (703/704) | Learning rate: (1e-08)
2022-06-07 00:11:07,178 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 20 |  Loss: (0.0038) | Acc: (99.85%) (1342/1344) | Learning rate: (1e-08)
2022-06-07 00:11:08,975 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 30 |  Loss: (0.0034) | Acc: (99.85%) (1981/1984) | Learning rate: (1e-08)
2022-06-07 00:11:10,774 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 40 |  Loss: (0.0037) | Acc: (99.85%) (2620/2624) | Learning rate: (1e-08)
2022-06-07 00:11:12,573 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 50 |  Loss: (0.0041) | Acc: (99.82%) (3258/3264) | Learning rate: (1e-08)
2022-06-07 00:11:14,373 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 60 |  Loss: (0.0036) | Acc: (99.85%) (3898/3904) | Learning rate: (1e-08)
2022-06-07 00:11:16,169 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 70 |  Loss: (0.0034) | Acc: (99.87%) (4538/4544) | Learning rate: (1e-08)
2022-06-07 00:11:17,968 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 80 |  Loss: (0.0032) | Acc: (99.88%) (5178/5184) | Learning rate: (1e-08)
2022-06-07 00:11:19,766 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 90 |  Loss: (0.0030) | Acc: (99.90%) (5818/5824) | Learning rate: (1e-08)
2022-06-07 00:11:21,563 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 100 |  Loss: (0.0029) | Acc: (99.91%) (6458/6464) | Learning rate: (1e-08)
2022-06-07 00:11:23,360 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 110 |  Loss: (0.0027) | Acc: (99.92%) (7098/7104) | Learning rate: (1e-08)
2022-06-07 00:11:25,158 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 120 |  Loss: (0.0031) | Acc: (99.88%) (7735/7744) | Learning rate: (1e-08)
2022-06-07 00:11:26,954 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 130 |  Loss: (0.0035) | Acc: (99.88%) (8374/8384) | Learning rate: (1e-08)
2022-06-07 00:11:28,752 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 140 |  Loss: (0.0036) | Acc: (99.88%) (9013/9024) | Learning rate: (1e-08)
2022-06-07 00:11:30,549 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 150 |  Loss: (0.0034) | Acc: (99.89%) (9653/9664) | Learning rate: (1e-08)
2022-06-07 00:11:32,347 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 160 |  Loss: (0.0034) | Acc: (99.87%) (10291/10304) | Learning rate: (1e-08)
2022-06-07 00:11:34,147 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 170 |  Loss: (0.0033) | Acc: (99.88%) (10931/10944) | Learning rate: (1e-08)
2022-06-07 00:11:35,946 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 180 |  Loss: (0.0033) | Acc: (99.88%) (11570/11584) | Learning rate: (1e-08)
2022-06-07 00:11:37,746 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 190 |  Loss: (0.0035) | Acc: (99.87%) (12208/12224) | Learning rate: (1e-08)
2022-06-07 00:11:39,545 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 200 |  Loss: (0.0035) | Acc: (99.87%) (12847/12864) | Learning rate: (1e-08)
2022-06-07 00:11:41,344 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 210 |  Loss: (0.0034) | Acc: (99.87%) (13487/13504) | Learning rate: (1e-08)
2022-06-07 00:11:43,144 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 220 |  Loss: (0.0033) | Acc: (99.88%) (14127/14144) | Learning rate: (1e-08)
2022-06-07 00:11:44,942 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 230 |  Loss: (0.0032) | Acc: (99.89%) (14767/14784) | Learning rate: (1e-08)
2022-06-07 00:11:46,741 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 240 |  Loss: (0.0032) | Acc: (99.89%) (15407/15424) | Learning rate: (1e-08)
2022-06-07 00:11:48,539 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 250 |  Loss: (0.0036) | Acc: (99.88%) (16045/16064) | Learning rate: (1e-08)
2022-06-07 00:11:50,339 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 260 |  Loss: (0.0036) | Acc: (99.88%) (16684/16704) | Learning rate: (1e-08)
2022-06-07 00:11:52,139 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 270 |  Loss: (0.0035) | Acc: (99.88%) (17324/17344) | Learning rate: (1e-08)
2022-06-07 00:11:53,937 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 280 |  Loss: (0.0034) | Acc: (99.89%) (17964/17984) | Learning rate: (1e-08)
2022-06-07 00:11:55,734 - CIFAR10 Classifier - INFO - Epoch: 53 | Batch_idx: 290 |  Loss: (0.0035) | Acc: (99.89%) (18603/18624) | Learning rate: (1e-08)
2022-06-07 00:12:09,343 - CIFAR10 Classifier - INFO - # TEST : Loss: (0.0815) | Acc: (98.04%) (9804/10000)
2022-06-07 00:12:09,344 - CIFAR10 Classifier - INFO - Epoch time : 0:01:06
2022-06-07 00:12:10,254 - CIFAR10 Classifier - INFO - Epoch: 54 | Batch_idx: 0 |  Loss: (0.0007) | Acc: (100.00%) (64/64) | Learning rate: (0.0)
2022-06-07 00:12:12,046 - CIFAR10 Classifier - INFO - Epoch: 54 | Batch_idx: 10 |  Loss: (0.0050) | Acc: (99.86%) (703/704) | Learning rate: (0.0)
